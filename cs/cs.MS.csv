,title,abstract
0,Real Options for Project Schedules (ROPS),"  Real Options for Project Schedules (ROPS) has three recursive
sampling/optimization shells. An outer Adaptive Simulated Annealing (ASA)
optimization shell optimizes parameters of strategic Plans containing multiple
Projects containing ordered Tasks. A middle shell samples probability
distributions of durations of Tasks. An inner shell samples probability
distributions of costs of Tasks. PATHTREE is used to develop options on
schedules.. Algorithms used for Trading in Risk Dimensions (TRD) are applied to
develop a relative risk analysis among projects.
"
1,"Algorithm for Evaluation of the Interval Power Function of Unconstrained
  Arguments","  We describe an algorithm for evaluation of the interval extension of the
power function of variables x and y given by the expression x^y. Our algorithm
reduces the general case to the case of non-negative bases.
"
2,Optimal Cache-Oblivious Mesh Layouts,"  A mesh is a graph that divides physical space into regularly-shaped regions.
Meshes computations form the basis of many applications, e.g. finite-element
methods, image rendering, and collision detection. In one important mesh
primitive, called a mesh update, each mesh vertex stores a value and repeatedly
updates this value based on the values stored in all neighboring vertices. The
performance of a mesh update depends on the layout of the mesh in memory.
  This paper shows how to find a memory layout that guarantees that the mesh
update has asymptotically optimal memory performance for any set of memory
parameters. Such a memory layout is called cache-oblivious. Formally, for a
$d$-dimensional mesh $G$, block size $B$, and cache size $M$ (where
$M=\Omega(B^d)$), the mesh update of $G$ uses $O(1+|G|/B)$ memory transfers.
The paper also shows how the mesh-update performance degrades for smaller
caches, where $M=o(B^d)$.
  The paper then gives two algorithms for finding cache-oblivious mesh layouts.
The first layout algorithm runs in time $O(|G|\log^2|G|)$ both in expectation
and with high probability on a RAM. It uses $O(1+|G|\log^2(|G|/M)/B)$ memory
transfers in expectation and $O(1+(|G|/B)(\log^2(|G|/M) + \log|G|))$ memory
transfers with high probability in the cache-oblivious and disk-access machine
(DAM) models. The layout is obtained by finding a fully balanced decomposition
tree of $G$ and then performing an in-order traversal of the leaves of the
tree. The second algorithm runs faster by almost a $\log|G|/\log\log|G|$ factor
in all three memory models, both in expectation and with high probability. The
layout obtained by finding a relax-balanced decomposition tree of $G$ and then
performing an in-order traversal of the leaves of the tree.
"
3,"Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in
  hypre and PETSc","  We describe our software package Block Locally Optimal Preconditioned
Eigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as
a stand-alone serial library, as an external package to PETSc (``Portable,
Extensible Toolkit for Scientific Computation'', a general purpose suite of
tools for the scalable solution of partial differential equations and related
problems developed by Argonne National Laboratory), and is also built into {\it
hypre} (``High Performance Preconditioners'', scalable linear solvers package
developed by Lawrence Livermore National Laboratory). The present BLOPEX
release includes only one solver--the Locally Optimal Block Preconditioned
Conjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\it
hypre} provides users with advanced high-quality parallel preconditioners for
linear systems, in particular, with domain decomposition and multigrid
preconditioners. With BLOPEX, the same preconditioners can now be efficiently
used for symmetric eigenvalue problems. PETSc facilitates the integration of
independently developed application modules with strict attention to component
interoperability, and makes BLOPEX extremely easy to compile and use with
preconditioners that are available via PETSc. We present the LOBPCG algorithm
in BLOPEX for {\it hypre} and PETSc. We demonstrate numerically the scalability
of BLOPEX by testing it on a number of distributed and shared memory parallel
systems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron
workstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition
and {\it hypre} multigrid preconditioning. We test BLOPEX on a model problem,
the standard 7-point finite-difference approximation of the 3-D Laplacian, with
the problem size in the range $10^5-10^8$.
"
4,Computing Integer Powers in Floating-Point Arithmetic,"  We introduce two algorithms for accurately evaluating powers to a positive
integer in floating-point arithmetic, assuming a fused multiply-add (fma)
instruction is available. We show that our log-time algorithm always produce
faithfully-rounded results, discuss the possibility of getting correctly
rounded results, and show that results correctly rounded in double precision
can be obtained if extended-precision is available with the possibility to
round into double precision (with a single rounding).
"
5,"Clustering and Feature Selection using Sparse Principal Component
  Analysis","  In this paper, we study the application of sparse principal component
analysis (PCA) to clustering and feature selection problems. Sparse PCA seeks
sparse factors, or linear combinations of the data variables, explaining a
maximum amount of variance in the data while having only a limited number of
nonzero coefficients. PCA is often used as a simple clustering technique and
sparse factors allow us here to interpret the clusters in terms of a reduced
set of variables. We begin with a brief introduction and motivation on sparse
PCA and detail our implementation of the algorithm in d'Aspremont et al.
(2005). We then apply these results to some classic clustering and feature
selection problems arising in biology.
"
6,"Fast computing of velocity field for flows in industrial burners and
  pumps","  In this work we present a technique of fast numerical computation for
solutions of Navier-Stokes equations in the case of flows of industrial
interest. At first the partial differential equations are translated into a set
of nonlinear ordinary differential equations using the geometrical shape of the
domain where the flow is developing, then these ODEs are numerically resolved
using a set of computations distributed among the available processors. We
present some results from simulations on a parallel hardware architecture using
native multithreads software and simulating a shared-memory or a
distributed-memory environment.
"
7,Numerical Calculation With Arbitrary Precision,"  The vast use of computers on scientific numerical computation makes the
awareness of the limited precision that these machines are able to provide us
an essential matter. A limited and insufficient precision allied to the
truncation and rounding errors may induce the user to incorrect interpretation
of his/hers answer. In this work, we have developed a computational package to
minimize this kind of error by offering arbitrary precision numbers and
calculation. This is very important in Physics where we can work with numbers
too small and too big simultaneously.
"
8,"Memory efficient scheduling of Strassen-Winograd's matrix multiplication
  algorithm","  We propose several new schedules for Strassen-Winograd's matrix
multiplication algorithm, they reduce the extra memory allocation requirements
by three different means: by introducing a few pre-additions, by overwriting
the input matrices, or by using a first recursive level of classical
multiplication. In particular, we show two fully in-place schedules: one having
the same number of operations, if the input matrices can be overwritten; the
other one, slightly increasing the constant of the leading term of the
complexity, if the input matrices are read-only. Many of these schedules have
been found by an implementation of an exhaustive search algorithm based on a
pebble game.
"
9,"Comments on the Reliability of Lawson and Hanson's Linear Distance
  Programming Algorithm: Subroutine LDP","  This brief paper: (1) Discusses strategies to generate random test cases that
can be used to extensively test any Linear Distance Program (LDP) software. (2)
Gives three numerical examples of input cases generated by this strategy that
cause problems in the Lawson and Hanson LDP module. (3) Proposes, as a standard
matter of acceptable implementation procedures, that (unless it is done
internally in the software itself, but, in general, this seems to be much rarer
than one would expect) all users should test the returned output from any LDP
module for self-consistency since it incurs only a small amount of added
computational overhead and it is not hard to do.
"
10,Difference Equations in Massive Higher Order Calculations,"  The calculation of massive 2--loop operator matrix elements, required for the
higher order Wilson coefficients for heavy flavor production in deeply
inelastic scattering, leads to new types of multiple infinite sums over
harmonic sums and related functions, which depend on the Mellin parameter $N$.
We report on the solution of these sums through higher order difference
equations using the summation package {\tt Sigma}.
"
11,Verified Real Number Calculations: A Library for Interval Arithmetic,"  Real number calculations on elementary functions are remarkably difficult to
handle in mechanical proofs. In this paper, we show how these calculations can
be performed within a theorem prover or proof assistant in a convenient and
highly automated as well as interactive way. First, we formally establish upper
and lower bounds for elementary functions. Then, based on these bounds, we
develop a rational interval arithmetic where real number calculations take
place in an algebraic setting. In order to reduce the dependency effect of
interval arithmetic, we integrate two techniques: interval splitting and taylor
series expansions. This pragmatic approach has been developed, and formally
verified, in a theorem prover. The formal development also includes a set of
customizable strategies to automate proofs involving explicit calculations over
real numbers. Our ultimate goal is to provide guaranteed proofs of numerical
properties with minimal human theorem-prover interaction.
"
12,Formally Verified Argument Reduction with a Fused-Multiply-Add,"  Cody & Waite argument reduction technique works perfectly for reasonably
large arguments but as the input grows there are no bit left to approximate the
constant with enough accuracy. Under mild assumptions, we show that the result
computed with a fused-multiply-add provides a fully accurate result for many
possible values of the input with a constant almost accurate to the full
working precision. We also present an algorithm for a fully accurate second
reduction step to reach double full accuracy (all the significand bits of two
numbers are significant) even in the worst cases of argument reduction. Our
work recalls the common algorithms and presents proofs of correctness. All the
proofs are formally verified using the Coq automatic proof checker.
"
13,"A Class of Parallel Tiled Linear Algebra Algorithms for Multicore
  Architectures","  As multicore systems continue to gain ground in the High Performance
Computing world, linear algebra algorithms have to be reformulated or new
algorithms have to be developed in order to take advantage of the architectural
features on these new processors. Fine grain parallelism becomes a major
requirement and introduces the necessity of loose synchronization in the
parallel execution of an operation. This paper presents an algorithm for the
Cholesky, LU and QR factorization where the operations can be represented as a
sequence of small tasks that operate on square blocks of data. These tasks can
be dynamically scheduled for execution based on the dependencies among them and
on the availability of computational resources. This may result in an out of
order execution of the tasks which will completely hide the presence of
intrinsically sequential tasks in the factorization. Performance comparisons
are presented with the LAPACK algorithms where parallelism can only be
exploited at the level of the BLAS operations and vendor implementations.
"
14,"Building the Tangent and Adjoint codes of the Ocean General Circulation
  Model OPA with the Automatic Differentiation tool TAPENADE","  The ocean general circulation model OPA is developed by the LODYC team at
Paris VI university. OPA has recently undergone a major rewriting, migrating to
FORTRAN95, and its adjoint code needs to be rebuilt. For earlier versions, the
adjoint of OPA was written by hand at a high development cost. We use the
Automatic Differentiation tool TAPENADE to build mechanicaly the tangent and
adjoint codes of OPA. We validate the differentiated codes by comparison with
divided differences, and also with an identical twin experiment. We apply
state-of-the-art methods to improve the performance of the adjoint code. In
particular we implement the Griewank and Walther's binomial checkpointing
algorithm which gives us an optimal trade-off between time and memory
consumption. We apply a specific strategy to differentiate the iterative linear
solver that comes from the implicit time stepping scheme
"
15,TRUST-TECH based Methods for Optimization and Learning,"  Many problems that arise in machine learning domain deal with nonlinearity
and quite often demand users to obtain global optimal solutions rather than
local optimal ones. Optimization problems are inherent in machine learning
algorithms and hence many methods in machine learning were inherited from the
optimization literature. Popularly known as the initialization problem, the
ideal set of parameters required will significantly depend on the given
initialization values. The recently developed TRUST-TECH (TRansformation Under
STability-reTaining Equilibria CHaracterization) methodology systematically
explores the subspace of the parameters to obtain a complete set of local
optimal solutions. In this thesis work, we propose TRUST-TECH based methods for
solving several optimization and machine learning problems. Two stages namely,
the local stage and the neighborhood-search stage, are repeated alternatively
in the solution space to achieve improvements in the quality of the solutions.
Our methods were tested on both synthetic and real datasets and the advantages
of using this novel framework are clearly manifested. This framework not only
reduces the sensitivity to initialization, but also allows the flexibility for
the practitioners to use various global and local methods that work well for a
particular problem of interest. Other hierarchical stochastic algorithms like
evolutionary algorithms and smoothing algorithms are also studied and
frameworks for combining these methods with TRUST-TECH have been proposed and
evaluated on several test systems.
"
16,Certifying floating-point implementations using Gappa,"  High confidence in floating-point programs requires proving numerical
properties of final and intermediate values. One may need to guarantee that a
value stays within some range, or that the error relative to some ideal value
is well bounded. Such work may require several lines of proof for each line of
code, and will usually be broken by the smallest change to the code (e.g. for
maintenance or optimization purpose). Certifying these programs by hand is
therefore very tedious and error-prone. This article discusses the use of the
Gappa proof assistant in this context. Gappa has two main advantages over
previous approaches: Its input format is very close to the actual C code to
validate, and it automates error evaluation and propagation using interval
arithmetic. Besides, it can be used to incrementally prove complex mathematical
properties pertaining to the C code. Yet it does not require any specific
knowledge about automatic theorem proving, and thus is accessible to a wide
community. Moreover, Gappa may generate a formal proof of the results that can
be checked independently by a lower-level proof assistant like Coq, hence
providing an even higher confidence in the certification of the numerical code.
The article demonstrates the use of this tool on a real-size example, an
elementary function with correctly rounded output.
"
17,Generic and Typical Ranks of Three-Way Arrays,"  The concept of tensor rank, introduced in the twenties, has been popularized
at the beginning of the seventies. This has allowed to carry out Factor
Analysis on arrays with more than two indices. The generic rank may be seen as
an upper bound to the number of factors that can be extracted from a given
tensor. We explain in this short paper how to obtain numerically the generic
rank of tensors of arbitrary dimensions, and compare it with the rare algebraic
results already known at order three. In particular, we examine the cases of
symmetric tensors, tensors with symmetric matrix slices, or tensors with free
entries.
"
18,Optimizing polynomials for floating-point implementation,"  The floating-point implementation of a function on an interval often reduces
to polynomial approximation, the polynomial being typically provided by Remez
algorithm. However, the floating-point evaluation of a Remez polynomial
sometimes leads to catastrophic cancellations. This happens when some of the
polynomial coefficients are very small in magnitude with respects to others. In
this case, it is better to force these coefficients to zero, which also reduces
the operation count. This technique, classically used for odd or even
functions, may be generalized to a much larger class of functions. An algorithm
is presented that forces to zero the smaller coefficients of the initial
polynomial thanks to a modified Remez algorithm targeting an incomplete
monomial basis. One advantage of this technique is that it is purely numerical,
the function being used as a numerical black box. This algorithm is implemented
within a larger polynomial implementation tool that is demonstrated on a range
of examples, resulting in polynomials with less coefficients than those
obtained the usual way.
"
19,"A Method for Solving Cyclic Block Penta-diagonal Systems of Linear
  Equations","  A method for solving cyclic block three-diagonal systems of equations is
generalized for solving a block cyclic penta-diagonal system of equations.
Introducing a special form of two new variables the original system is split
into three block pentagonal systems, which can be solved by the known methods.
As such method belongs to class of direct methods without pivoting.
Implementation of the algorithm is discussed in some details and the numerical
examples are present.
"
20,"GraphStream: A Tool for bridging the gap between Complex Systems and
  Dynamic Graphs","  The notion of complex systems is common to many domains, from Biology to
Economy, Computer Science, Physics, etc. Often, these systems are made of sets
of entities moving in an evolving environment. One of their major
characteristics is the emergence of some global properties stemmed from local
interactions between the entities themselves and between the entities and the
environment. The structure of these systems as sets of interacting entities
leads researchers to model them as graphs. However, their understanding
requires most often to consider the dynamics of their evolution. It is indeed
not relevant to study some properties out of any temporal consideration. Thus,
dynamic graphs seem to be a very suitable model for investigating the emergence
and the conservation of some properties. GraphStream is a Java-based library
whose main purpose is to help researchers and developers in their daily tasks
of dynamic problem modeling and of classical graph management tasks: creation,
processing, display, etc. It may also be used, and is indeed already used, for
teaching purpose. GraphStream relies on an event-based engine allowing several
event sources. Events may be included in the core of the application, read from
a file or received from an event handler.
"
21,"Conformal Computing: Algebraically connecting the hardware/software
  boundary using a uniform approach to high-performance computation for
  software and hardware applications","  We present a systematic, algebraically based, design methodology for
efficient implementation of computer programs optimized over multiple levels of
the processor/memory and network hierarchy. Using a common formalism to
describe the problem and the partitioning of data over processors and memory
levels allows one to mathematically prove the efficiency and correctness of a
given algorithm as measured in terms of a set of metrics (such as
processor/network speeds, etc.). The approach allows the average programmer to
achieve high-level optimizations similar to those used by compiler writers
(e.g. the notion of ""tiling"").
  The approach presented in this monograph makes use of A Mathematics of Arrays
(MoA, Mullin 1988) and an indexing calculus (i.e. the psi-calculus) to enable
the programmer to develop algorithms using high-level compiler-like
optimizations through the ability to algebraically compose and reduce sequences
of array operations. Extensive discussion and benchmark results are presented
for the Fast Fourier Transform and other important algorithms.
"
22,The QWalk Simulator of Quantum Walks,"  Several research groups are giving special attention to quantum walks
recently, because this research area have been used with success in the
development of new efficient quantum algorithms. A general simulator of quantum
walks is very important for the development of this area, since it allows the
researchers to focus on the mathematical and physical aspects of the research
instead of deviating the efforts to the implementation of specific numerical
simulations. In this paper we present QWalk, a quantum walk simulator for one-
and two-dimensional lattices. Finite two-dimensional lattices with generic
topologies can be used. Decoherence can be simulated by performing measurements
or by breaking links of the lattice. We use examples to explain the usage of
the software and to show some recent results of the literature that are easily
reproduced by the simulator.
"
23,Differentiation of Kaltofen's division-free determinant algorithm,"  Kaltofen has proposed a new approach in [Kaltofen 1992] for computing matrix
determinants. The algorithm is based on a baby steps/giant steps construction
of Krylov subspaces, and computes the determinant as the constant term of a
characteristic polynomial. For matrices over an abstract field and by the
results of Baur and Strassen 1983, the determinant algorithm, actually a
straight-line program, leads to an algorithm with the same complexity for
computing the adjoint of a matrix [Kaltofen 1992]. However, the latter is
obtained by the reverse mode of automatic differentiation and somehow is not
``explicit''. We study this adjoint algorithm, show how it can be implemented
(without resorting to an automatic transformation), and demonstrate its use on
polynomial matrices.
"
24,Certified Exact Transcendental Real Number Computation in Coq,"  Reasoning about real number expressions in a proof assistant is challenging.
Several problems in theorem proving can be solved by using exact real number
computation. I have implemented a library for reasoning and computing with
complete metric spaces in the Coq proof assistant and used this library to
build a constructive real number implementation including elementary real
number functions and proofs of correctness. Using this library, I have created
a tactic that automatically proves strict inequalities over closed elementary
real number expressions by computation.
"
25,Algorithmic Based Fault Tolerance Applied to High Performance Computing,"  We present a new approach to fault tolerance for High Performance Computing
system. Our approach is based on a careful adaptation of the Algorithmic Based
Fault Tolerance technique (Huang and Abraham, 1984) to the need of parallel
distributed computation. We obtain a strongly scalable mechanism for fault
tolerance. We can also detect and correct errors (bit-flip) on the fly of a
computation. To assess the viability of our approach, we have developed a fault
tolerant matrix-matrix multiplication subroutine and we propose some models to
predict its running time. Our parallel fault-tolerant matrix-matrix
multiplication scores 1.4 TFLOPS on 484 processors (cluster jacquard.nersc.gov)
and returns a correct result while one process failure has happened. This
represents 65% of the machine peak efficiency and less than 12% overhead with
respect to the fastest failure-free implementation. We predict (and have
observed) that, as we increase the processor count, the overhead of the fault
tolerance drops significantly.
"
26,"Revisiting the upper bounding process in a safe Branch and Bound
  algorithm","  Finding feasible points for which the proof succeeds is a critical issue in
safe Branch and Bound algorithms which handle continuous problems. In this
paper, we introduce a new strategy to compute very accurate approximations of
feasible points. This strategy takes advantage of the Newton method for
under-constrained systems of equations and inequalities. More precisely, it
exploits the optimal solution of a linear relaxation of the problem to compute
efficiently a promising upper bound. First experiments on the Coconuts
benchmarks demonstrate that this approach is very effective.
"
27,Executable Set Theory and Arithmetic Encodings in Prolog,"  The paper is organized as a self-contained literate Prolog program that
implements elements of an executable finite set theory with focus on
combinatorial generation and arithmetic encodings. The complete Prolog code is
available at http://logic.csci.unt.edu/tarau/research/2008/pHFS.zip . First,
ranking and unranking functions for some ""mathematically elegant"" data types in
the universe of Hereditarily Finite Sets with Urelements are provided,
resulting in arithmetic encodings for powersets, hypergraphs, ordinals and
choice functions. After implementing a digraph representation of Hereditarily
Finite Sets we define {\em decoration functions} that can recover well-founded
sets from encodings of their associated acyclic digraphs. We conclude with an
encoding of arbitrary digraphs and discuss a concept of duality induced by the
set membership relation. In the process, we uncover the surprising possibility
of internally sharing isomorphic objects, independently of their language level
types and meanings.
"
28,Ranking and Unranking of Hereditarily Finite Functions and Permutations,"  Prolog's ability to return multiple answers on backtracking provides an
elegant mechanism to derive reversible encodings of combinatorial objects as
Natural Numbers i.e. {\em ranking} and {\em unranking} functions. Starting from
a generalization of Ackerman's encoding of Hereditarily Finite Sets with
Urelements and a novel tupling/untupling operation, we derive encodings for
Finite Functions and use them as building blocks for an executable theory of
{\em Hereditarily Finite Functions}. The more difficult problem of {\em
ranking} and {\em unranking} {\em Hereditarily Finite Permutations} is then
tackled using Lehmer codes and factoradics.
  The paper is organized as a self-contained literate Prolog program available
at \url{http://logic.csci.unt.edu/tarau/research/2008/pHFF.zip}
"
29,"A Functional Hitchhiker's Guide to Hereditarily Finite Sets, Ackermann
  Encodings and Pairing Functions","  The paper is organized as a self-contained literate Haskell program that
implements elements of an executable finite set theory with focus on
combinatorial generation and arithmetic encodings. The code, tested under GHC
6.6.1, is available at http://logic.csci.unt.edu/tarau/research/2008/fSET.zip .
  We introduce ranking and unranking functions generalizing Ackermann's
encoding to the universe of Hereditarily Finite Sets with Urelements. Then we
build a lazy enumerator for Hereditarily Finite Sets with Urelements that
matches the unranking function provided by the inverse of Ackermann's encoding
and we describe functors between them resulting in arithmetic encodings for
powersets, hypergraphs, ordinals and choice functions. After implementing a
digraph representation of Hereditarily Finite Sets we define {\em decoration
functions} that can recover well-founded sets from encodings of their
associated acyclic digraphs. We conclude with an encoding of arbitrary digraphs
and discuss a concept of duality induced by the set membership relation.
  Keywords: hereditarily finite sets, ranking and unranking functions,
executable set theory, arithmetic encodings, Haskell data representations,
functional programming and computational mathematics
"
30,Accelerating Scientific Computations with Mixed Precision Algorithms,"  On modern architectures, the performance of 32-bit operations is often at
least twice as fast as the performance of 64-bit operations. By using a
combination of 32-bit and 64-bit floating point arithmetic, the performance of
many dense and sparse linear algebra algorithms can be significantly enhanced
while maintaining the 64-bit accuracy of the resulting solution. The approach
presented here can apply not only to conventional processors but also to other
technologies such as Field Programmable Gate Arrays (FPGA), Graphical
Processing Units (GPU), and the STI Cell BE processor. Results on modern
processor architectures and the STI Cell BE are presented.
"
31,Interpolation of Shifted-Lacunary Polynomials,"  Given a ""black box"" function to evaluate an unknown rational polynomial f in
Q[x] at points modulo a prime p, we exhibit algorithms to compute the
representation of the polynomial in the sparsest shifted power basis. That is,
we determine the sparsity t, the shift s (a rational), the exponents 0 <= e1 <
e2 < ... < et, and the coefficients c1,...,ct in Q\{0} such that f(x) =
c1(x-s)^e1+c2(x-s)^e2+...+ct(x-s)^et. The computed sparsity t is absolutely
minimal over any shifted power basis. The novelty of our algorithm is that the
complexity is polynomial in the (sparse) representation size, and in particular
is logarithmic in deg(f). Our method combines previous celebrated results on
sparse interpolation and computing sparsest shifts, and provides a way to
handle polynomials with extremely high degree which are, in some sense, sparse
in information.
"
32,Parallel GPU Implementation of Iterative PCA Algorithms,"  Principal component analysis (PCA) is a key statistical technique for
multivariate data analysis. For large data sets the common approach to PCA
computation is based on the standard NIPALS-PCA algorithm, which unfortunately
suffers from loss of orthogonality, and therefore its applicability is usually
limited to the estimation of the first few components. Here we present an
algorithm based on Gram-Schmidt orthogonalization (called GS-PCA), which
eliminates this shortcoming of NIPALS-PCA. Also, we discuss the GPU (Graphics
Processing Unit) parallel implementation of both NIPALS-PCA and GS-PCA
algorithms. The numerical results show that the GPU parallel optimized
versions, based on CUBLAS (NVIDIA) are substantially faster (up to 12 times)
than the CPU optimized versions based on CBLAS (GNU Scientific Library).
"
33,Efficient Multiplication of Dense Matrices over GF(2),"  We describe an efficient implementation of a hierarchy of algorithms for
multiplication of dense matrices over the field with two elements (GF(2)). In
particular we present our implementation -- in the M4RI library -- of
Strassen-Winograd matrix multiplication and the ""Method of the Four Russians""
multiplication (M4RM) and compare it against other available implementations.
Good performance is demonstrated on on AMD's Opteron and particulary good
performance on Intel's Core 2 Duo. The open-source M4RI library is available
stand-alone as well as part of the Sage mathematics software.
  In machine terms, addition in GF(2) is logical-XOR, and multiplication is
logical-AND, thus a machine word of 64-bits allows one to operate on 64
elements of GF(2) in parallel: at most one CPU cycle for 64 parallel additions
or multiplications. As such, element-wise operations over GF(2) are relatively
cheap. In fact, in this paper, we conclude that the actual bottlenecks are
memory reads and writes and issues of data locality. We present our empirical
findings in relation to minimizing these and give an analysis thereof.
"
34,"Geometric scaling: a simple preconditioner for certain linear systems
  with discontinuous coefficients","  Linear systems with large differences between coefficients (""discontinuous
coefficients"") arise in many cases in which partial differential
equations(PDEs) model physical phenomena involving heterogeneous media. The
standard approach to solving such problems is to use domain decomposition
techniques, with domain boundaries conforming to the boundaries between the
different media. This approach can be difficult to implement when the geometry
of the domain boundaries is complicated or the grid is unstructured. This work
examines the simple preconditioning technique of scaling the equations by
dividing each equation by the Lp-norm of its coefficients. This preconditioning
is called geometric scaling (GS). It has long been known that diagonal scaling
can be useful in improving convergence, but there is no study on the general
usefulness of this approach for discontinuous coefficients. GS was tested on
several nonsymmetric linear systems with discontinuous coefficients derived
from convection-diffusion elliptic PDEs with small to moderate convection
terms. It is shown that GS improved the convergence properties of restarted
GMRES and Bi-CGSTAB, with and without the ILUT preconditioner. GS was also
shown to improve the distribution of the eigenvalues by reducing their
concentration around the origin very significantly.
"
35,Bitslicing and the Method of Four Russians Over Larger Finite Fields,"  We present a method of computing with matrices over very small finite fields
of size larger than 2. Specifically, we show how the Method of Four Russians
can be efficiently adapted to these larger fields, and introduce a row-wise
matrix compression scheme that both reduces memory requirements and allows one
to vectorize element operations. We also present timings which confirm the
efficiency of these methods and exceed the speed of the fastest implementations
the authors are aware of.
"
36,"Rectangular Full Packed Format for Cholesky's Algorithm: Factorization,
  Solution and Inversion","  We describe a new data format for storing triangular, symmetric, and
Hermitian matrices called RFPF (Rectangular Full Packed Format). The standard
two dimensional arrays of Fortran and C (also known as full format) that are
used to represent triangular and symmetric matrices waste nearly half of the
storage space but provide high performance via the use of Level 3 BLAS.
Standard packed format arrays fully utilize storage (array space) but provide
low performance as there is no Level 3 packed BLAS. We combine the good
features of packed and full storage using RFPF to obtain high performance via
using Level 3 BLAS as RFPF is a standard full format representation. Also, RFPF
requires exactly the same minimal storage as packed format. Each LAPACK full
and/or packed triangular, symmetric, and Hermitian routine becomes a single new
RFPF routine based on eight possible data layouts of RFPF. This new RFPF
routine usually consists of two calls to the corresponding LAPACK full format
routine and two calls to Level 3 BLAS routines. This means {\it no} new
software is required. As examples, we present LAPACK routines for Cholesky
factorization, Cholesky solution and Cholesky inverse computation in RFPF to
illustrate this new work and to describe its performance on several commonly
used computer platforms. Performance of LAPACK full routines using RFPF versus
LAPACK full routines using standard format for both serial and SMP parallel
processing is about the same while using half the storage. Performance gains
are roughly one to a factor of 43 for serial and one to a factor of 97 for SMP
parallel times faster using vendor LAPACK full routines with RFPF than with
using vendor and/or reference packed routines.
"
37,A Density Matrix-based Algorithm for Solving Eigenvalue Problems,"  A new numerical algorithm for solving the symmetric eigenvalue problem is
presented. The technique deviates fundamentally from the traditional Krylov
subspace iteration based techniques (Arnoldi and Lanczos algorithms) or other
Davidson-Jacobi techniques, and takes its inspiration from the contour
integration and density matrix representation in quantum mechanics. It will be
shown that this new algorithm - named FEAST - exhibits high efficiency,
robustness, accuracy and scalability on parallel architectures. Examples from
electronic structure calculations of Carbon nanotubes (CNT) are presented, and
numerical performances and capabilities are discussed.
"
38,On the bit-complexity of sparse polynomial multiplication,"  In this paper, we present fast algorithms for the product of two multivariate
polynomials in sparse representation. The bit complexity of our algorithms are
studied in detail for various types of coefficients, and we derive new
complexity results for the power series multiplication in many variables. Our
algorithms are implemented and freely available within the Mathemagix software.
We show that their theoretical costs are well-reflected in practice.
"
39,"ALLSAT compressed with wildcards: All, or all maximum independent sets","  An odd cycle cover is a vertex set whose removal makes a graph bipartite. We
show that if a $k$-element odd cycle cover of a graph with w vertices is known
then all $N$ maximum anticliques (= independent sets) can be generated in time
$O(2^k w^3 + N w^2))$. Generating ${\it all}\ N'$ anticliques (maximum or not)
is easier and works for arbitrary graphs in time $O(N'w^2)$. In fact the use of
wildcards allows to compactly generate the anticliques in clusters.
"
40,Fast solving of Weighted Pairing Least-Squares systems,"  This paper presents a generalization of the ""weighted least-squares"" (WLS),
named ""weighted pairing least-squares"" (WPLS), which uses a rectangular weight
matrix and is suitable for data alignment problems. Two fast solving methods,
suitable for solving full rank systems as well as rank deficient systems, are
studied. Computational experiments clearly show that the best method, in terms
of speed, accuracy, and numerical stability, is based on a special {1, 2,
3}-inverse, whose computation reduces to a very simple generalization of the
usual ""Cholesky factorization-backward substitution"" method for solving linear
systems.
"
41,"Automatic generation of non-uniform random variates for arbitrary
  pointwise computable probability densities by tiling","  We present a rejection method based on recursive covering of the probability
density function with equal tiles. The concept works for any probability
density function that is pointwise computable or representable by tabular data.
By the implicit construction of piecewise constant majorizing and minorizing
functions that are arbitrarily close to the density function the production of
random variates is arbitrarily independent of the computation of the density
function and extremely fast. The method works unattended for probability
densities with discontinuities (jumps and poles). The setup time is short,
marginally independent of the shape of the probability density and linear in
table size. Recently formulated requirements to a general and automatic
non-uniform random number generator are topped. We give benchmarks together
with a similar rejection method and with a transformation method.
"
42,"Random numbers from the tails of probability distributions using the
  transformation method","  The speed of many one-line transformation methods for the production of, for
example, Levy alpha-stable random numbers, which generalize Gaussian ones, and
Mittag-Leffler random numbers, which generalize exponential ones, is very high
and satisfactory for most purposes. However, for the class of decreasing
probability densities fast rejection implementations like the Ziggurat by
Marsaglia and Tsang promise a significant speed-up if it is possible to
complement them with a method that samples the tails of the infinite support.
This requires the fast generation of random numbers greater or smaller than a
certain value. We present a method to achieve this, and also to generate random
numbers within any arbitrary interval. We demonstrate the method showing the
properties of the transform maps of the above mentioned distributions as
examples of stable and geometric stable random numbers used for the stochastic
solution of the space-time fractional diffusion equation.
"
43,"A Fast Multigrid Algorithm for Energy Minimization Under Planar Density
  Constraints","  The two-dimensional layout optimization problem reinforced by the efficient
space utilization demand has a wide spectrum of practical applications.
Formulating the problem as a nonlinear minimization problem under planar
equality and/or inequality density constraints, we present a linear time
multigrid algorithm for solving correction to this problem. The method is
demonstrated on various graph drawing (visualization) instances.
"
44,The generating of Fractal Images Using MathCAD Program,"  This paper presents the graphic representation in the z-plane of the first
three iterations of the algorithm that generates the Sierpinski Gasket. It
analyzes the influence of the f(z) map when we represent fractal images.
"
45,FISLAB - the Fuzzy Inference Tool-box for SCILAB,"  The present study represents ""The Fislab package of programs meant to develop
the fuzzy regulators in the Scilab environment"" in which we present some
general issues, usage requirements and the working mode of the Fislab
environment. In the second part of the article some features of the Scilab
functions from the Fislab package are described.
"
46,"The development of a fuzzy regulator with an entry and an output in
  Fislab","  The present article is a sequel of the article ""Fislab the Fuzzy Inference
Tool-Box for Scilab"" and it represents the practical application of:""The
development of the Fuzzy regulator with an input and an output in Fislab"". The
article contains, besides this application, some functions to be used in the
program, namely Scilab functions for the fuzzification of the firm information,
functions for the operation of de-fuzzification and functions for the
implementation of.
"
47,"HONEI: A collection of libraries for numerical computations targeting
  multiple processor architectures","  We present HONEI, an open-source collection of libraries offering a hardware
oriented approach to numerical calculations. HONEI abstracts the hardware, and
applications written on top of HONEI can be executed on a wide range of
computer architectures such as CPUs, GPUs and the Cell processor. We
demonstrate the flexibility and performance of our approach with two test
applications, a Finite Element multigrid solver for the Poisson problem and a
robust and fast simulation of shallow water waves. By linking against HONEI's
libraries, we achieve a twofold speedup over straight forward C++ code using
HONEI's SSE backend, and additional 3-4 and 4-16 times faster execution on the
Cell and a GPU. A second important aspect of our approach is that the full
performance capabilities of the hardware under consideration can be exploited
by adding optimised application-specific operations to the HONEI libraries.
HONEI provides all necessary infrastructure for development and evaluation of
such kernels, significantly simplifying their development.
"
48,"WinBioinfTools: Bioinformatics Tools for Windows High Performance
  Computing Server 2008","  Open source bioinformatics tools running under MS Windows are rare to find,
and those running under Windows HPC cluster are almost non-existing. This is
despite the fact that the Windows is the most popular operating system used
among life scientists. Therefore, we introduce in this initiative
WinBioinfTools, a toolkit containing a number of bioinformatics tools running
under Windows High Performance Computing Server 2008. It is an open source code
package, where users and developers can share and add to. We currently start
with three programs from the area of sequence analysis: 1) CoCoNUT for pairwise
genome comparison, 2) parallel BLAST for biological database search, and 3)
parallel global pairwise sequence alignment. In this report, we focus on
technical aspects concerning how some components of these tools were ported
from Linux/Unix environment to run under Windows. We also show the advantages
of using the Windows HPC Cluster 2008. We demonstrate by experiments the
performance gain achieved when using a computer cluster against a single
machine. Furthermore, we show the results of comparing the performance of
WinBioinfTools on the Windows and Linux Cluster.
"
49,"Limits of Educational Soft ""GeoGebra"" in a Critical Constructive Review","  Mathematical educational soft explore, investigating in a dynamical way, some
algebraically, geometrically problems, the expected results being used to
involve a lot of mathematical results. One such software soft is GeoGebra. The
software is free and multi-platform dynamic mathematics software for learning
and teaching, awards in Europe and the USA. This paper describes some critical
but constructive investigation using the platform for graph functions and
dynamic geometry.
"
50,Iterative Methods for Systems' Solving - a C# approach,"  This work wishes to support various mathematical issues concerning the
iterative methods with the help of new programming languages. We consider a way
to show how problems in math have an answer by using different academic
resources and different thoughts. Here we treat methods like Gauss-Seidel's,
Cramer's and Gauss-Jordan's.
"
51,The alternative operad is not Koszul,"  Using computer calculations, we prove the statement in the title.
"
52,"Real Solution Isolation with Multiplicity of Zero-Dimensional Triangular
  Systems","  Existing algorithms for isolating real solutions of zero-dimensional
polynomial systems do not compute the multiplicities of the solutions. In this
paper, we define in a natural way the multiplicity of solutions of
zero-dimensional triangular polynomial systems and prove that our definition is
equivalent to the classical definition of local (intersection) multiplicity.
Then we present an effective and complete algorithm for isolating real
solutions with multiplicities of zero-dimensional triangular polynomial systems
using our definition. The algorithm is based on interval arithmetic and
square-free factorization of polynomials with real algebraic coefficients. The
computational results on some examples from the literature are presented.
"
53,On computing the Hermite form of a matrix of differential polynomials,"  Given an n x n matrix over the ring of differential polynomials
F(t)[\D;\delta], we show how to compute the Hermite form H of A, and a
unimodular matrix U such that UA=H. The algorithm requires a polynomial number
of operations in terms of n, deg_D(A), and deg_t(A). When F is the field of
rational numbers, it also requires time polynomial in the bit-length of the
coefficients.
"
54,Asymmetric Quantum Cyclic Codes,"  It is recently conjectured in quantum information processing that phase-shift
errors occur with high probability than qubit-flip errors, hence the former is
more disturbing to quantum information than the later one. This leads us to
construct asymmetric quantum error controlling codes to protect quantum
information over asymmetric channels, $\Pr Z \geq \Pr X$. In this paper we
present two generic methods to derive asymmetric quantum cyclic codes using the
generator polynomials and defining sets of classical cyclic codes.
Consequently, the methods allow us to construct several families of asymmetric
quantum BCH, RS, and RM codes. Finally, the methods are used to construct
families of asymmetric subsystem codes.
"
55,"A generalized inner and outer product of arbitrary multi-dimensional
  arrays using A Mathematics of Arrays (MoA)","  An algorithm has been devised to compute the inner and outer product between
two arbitrary multi-dimensional arrays A and B in a single piece of code. It
was derived using A Mathematics of Arrays (MoA) and the $\psi$-calculus.
Extensive tests of the new algorithm are presented for running in sequential as
well as OpenMP multiple processor modes.
"
56,"Tensors and n-d Arrays:A Mathematics of Arrays (MoA), psi-Calculus and
  the Composition of Tensor and Array Operations","  The Kronecker product is a key algorithm and is ubiquitous across the
physical, biological, and computation social sciences. Thus considerations of
optimal implementation are important. The need to have high performance and
computational reproducibility is paramount. Moreover, due to the need to
compose multiple Kronecker products, issues related to data structures, layout
and indexing algebra require a new look at an old problem. This paper discusses
the outer product/tensor product and a special case of the tensor product: the
Kronecker product, along with optimal implementation when composed, and mapped
to complex processor/memory hierarchies. We discuss how the use of ``A
Mathematics of Arrays"" (MoA), and the psi-Calculus, (a calculus of indexing
with shapes), provides optimal, verifiable, reproducible, scalable, and
portable implementations of both hardware and software.
"
57,The Multiple Zeta Value Data Mine,"  We provide a data mine of proven results for multiple zeta values (MZVs) of
the form $\zeta(s_1,s_2,...,s_k)=\sum_{n_1>n_2>...>n_k>0}^\infty \{1/(n_1^{s_1}
>... n_k^{s_k})\}$ with weight $w=\sum_{i=1}^k s_i$ and depth $k$ and for Euler
sums of the form $\sum_{n_1>n_2>...>n_k>0}^\infty t\{(\epsilon_1^{n_1}
>...\epsilon_1 ^{n_k})/ (n_1^{s_1} ... n_k^{s_k}) \}$ with signs
$\epsilon_i=\pm1$. Notably, we achieve explicit proven reductions of all MZVs
with weights $w\le22$, and all Euler sums with weights $w\le12$, to bases whose
dimensions, bigraded by weight and depth, have sizes in precise agreement with
the Broadhurst--Kreimer and Broadhurst conjectures. Moreover, we lend further
support to these conjectures by studying even greater weights ($w\le30$), using
modular arithmetic. To obtain these results we derive a new type of relation
for Euler sums, the Generalized Doubling Relations. We elucidate the ""pushdown""
mechanism, whereby the ornate enumeration of primitive MZVs, by weight and
depth, is reconciled with the far simpler enumeration of primitive Euler sums.
There is some evidence that this pushdown mechanism finds its origin in
doubling relations. We hope that our data mine, obtained by exploiting the
unique power of the computer algebra language {\sc form}, will enable the study
of many more such consequences of the double-shuffle algebra of MZVs, and their
Euler cousins, which are already the subject of keen interest, to practitioners
of quantum field theory, and to mathematicians alike.
"
58,Computational Understanding and Manipulation of Symmetries,"  For natural and artificial systems with some symmetry structure,
computational understanding and manipulation can be achieved without learning
by exploiting the algebraic structure. Here we describe this algebraic
coordinatization method and apply it to permutation puzzles. Coordinatization
yields a structural understanding, not just solutions for the puzzles.
"
59,Mesh Algorithms for PDE with Sieve I: Mesh Distribution,"  We have developed a new programming framework, called Sieve, to support
parallel numerical PDE algorithms operating over distributed meshes. We have
also developed a reference implementation of Sieve in C++ as a library of
generic algorithms operating on distributed containers conforming to the Sieve
interface. Sieve makes instances of the incidence relation, or \emph{arrows},
the conceptual first-class objects represented in the containers. Further,
generic algorithms acting on this arrow container are systematically used to
provide natural geometric operations on the topology and also, through duality,
on the data. Finally, coverings and duality are used to encode not only
individual meshes, but all types of hierarchies underlying PDE data structures,
including multigrid and mesh partitions.
  In order to demonstrate the usefulness of the framework, we show how the mesh
partition data can be represented and manipulated using the same fundamental
mechanisms used to represent meshes. We present the complete description of an
algorithm to encode a mesh partition and then distribute a mesh, which is
independent of the mesh dimension, element shape, or embedding. Moreover, data
associated with the mesh can be similarly distributed with exactly the same
algorithm. The use of a high level of abstraction within the Sieve leads to
several benefits in terms of code reuse, simplicity, and extensibility. We
discuss these benefits and compare our approach to other existing mesh
libraries.
"
60,"Optimally Tuned Iterative Reconstruction Algorithms for Compressed
  Sensing","  We conducted an extensive computational experiment, lasting multiple
CPU-years, to optimally select parameters for two important classes of
algorithms for finding sparse solutions of underdetermined systems of linear
equations. We make the optimally tuned implementations available at {\tt
sparselab.stanford.edu}; they run `out of the box' with no user tuning: it is
not necessary to select thresholds or know the likely degree of sparsity. Our
class of algorithms includes iterative hard and soft thresholding with or
without relaxation, as well as CoSaMP, subspace pursuit and some natural
extensions. As a result, our optimally tuned algorithms dominate such
proposals. Our notion of optimality is defined in terms of phase transitions,
i.e. we maximize the number of nonzeros at which the algorithm can successfully
operate. We show that the phase transition is a well-defined quantity with our
suite of random underdetermined linear systems. Our tuning gives the highest
transition possible within each class of algorithms.
"
61,Topology of 2D and 3D Rational Curves,"  In this paper we present algorithms for computing the topology of planar and
space rational curves defined by a parametrization. The algorithms given here
work directly with the parametrization of the curve, and do not require to
compute or use the implicit equation of the curve (in the case of planar
curves) or of any projection (in the case of space curves). Moreover, these
algorithms have been implemented in Maple; the examples considered and the
timings obtained show good performance skills.
"
62,"Approximating Mathematical Semantic Web Services Using Approximation
  Formulas and Numerical Methods","  Mathematical semantic web services are very useful in practice, but only a
small number of research results are reported in this area. In this paper we
present a method of obtaining an approximation of a mathematical semantic web
service, from its semantic description, using existing mathematical semantic
web services, approximation formulas, and numerical methods techniques. We also
give a method for automatic comparison of two complexity functions. In
addition, we present a method for classifying the numerical methods
mathematical semantic web services from a library.
"
63,"Implementing Gr\""obner bases for operads","  We present an implementation of the algorithm for computing Groebner bases
for operads due to the first author and A. Khoroshkin. We discuss the actual
algorithms, the choices made for the implementation platform and the data
representation, and strengths and weaknesses of our approach.
"
64,"On the Different Shapes Arising in a Family of Rational Curves Depending
  on a Parameter","  Given a family of rational curves depending on a real parameter, defined by
its parametric equations, we provide an algorithm to compute a finite partition
of the parameter space (${\Bbb R}$, in general) so that the shape of the family
stays invariant along each element of the partition. So, from this partition
the topology types in the family can be determined. The algorithm is based on a
geometric interpretation of previous work (\cite{JGRS}) for the implicit case.
However, in our case the algorithm works directly with the parametrization of
the family, and the implicit equation does not need to be computed. Timings
comparing the algorithm in the implicit and the parametric cases are given;
these timings show that the parametric algorithm developed here provides in
general better results than the known algorithm for the implicit case.
"
65,Local Shape of Generalized Offsets to Algebraic Curves,"  In this paper we study the local behavior of an algebraic curve under a
geometric construction which is a variation of the usual offsetting
construction, namely the {\it generalized} offsetting process (\cite {SS99}).
More precisely, here we discuss when and how this geometric construction may
cause local changes in the shape of an algebraic curve, and we compare our
results with those obtained for the case of classical offsets (\cite{JGS07}).
For these purposes, we use well-known notions of Differential Geometry, and
also the notion of {\it local shape} introduced in \cite{JGS07}.
"
66,"PetRBF--A parallel O(N) algorithm for radial basis function
  interpolation","  We have developed a parallel algorithm for radial basis function (RBF)
interpolation that exhibits O(N) complexity,requires O(N) storage, and scales
excellently up to a thousand processes. The algorithm uses a GMRES iterative
solver with a restricted additive Schwarz method (RASM) as a preconditioner and
a fast matrix-vector algorithm. Previous fast RBF methods, --,achieving at most
O(NlogN) complexity,--, were developed using multiquadric and polyharmonic
basis functions. In contrast, the present method uses Gaussians with a small
variance (a common choice in particle methods for fluid simulation, our main
target application). The fast decay of the Gaussian basis function allows rapid
convergence of the iterative solver even when the subdomains in the RASM are
very small. The present method was implemented in parallel using the PETSc
library (developer version). Numerical experiments demonstrate its capability
in problems of RBF interpolation with more than 50 million data points, timing
at 106 seconds (19 iterations for an error tolerance of 10^-15 on 1024
processors of a Blue Gene/L (700 MHz PowerPC processors). The parallel code is
freely available in the open-source model.
"
67,"Transmission line inspires a new distributed algorithm to solve linear
  system of circuit","  Transmission line, or wire, is always troublesome to integrated circuits
designers, but it could be helpful to parallel computing researchers. This
paper proposes the Virtual Transmission Method (VTM), which is a new
distributed and stationary iterative algorithm to solve the linear system
extracted from circuit. It tears the circuit by virtual transmission lines to
achieve distributed computing. For the symmetric positive definite (SPD) linear
system, VTM is proved to be convergent. For the unsymmetrical linear system,
numerical experiments show that VTM is possible to achieve better convergence
property than the traditional stationary algorithms. VTM could be accelerated
by some preconditioning techniques, and the convergence speed of VTM is fast
when its preconditioner is properly chosen.
"
68,"Parallel Computation of Finite Element Navier-Stokes codes using MUMPS
  Solver","  The study deals with the parallelization of 2D and 3D finite element based
Navier-Stokes codes using direct solvers. Development of sparse direct solvers
using multifrontal solvers has significantly reduced the computational time of
direct solution methods. Although limited by its stringent memory requirements,
multifrontal solvers can be computationally efficient. First the performance of
MUltifrontal Massively Parallel Solver (MUMPS) is evaluated for both 2D and 3D
codes in terms of memory requirements and CPU times. The scalability of both
Newton and modified Newton algorithms is tested.
"
69,A Branch and Cut Algorithm for the Halfspace Depth Problem,"  The concept of \emph{data depth} in non-parametric multivariate descriptive
statistics is the generalization of the univariate rank method to multivariate
data. \emph{Halfspace depth} is a measure of data depth. Given a set $S$ of
points and a point $p$, the halfspace depth (or rank) of $p$ is defined as the
minimum number of points of $S$ contained in any closed halfspace with $p$ on
its boundary. Computing halfspace depth is NP-hard, and it is equivalent to the
Maximum Feasible Subsystem problem. In this paper a mixed integer program is
formulated with the big-$M$ method for the halfspace depth problem. We suggest
a branch and cut algorithm for these integer programs. In this algorithm,
Chinneck's heuristic algorithm is used to find an upper bound and a related
technique based on sensitivity analysis is used for branching. Irreducible
Infeasible Subsystem (IIS) hitting set cuts are applied. We also suggest a
binary search algorithm which may be more numerically stable. The algorithms
are implemented with the BCP framework from the \textbf{COIN-OR} project.
"
70,Isogenies of Elliptic Curves: A Computational Approach,"  Isogenies, the mappings of elliptic curves, have become a useful tool in
cryptology. These mathematical objects have been proposed for use in computing
pairings, constructing hash functions and random number generators, and
analyzing the reducibility of the elliptic curve discrete logarithm problem.
With such diverse uses, understanding these objects is important for anyone
interested in the field of elliptic curve cryptography. This paper, targeted at
an audience with a knowledge of the basic theory of elliptic curves, provides
an introduction to the necessary theoretical background for understanding what
isogenies are and their basic properties. This theoretical background is used
to explain some of the basic computational tasks associated with isogenies.
Herein, algorithms for computing isogenies are collected and presented with
proofs of correctness and complexity analyses. As opposed to the complex
analytic approach provided in most texts on the subject, the proofs in this
paper are primarily algebraic in nature. This provides alternate explanations
that some with a more concrete or computational bias may find more clear.
"
71,Numerical Algebraic Geometry for Macaulay2,"  Numerical Algebraic Geometry uses numerical data to describe algebraic
varieties. It is based on the methods of numerical polynomial homotopy
continuation, an alternative to the classical symbolic approaches of
computational algebraic geometry. We present a package, the driving idea behind
which is to interlink the existing symbolic methods of Macaulay2 and the
powerful engine of numerical approximate computations. The core procedures of
the package exhibit performance competitive with the other homotopy
continuation software.
"
72,Global communications in multiprocessor simulations of flames,"  In this paper we investigate performance of global communications in a
particular parallel code. The code simulates dynamics of expansion of premixed
spherical flames using an asymptotic model of Sivashinsky type and a spectral
numerical algorithm. As a result, the code heavily relies on global all-to-all
interprocessor communications implementing transposition of the distributed
data array in which numerical solution to the problem is stored. This global
data interdependence makes interprocessor connectivity of the HPC system as
important as the floating-point power of the processors of which the system is
built. Our experiments show that efficient numerical simulation of this
particular model, with global data interdependence, on modern HPC systems is
possible. Prospects of performance of more sophisticated models of flame
dynamics are analysed as well.
"
73,"Community landscapes: an integrative approach to determine overlapping
  network module hierarchy, identify key nodes and predict network dynamics","  Background: Network communities help the functional organization and
evolution of complex networks. However, the development of a method, which is
both fast and accurate, provides modular overlaps and partitions of a
heterogeneous network, has proven to be rather difficult. Methodology/Principal
Findings: Here we introduce the novel concept of ModuLand, an integrative
method family determining overlapping network modules as hills of an influence
function-based, centrality-type community landscape, and including several
widely used modularization methods as special cases. As various adaptations of
the method family, we developed several algorithms, which provide an efficient
analysis of weighted and directed networks, and (1) determine pervasively
overlapping modules with high resolution; (2) uncover a detailed hierarchical
network structure allowing an efficient, zoom-in analysis of large networks;
(3) allow the determination of key network nodes and (4) help to predict
network dynamics. Conclusions/Significance: The concept opens a wide range of
possibilities to develop new approaches and applications including network
routing, classification, comparison and prediction.
"
74,"NetEvo: A computational framework for the evolution of dynamical complex
  networks","  NetEvo is a computational framework designed to help understand the evolution
of dynamical complex networks. It provides flexible tools for the simulation of
dynamical processes on networks and methods for the evolution of underlying
topological structures. The concept of a supervisor is used to bring together
both these aspects in a coherent way. It is the job of the supervisor to rewire
the network topology and alter model parameters such that a user specified
performance measure is minimised. This performance measure can make use of
current topological information and simulated dynamical output from the system.
Such an abstraction provides a suitable basis in which to study many
outstanding questions related to complex system design and evolution.
"
75,"JBotSim, a Tool for Fast Prototyping of Distributed Algorithms in
  Dynamic Networks","  JBotSim is a java library that offers basic primitives for prototyping,
running, and visualizing distributed algorithms in dynamic networks. With
JBotSim, one can implement an idea in minutes and interact with it ({\it e.g.
}, add, move, or delete nodes) while it is running. JBotSim is well suited to
prepare live demonstrations of your algorithms to colleagues or students; it
can also be used to evaluate performance at the algorithmic level (number of
messages, number of rounds, etc.). Unlike most tools, JBotSim is not an
integrated environment. It is a lightweight library to be used in your program.
In this paper, we present an overview of its distinctive features and
architecture.
"
76,"Algorithmic Differentiation of Linear Algebra Functions with Application
  in Optimum Experimental Design (Extended Version)","  We derive algorithms for higher order derivative computation of the
rectangular $QR$ and eigenvalue decomposition of symmetric matrices with
distinct eigenvalues in the forward and reverse mode of algorithmic
differentiation (AD) using univariate Taylor propagation of matrices (UTPM).
Linear algebra functions are regarded as elementary functions and not as
algorithms. The presented algorithms are implemented in the BSD licensed AD
tool \texttt{ALGOPY}. Numerical tests show that the UTPM algorithms derived in
this paper produce results close to machine precision accuracy. The theory
developed in this paper is applied to compute the gradient of an objective
function motivated from optimum experimental design: $\nabla_x
\Phi(C(J(F(x,y))))$, where $\Phi = \{\lambda_1 : \lambda_1 C\}$, $C = (J^T
J)^{-1}$, $J = \frac{\dd F}{\dd y}$ and $F = F(x,y)$.
"
77,"Using Premia and Nsp for Constructing a Risk Management Benchmark for
  Testing Parallel Architecture","  Financial institutions have massive computations to carry out overnight which
are very demanding in terms of the consumed CPU. The challenge is to price many
different products on a cluster-like architecture. We have used the Premia
software to valuate the financial derivatives. In this work, we explain how
Premia can be embedded into Nsp, a scientific software like Matlab, to provide
a powerful tool to valuate a whole portfolio. Finally, we have integrated an
MPI toolbox into Nsp to enable to use Premia to solve a bunch of pricing
problems on a cluster. This unified framework can then be used to test
different parallel architectures.
"
78,"An in-place truncated Fourier transform and applications to polynomial
  multiplication","  The truncated Fourier transform (TFT) was introduced by van der Hoeven in
2004 as a means of smoothing the ""jumps"" in running time of the ordinary FFT
algorithm that occur at power-of-two input sizes. However, the TFT still
introduces these jumps in memory usage. We describe in-place variants of the
forward and inverse TFT algorithms, achieving time complexity O(n log n) with
only O(1) auxiliary space. As an application, we extend the second author's
results on space-restricted FFT-based polynomial multiplication to polynomials
of arbitrary degree.
"
79,The Power of Vocabulary: The Case of Cyclotomic Polynomials,"  We observe that the vocabulary used to construct the ""answer"" to problems in
computer algebra can have a dramatic effect on the computational complexity of
solving that problem. We recall a formalization of this observation and explain
the classic example of sparse polynomial arithmetic. For this case, we show
that it is possible to extend the vocabulary so as reap the benefits of
conciseness whilst avoiding the obvious pitfall of repeating the problem
statement as the ""solution"".
  It is possible to extend the vocabulary either by irreducible cyclotomics or
by $x^n-1$: we look at the options and suggest that the pragmatist might opt
for both.
"
80,Fast Arithmetics in Artin-Schreier Towers over Finite Fields,"  An Artin-Schreier tower over the finite field F_p is a tower of field
extensions generated by polynomials of the form X^p - X - a. Following Cantor
and Couveignes, we give algorithms with quasi-linear time complexity for
arithmetic operations in such towers. As an application, we present an
implementation of Couveignes' algorithm for computing isogenies between
elliptic curves using the p-torsion.
"
81,Assessment Of The Wind Farm Impact On The Radar,"  This study shows the means to evaluate the wind farm impact on the radar. It
proposes the set of tools, which can be used to realise this objective. The big
part of report covers the study of complex pattern propagation factor as the
critical issue of the Advanced Propagation Model (APM). Finally, the reader can
find here the implementation of this algorithm - the real scenario in Inverness
airport (the United Kingdom), where the ATC radar STAR 2000, developed by
Thales Air Systems, operates in the presence of several wind farms. Basically,
the project is based on terms of the department ""Strategy Technology &
Innovation"", where it has been done. Also you can find here how the radar
industry can act with the problem engendered by wind farms. The current
strategies in this area are presented, such as a wind turbine production,
improvements of air traffic handling procedures and the collaboration between
developers of radars and wind turbines. The possible strategy for Thales as a
main pioneer was given as well.
"
82,Factorization of Non-Commutative Polynomials,"  We describe an algorithm for the factorization of non-commutative polynomials
over a field. The first sketch of this algorithm appeared in an unpublished
manuscript (literally hand written notes) by James H. Davenport more than 20
years ago. This version of the algorithm contains some improvements with
respect to the original sketch. An improved version of the algorithm has been
fully implemented in the Axiom computer algebra system.
"
83,"Towards an Efficient Tile Matrix Inversion of Symmetric Positive
  Definite Matrices on Multicore Architectures","  The algorithms in the current sequential numerical linear algebra libraries
(e.g. LAPACK) do not parallelize well on multicore architectures. A new family
of algorithms, the tile algorithms, has recently been introduced. Previous
research has shown that it is possible to write efficient and scalable tile
algorithms for performing a Cholesky factorization, a (pseudo) LU
factorization, and a QR factorization. In this extended abstract, we attack the
problem of the computation of the inverse of a symmetric positive definite
matrix. We observe that, using a dynamic task scheduler, it is relatively
painless to translate existing LAPACK code to obtain a ready-to-be-executed
tile algorithm. However we demonstrate that non trivial compiler techniques
(array renaming, loop reversal and pipelining) need then to be applied to
further increase the parallelism of our application. We present preliminary
experimental results.
"
84,Complementary approaches to understanding the plant circadian clock,"  Circadian clocks are oscillatory genetic networks that help organisms adapt
to the 24-hour day/night cycle. The clock of the green alga Ostreococcus tauri
is the simplest plant clock discovered so far. Its many advantages as an
experimental system facilitate the testing of computational predictions.
  We present a model of the Ostreococcus clock in the stochastic process
algebra Bio-PEPA and exploit its mapping to different analysis techniques, such
as ordinary differential equations, stochastic simulation algorithms and
model-checking. The small number of molecules reported for this system tests
the limits of the continuous approximation underlying differential equations.
We investigate the difference between continuous-deterministic and
discrete-stochastic approaches. Stochastic simulation and model-checking allow
us to formulate new hypotheses on the system behaviour, such as the presence of
self-sustained oscillations in single cells under constant light conditions.
  We investigate how to model the timing of dawn and dusk in the context of
model-checking, which we use to compute how the probability distributions of
key biochemical species change over time. These show that the relative
variation in expression level is smallest at the time of peak expression,
making peak time an optimal experimental phase marker. Building on these
analyses, we use approaches from evolutionary systems biology to investigate
how changes in the rate of mRNA degradation impacts the phase of a key protein
likely to affect fitness. We explore how robust this circadian clock is towards
such potential mutational changes in its underlying biochemistry. Our work
shows that multiple approaches lead to a more complete understanding of the
clock.
"
85,"Transferring a symbolic polynomial expression from \emph{Mathematica} to
  \emph{Matlab}","  A \emph{Mathematica} Notebook is presented which allows for the transfer or
any kind of polynomial expression to \emph{Matlab}. The output is formatted in
such a way that \emph{Matlab} routines such as ""Root"" can be readily
implemented. Once the Notebook has been executed, only one copy-paste operation
in necessary.
"
86,Triangular Decomposition of Semi-algebraic Systems,"  Regular chains and triangular decompositions are fundamental and
well-developed tools for describing the complex solutions of polynomial
systems. This paper proposes adaptations of these tools focusing on solutions
of the real analogue: semi-algebraic systems. We show that any such system can
be decomposed into finitely many {\em regular semi-algebraic systems}. We
propose two specifications of such a decomposition and present corresponding
algorithms. Under some assumptions, one type of decomposition can be computed
in singly exponential time w.r.t.\ the number of variables. We implement our
algorithms and the experimental results illustrate their effectiveness.
"
87,Having Fun with Lambert W(x) Function,"  This short note presents the Lambert W(x) function and its possible
application in the framework of physics related to the Pierre Auger
Observatory. The actual numerical implementation in C++ consists of Halley's
and Fritsch's iteration with branch-point expansion, asymptotic series and
rational fits as initial approximations.
"
88,A Highly Efficient Parallel Algorithm for Computing the Fiedler Vector,"  This paper has been withdrawn by the author.
"
89,"Efficient Construction, Update and Downdate Of The Coefficients Of
  Interpolants Based On Polynomials Satisfying A Three-Term Recurrence Relation","  In this paper, we consider methods to compute the coefficients of
interpolants relative to a basis of polynomials satisfying a three-term
recurrence relation. Two new algorithms are presented: the first constructs the
coefficients of the interpolation incrementally and can be used to update the
coefficients whenever a nodes is added to or removed from the interpolation.
The second algorithm, which constructs the interpolation coefficients by
decomposing the Vandermonde-like matrix iteratively, can not be used to update
or downdate an interpolation, yet is more numerically stable than the first
algorithm and is more efficient when the coefficients of multiple
interpolations are to be computed over the same set of nodes.
"
90,A Review of Error Estimation in Adaptive Quadrature,"  The most critical component of any adaptive numerical quadrature routine is
the estimation of the integration error. Since the publication of the first
algorithms in the 1960s, many error estimation schemes have been presented,
evaluated and discussed. This paper presents a review of existing error
estimation techniques and discusses their differences and their common
features. Some common shortcomings of these algorithms are discussed and a new
general error estimation technique is presented.
"
91,"wiki.openmath.org - how it works, how you can participate","  At http://wiki.openmath.org, the OpenMath 2 and 3 Content Dictionaries are
accessible via a semantic wiki interface, powered by the SWiM system. We
shortly introduce the inner workings of the system, then describe how to use
it, and conclude with first experiences gained from OpenMath society members
working with the system and an outlook to further development plans.
"
92,SWiM -- A Semantic Wiki for Mathematical Knowledge Management,"  SWiM is a semantic wiki for collaboratively building, editing and browsing
mathematical knowledge represented in the domain-specific structural semantic
markup language OMDoc. It motivates users to contribute to collections of
mathematical knowledge by instantly sharing the benefits of knowledge-powered
services with them. SWiM is currently being used for authoring content
dictionaries, i. e. collections of uniquely identified mathematical symbols,
and prepared for managing a large-scale proof formalisation effort.
"
93,Computational Complexity of Iterated Maps on the Interval,"  The correct computation of orbits of discrete dynamical systems on the
interval is considered. Therefore, an arbitrary-precision floating-point
approach based on automatic error analysis is chosen and a general algorithm is
presented. The correctness of the algorithm is shown and the computational
complexity is analyzed. There are two main results. First, the computational
complexity measure considered here is related to the Lyapunov exponent of the
dynamical system under consideration. Second, the presented algorithm is
optimal with regard to that complexity measure.
"
94,MP users guide,"  MP is a package of ANSI Standard Fortran (ANS X3.9-1966) subroutines for
performing multiple-precision floating-point arithmetic and evaluating
elementary and special functions. The subroutines are machine independent and
the precision is arbitrary, subject to storage limitations. The User's Guide
describes the routines and their calling sequences, example and test programs,
use of the Augment precompiler, and gives installation instructions for the
package.
"
95,"Exact Sparse Matrix-Vector Multiplication on GPU's and Multicore
  Architectures","  We propose different implementations of the sparse matrix--dense vector
multiplication (\spmv{}) for finite fields and rings $\Zb/m\Zb$. We take
advantage of graphic card processors (GPU) and multi-core architectures. Our
aim is to improve the speed of \spmv{} in the \linbox library, and henceforth
the speed of its black box algorithms. Besides, we use this and a new
parallelization of the sigma-basis algorithm in a parallel block Wiedemann rank
implementation over finite fields.
"
96,Formal Proof of SCHUR Conjugate Function,"  The main goal of our work is to formally prove the correctness of the key
commands of the SCHUR software, an interactive program for calculating with
characters of Lie groups and symmetric functions. The core of the computations
relies on enumeration and manipulation of combinatorial structures. As a first
""proof of concept"", we present a formal proof of the conjugate function,
written in C. This function computes the conjugate of an integer partition. To
formally prove this program, we use the Frama-C software. It allows us to
annotate C functions and to generate proof obligations, which are proved using
several automated theorem provers. In this paper, we also draw on methodology,
discussing on how to formally prove this kind of program.
"
97,"Electronic Geometry Textbook: A Geometric Textbook Knowledge Management
  System","  Electronic Geometry Textbook is a knowledge management system that manages
geometric textbook knowledge to enable users to construct and share dynamic
geometry textbooks interactively and efficiently. Based on a knowledge base
organizing and storing the knowledge represented in specific languages, the
system implements interfaces for maintaining the data representing that
knowledge as well as relations among those data, for automatically generating
readable documents for viewing or printing, and for automatically discovering
the relations among knowledge data. An interface has been developed for users
to create geometry textbooks with automatic checking, in real time, of the
consistency of the structure of each resulting textbook. By integrating an
external geometric theorem prover and an external dynamic geometry software
package, the system offers the facilities for automatically proving theorems
and generating dynamic figures in the created textbooks. This paper provides a
comprehensive account of the current version of Electronic Geometry Textbook.
"
98,"The Formulator MathML Editor Project: User-Friendly Authoring of Content
  Markup Documents","  Implementation of an editing process for Content MathML formulas in common
visual style is a real challenge for a software developer who does not really
want the user to have to understand the structure of Content MathML in order to
edit an expression, since it is expected that users are often not that
technically minded. In this paper, we demonstrate how this aim is achieved in
the context of the Formulator project and discuss features of this MathML
editor, which provides a user with a WYSIWYG editing style while authoring
MathML documents with Content or mixed markup. We also present the approach
taken to enhance availability of the MathML editor to end-users, demonstrating
an online version of the editor that runs inside a Web browser.
"
99,"Universal algorithms, mathematics of semirings and parallel computations","  This is a survey paper on applications of mathematics of semirings to
numerical analysis and computing. Concepts of universal algorithm and generic
program are discussed. Relations between these concepts and mathematics of
semirings are examined. A very brief introduction to mathematics of semirings
(including idempotent and tropical mathematics) is presented. Concrete
applications to optimization problems, idempotent linear algebra and interval
analysis are indicated. It is known that some nonlinear problems (and
especially optimization problems) become linear over appropriate semirings with
idempotent addition (the so-called idempotent superposition principle). This
linearity over semirings is convenient for parallel computations.
"
100,The myth of equidistribution for high-dimensional simulation,"  A pseudo-random number generator (RNG) might be used to generate w-bit random
samples in d dimensions if the number of state bits is at least dw. Some RNGs
perform better than others and the concept of equidistribution has been
introduced in the literature in order to rank different RNGs. We define what it
means for a RNG to be (d,w)-equidistributed, and then argue that
(d,w)-equidistribution is not necessarily a desirable property.
"
101,Some comments on C. S. Wallace's random number generators,"  We outline some of Chris Wallace's contributions to pseudo-random number
generation. In particular, we consider his idea for generating normally
distributed variates without relying on a source of uniform random numbers, and
compare it with more conventional methods for generating normal random numbers.
Implementations of Wallace's idea can be very fast (approximately as fast as
good uniform generators). We discuss the statistical quality of the output, and
mention how certain pitfalls can be avoided.
"
102,SABRE: A Tool for Stochastic Analysis of Biochemical Reaction Networks,"  The importance of stochasticity within biological systems has been shown
repeatedly during the last years and has raised the need for efficient
stochastic tools. We present SABRE, a tool for stochastic analysis of
biochemical reaction networks. SABRE implements fast adaptive uniformization
(FAU), a direct numerical approximation algorithm for computing transient
solutions of biochemical reaction networks. Biochemical reactions networks
represent biological systems studied at a molecular level and these reactions
can be modeled as transitions of a Markov chain. SABRE accepts as input the
formalism of guarded commands, which it interprets either as continuous-time or
as discrete-time Markov chains. Besides operating in a stochastic mode, SABRE
may also perform a deterministic analysis by directly computing a mean-field
approximation of the system under study. We illustrate the different
functionalities of SABRE by means of biological case studies.
"
103,NZMATH 1.0,"  This is an announcement of the first official release ver.1.0 of a Python
system NZMATH for number theory. We overview all functions in NZMATH 1.0, show
main properties after former report on NZMATH 0.5.0, and describe new features
for stable development. The most important point of the release is that we can
now treat number fields. The second big change is that new type of polynomial
programs are provided. Elliptic curve primality proving and its related
programs are also available, where we partly use a library outside NZMATH as an
advantage of writing the system only by Python. On method of development, a new
feature is that NZMATH is registered on SourceForge as an open source project
to keep continuous development of the project. This is a unique attempt among
existing systems for number theory.
"
104,Groebner bases in Java with applications in computer graphics,"  In this paper we present a Java implementation of the algorithm that computes
Buchbereger's and reduced Groebner's basis step by step. The Java application
enables graphical representation of the intersection of two surfaces in
3-dimensional space and determines conditions of existence and planarity of the
intersection.
"
105,Random Numbers in Scientific Computing: An Introduction,"  Random numbers play a crucial role in science and industry. Many numerical
methods require the use of random numbers, in particular the Monte Carlo
method. Therefore it is of paramount importance to have efficient random number
generators. The differences, advantages and disadvantages of true and pseudo
random number generators are discussed with an emphasis on the intrinsic
details of modern and fast pseudo random number generators. Furthermore,
standard tests to verify the quality of the random numbers produced by a given
generator are outlined. Finally, standard scientific libraries with built-in
generators are presented, as well as different approaches to generate
nonuniform random numbers. Potential problems that one might encounter when
using large parallel machines are discussed.
"
106,An OpenMath Content Dictionary for Tensor Concepts,"  We introduce a new OpenMath content dictionary, named tensor1, containing
symbols for the expression of tensor formulas. These symbols support the
expression of non-Cartesian coordinates and invariant, multilinear expressions
in the context of coordinate transformations. While current OpenMath symbols
support the expression of linear algebra formulas using matrices and vectors,
we find that there is an underlying assumption of Cartesian, or standard,
coordinates that makes the expression of general tensor formulas difficult, if
not impossible. In introducing these new OpenMath symbols for the expression of
tensor formulas, we attempt to maintain, as much as possible, consistency with
prior OpenMath symbol definitions for linear algebra.
"
107,"Nonsingular Efficient Modeling of Rotations in 3-space using three
  components","  This article introduces yet another representation of rotations in 3-space.
The rotations form a 3-dimensional projective space, which fact has not been
exploited in Computer Science. We use the four affine patches of this
projective space to parametrize the rotations. This affine patch representation
is more compact than quaternions (which require 4 components for calculations),
encompasses the entire rotation group without singularities (unlike the Euler
angles and rotation vector approaches), and requires only ratios of linear or
quadratic polynomials for basic computations (unlike the Euler angles and
rotation vector approaches which require transcendental functions).
  As an example, we derive the differential equation for the integration of
angular velocity using this affine patch representation of rotations. We remark
that the complexity of this equation is the same as the corresponding
quaternion equation, but has advantages over the quaternion approach e.g.
renormalization to unit length is not required, and state space has no dead
directions.
"
108,Adapting Mathematical Domain Reasoners,"  Mathematical learning environments help students in mastering mathematical
knowledge. Mature environments typically offer thousands of interactive
exercises. Providing feedback to students solving interactive exercises
requires domain reasoners for doing the exercise-specific calculations. Since a
domain reasoner has to solve an exercise in the same way a student should solve
it, the structure of domain reasoners should follow the layered structure of
the mathematical domains. Furthermore, learners, teachers, and environment
builders have different requirements for adapting domain reasoners, such as
providing more details, disallowing or enforcing certain solutions, and
combining multiple mathematical domains in a new domain. In previous work we
have shown how domain reasoners for solving interactive exercises can be
expressed in terms of rewrite strategies, rewrite rules, and views. This paper
shows how users can adapt and configure such domain reasoners to their own
needs. This is achieved by enabling users to explicitly communicate the
components that are used for solving an exercise.
"
109,Variants of Mersenne Twister Suitable for Graphic Processors,"  This paper proposes a type of pseudorandom number generator, Mersenne Twister
for Graphic Processor (MTGP), for efficient generation on graphic processessing
units (GPUs). MTGP supports large state sizes such as 11213 bits, and uses the
high parallelism of GPUs in computing many steps of the recursion in parallel.
The second proposal is a parameter-set generator for MTGP, named MTGP Dynamic
Creator (MTGPDC). MT- GPDC creates up to 2^32 distinct parameter sets which
generate sequences with high-dimensional uniformity. This facility is suitable
for a large grid of GPUs where each GPU requires separate random number
streams. MTGP is based on linear recursion over the two-element field, and has
better high-dimensional equidistribution than the Mersenne Twister pseudorandom
number generator.
"
110,Making big steps in trajectories,"  We consider the solution of initial value problems within the context of
hybrid systems and emphasise the use of high precision approximations (in
software for exact real arithmetic). We propose a novel algorithm for the
computation of trajectories up to the area where discontinuous jumps appear,
applicable for holomorphic flow functions. Examples with a prototypical
implementation illustrate that the algorithm might provide results with higher
precision than well-known ODE solvers at a similar computation time.
"
111,"Computational Complexity of Iterated Maps on the Interval (Extended
  Abstract)","  The exact computation of orbits of discrete dynamical systems on the interval
is considered. Therefore, a multiple-precision floating point approach based on
error analysis is chosen and a general algorithm is presented. The correctness
of the algorithm is shown and the computational complexity is analyzed. As a
main result, the computational complexity measure considered here is related to
the Ljapunow exponent of the dynamical system under consideration.
"
112,LSMR: An iterative algorithm for sparse least-squares problems,"  An iterative method LSMR is presented for solving linear systems $Ax=b$ and
least-squares problem $\min \norm{Ax-b}_2$, with $A$ being sparse or a fast
linear operator. LSMR is based on the Golub-Kahan bidiagonalization process. It
is analytically equivalent to the MINRES method applied to the normal equation
$A\T Ax = A\T b$, so that the quantities $\norm{A\T r_k}$ are monotonically
decreasing (where $r_k = b - Ax_k$ is the residual for the current iterate
$x_k$). In practice we observe that $\norm{r_k}$ also decreases monotonically.
Compared to LSQR, for which only $\norm{r_k}$ is monotonic, it is safer to
terminate LSMR early. Improvements for the new iterative method in the presence
of extra available memory are also explored.
"
113,"Genbit Compress Tool(GBC): A Java-Based Tool to Compress DNA Sequences
  and Compute Compression Ratio(bits/base) of Genomes","  We present a Compression Tool, ""GenBit Compress"", for genetic sequences based
on our new proposed ""GenBit Compress Algorithm"". Our Tool achieves the best
compression ratios for Entire Genome (DNA sequences) . Significantly better
compression results show that GenBit compress algorithm is the best among the
remaining Genome compression algorithms for non-repetitive DNA sequences in
Genomes. The standard Compression algorithms such as gzip or compress cannot
compress DNA sequences but only expand them in size. In this paper we consider
the problem of DNA compression. It is well known that one of the main features
of DNA Sequences is that they contain substrings which are duplicated except
for a few random Mutations. For this reason most DNA compressors work by
searching and encoding approximate repeats. We depart from this strategy by
searching and encoding only exact repeats. our proposed algorithm achieves the
best compression ratio for DNA sequences for larger genome. As long as 8 lakh
characters can be given as input While achieving the best compression ratios
for DNA sequences, our new GenBit Compress program significantly improves the
running time of all previous DNA compressors. Assigning binary bits for
fragments of DNA sequence is also a unique concept introduced in this program
for the first time in DNA compression.
"
114,Efficient Decomposition of Dense Matrices over GF(2),"  In this work we describe an efficient implementation of a hierarchy of
algorithms for the decomposition of dense matrices over the field with two
elements (GF(2)). Matrix decomposition is an essential building block for
solving dense systems of linear and non-linear equations and thus much research
has been devoted to improve the asymptotic complexity of such algorithms. In
this work we discuss an implementation of both well-known and improved
algorithms in the M4RI library. The focus of our discussion is on a new variant
of the M4RI algorithm - denoted MMPF in this work -- which allows for
considerable performance gains in practice when compared to the previously
fastest implementation. We provide performance figures on x86_64 CPUs to
demonstrate the viability of our approach.
"
115,Highly Parallel Sparse Matrix-Matrix Multiplication,"  Generalized sparse matrix-matrix multiplication is a key primitive for many
high performance graph algorithms as well as some linear solvers such as
multigrid. We present the first parallel algorithms that achieve increasing
speedups for an unbounded number of processors. Our algorithms are based on
two-dimensional block distribution of sparse matrices where serial sections use
a novel hypersparse kernel for scalability. We give a state-of-the-art MPI
implementation of one of our algorithms. Our experiments show scaling up to
thousands of processors on a variety of test scenarios.
"
116,Towards OpenMath Content Dictionaries as Linked Data,"  ""The term 'Linked Data' refers to a set of best practices for publishing and
connecting structured data on the web"". Linked Data make the Semantic Web work
practically, which means that information can be retrieved without complicated
lookup mechanisms, that a lightweight semantics enables scalable reasoning, and
that the decentral nature of the Web is respected. OpenMath Content
Dictionaries (CDs) have the same characteristics - in principle, but not yet in
practice. The Linking Open Data movement has made a considerable practical
impact: Governments, broadcasting stations, scientific publishers, and many
more actors are already contributing to the ""Web of Data"". Queries can be
answered in a distributed way, and services aggregating data from different
sources are replacing hard-coded mashups. However, these services are currently
entirely lacking mathematical functionality. I will discuss real-world
scenarios, where today's RDF-based Linked Data do not quite get their job done,
but where an integration of OpenMath would help - were it not for certain
conceptual and practical restrictions. I will point out conceptual shortcomings
in the OpenMath 2 specification and common bad practices in publishing CDs and
then propose concrete steps to overcome them and to contribute OpenMath CDs to
the Web of Data.
"
117,Open Graphs and Computational Reasoning,"  We present a form of algebraic reasoning for computational objects which are
expressed as graphs. Edges describe the flow of data between primitive
operations which are represented by vertices. These graphs have an interface
made of half-edges (edges which are drawn with an unconnected end) and enjoy
rich compositional principles by connecting graphs along these half-edges. In
particular, this allows equations and rewrite rules to be specified between
graphs. Particular computational models can then be encoded as an axiomatic set
of such rules. Further rules can be derived graphically and rewriting can be
used to simulate the dynamics of a computational system, e.g. evaluating a
program on an input. Examples of models which can be formalised in this way
include traditional electronic circuits as well as recent categorical accounts
of quantum information.
"
118,A domain decomposing parallel sparse linear system solver,"  The solution of large sparse linear systems is often the most time-consuming
part of many science and engineering applications. Computational fluid
dynamics, circuit simulation, power network analysis, and material science are
just a few examples of the application areas in which large sparse linear
systems need to be solved effectively. In this paper we introduce a new
parallel hybrid sparse linear system solver for distributed memory
architectures that contains both direct and iterative components. We show that
by using our solver one can alleviate the drawbacks of direct and iterative
solvers, achieving better scalability than with direct solvers and more
robustness than with classical preconditioned iterative solvers. Comparisons to
well-known direct and iterative solvers on a parallel architecture are
provided.
"
119,Runtime-Flexible Multi-dimensional Arrays and Views for C++98 and C++0x,"  Multi-dimensional arrays are among the most fundamental and most useful data
structures of all. In C++, excellent template libraries exist for arrays whose
dimension is fixed at runtime. Arrays whose dimension can change at runtime
have been implemented in C. However, a generic object-oriented C++
implementation of runtime-flexible arrays has so far been missing. In this
article, we discuss our new implementation called Marray, a package of class
templates that fills this gap. Marray is based on views as an underlying
concept. This concept brings some of the flexibility known from script
languages such as R and MATLAB to C++. Marray is free both for commercial and
non-commercial use and is publicly available from www.andres.sc/marray
"
120,"Applying dissipative dynamical systems to pseudorandom number
  generation: Equidistribution property and statistical independence of bits at
  distances up to logarithm of mesh size","  The behavior of a family of dissipative dynamical systems representing
transformations of two-dimensional torus is studied on a discrete lattice and
compared with that of conservative hyperbolic automorphisms of the torus.
Applying dissipative dynamical systems to generation of pseudorandom numbers is
shown to be advantageous and equidistribution of probabilities for the
sequences of bits can be achieved. A new algorithm for generating uniform
pseudorandom numbers is proposed. The theory of the generator, which includes
proofs of periodic properties and of statistical independence of bits at
distances up to logarithm of mesh size, is presented. Extensive statistical
testing using available test packages demonstrates excellent results, while the
speed of the generator is comparable to other modern generators.
"
121,M-Learning: A New Paradigm of Learning Mathematics in Malaysia,"  M-Learning is a new learning paradigm of the new social structure with mobile
and wireless technologies.Smart school is one of the four flagship applications
for Multimedia Super Corridor (MSC) under Malaysian government initiative to
improve education standard in the country. With the advances of mobile devices
technologies, mobile learning could help the government in realizing the
initiative. This paper discusses the prospect of implementing mobile learning
for primary school students. It indicates significant and challenges and
analysis of user perceptions on potential mobile applications through a survey
done in primary school context. The authors propose the m-Learning for
mathematics by allowing the extension of technology in the traditional
classroom in term of learning and teaching.
"
122,"LinBox founding scope allocation, parallel building blocks, and separate
  compilation","  To maximize efficiency in time and space, allocations and deallocations, in
the exact linear algebra library \linbox, must always occur in the founding
scope. This provides a simple lightweight allocation model. We present this
model and its usage for the rebinding of matrices between different coefficient
domains. We also present automatic tools to speed-up the compilation of
template libraries and a software abstraction layer for the introduction of
transparent parallelism at the algorithmic level.
"
123,"How to obtain efficient GPU kernels: an illustration using FMM & FGT
  algorithms","  Computing on graphics processors is maybe one of the most important
developments in computational science to happen in decades. Not since the
arrival of the Beowulf cluster, which combined open source software with
commodity hardware to truly democratize high-performance computing, has the
community been so electrified. Like then, the opportunity comes with
challenges. The formulation of scientific algorithms to take advantage of the
performance offered by the new architecture requires rethinking core methods.
Here, we have tackled fast summation algorithms (fast multipole method and fast
Gauss transform), and applied algorithmic redesign for attaining performance on
gpus. The progression of performance improvements attained illustrates the
exercise of formulating algorithms for the massively parallel architecture of
the gpu. The end result has been gpu kernels that run at over 500 Gigaflops on
one nvidia Tesla C1060 card, thereby reaching close to practical peak. We can
confidently say that gpu computing is not just a vogue, it is truly an
irresistible trend in high-performance computing.
"
124,"Parameterized Adaptive Multidimensional Integration Routines (PAMIR):
  Localization by Repeated 2^p Subdivision","  This book draft gives the theory of a new method for p dimensional adaptive
integration by repeated 2^p subdivision of simplexes and hypercubes. A new
method of constructing high order integration routines for these geometries
permits adjustable samplings of the integration region controlled by user
supplied parameters. An outline of the programs and use instructions are also
included in the draft. The fortran programs are not included, but will be
published with this draft as a book.
"
125,"An Elimination Method for Solving Bivariate Polynomial Systems:
  Eliminating the Usual Drawbacks","  We present an exact and complete algorithm to isolate the real solutions of a
zero-dimensional bivariate polynomial system. The proposed algorithm
constitutes an elimination method which improves upon existing approaches in a
number of points. First, the amount of purely symbolic operations is
significantly reduced, that is, only resultant computation and square-free
factorization is still needed. Second, our algorithm neither assumes generic
position of the input system nor demands for any change of the coordinate
system. The latter is due to a novel inclusion predicate to certify that a
certain region is isolating for a solution. Our implementation exploits
graphics hardware to expedite the resultant computation. Furthermore, we
integrate a number of filtering techniques to improve the overall performance.
Efficiency of the proposed method is proven by a comparison of our
implementation with two state-of-the-art implementations, that is, LPG and
Maple's isolate. For a series of challenging benchmark instances, experiments
show that our implementation outperforms both contestants.
"
126,"A Hybrid Parallelization of AIM for Multi-Core Clusters: Implementation
  Details and Benchmark Results on Ranger","  This paper presents implementation details and empirical results for a hybrid
message passing and shared memory paralleliziation of the adaptive integral
method (AIM). AIM is implemented on a (near) petaflop supercomputing cluster of
quad-core processors and its accuracy, complexity, and scalability are
investigated by solving benchmark scattering problems. The timing and speedup
results on up to 1024 processors show that the hybrid MPI/OpenMP
parallelization of AIM exhibits better strong scalability (fixed problem size
speedup) than pure MPI parallelization of it when multiple cores are used on
each processor.
"
127,alphaCertified: certifying solutions to polynomial systems,"  Smale's alpha-theory uses estimates related to the convergence of Newton's
method to give criteria implying that Newton iterations will converge
quadratically to solutions to a square polynomial system. The program
alphaCertified implements algorithms based on alpha-theory to certify solutions
to polynomial systems using both exact rational arithmetic and arbitrary
precision floating point arithmetic. It also implements an algorithm to certify
whether a given point corresponds to a real solution to a real polynomial
system, as well as algorithms to heuristically validate solutions to
overdetermined systems. Examples are presented to demonstrate the algorithms.
"
128,"Minimizing Communication for Eigenproblems and the Singular Value
  Decomposition","  Algorithms have two costs: arithmetic and communication. The latter
represents the cost of moving data, either between levels of a memory
hierarchy, or between processors over a network. Communication often dominates
arithmetic and represents a rapidly increasing proportion of the total cost, so
we seek algorithms that minimize communication. In \cite{BDHS10} lower bounds
were presented on the amount of communication required for essentially all
$O(n^3)$-like algorithms for linear algebra, including eigenvalue problems and
the SVD. Conventional algorithms, including those currently implemented in
(Sca)LAPACK, perform asymptotically more communication than these lower bounds
require. In this paper we present parallel and sequential eigenvalue algorithms
(for pencils, nonsymmetric matrices, and symmetric matrices) and SVD algorithms
that do attain these lower bounds, and analyze their convergence and
communication costs.
"
129,Domain Decomposition method on GPU cluster,"  Pallalel GPGPU computing for lattice QCD simulations has a bottleneck on the
GPU to GPU data communication due to the lack of the direct data exchanging
facility. In this work we investigate the performance of quark solver using the
restricted additive Schwarz (RAS) preconditioner on a low cost GPU cluster. We
expect that the RAS preconditioner with appropriate domaindecomposition and
task distribution reduces the communication bottleneck. The GPU cluster we
constructed is composed of four PC boxes, two GPU cards are attached to each
box, and we have eight GPU cards in total. The compute nodes are connected with
rather slow but low cost Gigabit-Ethernet. We include the RAS preconditioner in
the single-precision part of the mixedprecision nested-BiCGStab algorithm and
the single-precision task is distributed to the multiple GPUs. The benchmarking
is done with the O(a)-improved Wilson quark on a randomly generated gauge
configuration with the size of $32^4$. We observe a factor two improvment on
the solver performance with the RAS precoditioner compared to that without the
preconditioner and find that the improvment mainly comes from the reduction of
the communication bottleneck as we expected.
"
130,Fast Multiplication of Matrices with Decay,"  A fast algorithm for the approximate multiplication of matrices with decay is
introduced; the Sparse Approximate Matrix Multiply (SpAMM) reduces complexity
in the product space, a different approach from current methods that economize
within the matrix space through truncation or rank reduction. Matrix truncation
(element dropping) is compared to SpAMM for quantum chemical matrices with
approximate exponential and algebraic decay. For matched errors in the
electronic total energy, SpAMM is found to require fewer to far fewer floating
point operations relative to dropping. The challenges and opportunities
afforded by this new approach are discussed, including the potential for high
performance implementations.
"
131,"A Symbolic Transformation Language and its Application to a Multiscale
  Method","  The context of this work is the design of a software, called MEMSALab,
dedicated to the automatic derivation of multiscale models of arrays of micro-
and nanosystems. In this domain a model is a partial differential equation.
Multiscale methods approximate it by another partial differential equation
which can be numerically simulated in a reasonable time. The challenge consists
in taking into account a wide range of geometries combining thin and periodic
structures with the possibility of multiple nested scales.
  In this paper we present a transformation language that will make the
development of MEMSALab more feasible. It is proposed as a Maple package for
rule-based programming, rewriting strategies and their combination with
standard Maple code. We illustrate the practical interest of this language by
using it to encode two examples of multiscale derivations, namely the two-scale
limit of the derivative operator and the two-scale model of the stationary heat
equation.
"
132,Diversification improves interpolation,"  We consider the problem of interpolating an unknown multivariate polynomial
with coefficients taken from a finite field or as numerical approximations of
complex numbers. Building on the recent work of Garg and Schost, we improve on
the best-known algorithm for interpolation over large finite fields by
presenting a Las Vegas randomized algorithm that uses fewer black box
evaluations. Using related techniques, we also address numerical interpolation
of sparse polynomials with complex coefficients, and provide the first provably
stable algorithm (in the sense of relative error) for this problem, at the cost
of modestly more evaluations. A key new technique is a randomization which
makes all coefficients of the unknown polynomial distinguishable, producing
what we call a diverse polynomial. Another departure from most previous
approaches is that our algorithms do not rely on root finding as a subroutine.
We show how these improvements affect the practical performance with trial
implementations.
"
133,Univariate real root isolation in an extension field,"  We present algorithmic, complexity and implementation results for the problem
of isolating the real roots of a univariate polynomial in $B_{\alpha} \in
L[y]$, where $L=\QQ(\alpha)$ is a simple algebraic extension of the rational
numbers. We consider two approaches for tackling the problem. In the first
approach using resultant computations we perform a reduction to a polynomial
with integer coefficients. We compute separation bounds for the roots, and
using them we deduce that we can isolate the real roots of $B_{\alpha}$ in
$\sOB(N^{10})$, where $N$ is an upper bound on all the quantities (degree and
bitsize) of the input polynomials. In the second approach we isolate the real
roots working directly on the polynomial of the input. We compute improved
separation bounds for real roots and we prove that they are optimal, under mild
assumptions. For isolating the roots we consider a modified Sturm's algorithm,
and a modified version of \func{descartes}' algorithm introduced by Sagraloff.
For the former we prove a complexity bound of $\sOB(N^8)$ and for the latter a
bound of $\sOB(N^{7})$. We implemented the algorithms in \func{C} as part of
the core library of \mathematica and we illustrate their efficiency over
various data sets. Finally, we present complexity results for the general case
of the first approach, where the coefficients belong to multiple extensions.
"
134,"Simulation of Self-Assembly in the Abstract Tile Assembly Model with ISU
  TAS","  Since its introduction by Erik Winfree in 1998, the abstract Tile Assembly
Model (aTAM) has inspired a wealth of research. As an abstract model for tile
based self-assembly, it has proven to be remarkably powerful and expressive in
terms of the structures which can self-assemble within it. As research has
progressed in the aTAM, the self-assembling structures being studied have
become progressively more complex. This increasing complexity, along with a
need for standardization of definitions and tools among researchers, motivated
the development of the Iowa State University Tile Assembly Simulator (ISU TAS).
ISU TAS is a graphical simulator and tile set editor for designing and building
2-D and 3-D aTAM tile assembly systems and simulating their self-assembly. This
paper reviews the features and functionality of ISU TAS and describes how it
can be used to further research into the complexities of the aTAM. Software and
source code are available at http://www.cs.iastate.edu/~lnsa.
"
135,The NumPy array: a structure for efficient numerical computation,"  In the Python world, NumPy arrays are the standard representation for
numerical data. Here, we show how these arrays enable efficient implementation
of numerical computations in a high-level language. Overall, three techniques
are applied to improve performance: vectorizing calculations, avoiding copying
data in memory, and minimizing operation counts. We first present the NumPy
array structure, then show how to use it for efficient computation, and finally
how to share array data with other libraries.
"
136,"Efficient numerical computation of the Pfaffian for dense and banded
  skew-symmetric matrices","  Computing the Pfaffian of a skew-symmetric matrix is a problem that arises in
various fields of physics. Both computing the Pfaffian and a related problem,
computing the canonical form of a skew-symmetric matrix under unitary
congruence, can be solved easily once the skew-symmetric matrix has been
reduced to skew-symmetric tridiagonal form. We develop efficient numerical
methods for computing this tridiagonal form based on Gauss transformations,
using a skew-symmetric, blocked form of the Parlett-Reid algorithm, or based on
unitary transformations, using block Householder transformations and Givens
rotations, that are applicable to dense and banded matrices, respectively. We
also give a complete and fully optimized implementation of these algorithms in
Fortran, and also provide Python, Matlab and Mathematica implementations for
convenience. Finally, we apply these methods to compute the topological charge
of a class D nanowire, and show numerically the equivalence of definitions
based on the Hamiltonian and the scattering matrix.
"
137,Quantum Anticipation Explorer,"  Quantum anticipation explorer is a computer program allowing the numerical
exploration of quantum anticipation which has been analyzed in arXiv:0810.183v1
and arXiv:1003.1090v1 for H-Atom, equidistant, random and custom spectra. This
tool determines the anticipation strength at those times orthogonal evolution
is possible. This paper is the user's guide explaining its capabilities,
installation and usage, and documenting the mathematics and algorithms
implemented in the software. A zip file containing the setup and documentation
can be downloaded from
http://www.thomannconsulting.ch/public/aboutus/aboutus-en.htm free of cost.
"
138,Generating and using truly random quantum states in Mathematica,"  The problem of generating random quantum states is of a great interest from
the quantum information theory point of view. In this paper we present a
package for Mathematica computing system harnessing a specific piece of
hardware, namely Quantis quantum random number generator (QRNG), for
investigating statistical properties of quantum states. The described package
implements a number of functions for generating random states, which use
Quantis QRNG as a source of randomness. It also provides procedures which can
be used in simulations not related directly to quantum information processing.
"
139,"XMLlab : multimedia publication of simulations applets using XML and
  Scilab","  We present an XML-based simulation authoring environment. The proposed
description language allows to describe mathematical objects such as systems of
ordinary differential equations, partial differential equations in two
dimensions, or simple curves and surfaces. It also allows to describe the
parameters on which these objects depend. This language is independent of the
target software and allows to ensure the perennity of author's work, as well as
collaborative work and content reuse. The actual implementation of XMLlab
allows to run the generated simulations within the open source mathematical
software Scilab, either locally when Scilab is installed on the client
machines, or on thin clients running a simple web browser, when XMLlab and
Scilab are installed on a distant server running a standard HTTP server.
"
140,Finite Element Integration on GPUs,"  We present a novel finite element integration method for low order elements
on GPUs. We achieve more than 100GF for element integration on first order
discretizations of both the Laplacian and Elasticity operators.
"
141,"The Planetary System: Executable Science, Technology, Engineering and
  Math Papers","  Executable scientific papers contain not just layouted text for reading. They
contain, or link to, machine-comprehensible representations of the scientific
findings or experiments they describe. Client-side players can thus enable
readers to ""check, manipulate and explore the result space"". We have realized
executable papers in the STEM domain with the Planetary system. Semantic
annotations associate the papers with a content commons holding the background
ontology, the annotations are exposed as Linked Data, and a frontend player
application hooks modular interactive services into the semantic annotations.
"
142,"Fast Sparse Matrix-Vector Multiplication on GPUs: Implications for Graph
  Mining","  Scaling up the sparse matrix-vector multiplication kernel on modern Graphics
Processing Units (GPU) has been at the heart of numerous studies in both
academia and industry. In this article we present a novel non-parametric,
self-tunable, approach to data representation for computing this kernel,
particularly targeting sparse matrices representing power-law graphs. Using
real data, we show how our representation scheme, coupled with a novel tiling
algorithm, can yield significant benefits over the current state of the art GPU
efforts on a number of core data mining algorithms such as PageRank, HITS and
Random Walk with Restart.
"
143,"Software for Generation of Classes of Test Functions with Known Local
  and Global Minima for Global Optimization","  A procedure for generating non-differentiable, continuously differentiable,
and twice continuously differentiable classes of test functions for
multiextremal multidimensional box-constrained global optimization and a
corresponding package of C subroutines are presented. Each test class consists
of 100 functions. Test functions are generated by defining a convex quadratic
function systematically distorted by polynomials in order to introduce local
minima. To determine a class, the user defines the following parameters: (i)
problem dimension, (ii) number of local minima, (iii) value of the global
minimum, (iv) radius of the attraction region of the global minimizer, (v)
distance from the global minimizer to the vertex of the quadratic function.
Then, all other necessary parameters are generated randomly for all 100
functions of the class. Full information about each test function including
locations and values of all local minima is supplied to the user. Partial
derivatives are also generated where possible.
"
144,"Data sets of very large linear feasibility problems solved by projection
  methods","  We give a link to a page on the Web on which we deposited a set of eight huge
Linear Programming (LP) problems for Intensity-Modulated Proton Therapy (IMPT)
treatment planning. These huge LP problems were employed in our recent research
and we were asked to make them public.
"
145,"A study of the existing linear algebra libraries that you can use from
  C++ (Une \'etude des biblioth\`eques d'alg\`ebre lin\'eaire utilisables en
  C++)","  A study of the existing linear algebra libraries that you can use from C++
"
146,PyDEC: Software and Algorithms for Discretization of Exterior Calculus,"  This paper describes the algorithms, features and implementation of PyDEC, a
Python library for computations related to the discretization of exterior
calculus. PyDEC facilitates inquiry into both physical problems on manifolds as
well as purely topological problems on abstract complexes. We describe
efficient algorithms for constructing the operators and objects that arise in
discrete exterior calculus, lowest order finite element exterior calculus and
in related topological problems. Our algorithms are formulated in terms of
high-level matrix operations which extend to arbitrary dimension. As a result,
our implementations map well to the facilities of numerical libraries such as
NumPy and SciPy. The availability of such libraries makes Python suitable for
prototyping numerical methods. We demonstrate how PyDEC is used to solve
physical and topological problems through several concise examples.
"
147,sin[n Delta t sin (n Delta t1)] as a source of unpredictable dynamics,"  We investigate the ability of the function sin[n Delta t sin (n Delta t1)],
where n is an integer and growing number, to produce unpredictable sequences of
numbers. Classical mathematical tools for distinguishing periodic from chaotic
or random behaviour, such as sensitivity to the initial conditions, Fourier
analysis, and autocorrelation are used. Moreover, the function acos{sin[n Delta
t sin (n Delta t1)]}/pigreek is introduced to have an uniform density of
numbers in the interval [0,1], so it can be submitted to a battery of widely
used tests for random number generators. All these tools show that a proper
choice of Delta t and Delta t1, can produce a sequence of numbers behaving as
unpredictable dynamics.
"
148,Arrangement Computation for Planar Algebraic Curves,"  We present a new certified and complete algorithm to compute arrangements of
real planar algebraic curves. Our algorithm provides a geometric-topological
analysis of the decomposition of the plane induced by a finite number of
algebraic curves in terms of a cylindrical algebraic decomposition of the
plane. Compared to previous approaches, we improve in two main aspects:
Firstly, we significantly reduce the amount of exact operations, that is, our
algorithms only uses resultant and gcd as purely symbolic operations. Secondly,
we introduce a new hybrid method in the lifting step of our algorithm which
combines the usage of a certified numerical complex root solver and information
derived from the resultant computation. Additionally, we never consider any
coordinate transformation and the output is also given with respect to the
initial coordinate system. We implemented our algorithm as a prototypical
package of the C++-library CGAL. Our implementation exploits graphics hardware
to expedite the resultant and gcd computation. We also compared our
implementation with the current reference implementation, that is, CGAL's curve
analysis and arrangement for algebraic curves. For various series of
challenging instances, our experiments show that the new implementation
outperforms the existing one.
"
149,DOLFIN: Automated Finite Element Computing,"  We describe here a library aimed at automating the solution of partial
differential equations using the finite element method. By employing novel
techniques for automated code generation, the library combines a high level of
expressiveness with efficient computation. Finite element variational forms may
be expressed in near mathematical notation, from which low-level code is
automatically generated, compiled and seamlessly integrated with efficient
implementations of computational meshes and high-performance linear algebra.
Easy-to-use object-oriented interfaces to the library are provided in the form
of a C++ library and a Python module. This paper discusses the mathematical
abstractions and methods used in the design of the library and its
implementation. A number of examples are presented to demonstrate the use of
the library in application code.
"
150,"Optimisations for quadrature representations of finite element tensors
  through automated code generation","  We examine aspects of the computation of finite element matrices and vectors
which are made possible by automated code generation. Given a variational form
in a syntax which resembles standard mathematical notation, the low-level
computer code for building finite element tensors, typically matrices, vectors
and scalars, can be generated automatically via a form compiler. In particular,
the generation of code for computing finite element matrices using a quadrature
approach is addressed. For quadrature representations, a number of optimisation
strategies which are made possible by automated code generation are presented.
The relative performance of two different automatically generated
representations of finite element matrices is examined, with a particular
emphasis on complicated variational forms. It is shown that approaches which
perform best for simple forms are not tractable for more complicated problems
in terms of run time performance, the time required to generate the code or the
size of the generated code. The approach and optimisations elaborated here are
effective for a range of variational forms.
"
151,Automated code generation for discontinuous Galerkin methods,"  A compiler approach for generating low-level computer code from high-level
input for discontinuous Galerkin finite element forms is presented. The input
language mirrors conventional mathematical notation, and the compiler generates
efficient code in a standard programming language. This facilitates the rapid
generation of efficient code for general equations in varying spatial
dimensions. Key concepts underlying the compiler approach and the automated
generation of computer code are elaborated. The approach is demonstrated for a
range of common problems, including the Poisson, biharmonic,
advection--diffusion and Stokes equations.
"
152,Algorithms for Computing Triangular Decompositions of Polynomial Systems,"  We propose new algorithms for computing triangular decompositions of
polynomial systems incrementally. With respect to previous works, our
improvements are based on a {\em weakened} notion of a polynomial GCD modulo a
regular chain, which permits to greatly simplify and optimize the
sub-algorithms. Extracting common work from similar expensive computations is
also a key feature of our algorithms. In our experimental results the
implementation of our new algorithms, realized with the {\RegularChains}
library in {\Maple}, outperforms solvers with similar specifications by several
orders of magnitude on sufficiently difficult problems.
"
153,Computational Tools for Cohomology of Toric Varieties,"  In this review, novel non-standard techniques for the computation of
cohomology classes on toric varieties are summarized. After an introduction of
the basic definitions and properties of toric geometry, we discuss a specific
computational algorithm for the determination of the dimension of line-bundle
valued cohomology groups on toric varieties. Applications to the computation of
chiral massless matter spectra in string compactifications are discussed and,
using the software package cohomCalg, its utility is highlighted on a new
target space dual pair of (0,2) heterotic string models.
"
154,Operand Folding Hardware Multipliers,"  This paper describes a new accumulate-and-add multiplication algorithm. The
method partitions one of the operands and re-combines the results of
computations done with each of the partitions. The resulting design turns-out
to be both compact and fast.
  When the operands' bit-length $m$ is 1024, the new algorithm requires only
$0.194m+56$ additions (on average), this is about half the number of additions
required by the classical accumulate-and-add multiplication algorithm
($\frac{m}2$).
"
155,"Symbolic computation of weighted Moore-Penrose inverse using
  partitioning method","  We propose a method and algorithm for computing the weighted Moore-Penrose
inverse of one-variable rational matrices. Continuing this idea, we develop an
algorithm for computing the weighted Moore-Penrose inverse of one-variable
polynomial matrix. These methods and algorithms are generalizations of the
method for computing the weighted Moore-Penrose inverse for constant matrices,
originated in Wang and Chen [G.R. Wang, Y.L. Chen, A recursive algorithm for
computing the weighted Moore-Penrose inverse AMN, J. Comput. Math. 4 (1986)
74-85], and the partitioning method for computing the Moore-Penrose inverse of
rational and polynomial matrices introduced in Stanimirovic and Tasic [P.S.
Stanimirovic, M.B. Tasic, Partitioning method for rational and polynomial
matrices, Appl. Math. Comput. 155 (2004) 137-163]. Algorithms are implemented
in the symbolic computational package MATHEMATICA.
"
156,About the generalized LM-inverse and the weighted Moore-Penrose inverse,"  The recursive method for computing the generalized LM-inverse of a constant
rectangular matrix augmented by a column vector is proposed in Udwadia and
Phohomsiri (2007) [16] and [17]. The corresponding algorithm for the sequential
determination of the generalized LM-inverse is established in the present
paper. We prove that the introduced algorithm for computing the generalized
LM-inverse and the algorithm for the computation of the weighted Moore-Penrose
inverse developed by Wang and Chen (1986) in [23] are equivalent algorithms.
Both of the algorithms are implemented in the present paper using the package
MATHEMATICA. Several rational test matrices and randomly generated constant
matrices are tested and the CPU time is compared and discussed.
"
157,Parallel Breadth-First Search on Distributed Memory Systems,"  Data-intensive, graph-based computations are pervasive in several scientific
applications, and are known to to be quite challenging to implement on
distributed memory systems. In this work, we explore the design space of
parallel algorithms for Breadth-First Search (BFS), a key subroutine in several
graph algorithms. We present two highly-tuned parallel approaches for BFS on
large parallel systems: a level-synchronous strategy that relies on a simple
vertex-based partitioning of the graph, and a two-dimensional sparse
matrix-partitioning-based approach that mitigates parallel communication
overhead. For both approaches, we also present hybrid versions with intra-node
multithreading. Our novel hybrid two-dimensional algorithm reduces
communication times by up to a factor of 3.5, relative to a common vertex based
approach. Our experimental study identifies execution regimes in which these
approaches will be competitive, and we demonstrate extremely high performance
on leading distributed-memory parallel systems. For instance, for a 40,000-core
parallel execution on Hopper, an AMD Magny-Cours based system, we achieve a BFS
performance rate of 17.8 billion edge visits per second on an undirected graph
of 4.3 billion vertices and 68.7 billion edges with skewed degree distribution.
"
158,"A novel parallel algorithm for Gaussian Elimination of sparse
  unsymmetric matrices","  We describe a new algorithm for Gaussian Elimination suitable for general
(unsymmetric and possibly singular) sparse matrices, of any entry type, which
has a natural parallel and distributed-memory formulation but degrades
gracefully to sequential execution.
  We present a sample MPI implementation of a program computing the rank of a
sparse integer matrix using the proposed algorithm. Some preliminary
performance measurements are presented and discussed, and the performance of
the algorithm is compared to corresponding state-of-the-art algorithms for
floating-point and integer matrices.
"
159,A search for an optimal start system for numerical homotopy continuation,"  We use our recent implementation of a certified homotopy tracking algorithm
to search for start systems that minimize the average complexity of finding all
roots of a regular system of polynomial equations. While finding optimal start
systems is a hard problem, our experiments show that it is possible to find
start systems that deliver better average complexity than the ones that are
commonly used in the existing homotopy continuation software.
"
160,PHCpack in Macaulay2,"  The Macaulay2 package PHCpack.m2 provides an interface to PHCpack, a
general-purpose polynomial system solver that uses homotopy continuation. The
main method is a numerical blackbox solver which is implemented for all Laurent
systems. The package also provides a fast mixed volume computation, the ability
to filter solutions, homotopy path tracking, and a numerical irreducible
decomposition method. As the size of many problems in applied algebraic
geometry often surpasses the capabilities of symbolic software, this package
will be of interest to those working on problems involving large polynomial
systems.
"
161,Activity-Based Search for Black-Box Contraint-Programming Solvers,"  Robust search procedures are a central component in the design of black-box
constraint-programming solvers. This paper proposes activity-based search, the
idea of using the activity of variables during propagation to guide the search.
Activity-based search was compared experimentally to impact-based search and
the WDEG heuristics. Experimental results on a variety of benchmarks show that
activity-based search is more robust than other heuristics and may produce
significant improvements in performance.
"
162,ShearLab: A Rational Design of a Digital Parabolic Scaling Algorithm,"  Multivariate problems are typically governed by anisotropic features such as
edges in images. A common bracket of most of the various directional
representation systems which have been proposed to deliver sparse
approximations of such features is the utilization of parabolic scaling. One
prominent example is the shearlet system. Our objective in this paper is
three-fold: We firstly develop a digital shearlet theory which is rationally
designed in the sense that it is the digitization of the existing shearlet
theory for continuous data. This implicates that shearlet theory provides a
unified treatment of both the continuum and digital realm. Secondly, we analyze
the utilization of pseudo-polar grids and the pseudo-polar Fourier transform
for digital implementations of parabolic scaling algorithms. We derive an
isometric pseudo-polar Fourier transform by careful weighting of the
pseudo-polar grid, allowing exploitation of its adjoint for the inverse
transform. This leads to a digital implementation of the shearlet transform; an
accompanying Matlab toolbox called ShearLab is provided. And, thirdly, we
introduce various quantitative measures for digital parabolic scaling
algorithms in general, allowing one to tune parameters and objectively improve
the implementation as well as compare different directional transform
implementations. The usefulness of such measures is exemplarily demonstrated
for the digital shearlet transform.
"
163,"Methods of Matrix Multiplication: An Overview of Several Methods and
  their Implementation","  In this overview article we present several methods for multiplying matrices
and the implementation of these methods in C. Also a little test program is
given to compare their running time and the numerical stability.
  The methods are: naive method, naive method working on arrays, naive method
with the \textsc{Kahan} trick, three methods with loop unrolling, winograd
method and the scaled variant, original \textsc{Strassen} method and the
\textsc{Strassen}-\textsc{Winograd} variant.
  Please note, that this is the FIRST version. The algorithms are not well
tested and the implementation is not optimized. If you like to join the
project, please contact me.
"
164,The MathScheme Library: Some Preliminary Experiments,"  We present some of the experiments we have performed to best test our design
for a library for MathScheme, the mechanized mathematics software system we are
building. We wish for our library design to use and reflect, as much as
possible, the mathematical structure present in the objects which populate the
library.
"
165,"A Tuned and Scalable Fast Multipole Method as a Preeminent Algorithm for
  Exascale Systems","  Among the algorithms that are likely to play a major role in future exascale
computing, the fast multipole method (FMM) appears as a rising star. Our
previous recent work showed scaling of an FMM on GPU clusters, with problem
sizes in the order of billions of unknowns. That work led to an extremely
parallel FMM, scaling to thousands of GPUs or tens of thousands of CPUs. This
paper reports on a a campaign of performance tuning and scalability studies
using multi-core CPUs, on the Kraken supercomputer. All kernels in the FMM were
parallelized using OpenMP, and a test using 10^7 particles randomly distributed
in a cube showed 78% efficiency on 8 threads. Tuning of the
particle-to-particle kernel using SIMD instructions resulted in 4x speed-up of
the overall algorithm on single-core tests with 10^3 - 10^7 particles. Parallel
scalability was studied in both strong and weak scaling. The strong scaling
test used 10^8 particles and resulted in 93% parallel efficiency on 2048
processes for the non-SIMD code and 54% for the SIMD-optimized code (which was
still 2x faster). The weak scaling test used 10^6 particles per process, and
resulted in 72% efficiency on 32,768 processes, with the largest calculation
taking about 40 seconds to evaluate more than 32 billion unknowns. This work
builds up evidence for our view that FMM is poised to play a leading role in
exascale computing, and we end the paper with a discussion of the features that
make it a particularly favorable algorithm for the emerging heterogeneous and
massively parallel architectural landscape.
"
166,A Library for Implementing the Multiple Hypothesis Tracking Algorithm,"  The Multiple Hypothesis Tracking (MHT) algorithm is known to produce good
results in difficult multi-target tracking situations. However, its
implementation is not trivial, and is associated with a significant programming
effort, code size and long implementation time. We propose a library which
addresses these problems by providing a domain independent implementation of
the most complex MHT operations. We also address the problem of applying
clustering in domain independent manner.
"
167,Tactics for Reasoning modulo AC in Coq,"  We present a set of tools for rewriting modulo associativity and
commutativity (AC) in Coq, solving a long-standing practical problem. We use
two building blocks: first, an extensible reflexive decision procedure for
equality modulo AC; second, an OCaml plug-in for pattern matching modulo AC. We
handle associative only operations, neutral elements, uninterpreted function
symbols, and user-defined equivalence relations. By relying on type-classes for
the reification phase, we can infer these properties automatically, so that
end-users do not need to specify which operation is A or AC, or which constant
is a neutral element.
"
168,"GPU-Based Heuristic Solver for Linear Sum Assignment Problems Under
  Real-time Constraints","  In this paper we modify a fast heuristic solver for the Linear Sum Assignment
Problem (LSAP) for use on Graphical Processing Units (GPUs). The motivating
scenario is an industrial application for P2P live streaming that is moderated
by a central node which is periodically solving LSAP instances for assigning
peers to one another. The central node needs to handle LSAP instances involving
thousands of peers in as near to real-time as possible. Our findings are
generic enough to be applied in other contexts. Our main result is a parallel
version of a heuristic algorithm called Deep Greedy Switching (DGS) on GPUs
using the CUDA programming language. DGS sacrifices absolute optimality in
favor of low computation time and was designed as an alternative to classical
LSAP solvers such as the Hungarian and auctioning methods. The contribution of
the paper is threefold: First, we present the process of trial and error we
went through, in the hope that our experience will be beneficial to adopters of
GPU programming for similar problems. Second, we show the modifications needed
to parallelize the DGS algorithm. Third, we show the performance gains of our
approach compared to both a sequential CPU-based implementation of DGS and a
parallel GPU-based implementation of the auctioning algorithm.
"
169,"An algorithm for autonomously plotting solution sets in the presence of
  turning points","  Plotting solution sets for particular equations may be complicated by the
existence of turning points. Here we describe an algorithm which not only
overcomes such problematic points, but does so in the most general of settings.
Applications of the algorithm are highlighted through two examples: the first
provides verification, while the second demonstrates a non-trivial application.
The latter is followed by a thorough run-time analysis. While both examples
deal with bivariate equations, it is discussed how the algorithm may be
generalized for space curves in $\R^{3}$.
"
170,"Integrating Generic Sensor Fusion Algorithms with Sound State
  Representations through Encapsulation of Manifolds","  Common estimation algorithms, such as least squares estimation or the Kalman
filter, operate on a state in a state space S that is represented as a
real-valued vector. However, for many quantities, most notably orientations in
3D, S is not a vector space, but a so-called manifold, i.e. it behaves like a
vector space locally but has a more complex global topological structure. For
integrating these quantities, several ad-hoc approaches have been proposed.
  Here, we present a principled solution to this problem where the structure of
the manifold S is encapsulated by two operators, state displacement [+]:S x R^n
--> S and its inverse [-]: S x S --> R^n. These operators provide a local
vector-space view \delta; --> x [+] \delta; around a given state x. Generic
estimation algorithms can then work on the manifold S mainly by replacing +/-
with [+]/[-] where appropriate. We analyze these operators axiomatically, and
demonstrate their use in least-squares estimation and the Unscented Kalman
Filter. Moreover, we exploit the idea of encapsulation from a software
engineering perspective in the Manifold Toolkit, where the [+]/[-] operators
mediate between a ""flat-vector"" view for the generic algorithm and a
""named-members"" view for the problem specific functions.
"
171,Licensing the Mizar Mathematical Library,"  The Mizar Mathematical Library (MML) is a large corpus of formalised
mathematical knowledge. It has been constructed over the course of many years
by a large number of authors and maintainers. Yet the legal status of these
efforts of the Mizar community has never been clarified. In 2010, after many
years of loose deliberations, the community decided to investigate the issue of
licensing the content of the MML, thereby clarifying and crystallizing the
status of the texts, the text's authors, and the library's long-term
maintainers. The community has settled on a copyright and license policy that
suits the peculiar features of Mizar and its community. In this paper we
discuss the copyright and license solutions. We offer our experience in the
hopes that the communities of other libraries of formalised mathematical
knowledge might take up the legal and scientific problems that we addressed for
Mizar.
"
172,"Using Java for distributed computing in the Gaia satellite data
  processing","  In recent years Java has matured to a stable easy-to-use language with the
flexibility of an interpreter (for reflection etc.) but the performance and
type checking of a compiled language. When we started using Java for
astronomical applications around 1999 they were the first of their kind in
astronomy. Now a great deal of astronomy software is written in Java as are
many business applications.
  We discuss the current environment and trends concerning the language and
present an actual example of scientific use of Java for high-performance
distributed computing: ESA's mission Gaia. The Gaia scanning satellite will
perform a galactic census of about 1000 million objects in our galaxy. The Gaia
community has chosen to write its processing software in Java. We explore the
manifold reasons for choosing Java for this large science collaboration.
  Gaia processing is numerically complex but highly distributable, some parts
being embarrassingly parallel. We describe the Gaia processing architecture and
its realisation in Java. We delve into the astrometric solution which is the
most advanced and most complex part of the processing. The Gaia simulator is
also written in Java and is the most mature code in the system. This has been
successfully running since about 2005 on the supercomputer ""Marenostrum"" in
Barcelona. We relate experiences of using Java on a large shared machine.
  Finally we discuss Java, including some of its problems, for scientific
computing.
"
173,Some Software Packages for Partial SVD Computation,"  This technical report introduces some software packages for partial SVD
computation, including optimized PROPACK, modified PROPACK for computing
singular values above a threshold and the corresponding singular vectors, and
block Lanczos with warm start (BLWS). The current version is preliminary. The
details will be enriched soon.
"
174,"Hierarchical N-body simulations with auto-tuning for heterogeneous
  systems","  With the current hybridization of treecodes and FMMs, combined with
auto-tuning capabilities on heterogeneous architectures, the flexibility of
fast N-body methods has been greatly enhanced. These features are a requirement
to developing a black-box software library for fast N-body algorithms on
heterogeneous systems, which is our immediate goal.
"
175,"Specific ""scientific"" data structures, and their processing","  Programming physicists use, as all programmers, arrays, lists, tuples,
records, etc., and this requires some change in their thought patterns while
converting their formulae into some code, since the ""data structures"" operated
upon, while elaborating some theory and its consequences, are rather: power
series and Pad\'e approximants, differential forms and other instances of
differential algebras, functionals (for the variational calculus), trajectories
(solutions of differential equations), Young diagrams and Feynman graphs, etc.
Such data is often used in a [semi-]numerical setting, not necessarily
""symbolic"", appropriate for the computer algebra packages. Modules adapted to
such data may be ""just libraries"", but often they become specific, embedded
sub-languages, typically mapped into object-oriented frameworks, with
overloaded mathematical operations. Here we present a functional approach to
this philosophy. We show how the usage of Haskell datatypes and - fundamental
for our tutorial - the application of lazy evaluation makes it possible to
operate upon such data (in particular: the ""infinite"" sequences) in a natural
and comfortable manner.
"
176,A New Vectorization Technique for Expression Templates in C++,"  Vector operations play an important role in high performance computing and
are typically provided by highly optimized libraries that implement the BLAS
(Basic Linear Algebra Subprograms) interface. In C++ templates and operator
overloading allow the implementation of these vector operations as expression
templates which construct custom loops at compile time and providing a more
abstract interface. Unfortunately existing expression template libraries lack
the performance of fast BLAS(Basic Linear Algebra Subprograms) implementations.
This paper presents a new approach - Statically Accelerated Loop Templates
(SALT) - to close this performance gap by combining expression templates with
an aggressive loop unrolling technique. Benchmarks were conducted using the
Intel C++ compiler and GNU Compiler Collection to assess the performance of our
library relative to Intel's Math Kernel Library as well as the Eigen template
library. The results show that the approach is able to provide optimization
comparable to the fastest available BLAS implementations, while retaining the
convenience and flexibility of a template library.
"
177,"Parallel Sparse Matrix-Matrix Multiplication and Indexing:
  Implementation and Experiments","  Generalized sparse matrix-matrix multiplication (or SpGEMM) is a key
primitive for many high performance graph algorithms as well as for some linear
solvers, such as algebraic multigrid. Here we show that SpGEMM also yields
efficient algorithms for general sparse-matrix indexing in distributed memory,
provided that the underlying SpGEMM implementation is sufficiently flexible and
scalable. We demonstrate that our parallel SpGEMM methods, which use
two-dimensional block data distributions with serial hypersparse kernels, are
indeed highly flexible, scalable, and memory-efficient in the general case.
This algorithm is the first to yield increasing speedup on an unbounded number
of processors; our experiments show scaling up to thousands of processors in a
variety of test scenarios.
"
178,"LSRN: A Parallel Iterative Solver for Strongly Over- or Under-Determined
  Systems","  We describe a parallel iterative least squares solver named \texttt{LSRN}
that is based on random normal projection. \texttt{LSRN} computes the
min-length solution to $\min_{x \in \mathbb{R}^n} \|A x - b\|_2$, where $A \in
\mathbb{R}^{m \times n}$ with $m \gg n$ or $m \ll n$, and where $A$ may be
rank-deficient. Tikhonov regularization may also be included. Since $A$ is only
involved in matrix-matrix and matrix-vector multiplications, it can be a dense
or sparse matrix or a linear operator, and \texttt{LSRN} automatically speeds
up when $A$ is sparse or a fast linear operator. The preconditioning phase
consists of a random normal projection, which is embarrassingly parallel, and a
singular value decomposition of size $\lceil \gamma \min(m,n) \rceil \times
\min(m,n)$, where $\gamma$ is moderately larger than 1, e.g., $\gamma = 2$. We
prove that the preconditioned system is well-conditioned, with a strong
concentration result on the extreme singular values, and hence that the number
of iterations is fully predictable when we apply LSQR or the Chebyshev
semi-iterative method. As we demonstrate, the Chebyshev method is particularly
efficient for solving large problems on clusters with high communication cost.
Numerical results demonstrate that on a shared-memory machine, \texttt{LSRN}
outperforms LAPACK's DGELSD on large dense problems, and MATLAB's backslash
(SuiteSparseQR) on sparse problems. Further experiments demonstrate that
\texttt{LSRN} scales well on an Amazon Elastic Compute Cloud cluster.
"
179,Asymptotic Methods of ODEs: Exploring Singularities of the Second Kind,"  We develop symbolic methods of asymptotic approximations for solutions of
linear ordinary differential equations and use to them stabilize numerical
calculations. Our method follows classical analysis for first-order systems and
higher-order scalar equations where growth behavior is expressed in terms of
elementary functions. We then recast our equations in mollified form - thereby
obtaining stability.
"
180,Metaprogramming Applied to Numerical Problems,"  From the discovery that the template system of C++ forms a Turing complete
language in 1994, a programming technique called Template Metaprogramming has
emerged that allows for the creation of faster, more generic and better code.
Here, we apply Template Metaprogramming to implement a generic Runge-Kutta
scheme that can be used to numerically solve ordinary differential equations.
We show that using Template Metaprogramming results in a significantly improved
performance compared to a classical implementation.
"
181,Odeint - Solving ordinary differential equations in C++,"  Many physical, biological or chemical systems are modeled by ordinary
differential equations (ODEs) and finding their solution is an every-day-task
for many scientists. Here, we introduce a new C++ library dedicated to find
numerical solutions of initial value problems of ODEs: odeint (www.odeint.com).
odeint is implemented in a highly generic way and provides extensive
interoperability at top performance. For example, due to it's modular design it
can be easily parallized with OpenMP and even runs on CUDA GPUs. Despite that,
it provides a convenient interface that allows for a simple and easy usage.
"
182,"Proceedings 10th International Workshop on the ACL2 Theorem Prover and
  its Applications","  This volume contains the proceedings of ACL2 2011, the International Workshop
on the ACL2 Theorem Prover and its Applications. The workshop was held in
Austin, Texas, USA, on November 3-4 2011. ACL2 2011 is the tenth in a series of
workshops on the ACL2 Theorem Prover and its Applications. The workshop was
co-located with the eleventh Conference on Formal Methods in Computer Aided
Design (FMCAD'11). The ACL2 Workshop series provide a major technical forum for
researchers to present and discuss improvements and extensions to the theorem
prover, comparisons of ACL2 with other systems, and applications of ACL2 in
formal verification or formalized mathematics. Workshops have been held at
approxiamately 18 month intervals since 1999. ACL2 is the most recent
incarnation of the Boyer-Moore family of theorem provers, for which, Robert
Boyer, Matt Kaufmann and J Strother Moore received the 2005 ACM Software System
Award. It is state-of-the-art automated reasoning system that has been
successfully used in academia, government and industry for specification and
verification of computing systems. More details can be found in the proceedings
and on the workshop web page (www.cs.ru.nl/~julien/acl2-11/).
"
183,How Can I Do That with ACL2? Recent Enhancements to ACL2,"  The last several years have seen major enhancements to ACL2 functionality,
largely driven by requests from its user community, including utilities now in
common use such as 'make-event', 'mbe', and trust tags. In this paper we
provide user-level summaries of some ACL2 enhancements introduced after the
release of Version 3.5 (in May, 2009, at about the time of the 2009 ACL2
workshop) up through the release of Version 4.3 in July, 2011, roughly a couple
of years later. Many of these features are not particularly well known yet, but
most ACL2 users could take advantage of at least some of them. Some of the
changes could affect existing proof efforts, such as a change that treats pairs
of functions such as 'member' and 'member-equal' as the same function.
"
184,"Formal Verification of an Iterative Low-Power x86 Floating-Point
  Multiplier with Redundant Feedback","  We present the formal verification of a low-power x86 floating-point
multiplier. The multiplier operates iteratively and feeds back intermediate
results in redundant representation. It supports x87 and SSE instructions in
various precisions and can block the issuing of new instructions. The design
has been optimized for low-power operation and has not been constrained by the
formal verification effort. Additional improvements for the implementation were
identified through formal verification. The formal verification of the design
also incorporates the implementation of clock-gating and control logic. The
core of the verification effort was based on ACL2 theorem proving.
Additionally, model checking has been used to verify some properties of the
floating-point scheduler that are relevant for the correct operation of the
unit.
"
185,"LINPRO: linear inverse problem library for data contaminated by
  statistical noise","  The library LINPRO which provides solution to the linear inverse problem for
data contaminated by a statistical noise is presented. The library makes use of
two methods: Maximum Entropy Method and Singular Value Decomposition. As an
example it has been applied to perform an analytic continuation of the
imaginary time propagator obtained within the Quantum Monte Carlo method.
"
186,"Throughput-Distortion Computation Of Generic Matrix Multiplication:
  Toward A Computation Channel For Digital Signal Processing Systems","  The generic matrix multiply (GEMM) function is the core element of
high-performance linear algebra libraries used in many
computationally-demanding digital signal processing (DSP) systems. We propose
an acceleration technique for GEMM based on dynamically adjusting the
imprecision (distortion) of computation. Our technique employs adaptive scalar
companding and rounding to input matrix blocks followed by two forms of packing
in floating-point that allow for concurrent calculation of multiple results.
Since the adaptive companding process controls the increase of concurrency (via
packing), the increase in processing throughput (and the corresponding increase
in distortion) depends on the input data statistics. To demonstrate this, we
derive the optimal throughput-distortion control framework for GEMM for the
broad class of zero-mean, independent identically distributed, input sources.
Our approach converts matrix multiplication in programmable processors into a
computation channel: when increasing the processing throughput, the output
noise (error) increases due to (i) coarser quantization and (ii) computational
errors caused by exceeding the machine-precision limitations. We show that,
under certain distortion in the GEMM computation, the proposed framework can
significantly surpass 100% of the peak performance of a given processor. The
practical benefits of our proposal are shown in a face recognition system and a
multi-layer perceptron system trained for metadata learning from a large music
feature database.
"
187,"Design and Simulation of an 8-bit Dedicated Processor for calculating
  the Sine and Cosine of an Angle using the CORDIC Algorithm","  This paper describes the design and simulation of an 8-bit dedicated
processor for calculating the Sine and Cosine of an Angle using CORDIC
Algorithm (COordinate Rotation DIgital Computer), a simple and efficient
algorithm to calculate hyperbolic and trigonometric functions. We have proposed
a dedicated processor system, modeled by writing appropriate programs in VHDL,
for calculating the Sine and Cosine of an angle. System simulation was carried
out using ModelSim 6.3f and Xilinx ISE Design Suite 12.3. A maximum frequency
of 81.353 MHz was reached with a minimum period of 12.292 ns. 126 (3%) slices
were used. This paper attempts to survey the existing CORDIC algorithm with an
eye towards implementation in Field Programmable Gate Arrays (FPGAs). A brief
description of the theory behind the algorithm and the derivation of the Sine
and Cosine of an angle using the CORDIC algorithm has been presented. The
system can be implemented using Spartan3 XC3S400 with Xilinx ISE 12.3 and VHDL.
"
188,"A multiprecision matrix calculation library and its extension library
  for a matrix-product-state simulation of quantum computing","  A C++ library, named ZKCM, has been developed for the purpose of
multiprecision matrix calculations, which is based on the GNU MP and MPFR
libraries. It is especially convenient for writing programs involving
tensor-product operations, tracing-out operations, and singular-value
decompositions. Its extension library, ZKCM_QC, for simulating quantum
computing has been developed using the time-dependent matrix-product-state
simulation method. This report gives a brief introduction to the libraries with
sample programs.
"
189,tym: Typed Matlab,"  Although, many scientists and engineers use Octave or MATLAB as their
preferred programming language, dynamic nature of these languages can lead to
slower running-time of programs written in these languages compared to programs
written in languages which are not as dynamic, like C, C++ and Fortran. In this
work we developed a translator for a new programming language (tym) which tries
to address performance issues, common in scientific programs, by adding new
constructs to a subset of Octave/MATLAB language. Our translator compiles
programs written in tym, to efficient C++ code.
"
190,Matrix Inversion Using Cholesky Decomposition,"  In this paper we present a method for matrix inversion based on Cholesky
decomposition with reduced number of operations by avoiding computation of
intermediate results; further, we use fixed point simulations to compare the
numerical accuracy of the method.
"
191,Solving Dense Generalized Eigenproblems on Multi-threaded Architectures,"  We compare two approaches to compute a portion of the spectrum of dense
symmetric definite generalized eigenproblems: one is based on the reduction to
tridiagonal form, and the other on the Krylov-subspace iteration. Two
large-scale applications, arising in molecular dynamics and material science,
are employed to investigate the contributions of the application, architecture,
and parallelism of the method to the performance of the solvers. The
experimental results on a state-of-the-art 8-core platform, equipped with a
graphics processing unit (GPU), reveal that in real applications, iterative
Krylov-subspace methods can be a competitive approach also for the solution of
dense problems.
"
192,"Efficient Dense Gaussian Elimination over the Finite Field with Two
  Elements","  In this work we describe an efficient implementation of a hierarchy of
algorithms for Gaussian elimination upon dense matrices over the field with two
elements. We discuss both well-known and new algorithms as well as our
implementations in the M4RI library, which has been adopted into Sage. The
focus of our discussion is a block iterative algorithm for PLE decomposition
which is inspired by the M4RI algorithm. The implementation presented in this
work provides considerable performance gains in practice when compared to the
previously fastest implementation. We provide performance figures on x86_64
CPUs to demonstrate the alacrity of our approach.
"
193,"PyClaw: Accessible, Extensible, Scalable Tools for Wave Propagation
  Problems","  Development of scientific software involves tradeoffs between ease of use,
generality, and performance. We describe the design of a general hyperbolic PDE
solver that can be operated with the convenience of MATLAB yet achieves
efficiency near that of hand-coded Fortran and scales to the largest
supercomputers. This is achieved by using Python for most of the code while
employing automatically-wrapped Fortran kernels for computationally intensive
routines, and using Python bindings to interface with a parallel computing
library and other numerical packages. The software described here is PyClaw, a
Python-based structured grid solver for general systems of hyperbolic PDEs
\cite{pyclaw}. PyClaw provides a powerful and intuitive interface to the
algorithms of the existing Fortran codes Clawpack and SharpClaw, simplifying
code development and use while providing massive parallelism and scalable
solvers via the PETSc library. The package is further augmented by use of
PyWENO for generation of efficient high-order weighted essentially
non-oscillatory reconstruction code. The simplicity, capability, and
performance of this approach are demonstrated through application to example
problems in shallow water flow, compressible flow and elasticity.
"
194,"The M4RIE library for dense linear algebra over small fields with even
  characteristic","  In this work, we present the M4RIE library which implements efficient
algorithms for linear algebra with dense matrices over GF(2^e) for 2 <= 2 <=
10. As the name of the library indicates, it makes heavy use of the M4RI
library both directly (i.e., by calling it) and indirectly (i.e., by using its
concepts). We provide an open-source GPLv2+ C library for efficient linear
algebra over GF(2^e) for e small. In this library we implemented an idea due to
Bradshaw and Boothby which reduces matrix multiplication over GF(p^k) to a
series of matrix multiplications over GF(p). Furthermore, we propose a caching
technique - Newton-John tables - to avoid finite field multiplications which is
inspired by Kronrod's method (""M4RM"") for matrix multiplication over GF(2).
Using these two techniques we provide asymptotically fast triangular solving
with matrices (TRSM) and PLE-based Gaussian elimination. As a result, we are
able to significantly improve upon the state of the art in dense linear algebra
over GF(2^e) with 2 <= e <= 10.
"
195,"Complexity and Algorithms for Euler Characteristic of Simplicial
  Complexes","  We consider the problem of computing the Euler characteristic of an abstract
simplicial complex given by its vertices and facets. We show that this problem
is #P-complete and present two new practical algorithms for computing Euler
characteristic. The two new algorithms are derived using combinatorial
commutative algebra and we also give a second description of them that requires
no algebra. We present experiments showing that the two new algorithms can be
implemented to be faster than previous Euler characteristic implementations by
a large margin.
"
196,"Sparse matrix-vector multiplication on GPGPU clusters: A new storage
  format and a scalable implementation","  Sparse matrix-vector multiplication (spMVM) is the dominant operation in many
sparse solvers. We investigate performance properties of spMVM with matrices of
various sparsity patterns on the nVidia ""Fermi"" class of GPGPUs. A new ""padded
jagged diagonals storage"" (pJDS) format is proposed which may substantially
reduce the memory overhead intrinsic to the widespread ELLPACK-R scheme. In our
test scenarios the pJDS format cuts the overall spMVM memory footprint on the
GPGPU by up to 70%, and achieves 95% to 130% of the ELLPACK-R performance.
Using a suitable performance model we identify performance bottlenecks on the
node level that invalidate some types of matrix structures for efficient
multi-GPGPU parallelization. For appropriate sparsity patterns we extend
previous work on distributed-memory parallel spMVM to demonstrate a scalable
hybrid MPI-GPGPU code, achieving efficient overlap of communication and
computation.
"
197,"Rank-profile revealing Gaussian elimination and the CUP matrix
  decomposition","  Transforming a matrix over a field to echelon form, or decomposing the matrix
as a product of structured matrices that reveal the rank profile, is a
fundamental building block of computational exact linear algebra. This paper
surveys the well known variations of such decompositions and transformations
that have been proposed in the literature. We present an algorithm to compute
the CUP decomposition of a matrix, adapted from the LSP algorithm of Ibarra,
Moran and Hui (1982), and show reductions from the other most common Gaussian
elimination based matrix transformations and decompositions to the CUP
decomposition. We discuss the advantages of the CUP algorithm over other
existing algorithms by studying time and space complexities: the asymptotic
time complexity is rank sensitive, and comparing the constants of the leading
terms, the algorithms for computing matrix invariants based on the CUP
decomposition are always at least as good except in one case. We also show that
the CUP algorithm, as well as the computation of other invariants such as
transformation to reduced column echelon form using the CUP algorithm, all work
in place, allowing for example to compute the inverse of a matrix on the same
storage as the input matrix.
"
198,Scikit-learn: Machine Learning in Python,"  Scikit-learn is a Python module integrating a wide range of state-of-the-art
machine learning algorithms for medium-scale supervised and unsupervised
problems. This package focuses on bringing machine learning to non-specialists
using a general-purpose high-level language. Emphasis is put on ease of use,
performance, documentation, and API consistency. It has minimal dependencies
and is distributed under the simplified BSD license, encouraging its use in
both academic and commercial settings. Source code, binaries, and documentation
can be downloaded from http://scikit-learn.org.
"
199,"Evaluating polynomials in several variables and their derivatives on a
  GPU computing processor","  In order to obtain more accurate solutions of polynomial systems with
numerical continuation methods we use multiprecision arithmetic. Our goal is to
offset the overhead of double double arithmetic accelerating the path trackers
and in particular Newton's method with a general purpose graphics processing
unit. In this paper we describe algorithms for the massively parallel
evaluation and differentiation of sparse polynomials in several variables. We
report on our implementation of the algorithmic differentiation of products of
variables on the NVIDIA Tesla C2050 Computing Processor using the NVIDIA CUDA
compiler tools.
"
200,ProofPeer - A Cloud-based Interactive Theorem Proving System,"  ProofPeer strives to be a system for cloud-based interactive theorem proving.
After illustrating why such a system is needed, the paper presents some of the
design challenges that ProofPeer needs to meet to succeed. Contexts are
presented as a solution to the problem of sharing proof state among the users
of ProofPeer. Chronicles are introduced as a way to organize and version
contexts.
"
201,A Representation of Binary Matrices,"  In this article we discuss the presentation of a random binary matrix using
sequence of whole nonnegative numbers. We examine some advantages and
disadvantages of this presentation as an alternative of the standard
presentation using two-dimensional array. It is shown that the presentation of
binary matrices using ordered n-tuples of natural numbers makes the algorithms
faster and saves a lot of memory. In this work we use object-oriented
programming using the syntax and the semantic of C++ programming language.
"
202,Exact Symbolic-Numeric Computation of Planar Algebraic Curves,"  We present a novel certified and complete algorithm to compute arrangements
of real planar algebraic curves. It provides a geometric-topological analysis
of the decomposition of the plane induced by a finite number of algebraic
curves in terms of a cylindrical algebraic decomposition. From a high-level
perspective, the overall method splits into two main subroutines, namely an
algorithm denoted Bisolve to isolate the real solutions of a zero-dimensional
bivariate system, and an algorithm denoted GeoTop to analyze a single algebraic
curve.
  Compared to existing approaches based on elimination techniques, we
considerably improve the corresponding lifting steps in both subroutines. As a
result, generic position of the input system is never assumed, and thus our
algorithm never demands for any change of coordinates. In addition, we
significantly limit the types of involved exact operations, that is, we only
use resultant and gcd computations as purely symbolic operations. The latter
results are achieved by combining techniques from different fields such as
(modular) symbolic computation, numerical analysis and algebraic geometry.
  We have implemented our algorithms as prototypical contributions to the
C++-project CGAL. They exploit graphics hardware to expedite the symbolic
computations. We have also compared our implementation with the current
reference implementations, that is, LGP and Maple's Isolate for polynomial
system solving, and CGAL's bivariate algebraic kernel for analyses and
arrangement computations of algebraic curves. For various series of challenging
instances, our exhaustive experiments show that the new implementations
outperform the existing ones.
"
203,"Matrix representation of a solution of a combinatorial problem of the
  group theory","  An equivalence relation in the symmetric group, where is a positive integer
has been considered. An algorithm for calculation of the number of the
equivalence classes by this relation for arbitrary integer has been described.
"
204,On the Shape of Curves that are Rational in Polar Coordinates,"  In this paper we provide a computational approach to the shape of curves
which are rational in polar coordinates, i.e. which are defined by means of a
parametrization (r(t),\theta(t)) where both r(t),\theta(t) are rational
functions. Our study includes theoretical aspects on the shape of these curves,
and algorithmic results which eventually lead to an algorithm for plotting the
""interesting parts"" of the curve, i.e. the parts showing the main geometrical
features of it. On the theoretical side, we prove that these curves, with the
exceptions of lines and circles, cannot be algebraic (in cartesian
coordinates), we characterize the existence of infinitely many
self-intersections, and we connect this with certain phenomena which are not
possible in the algebraic world, namely the existence of limit circles, limit
points, or spiral branches. On the practical side, we provide an algorithm
which has been implemented in the computer algebra system Maple to visualize
this kind of curves. Our implementation makes use (and improves some aspects
of) the command polarplot currently available in Maple for plotting curves in
polar form.
"
205,The Optimal Uncertainty Algorithm in the Mystic Framework,"  We have recently proposed a rigorous framework for Uncertainty Quantification
(UQ) in which UQ objectives and assumption/information set are brought into the
forefront, providing a framework for the communication and comparison of UQ
results. In particular, this framework does not implicitly impose inappropriate
assumptions nor does it repudiate relevant information. This framework, which
we call Optimal Uncertainty Quantification (OUQ), is based on the observation
that given a set of assumptions and information, there exist bounds on
uncertainties obtained as values of optimization problems and that these bounds
are optimal. It provides a uniform environment for the optimal solution of the
problems of validation, certification, experimental design, reduced order
modeling, prediction, extrapolation, all under aleatoric and epistemic
uncertainties. OUQ optimization problems are extremely large, and even though
under general conditions they have finite-dimensional reductions, they must
often be solved numerically. This general algorithmic framework for OUQ has
been implemented in the mystic optimization framework. We describe this
implementation, and demonstrate its use in the context of the Caltech surrogate
model for hypervelocity impact.
"
206,Building a Framework for Predictive Science,"  Key questions that scientists and engineers typically want to address can be
formulated in terms of predictive science. Questions such as: ""How well does my
computational model represent reality?"", ""What are the most important
parameters in the problem?"", and ""What is the best next experiment to perform?""
are fundamental in solving scientific problems. Mystic is a framework for
massively-parallel optimization and rigorous sensitivity analysis that enables
these motivating questions to be addressed quantitatively as global
optimization problems. Often realistic physics, engineering, and materials
models may have hundreds of input parameters, hundreds of constraints, and may
require execution times of seconds or longer. In more extreme cases, realistic
models may be multi-scale, and require the use of high-performance computing
clusters for their evaluation. Predictive calculations, formulated as a global
optimization over a potential surface in design parameter space, may require an
already prohibitively large simulation to be performed hundreds, if not
thousands, of times. The need to prepare, schedule, and monitor thousands of
model evaluations, and dynamically explore and analyze results, is a
challenging problem that requires a software infrastructure capable of
distributing and managing computations on large-scale heterogeneous resources.
In this paper, we present the design behind an optimization framework, and also
a framework for heterogeneous computing, that when utilized together, can make
computationally intractable sensitivity and optimization problems much more
tractable.
"
207,Singular Values using Cholesky Decomposition,"  In this paper two ways to compute singular values are presented which use
Cholesky decomposition as their basic operation.
"
208,Fatgraph Algorithms and the Homology of the Kontsevich Complex,"  Fatgraphs are multigraphs enriched with a cyclic order of the edges incident
to a vertex. This paper presents algorithms to: (1) generate the set of all
fatgraphs having a given genus and number of boundary cycles; (2) compute
automorphisms of any given fatgraph; (3) compute the homology of the fatgraph
complex. The algorithms are suitable for effective computer implementation.
  In particular, this allows us to compute the rational homology of the moduli
space of Riemann surfaces with marked points. We thus compute the Betti numbers
of $M_{g,n}$ with $(2g + n) \leq 6$, corroborating known results.
"
209,"Function call overhead benchmarks with MATLAB, Octave, Python, Cython
  and C","  We consider the overhead of function calls in the programming languages
MATLAB/Octave, Python, Cython and C. In many applications a function has to be
called very often inside a loop. One such application in numerical analysis is
the finite element method where integrals have to be computed on each element
in a loop. The called functions can often be evaluated efficiently but the
function call itself may be time-consuming. We present a benchmark whose goal
is to identify and quantify optimization potentials with respect to time
consumption caused by function calls in the mentioned programming languages.
"
210,Implementation of a Unimodularity Test,"  This paper describes implementation and computational results of a polynomial
test of total unimodularity. The test is a simplified version of a prior
method. The program also decides two related unimodularity properties. The
software is available free of charge in source code form under the Boost
Software License.
"
211,Computable Hilbert Schemes,"  In this PhD thesis we propose an algorithmic approach to the study of the
Hilbert scheme. Developing algorithmic methods, we also obtain general results
about Hilbert schemes. In Chapter 1 we discuss the equations defining the
Hilbert scheme as subscheme of a suitable Grassmannian and in Chapter 5 we
determine a new set of equations of degree lower than the degree of equations
known so far. In Chapter 2 we study the most important objects used to project
algorithmic techniques, namely Borel-fixed ideals. We determine an algorithm
computing all the saturated Borel-fixed ideals with Hilbert polynomial assigned
and we investigate their combinatorial properties. In Chapter 3 we show a new
type of flat deformations of Borel-fixed ideals which lead us to give a new
proof of the connectedness of the Hilbert scheme. In Chapter 4 we construct
families of ideals that generalize the notion of family of ideals sharing the
same initial ideal with respect to a fixed term ordering. Some of these
families correspond to open subsets of the Hilbert scheme and can be used to a
local study of the Hilbert scheme. In Chapter 6 we deal with the problem of the
connectedness of the Hilbert scheme of locally Cohen-Macaulay curves in the
projective 3-space. We show that one of the Hilbert scheme considered a ""good""
candidate to be non-connected, is instead connected. Moreover there are three
appendices that present and explain how to use the implementations of the
algorithms proposed.
"
212,Proceedings First Workshop on CTP Components for Educational Software,"  The THedu'11 workshop received thirteen submissions, twelve of which were
accepted and presented during the workshop. For the post-conference proceedings
nine submission where received and accepted. The submissions are within the
scope of the following points, which have been announced in the call of papers:
CTP-based software tools for education; CTP technology combined with novel
interfaces, drag and drop, etc.; technologies to access ITP knowledge relevant
for a certain step of problem solving; usability considerations on representing
ITP knowledge; combination of deduction and computation; formal problem
specifications; effectiveness of ATP in checking user input; formats for
deductive content in proof documents, geometric constructions, etc; formal
domain models for e-learning in mathematics and applications.
"
213,Towards an Intelligent Tutor for Mathematical Proofs,"  Computer-supported learning is an increasingly important form of study since
it allows for independent learning and individualized instruction. In this
paper, we discuss a novel approach to developing an intelligent tutoring system
for teaching textbook-style mathematical proofs. We characterize the
particularities of the domain and discuss common ITS design models. Our
approach is motivated by phenomena found in a corpus of tutorial dialogs that
were collected in a Wizard-of-Oz experiment. We show how an intelligent tutor
for textbook-style mathematical proofs can be built on top of an adapted
assertion-level proof assistant by reusing representations and proof search
strategies originally developed for automated and interactive theorem proving.
The resulting prototype was successfully evaluated on a corpus of tutorial
dialogs and yields good results.
"
214,Automatic Deduction in Dynamic Geometry using Sage,"  We present a symbolic tool that provides robust algebraic methods to handle
automatic deduction tasks for a dynamic geometry construction. The main
prototype has been developed as two different worksheets for the open source
computer algebra system Sage, corresponding to two different ways of coding a
geometric construction. In one worksheet, diagrams constructed with the open
source dynamic geometry system GeoGebra are accepted. In this worksheet,
Groebner bases are used to either compute the equation of a geometric locus in
the case of a locus construction or to determine the truth of a general
geometric statement included in the GeoGebra construction as a boolean
variable. In the second worksheet, locus constructions coded using the common
file format for dynamic geometry developed by the Intergeo project are accepted
for computation. The prototype and several examples are provided for testing.
Moreover, a third Sage worksheet is presented in which a novel algorithm to
eliminate extraneous parts in symbolically computed loci has been implemented.
The algorithm, based on a recent work on the Groebner cover of parametric
systems, identifies degenerate components and extraneous adherence points in
loci, both natural byproducts of general polynomial algebraic methods. Detailed
examples are discussed.
"
215,Formalization and Implementation of Algebraic Methods in Geometry,"  We describe our ongoing project of formalization of algebraic methods for
geometry theorem proving (Wu's method and the Groebner bases method), their
implementation and integration in educational tools. The project includes
formal verification of the algebraic methods within Isabelle/HOL proof
assistant and development of a new, open-source Java implementation of the
algebraic methods. The project should fill-in some gaps still existing in this
area (e.g., the lack of formal links between algebraic methods and synthetic
geometry and the lack of self-contained implementations of algebraic methods
suitable for integration with dynamic geometry tools) and should enable new
applications of theorem proving in education.
"
216,"Integrating DGSs and GATPs in an Adaptative and Collaborative
  Blended-Learning Web-Environment","  The area of geometry with its very strong and appealing visual contents and
its also strong and appealing connection between the visual content and its
formal specification, is an area where computational tools can enhance, in a
significant way, the learning environments.
  The dynamic geometry software systems (DGSs) can be used to explore the
visual contents of geometry. This already mature tools allows an easy
construction of geometric figures build from free objects and elementary
constructions. The geometric automated theorem provers (GATPs) allows formal
deductive reasoning about geometric constructions, extending the reasoning via
concrete instances in a given model to formal deductive reasoning in a
geometric theory.
  An adaptative and collaborative blended-learning environment where the DGS
and GATP features could be fully explored would be, in our opinion a very rich
and challenging learning environment for teachers and students.
  In this text we will describe the Web Geometry Laboratory a Web environment
incorporating a DGS and a repository of geometric problems, that can be used in
a synchronous and asynchronous fashion and with some adaptative and
collaborative features.
  As future work we want to enhance the adaptative and collaborative aspects of
the environment and also to incorporate a GATP, constructing a dynamic and
individualised learning environment for geometry.
"
217,"Computer-Assisted Program Reasoning Based on a Relational Semantics of
  Programs","  We present an approach to program reasoning which inserts between a program
and its verification conditions an additional layer, the denotation of the
program expressed in a declarative form. The program is first translated into
its denotation from which subsequently the verification conditions are
generated. However, even before (and independently of) any verification
attempt, one may investigate the denotation itself to get insight into the
""semantic essence"" of the program, in particular to see whether the denotation
indeed gives reason to believe that the program has the expected behavior.
Errors in the program and in the meta-information may thus be detected and
fixed prior to actually performing the formal verification. More concretely,
following the relational approach to program semantics, we model the effect of
a program as a binary relation on program states. A formal calculus is devised
to derive from a program a logic formula that describes this relation and is
subject for inspection and manipulation. We have implemented this idea in a
comprehensive form in the RISC ProgramExplorer, a new program reasoning
environment for educational purposes which encompasses the previously developed
RISC ProofNavigator as an interactive proving assistant.
"
218,Isabelle/PIDE as Platform for Educational Tools,"  The Isabelle/PIDE platform addresses the question whether proof assistants of
the LCF family are suitable as technological basis for educational tools. The
traditionally strong logical foundations of systems like HOL, Coq, or Isabelle
have so far been counter-balanced by somewhat inaccessible interaction via the
TTY (or minor variations like the well-known Proof General / Emacs interface).
Thus the fundamental question of math education tools with fully-formal
background theories has often been answered negatively due to accidental
weaknesses of existing proof engines.
  The idea of ""PIDE"" (which means ""Prover IDE"") is to integrate existing
provers like Isabelle into a larger environment, that facilitates access by
end-users and other tools. We use Scala to expose the proof engine in ML to the
JVM world, where many user-interfaces, editor frameworks, and educational tools
already exist. This shall ultimately lead to combined mathematical assistants,
where the logical engine is in the background, without obstructing the view on
applications of formal methods, formalized mathematics, and math education in
particular.
"
219,The GF Mathematics Library,"  This paper is devoted to present the Mathematics Grammar Library, a system
for multilingual mathematical text processing. We explain the context in which
it originated, its current design and functionality and the current development
goals. We also present two prototype services and comment on possible future
applications in the area of artificial mathematics assistants.
"
220,Technique detection software for Sparse Matrices,"  Sparse storage formats are techniques for storing and processing the sparse
matrix data efficiently. The performance of these storage formats depend upon
the distribution of non-zeros, within the matrix in different dimensions. In
order to have better results we need a technique that suits best the
organization of data in a particular matrix. So the decision of selecting a
better technique is the main step towards improving the system's results
otherwise the efficiency can be decreased. The purpose of this research is to
help identify the best storage format in case of reduced storage size and high
processing efficiency for a sparse matrix.
"
221,"Efficient Spherical Harmonic Transforms aimed at pseudo-spectral
  numerical simulations","  In this paper, we report on very efficient algorithms for the spherical
harmonic transform (SHT). Explicitly vectorized variations of the algorithm
based on the Gauss-Legendre quadrature are discussed and implemented in the
SHTns library which includes scalar and vector transforms. The main
breakthrough is to achieve very efficient on-the-fly computations of the
Legendre associated functions, even for very high resolutions, by taking
advantage of the specific properties of the SHT and the advanced capabilities
of current and future computers. This allows us to simultaneously and
significantly reduce memory usage and computation time of the SHT. We measure
the performance and accuracy of our algorithms. Even though the complexity of
the algorithms implemented in SHTns are in $O(N^3)$ (where N is the maximum
harmonic degree of the transform), they perform much better than any third
party implementation, including lower complexity algorithms, even for
truncations as high as N=1023. SHTns is available at
https://bitbucket.org/nschaeff/shtns as open source software.
"
222,mlpy: Machine Learning Python,"  mlpy is a Python Open Source Machine Learning library built on top of
NumPy/SciPy and the GNU Scientific Libraries. mlpy provides a wide range of
state-of-the-art machine learning methods for supervised and unsupervised
problems and it is aimed at finding a reasonable compromise among modularity,
maintainability, reproducibility, usability and efficiency. mlpy is
multiplatform, it works with Python 2 and 3 and it is distributed under GPL3 at
the website http://mlpy.fbk.eu.
"
223,"On the asymptotic and practical complexity of solving bivariate systems
  over the reals","  This paper is concerned with exact real solving of well-constrained,
bivariate polynomial systems. The main problem is to isolate all common real
roots in rational rectangles, and to determine their intersection
multiplicities. We present three algorithms and analyze their asymptotic bit
complexity, obtaining a bound of $\sOB(N^{14})$ for the purely projection-based
method, and $\sOB(N^{12})$ for two subresultant-based methods: this notation
ignores polylogarithmic factors, where $N$ bounds the degree and the bitsize of
the polynomials. The previous record bound was $\sOB(N^{14})$.
  Our main tool is signed subresultant sequences. We exploit recent advances on
the complexity of univariate root isolation, and extend them to sign evaluation
of bivariate polynomials over two algebraic numbers, and real root counting for
polynomials over an extension field. Our algorithms apply to the problem of
simultaneous inequalities; they also compute the topology of real plane
algebraic curves in $\sOB(N^{12})$, whereas the previous bound was
$\sOB(N^{14})$.
  All algorithms have been implemented in MAPLE, in conjunction with numeric
filtering. We compare them against FGB/RS, system solvers from SYNAPS, and
MAPLE libraries INSULATE and TOP, which compute curve topology. Our software is
among the most robust, and its runtimes are comparable, or within a small
constant factor, with respect to the C/C++ libraries.
  Key words: real solving, polynomial systems, complexity, MAPLE software
"
224,"Can the Eureqa symbolic regression program, computer algebra and
  numerical analysis help each other?","  The Eureqa symbolic regression program has recently received extensive press
praise. A representative quote is
  ""There are very clever 'thinking machines' in existence today, such as
Watson, the IBM computer that conquered Jeopardy! last year. But next to
Eureqa, Watson is merely a glorified search engine.""
  The program was designed to work with noisy experimental data. However, if
the data is generated from an expression for which there exists more concise
equivalent expressions, sometimes some of the Eureqa results are one or more of
those more concise equivalents. If not, perhaps one or more of the returned
Eureqa results might be a sufficiently accurate approximation that is more
concise than the given expression. Moreover, when there is no known closed form
expression, the data points can be generated by numerical methods, enabling
Eureqa to find expressions that concisely fit those data points with sufficient
accuracy. In contrast to typical regression software, the user does not have to
explicitly or implicitly provide a specific expression or class of expressions
containiing unknown constants for the software to determine.
  Is Eureqa useful enough in these regards to provide an additional tool for
experimental mathematics, computer algebra users and numerical analysis? Yes if
used carefully. Can computer algebra and numerical methods help Eureqa?
Definitely.
"
225,"General Complex Polynomial Root Solver and Its Further Optimization for
  Binary Microlenses","  We present a new algorithm to solve polynomial equations, and publish its
code, which is 1.6-3 times faster than the ZROOTS subroutine that is
commercially available from Numerical Recipes, depending on application. The
largest improvement, when compared to naive solvers, comes from a fail-safe
procedure that permits us to skip the majority of the calculations in the great
majority of cases, without risking catastrophic failure in the few cases that
these are actually required. Second, we identify a discriminant that enables a
rational choice between Laguerre's Method and Newton's Method (or a new
intermediate method) on a case-by-case basis. We briefly review the history of
root solving and demonstrate that ""Newton's Method"" was discovered neither by
Newton (1671) nor by Raphson (1690), but only by Simpson (1740). Some of the
arguments leading to this conclusion were first given by the British historian
of science Nick Kollerstrom in 1992, but these do not appear to have penetrated
the astronomical community. Finally, we argue that Numerical Recipes should
voluntarily surrender its copyright protection for non-profit applications,
despite the fact that, in this particular case, such protection was the major
stimulant for developing our improved algorithm.
"
226,"NLSEmagic: Nonlinear Schr\""odinger Equation Multidimensional
  Matlab-based GPU-accelerated Integrators using Compact High-order Schemes","  We present a simple to use, yet powerful code package called NLSEmagic to
numerically integrate the nonlinear Schr\""odinger equation in one, two, and
three dimensions. NLSEmagic is a high-order finite-difference code package
which utilizes graphic processing unit (GPU) parallel architectures. The codes
running on the GPU are many times faster than their serial counterparts, and
are much cheaper to run than on standard parallel clusters. The codes are
developed with usability and portability in mind, and therefore are written to
interface with MATLAB utilizing custom GPU-enabled C codes with the
MEX-compiler interface. The packages are freely distributed, including user
manuals and set-up files.
"
227,"Subtotal ordering -- a pedagogically advantageous algorithm for
  computing total degree reverse lexicographic order","  Total degree reverse lexicographic order is currently generally regarded as
most often fastest for computing Groebner bases. This article describes an
alternate less mysterious algorithm for computing this order using exponent
subtotals and describes why it should be very nearly the same speed the
traditional algorithm, all other things being equal. However, experimental
evidence suggests that subtotal order is actually slightly faster for the
Mathematica Groebner basis implementation more often than not. This is probably
because the weight vectors associated with the natural subtotal weight matrix
and with the usual total degree reverse lexicographic weight matrix are
different, and Mathematica also uses those the corresponding weight vectors to
help select successive S polynomials and divisor polynomials: Those selection
heuristics appear to work slightly better more often with subtotal weight
vectors.
  However, the most important advantage of exponent subtotals is pedagogical.
It is easier to understand than the total degree reverse lexicographic
algorithm, and it is more evident why the resulting order is often the fastest
known order for computing Groebner bases.
  Keywords: Term order, Total degree reverse lexicographic, tdeg, grevlex,
Groebner basis
"
228,Simplifying products of fractional powers of powers,"  Most computer algebra systems incorrectly simplify (z - z)/(sqrt(w^2)/w^3 -
1/(w*sqrt(w^2))) to 0 rather than to 0/0. The reasons for this are:
  1. The default simplification doesn't succeed in simplifying the denominator
to 0.
  2. There is a rule that 0 is the result of 0 divided by anything that doesn't
simplify to either 0 or 0/0.
  Try it on your computer algebra systems!
  This article describes how to simplify products of the form w^a*(w^b1)^g1 ...
(w^bn)^gn correctly and well, where w is any real or complex expression and the
exponents are rational numbers.
  It might seem that correct good simplification of such a restrictive
expression class must already be published and/or built into at least one
widely used computer-algebra system, but apparently this issue has been
overlooked. Default and relevant optional simplification was tested with 86
examples for n=1 on Derive, Maple, Mathematica, Maxima and TI-CAS. Totaled over
all five systems, 11% of the results were not equivalent to the input
everywhere, 50% of the results did not simplify to 0 a result that was
equivalent to 0, and at least 16% of the results exhibited one or more of four
additional flaw types. There was substantial room for improvement in all five
systems, including the two for which I was a co-author.
  The good news is: These flaws are easy to fix.
"
229,Series misdemeanors,"  Puiseux series are power series in which the exponents can be fractional
and/or negative rational numbers. Several computer algebra systems have one or
more built-in or loadable functions for computing truncated Puiseux series --
perhaps generalized to allow coefficients containing functions of the series
variable that are dominated by any power of that variable, such as logarithms
and nested logarithms of the series variable. Some computer-algebra systems
also offer functions that can compute more-general truncated recursive
hierarchical series. However, for all of these kinds of truncated series there
are important implementation details that haven't been addressed before in the
published literature and in current implementations.
  For implementers this article contains ideas for designing more convenient,
correct, and efficient implementations or improving existing ones. For users,
this article is a warning about some of these limitations. Many of the ideas in
this article have been implemented in the computer-algebra within the TI-Nspire
calculator, Windows and Macintosh products.
"
230,"AD in Fortran, Part 1: Design","  We propose extensions to Fortran which integrate forward and reverse
Automatic Differentiation (AD) directly into the programming model.
Irrespective of implementation technology, embedding AD constructs directly
into the language extends the reach and convenience of AD while allowing
abstraction of concepts of interest to scientific-computing practice, such as
root finding, optimization, and finding equilibria of continuous games.
Multiple different subprograms for these tasks can share common interfaces,
regardless of whether and how they use AD internally. A programmer can maximize
a function F by calling a library maximizer, XSTAR=ARGMAX(F,X0), which
internally constructs derivatives of F by AD, without having to learn how to
use any particular AD tool. We illustrate the utility of these extensions by
example: programs become much more concise and closer to traditional
mathematical notation. A companion paper describes how these extensions can be
implemented by a program that generates input to existing Fortran-based AD
tools.
"
231,"AD in Fortran, Part 2: Implementation via Prepreprocessor","  We describe an implementation of the Farfel Fortran AD extensions. These
extensions integrate forward and reverse AD directly into the programming
model, with attendant benefits to flexibility, modularity, and ease of use. The
implementation we describe is a ""prepreprocessor"" that generates input to
existing Fortran-based AD tools. In essence, blocks of code which are targeted
for AD by Farfel constructs are put into subprograms which capture their
lexical variable context, and these are closure-converted into top-level
subprograms and specialized to eliminate EXTERNAL arguments, rendering them
amenable to existing AD preprocessors, which are then invoked, possibly
repeatedly if the AD is nested.
"
232,An Optimized Sparse Approximate Matrix Multiply for Matrices with Decay,"  We present an optimized single-precision implementation of the Sparse
Approximate Matrix Multiply (\SpAMM{}) [M. Challacombe and N. Bock, arXiv {\bf
1011.3534} (2010)], a fast algorithm for matrix-matrix multiplication for
matrices with decay that achieves an $\mathcal{O} (n \log n)$ computational
complexity with respect to matrix dimension $n$. We find that the max norm of
the error achieved with a \SpAMM{} tolerance below $2 \times 10^{-8}$ is lower
than that of the single-precision {\tt SGEMM} for dense quantum chemical
matrices, while outperforming {\tt SGEMM} with a cross-over already for small
matrices ($n \sim 1000$). Relative to naive implementations of \SpAMM{} using
Intel's Math Kernel Library ({\tt MKL}) or AMD's Core Math Library ({\tt
ACML}), our optimized version is found to be significantly faster. Detailed
performance comparisons are made for quantum chemical matrices with differently
structured sub-blocks. Finally, we discuss the potential of improved hardware
prefetch to yield 2--3x speedups.
"
233,Set Reduction In Nonlinear Equations,"  In this paper, an idea to solve nonlinear equations is presented. During the
solution of any problem with Newton's Method, it might happen that some of the
unknowns satisfy the convergence criteria where the others fail. The
convergence happens only when all variables reach to the convergence limit. A
method to reduce the dimension of the overall system by excluding some of the
unknowns that satisfy an intermediate tolerance is introduced. In this
approach, a smaller system is solved in less amount of time and already
established local solutions are preserved and kept as constants while the other
variables that belong to the ""set"" will be relaxed. To realize the idea, an
algorithm is given that utilizes applications of pointers to reduce and
evaluate the sets. Matrix-free Newton-Krylov Techniques are used on a test
problem and it is shown that proposed idea improves the overall convergence.
"
234,Scilab and SIP for Image Processing,"  This paper is an overview of Image Processing and Analysis using Scilab, a
free prototyping environment for numerical calculations similar to Matlab. We
demonstrate the capabilities of SIP -- the Scilab Image Processing Toolbox --
which extends Scilab with many functions to read and write images in over 100
major file formats, including PNG, JPEG, BMP, and TIFF. It also provides
routines for image filtering, edge detection, blurring, segmentation, shape
analysis, and image recognition. Basic directions to install Scilab and SIP are
given, and also a mini-tutorial on Scilab. Three practical examples of image
analysis are presented, in increasing degrees of complexity, showing how
advanced image analysis techniques seems uncomplicated in this environment.
"
235,FEAST Eigenvalue Solver v3.0 User Guide,"  The FEAST eigensolver package is a free high-performance numerical library
for solving the Hermitian and non-Hermitian eigenvalue problems, and obtaining
all the eigenvalues and (right/left) eigenvectors within a given search
interval or arbitrary contour in the complex plane. Its originality lies with a
new transformative numerical approach to the traditional eigenvalue algorithm
design - the FEAST algorithm. The FEAST eigensolver combines simplicity and
efficiency and it offers many important capabilities for achieving high
performance, robustness, accuracy, and scalability on parallel architectures.
FEAST is both a comprehensive library package, and an easy to use software. It
includes flexible reverse communication interfaces and ready to use predefined
interfaces for dense, banded and sparse systems. The current version v3.0 of
the FEAST package can address both Hermitian and non-Hermitian eigenvalue
problems (real symmetric, real non-symmetric, complex Hermitian, complex
symmetric, or complex general systems) on both shared-memory and distributed
memory architectures (i.e contains both FEAST-SMP and FEAST-MPI packages). This
User's guide provides instructions for installation setup, a detailed
description of the FEAST interfaces and a large number of examples.
"
236,Series Crimes,"  Puiseux series are power series in which the exponents can be fractional
and/or negative rational numbers. Several computer algebra systems have one or
more built-in or loadable functions for computing truncated Puiseux series.
Some are generalized to allow coefficients containing functions of the series
variable that are dominated by any power of that variable, such as logarithms
and nested logarithms of the series variable. Some computer algebra systems
also have built-in or loadable functions that compute infinite Puiseux series.
Unfortunately, there are some little-known pitfalls in computing Puiseux
series. The most serious of these is expansions within branch cuts or at branch
points that are incorrect for some directions in the complex plane. For example
with each series implementation accessible to you:
  Compare the value of (z^2 + z^3)^(3/2) with that of its truncated series
expansion about z = 0, approximated at z = -0.01. Does the series converge to a
value that is the negative of the correct value?
  Compare the value of ln(z^2 + z^3) with its truncated series expansion about
z = 0, approximated at z = -0.01 + 0.1i. Does the series converge to a value
that is incorrect by 2pi i?
  Compare arctanh(-2 + ln(z)z) with its truncated series expansion about z = 0,
approximated at z = -0.01. Does the series converge to a value that is
incorrect by about pi i?
  At the time of this writing, most implementations that accommodate such
series exhibit such errors. This article describes how to avoid these errors
both for manual derivation of series and when implementing series packages.
"
237,The Kernel Quantum Probabilities (KQP) Library,"  In this document, we show how the different quantities necessary to compute
kernel quantum probabilities can be computed. This document form the basis of
the implementation of the Kernel Quantum Probability (KQP) open source project
"
238,Theory Presentation Combinators,"  We motivate and give semantics to theory presentation combinators as the
foundational building blocks for a scalable library of theories. The key
observation is that the category of contexts and fibered categories are the
ideal theoretical tools for this purpose.
"
239,"Computational science and re-discovery: open-source implementations of
  ellipsoidal harmonics for problems in potential theory","  We present two open-source (BSD) implementations of ellipsoidal harmonic
expansions for solving problems of potential theory using separation of
variables. Ellipsoidal harmonics are used surprisingly infrequently,
considering their substantial value for problems ranging in scale from
molecules to the entire solar system. In this article, we suggest two possible
reasons for the paucity relative to spherical harmonics. The first is
essentially historical---ellipsoidal harmonics developed during the late 19th
century and early 20th, when it was found that only the lowest-order harmonics
are expressible in closed form. Each higher-order term requires the solution of
an eigenvalue problem, and tedious manual computation seems to have discouraged
applications and theoretical studies. The second explanation is practical: even
with modern computers and accurate eigenvalue algorithms, expansions in
ellipsoidal harmonics are significantly more challenging to compute than those
in Cartesian or spherical coordinates. The present implementations reduce the
""barrier to entry"" by providing an easy and free way for the community to begin
using ellipsoidal harmonics in actual research. We demonstrate our
implementation using the specific and physiologically crucial problem of how
charged proteins interact with their environment, and ask: what other
analytical tools await re-discovery in an era of inexpensive computation?
"
240,TeXmacs-Reduce interface,"  This tutorial (based on the talk at the TeXmacs workshop in Faro, Portugal,
February 26 - March 2, 2012) describes the new and improved Reduce plugin in
GNU TeXmacs.
"
241,"Heterogeneous Highly Parallel Implementation of Matrix Exponentiation
  Using GPU","  The vision of super computer at every desk can be realized by powerful and
highly parallel CPUs or GPUs or APUs. Graphics processors once specialized for
the graphics applications only, are now used for the highly computational
intensive general purpose applications. Very expensive GFLOPs and TFLOP
performance has become very cheap with the GPGPUs. Current work focuses mainly
on the highly parallel implementation of Matrix Exponentiation. Matrix
Exponentiation is widely used in many areas of scientific community ranging
from highly critical flight, CAD simulations to financial, statistical
applications. Proposed solution for Matrix Exponentiation uses OpenCL for
exploiting the hyper parallelism offered by the many core GPGPUs. It employs
many general GPU optimizations and architectural specific optimizations. This
experimentation covers the optimizations targeted specific to the Scientific
Graphics cards (Tesla-C2050). Heterogeneous Highly Parallel Matrix
Exponentiation method has been tested for matrices of different sizes and with
different powers. The devised Kernel has shown 1000X speedup and 44 fold
speedup with the naive GPU Kernel.
"
242,"Block-Structured Adaptive Mesh Refinement Algorithms for Vlasov
  Simulation","  Direct discretization of continuum kinetic equations, like the Vlasov
equation, are under-utilized because the distribution function generally exists
in a high-dimensional (>3D) space and computational cost increases
geometrically with dimension. We propose to use high-order finite-volume
techniques with block-structured adaptive mesh refinement (AMR) to reduce the
computational cost. The primary complication comes from a solution state
comprised of variables of different dimensions. We develop the algorithms
required to extend standard single-dimension block structured AMR to the
multi-dimension case. Specifically, algorithms for reduction and injection
operations that transfer data between mesh hierarchies of different dimensions
are explained in detail. In addition, modifications to the basic AMR algorithm
that enable the use of high-order spatial and temporal discretizations are
discussed. Preliminary results for a standard 1D+1V Vlasov-Poisson test problem
are presented. Results indicate that there is potential for significant savings
for some classes of Vlasov problems.
"
243,"Reimplementing the Mathematical Subject Classification (MSC) as a Linked
  Open Dataset","  The Mathematics Subject Classification (MSC) is a widely used scheme for
classifying documents in mathematics by subject. Its traditional, idiosyncratic
conceptualization and representation makes the scheme hard to maintain and
requires custom implementations of search, query and annotation support. This
limits uptake e.g. in semantic web technologies in general and the creation and
exploration of connections between mathematics and related domains (e.g.
science) in particular.
  This paper presents the new official implementation of the MSC2010 as a
Linked Open Dataset, building on SKOS (Simple Knowledge Organization System).
We provide a brief overview of the dataset's structure, its available
implementations, and first applications.
"
244,Point-and-write --- Documenting Formal Mathematics by Reference,"  This paper describes the design and implementation of mechanisms for
light-weight inclusion of formal mathematics in informal mathematical writings,
particularly in a Web-based setting. This is conceptually done in three stages:
(i) by choosing a suitable representation layer (based on RDF) for encoding the
information about available resources of formal mathematics, (ii) by exporting
this information from formal libraries, and (iii) by providing syntax and
implementation for including formal mathematics in informal writings.
  We describe the use case of an author referring to formal text from an
informal narrative, and discuss design choices entailed by this use case.
Furthermore, we describe an implementation of the use case within the Agora
prototype: a Wiki for collaborating on formalized mathematics.
"
245,"Automated derivation of the adjoint of high-level transient finite
  element programs","  In this paper we demonstrate a new technique for deriving discrete adjoint
and tangent linear models of finite element models. The technique is
significantly more efficient and automatic than standard algorithmic
differentiation techniques. The approach relies on a high-level symbolic
representation of the forward problem. In contrast to developing a model
directly in Fortran or C++, high-level systems allow the developer to express
the variational problems to be solved in near-mathematical notation. As such,
these systems have a key advantage: since the mathematical structure of the
problem is preserved, they are more amenable to automated analysis and
manipulation. The framework introduced here is implemented in a freely
available software package named dolfin-adjoint, based on the FEniCS Project.
Our approach to automated adjoint derivation relies on run-time annotation of
the temporal structure of the model, and employs the FEniCS finite element form
compiler to automatically generate the low-level code for the derived models.
The approach requires only trivial changes to a large class of forward models,
including complicated time-dependent nonlinear models. The adjoint model
automatically employs optimal checkpointing schemes to mitigate storage
requirements for nonlinear models, without any user management or intervention.
Furthermore, both the tangent linear and adjoint models naturally work in
parallel, without any need to differentiate through calls to MPI or to parse
OpenMP directives. The generality, applicability and efficiency of the approach
are demonstrated with examples from a wide range of scientific applications.
"
246,"Automating embedded analysis capabilities and managing software
  complexity in multiphysics simulation part I: template-based generic
  programming","  An approach for incorporating embedded simulation and analysis capabilities
in complex simulation codes through template-based generic programming is
presented. This approach relies on templating and operator overloading within
the C++ language to transform a given calculation into one that can compute a
variety of additional quantities that are necessary for many state-of-the-art
simulation and analysis algorithms. An approach for incorporating these ideas
into complex simulation codes through general graph-based assembly is also
presented. These ideas have been implemented within a set of packages in the
Trilinos framework and are demonstrated on a simple problem from chemical
engineering.
"
247,Reliable Generation of High-Performance Matrix Algebra,"  Scientific programmers often turn to vendor-tuned Basic Linear Algebra
Subprograms (BLAS) to obtain portable high performance. However, many numerical
algorithms require several BLAS calls in sequence, and those successive calls
result in suboptimal performance. The entire sequence needs to be optimized in
concert. Instead of vendor-tuned BLAS, a programmer could start with source
code in Fortran or C (e.g., based on the Netlib BLAS) and use a
state-of-the-art optimizing compiler. However, our experiments show that
optimizing compilers often attain only one-quarter the performance of
hand-optimized code. In this paper we present a domain-specific compiler for
matrix algebra, the Build to Order BLAS (BTO), that reliably achieves high
performance using a scalable search algorithm for choosing the best combination
of loop fusion, array contraction, and multithreading for data parallelism. The
BTO compiler generates code that is between 16% slower and 39% faster than
hand-optimized code.
"
248,High-Performance Solvers for Dense Hermitian Eigenproblems,"  We introduce a new collection of solvers - subsequently called EleMRRR - for
large-scale dense Hermitian eigenproblems. EleMRRR solves various types of
problems: generalized, standard, and tridiagonal eigenproblems. Among these,
the last is of particular importance as it is a solver on its own right, as
well as the computational kernel for the first two; we present a fast and
scalable tridiagonal solver based on the Algorithm of Multiple Relatively
Robust Representations - referred to as PMRRR. Like the other EleMRRR solvers,
PMRRR is part of the freely available Elemental library, and is designed to
fully support both message-passing (MPI) and multithreading parallelism (SMP).
As a result, the solvers can equally be used in pure MPI or in hybrid MPI-SMP
fashion. We conducted a thorough performance study of EleMRRR and ScaLAPACK's
solvers on two supercomputers. Such a study, performed with up to 8,192 cores,
provides precise guidelines to assemble the fastest solver within the ScaLAPACK
framework; it also indicates that EleMRRR outperforms even the fastest solvers
built from ScaLAPACK's components.
"
249,Isogeometric analysis: an overview and computer implementation aspects,"  Isogeometric analysis (IGA) represents a recently developed technology in
computational mechanics that offers the possibility of integrating methods for
analysis and Computer Aided Design (CAD) into a single, unified process. The
implications to practical engineering design scenarios are profound, since the
time taken from design to analysis is greatly reduced, leading to dramatic
gains in efficiency. The tight coupling of CAD and analysis within IGA requires
knowledge from both fields and it is one of the goals of the present paper to
outline much of the commonly used notation. In this manuscript, through a clear
and simple Matlab implementation, we present an introduction to IGA applied to
the Finite Element (FE) method and related computer implementation aspects.
Furthermore, implemen- tation of the extended IGA which incorporates enrichment
functions through the partition of unity method (PUM) is also presented, where
several examples for both two-dimensional and three-dimensional fracture are
illustrated. The open source Matlab code which accompanies the present paper
can be applied to one, two and three-dimensional problems for linear
elasticity, linear elastic fracture mechanics, structural mechanics
(beams/plates/shells including large displacements and rotations) and Poisson
problems with or without enrichment. The Bezier extraction concept that allows
FE analysis to be performed efficiently on T-spline geometries is also
incorporated. The article includes a summary of recent trends and developments
within the field of IGA.
"
250,"A Heterogeneous Accelerated Matrix Multiplication: OpenCL + APU + GPU+
  Fast Matrix Multiply","  As users and developers, we are witnessing the opening of a new computing
scenario: the introduction of hybrid processors into a single die, such as an
accelerated processing unit (APU) processor, and the plug-and-play of
additional graphics processing units (GPUs) onto a single motherboard. These
APU processors provide multiple symmetric cores with their memory hierarchies
and an integrated GPU. Moreover, these processors are designed to work with
external GPUs that can push the peak performance towards the TeraFLOPS
boundary. We present a case study for the development of dense Matrix
Multiplication (MM) codes for matrix sizes up to 19K\times19K, thus using all
of the above computational engines, and an achievable peak performance of 200
GFLOPS for, literally, a made- at-home built. We present the results of our
experience, the quirks, the pitfalls, the achieved performance, and the
achievable peak performance.
"
251,"Efficient Expression Templates for Operator Overloading-based Automatic
  Differentiation","  Expression templates are a well-known set of techniques for improving the
efficiency of operator overloading-based forward mode automatic differentiation
schemes in the C++ programming language by translating the differentiation from
individual operators to whole expressions. However standard expression template
approaches result in a large amount of duplicate computation, particularly for
large expression trees, degrading their performance. In this paper we describe
several techniques for improving the efficiency of expression templates and
their implementation in the automatic differentiation package Sacado. We
demonstrate their improved efficiency through test functions as well as their
application to differentiation of a large-scale fluid dynamics simulation code.
"
252,"Automating embedded analysis capabilities and managing software
  complexity in multiphysics simulation part II: application to partial
  differential equations","  A template-based generic programming approach was presented in a previous
paper that separates the development effort of programming a physical model
from that of computing additional quantities, such as derivatives, needed for
embedded analysis algorithms. In this paper, we describe the implementation
details for using the template-based generic programming approach for
simulation and analysis of partial differential equations (PDEs). We detail
several of the hurdles that we have encountered, and some of the software
infrastructure developed to overcome them. We end with a demonstration where we
present shape optimization and uncertainty quantification results for a 3D PDE
application.
"
253,Sample programs in C++ for matrix computations in max plus algebra,"  The main purpose of this paper is to propose five programs in C++ for matrix
computations and solving recurrent equations systems with entries in max plus
algebra.
"
254,A Domain-Specific Compiler for Linear Algebra Operations,"  We present a prototypical linear algebra compiler that automatically exploits
domain-specific knowledge to generate high-performance algorithms. The input to
the compiler is a target equation together with knowledge of both the structure
of the problem and the properties of the operands. The output is a variety of
high-performance algorithms, and the corresponding source code, to solve the
target equation. Our approach consists in the decomposition of the input
equation into a sequence of library-supported kernels. Since in general such a
decomposition is not unique, our compiler returns not one but a number of
algorithms. The potential of the compiler is shown by means of its application
to a challenging equation arising within the genome-wide association study. As
a result, the compiler produces multiple ""best"" algorithms that outperform the
best existing libraries.
"
255,OpenGM: A C++ Library for Discrete Graphical Models,"  OpenGM is a C++ template library for defining discrete graphical models and
performing inference on these models, using a wide range of state-of-the-art
algorithms. No restrictions are imposed on the factor graph to allow for
higher-order factors and arbitrary neighborhood structures. Large models with
repetitive structure are handled efficiently because (i) functions that occur
repeatedly need to be stored only once, and (ii) distinct functions can be
implemented differently, using different encodings alongside each other in the
same model. Several parametric functions (e.g. metrics), sparse and dense value
tables are provided and so is an interface for custom C++ code. Algorithms are
separated by design from the representation of graphical models and are easily
exchangeable. OpenGM, its algorithms, HDF5 file format and command line tools
are modular and extendible.
"
256,Parallelizing Mizar,"  This paper surveys and describes the implementation of parallelization of the
Mizar proof checking and of related Mizar utilities. The implementation makes
use of Mizar's compiler-like division into several relatively independent
passes, with typically quite different processing speeds. The information
produced in earlier (typically much faster) passes can be used to parallelize
the later (typically much slower) passes. The parallelization now works by
splitting the formalization into a suitable number of pieces that are processed
in parallel, assembling from them together the required results. The
implementation is evaluated on examples from the Mizar library, and future
extensions are discussed.
"
257,Parallel random variates generator for GPUs based on normal numbers,"  Pseudorandom number generators are required for many computational tasks,
such as stochastic modelling and simulation. This paper investigates the serial
CPU and parallel GPU implementation of a Linear Congruential Generator based on
the binary representation of the normal number $\alpha_{2,3}$. We adapted two
methods of modular reduction which allowed us to perform most operations in
64-bit integer arithmetic, improving on the original implementation based on
106-bit double-double operations. We found that our implementation is faster
than existing methods in literature, and our generation rate is close to the
limiting rate imposed by the efficiency of writing to a GPU's global memory.
"
258,"Performance of FORTRAN and C GPU Extensions for a Benchmark Suite of
  Fourier Pseudospectral Algorithms","  A comparison of PGI OpenACC, FORTRAN CUDA, and Nvidia CUDA pseudospectral
methods on a single GPU and GCC FORTRAN on single and multiple CPU cores is
reported. The GPU implementations use CuFFT and the CPU implementations use
FFTW. Porting pre-existing FORTRAN codes to utilize a GPUs is efficient and
easy to implement with OpenACC and CUDA FORTRAN. Example programs are provided.
"
259,Bayesian Modeling with Gaussian Processes using the GPstuff Toolbox,"  Gaussian processes (GP) are powerful tools for probabilistic modeling
purposes. They can be used to define prior distributions over latent functions
in hierarchical Bayesian models. The prior over functions is defined implicitly
by the mean and covariance function, which determine the smoothness and
variability of the function. The inference can then be conducted directly in
the function space by evaluating or approximating the posterior process.
Despite their attractive theoretical properties GPs provide practical
challenges in their implementation. GPstuff is a versatile collection of
computational tools for GP models compatible with Linux and Windows MATLAB and
Octave. It includes, among others, various inference methods, sparse
approximations and tools for model assessment. In this work, we review these
tools and demonstrate the use of GPstuff in several models.
"
260,"Utilizing Static Analysis and Code Generation to Accelerate Neural
  Networks","  As datasets continue to grow, neural network (NN) applications are becoming
increasingly limited by both the amount of available computational power and
the ease of developing high-performance applications. Researchers often must
have expert systems knowledge to make their algorithms run efficiently.
Although available computing power increases rapidly each year, algorithm
efficiency is not able to keep pace due to the use of general purpose
compilers, which are not able to fully optimize specialized application
domains. Within the domain of NNs, we have the added knowledge that network
architecture remains constant during training, meaning the architecture's data
structure can be statically optimized by a compiler. In this paper, we present
SONNC, a compiler for NNs that utilizes static analysis to generate optimized
parallel code. We show that SONNC's use of static optimizations make it able to
outperform hand-optimized C++ code by up to 7.8X, and MATLAB code by up to 24X.
Additionally, we show that use of SONNC significantly reduces code complexity
when using structurally sparse networks.
"
261,Multivariate Polynomials in Sage,"  We have developed a patch implementing multivariate polynomials seen as a
multi-base algebra. The patch is to be released into the software Sage and can
already be found within the Sage-Combinat distribution. One can use our patch
to define a polynomial in a set of indexed variables and expand it into a
linear basis of the multivariate polynomials. So far, we have the Schubert
polynomials, the Key polynomials of types A, B, C, or D, the Grothendieck
polynomials and the non-symmetric Macdonald polynomials. One can also use a
double set of variables and work with specific double-linear bases like the
double Schubert polynomials or double Grothendieck polynomials. Our
implementation is based on a definition of the basis using divided difference
operators and one can also define new bases using these operators.
"
262,"Modular Arithmetic Expressions and Primality Testing via DNA
  Self-Assembly","  Self-assembly is a fundamental process by which supramolecular species form
spontaneously from their components. This process is ubiquitous throughout the
life chemistry and is central to biological information processing. Algorithms
for solving many mathematical and computational problems via tile self assembly
have been proposed by many researchers in the last decade. In particular tile
set for doing basic arithmetic of two inputs have been given. In this work we
give tile set for doing basic arithmetic (addition, subtraction,
multiplication) of n inputs and subsequently computing its modulo. We also
present a tile set for primality testing. Finally we present a software
'xtilemod' for doing modular arithmetic. This simplifies the task of creating
the input files to xgrow simulator for doing basic (addition, subtraction,
multiplication and division) as well as modular arithmetic of n inputs. Similar
software for creating tile set for primality testing is also given.
"
263,"Bayes Blocks: An Implementation of the Variational Bayesian Building
  Blocks Framework","  A software library for constructing and learning probabilistic models is
presented. The library offers a set of building blocks from which a large
variety of static and dynamic models can be built. These include hierarchical
models for variances of other variables and many nonlinear models. The
underlying variational Bayesian machinery, providing for fast and robust
estimation but being mathematically rather involved, is almost completely
hidden from the user thus making it very easy to use the library. The building
blocks include Gaussian, rectified Gaussian and mixture-of-Gaussians variables
and computational nodes which can be combined rather freely.
"
264,Discovery of non-gaussian linear causal models using ICA,"  In recent years, several methods have been proposed for the discovery of
causal structure from non-experimental data (Spirtes et al. 2000; Pearl 2000).
Such methods make various assumptions on the data generating process to
facilitate its identification from purely observational data. Continuing this
line of research, we show how to discover the complete causal structure of
continuous-valued data, under the assumptions that (a) the data generating
process is linear, (b) there are no unobserved confounders, and (c) disturbance
variables have non-gaussian distributions of non-zero variances. The solution
relies on the use of the statistical method known as independent component
analysis (ICA), and does not require any pre-specified time-ordering of the
variables. We provide a complete Matlab package for performing this LiNGAM
analysis (short for Linear Non-Gaussian Acyclic Model), and demonstrate the
effectiveness of the method using artificially generated data.
"
265,A Generic Library for Stencil Computations,"  In this era of diverse and heterogeneous computer architectures, the
programmability issues, such as productivity and portable efficiency, are
crucial to software development and algorithm design. One way to approach the
problem is to step away from traditional sequential programming languages and
move toward domain specific programming environments to balance between
expressivity and efficiency. In order to demonstrate this principle, we
developed a domain specific C++ generic library for stencil computations, like
PDE solvers. The library features high level constructs to specify computation
and allows the development of parallel stencil computations with very limited
effort. The high abstraction constructs (like do_all and do_reduce) make the
program shorter and cleaner with increased contextual information for better
performance exploitation. The results show good performance from Windows
multicores, to HPC clusters and machines with accelerators, like GPUs.
"
266,"How good are MatLab, Octave and Scilab for Computational Modelling?","  In this article we test the accuracy of three platforms used in computational
modelling: MatLab, Octave and Scilab, running on i386 architecture and three
operating systems (Windows, Ubuntu and Mac OS). We submitted them to numerical
tests using standard data sets and using the functions provided by each
platform. A Monte Carlo study was conducted in some of the datasets in order to
verify the stability of the results with respect to small departures from the
original input. We propose a set of operations which include the computation of
matrix determinants and eigenvalues, whose results are known. We also used data
provided by NIST (National Institute of Standards and Technology), a protocol
which includes the computation of basic univariate statistics (mean, standard
deviation and first-lag correlation), linear regression and extremes of
probability distributions. The assessment was made comparing the results
computed by the platforms with certified values, that is, known results,
computing the number of correct significant digits.
"
267,On Formal Specification of Maple Programs,"  This paper is an example-based demonstration of our initial results on the
formal specification of programs written in the computer algebra language
MiniMaple (a substantial subset of Maple with slight extensions). The main goal
of this work is to define a verification framework for MiniMaple. Formal
specification of MiniMaple programs is rather complex task as it supports
non-standard types of objects, e.g. symbols and unevaluated expressions, and
additional functions and predicates, e.g. runtime type tests etc. We have used
the specification language to specify various computer algebra concepts
respective objects of the Maple package DifferenceDifferential developed at our
institute.
"
268,Towards the Formal Specification and Verification of Maple Programs,"  In this paper, we present our ongoing work and initial results on the formal
specification and verification of MiniMaple (a substantial subset of Maple with
slight extensions) programs. The main goal of our work is to find behavioral
errors in such programs w.r.t. their specifications by static analysis. This
task is more complex for widely used computer algebra languages like Maple as
these are fundamentally different from classical languages: they support
non-standard types of objects such as symbols, unevaluated expressions and
polynomials and require abstract computer algebraic concepts and objects such
as rings and orderings etc. As a starting point we have defined and formalized
a syntax, semantics, type system and specification language for MiniMaple.
"
269,"Verifying an algorithm computing Discrete Vector Fields for digital
  imaging","  In this paper, we present a formalization of an algorithm to construct
admissible discrete vector fields in the Coq theorem prover taking advantage of
the SSReflect library. Discrete vector fields are a tool which has been
welcomed in the homological analysis of digital images since it provides a
procedure to reduce the amount of information but preserving the homological
properties. In particular, thanks to discrete vector fields, we are able to
compute, inside Coq, homological properties of biomedical images which
otherwise are out of the reach of this system.
"
270,Isabelle/jEdit --- a Prover IDE within the PIDE framework,"  PIDE is a general framework for document-oriented prover interaction and
integration, based on a bilingual architecture that combines ML and Scala. The
overall aim is to connect LCF-style provers like Isabelle (or Coq or HOL) with
sophisticated front-end technology on the JVM platform, overcoming command-line
interaction at last.
  The present system description specifically covers Isabelle/jEdit as part of
the official release of Isabelle2011-1 (October 2011). It is a concrete Prover
IDE implementation based on Isabelle/PIDE library modules (implemented in
Scala) on the one hand, and the well-known text editor framework of jEdit
(implemented in Java) on the other hand.
  The interaction model of our Prover IDE follows the idea of continuous proof
checking: the theory source text is annotated by semantic information by the
prover as it becomes available incrementally. This works via an asynchronous
protocol that neither blocks the editor nor stops the prover from exploiting
parallelism on multi-core hardware. The jEdit GUI provides standard metaphors
for augmented text editing (highlighting, squiggles, tooltips, hyperlinks etc.)
that we have instrumented to render the formal content from the prover context.
Further refinement of the jEdit display engine via suitable plugins and fonts
approximates mathematical rendering in the text buffer, including symbols from
the TeX repertoire, and sub-/superscripts.
  Isabelle/jEdit is presented here both as a usable interface for current
Isabelle, and as a reference application to inspire further projects based on
PIDE.
"
271,"Swarm-NG: a CUDA Library for Parallel n-body Integrations with focus on
  Simulations of Planetary Systems","  We present Swarm-NG, a C++ library for the efficient direct integration of
many n-body systems using highly-parallel Graphics Processing Unit (GPU), such
as NVIDIA's Tesla T10 and M2070 GPUs. While previous studies have demonstrated
the benefit of GPUs for n-body simulations with thousands to millions of
bodies, Swarm-NG focuses on many few-body systems, e.g., thousands of systems
with 3...15 bodies each, as is typical for the study of planetary systems.
Swarm-NG parallelizes the simulation, including both the numerical integration
of the equations of motion and the evaluation of forces using NVIDIA's ""Compute
Unified Device Architecture"" (CUDA) on the GPU. Swarm-NG includes optimized
implementations of 4th order time-symmetrized Hermite integration and mixed
variable symplectic integration, as well as several sample codes for other
algorithms to illustrate how non-CUDA-savvy users may themselves introduce
customized integrators into the Swarm-NG framework. To optimize performance, we
analyze the effect of GPU-specific parameters on performance under double
precision.
  Applications of Swarm-NG include studying the late stages of planet
formation, testing the stability of planetary systems and evaluating the
goodness-of-fit between many planetary system models and observations of
extrasolar planet host stars (e.g., radial velocity, astrometry, transit
timing). While Swarm-NG focuses on the parallel integration of many planetary
systems,the underlying integrators could be applied to a wide variety of
problems that require repeatedly integrating a set of ordinary differential
equations many times using different initial conditions and/or parameter
values.
"
272,"Computational topology with Regina: Algorithms, heuristics and
  implementations","  Regina is a software package for studying 3-manifold triangulations and
normal surfaces. It includes a graphical user interface and Python bindings,
and also supports angle structures, census enumeration, combinatorial
recognition of triangulations, and high-level functions such as 3-sphere
recognition, unknot recognition and connected sum decomposition.
  This paper brings 3-manifold topologists up-to-date with Regina as it appears
today, and documents for the first time in the literature some of the key
algorithms, heuristics and implementations that are central to Regina's
performance. These include the all-important simplification heuristics, key
choices of data structures and algorithms to alleviate bottlenecks in normal
surface enumeration, modern implementations of 3-sphere recognition and
connected sum decomposition, and more. We also give some historical background
for the project, including the key role played by Rubinstein in its genesis 15
years ago, and discuss current directions for future development.
"
273,"Analytical Nonlocal Electrostatics Using Eigenfunction Expansions of
  Boundary-Integral Operators","  In this paper, we present an analytical solution to nonlocal continuum
electrostatics for an arbitrary charge distribution in a spherical solute. Our
approach relies on two key steps: (1) re-formulating the PDE problem using
boundary-integral equations, and (2) diagonalizing the boundary-integral
operators using the fact their eigenfunctions are the surface spherical
harmonics. To introduce this uncommon approach for analytical calculations in
separable geometries, we rederive Kirkwood's classic results for a protein
surrounded concentrically by a pure-water ion-exclusion layer and then a dilute
electrolyte (modeled with the linearized Poisson--Boltzmann equation). Our main
result, however, is an analytical method for calculating the reaction potential
in a protein embedded in a nonlocal-dielectric solvent, the Lorentz model
studied by Dogonadze and Kornyshev. The analytical method enables biophysicists
to study the new nonlocal theory in a simple, computationally fast way; an
open-source MATLAB implementation is included as supplemental information.
"
274,"Employing online quantum random number generators for generating truly
  random quantum states in Mathematica","  We present a new version of TRQS package for Mathematica computing system.
The package allows harnessing quantum random number generators (QRNG) for
investigating the statistical properties of quantum states. It implements a
number of functions for generating random states. The new version of the
package adds the ability to use the on-line quantum random number generator
service and implements new functions for retrieving lists of random numbers.
Thanks to the introduced improvements, the new version provides faster access
to high-quality sources of random numbers and can be used in simulations
requiring large amount of random data.
"
275,"Hamilton Operators, Discrete Symmetries, Brute Force and SymbolicC++","  To find the discrete symmetries of a Hamilton operator $\hat H$ is of central
importance in quantum theory. Here we describe and implement a brute force
method to determine the discrete symmetries given by permutation matrices for
Hamilton operators acting in a finite-dimensional Hilbert space. Spin and Fermi
systems are considered as examples. A computer algebra implementation in
SymbolicC++ is provided.
"
276,"User Manual for the Complex Conjugate Gradient Methods Library CCGPAK
  2.0","  This manual describes the library of conjugate gradients codes CCGPAK, which
solves system of complex linear system of equations. The library is written in
FORTRAN90 and is highly portable. The codes are general and provide mechanism
for matrix times vector multiplication which is separated from the conjugate
gradient iterations itself. It is simple to switch between single and double
precisions. All codes follow the same naming conventions.
"
277,"Parallel Random Search Algorithm of Constrained Pseudo-Boolean
  Optimization for Some Distinctive Large-Scale Problems","  In this paper, we consider an approach to the parallelizing of the algorithms
realizing the modified probability changigng method with adaptation and partial
rollback procedure for constrained pseudo-Boolean optimization problems.
Existing optimization algorithms are adapted for the shared memory and clusters
(PVM library). The parallel efficiency is estimated for the lagre-scale
non-linear pseudo-Boolean optimization problems with linear constraints.
Initially designed for unconstrained optimization, the probability changing
method (MIVER) allows us finding the approximate solution of different linear
and non-linear pseudo-Boolean optimization problems with constraints. Although,
in case of large-scale problems, the computational demands are also very high
and the precision of the result depends on the time spent. In case of the
constrained optimization problem, even the search of any permissibly solution
can take very large computational resources. The rapid development of the
parallel processor systems which are often implemented even in the computer
systems designed for home use allows to reduce significantly the time spent to
find the acceptable solution with a speed-up close to ideal.
"
278,Lambert W Function for Applications in Physics,"  The Lambert W(x) function and its possible applications in physics are
presented. The actual numerical implementation in C++ consists of Halley's and
Fritsch's iterations with initial approximations based on branch-point
expansion, asymptotic series, rational fits, and continued-logarithm recursion.
"
279,"A Massively Parallel Algebraic Multigrid Preconditioner based on
  Aggregation for Elliptic Problems with Heterogeneous Coefficients","  This paper describes a massively parallel algebraic multigrid method based on
non-smoothed aggregation. It is especially suited for solving heterogeneous
elliptic problems as it uses a greedy heuristic algorithm for the aggregation
that detects changes in the coefficients and prevents aggregation across them.
Using decoupled aggregation on each process with data agglomeration onto fewer
processes on the coarse level, it weakly scales well in terms of both total
time to solution and time per iteration to nearly 300,000 cores. Because of
simple piecewise constant interpolation between the levels, its memory
consumption is low and allows solving problems with more than 100,000,000,000
degrees of freedom.
"
280,"A C++11 implementation of arbitrary-rank tensors for high-performance
  computing","  This article discusses an efficient implementation of tensors of arbitrary
rank by using some of the idioms introduced by the recently published C++ ISO
Standard (C++11). With the aims at providing a basic building block for
high-performance computing, a single Array class template is carefully crafted,
from which vectors, matrices, and even higher-order tensors can be created. An
expression template facility is also built around the array class template to
provide convenient mathematical syntax. As a result, by using templates, an
extra high-level layer is added to the C++ language when dealing with algebraic
objects and their operations, without compromising performance. The
implementation is tested running on both CPU and GPU.
"
281,Programming Languages for Scientific Computing,"  Scientific computation is a discipline that combines numerical analysis,
physical understanding, algorithm development, and structured programming.
Several yottacycles per year on the world's largest computers are spent
simulating problems as diverse as weather prediction, the properties of
material composites, the behavior of biomolecules in solution, and the quantum
nature of chemical compounds. This article is intended to review specfic
languages features and their use in computational science. We will review the
strengths and weaknesses of different programming styles, with examples taken
from widely used scientific codes.
"
282,Performance Modeling for Dense Linear Algebra,"  It is well known that the behavior of dense linear algebra algorithms is
greatly influenced by factors like target architecture, underlying libraries
and even problem size; because of this, the accurate prediction of their
performance is a real challenge. In this article, we are not interested in
creating accurate models for a given algorithm, but in correctly ranking a set
of equivalent algorithms according to their performance. Aware of the
hierarchical structure of dense linear algebra routines, we approach the
problem by developing a framework for the automatic generation of statistical
performance models for BLAS and LAPACK libraries. This allows us to obtain
predictions through evaluating and combining such models. We demonstrate that
our approach is successful in both single- and multi-core environments, not
only in the ranking of algorithms but also in tuning their parameters.
"
283,"Writing Reusable Digital Geometry Algorithms in a Generic Image
  Processing Framework","  Digital Geometry software should reflect the generality of the underlying
mathe- matics: mapping the latter to the former requires genericity. By
designing generic solutions, one can effectively reuse digital geometry data
structures and algorithms. We propose an image processing framework focused on
the Generic Programming paradigm in which an algorithm on the paper can be
turned into a single code, written once and usable with various input types.
This approach enables users to design and implement new methods at a lower
cost, try cross-domain experiments and help generalize results
"
284,"copulaedas: An R Package for Estimation of Distribution Algorithms Based
  on Copulas","  The use of copula-based models in EDAs (estimation of distribution
algorithms) is currently an active area of research. In this context, the
copulaedas package for R provides a platform where EDAs based on copulas can be
implemented and studied. The package offers complete implementations of various
EDAs based on copulas and vines, a group of well-known optimization problems,
and utility functions to study the performance of the algorithms. Newly
developed EDAs can be easily integrated into the package by extending an S4
class with generic functions for their main components. This paper presents
copulaedas by providing an overview of EDAs based on copulas, a description of
the implementation of the package, and an illustration of its use through
examples. The examples include running the EDAs defined in the package,
implementing new algorithms, and performing an empirical study to compare the
behavior of different algorithms on benchmark functions and a real-world
problem.
"
285,"On Newton-Raphson iteration for multiplicative inverses modulo prime
  powers","  We study algorithms for the fast computation of modular inverses.
Newton-Raphson iteration over $p$-adic numbers gives a recurrence relation
computing modular inverse modulo $p^m$, that is logarithmic in $m$. We solve
the recurrence to obtain an explicit formula for the inverse. Then we study
different implementation variants of this iteration and show that our explicit
formula is interesting for small exponent values but slower or large exponent,
say of more than $700$ bits. Overall we thus propose a hybrid combination of
our explicit formula and the best asymptotic variants. This hybrid combination
yields then a constant factor improvement, also for large exponents.
"
286,Best Practices for Scientific Computing,"  Scientists spend an increasing amount of time building and using software.
However, most scientists are never taught how to do this efficiently. As a
result, many are unaware of tools and practices that would allow them to write
more reliable and maintainable code with less effort. We describe a set of best
practices for scientific software development that have solid foundations in
research and experience, and that improve scientists' productivity and the
reliability of their software.
"
287,"Orthogononalization on a general purpose graphics processing unit with
  double double and quad double arithmetic","  Our problem is to accurately solve linear systems on a general purpose
graphics processing unit with double double and quad double arithmetic. The
linear systems originate from the application of Newton's method on polynomial
systems. Newton's method is applied as a corrector in a path following method,
so the linear systems are solved in sequence and not simultaneously. One
solution path may require the solution of thousands of linear systems. In
previous work we reported good speedups with our implementation to evaluate and
differentiate polynomial systems on the NVIDIA Tesla C2050. Although the cost
of evaluation and differentiation often dominates the cost of linear system
solving in Newton's method, because of the limited bandwidth of the
communication between CPU and GPU, we cannot afford to send the linear system
to the CPU for solving during path tracking.
  Because of large degrees, the Jacobian matrix may contain extreme values,
requiring extended precision, leading to a significant overhead. This overhead
of multiprecision arithmetic is our main motivation to develop a massively
parallel algorithm. To allow overdetermined linear systems we solve linear
systems in the least squares sense, computing the QR decomposition of the
matrix by the modified Gram-Schmidt algorithm. We describe our implementation
of the modified Gram-Schmidt orthogonalization method for the NVIDIA Tesla
C2050, using double double and quad double arithmetic. Our experimental results
show that the achieved speedups are sufficiently high to compensate for the
overhead of one extra level of precision.
"
288,SMAT: An Input Adaptive Sparse Matrix-Vector Multiplication Auto-Tuner,"  Sparse matrix vector multiplication (SpMV) is an important kernel in
scientific and engineering applications. The previous optimizations are sparse
matrix format specific and expose the choice of the best format to application
programmers. In this work we develop an auto-tuning framework to bridge gap
between the specific optimized kernels and their general-purpose use. We
propose an SpMV auto-tuner (SMAT) that provides an unified interface based on
compressed sparse row (CSR) to programmers by implicitly choosing the best
format and the fastest implementation of any input sparse matrix in runtime.
SMAT leverage a data mining model, which is formulated based on a set of
performance parameters extracted from 2373 matrices in UF sparse matrix
collection, to fast search the best combination. The experiments show that SMAT
achieves the maximum performance of 75 GFLOP/s in single-precision and 33
GFLOP/s in double-precision on Intel, and 41 GFLOP/s in single-precision and 34
GFLOP/s in double-precision on AMD. Compared with the sparse functions in MKL
library, SMAT runs faster by more than 3 times.
"
289,"Symbolic Analysis for Boundary Problems: From Rewriting to Parametrized
  Gr\""obner Bases","  We review our algebraic framework for linear boundary problems (concentrating
on ordinary differential equations). Its starting point is an appropriate
algebraization of the domain of functions, which we have named
integro-differential algebras. The algebraic treatment of boundary problems
brings up two new algebraic structures whose symbolic representation and
computational realization is based on canonical forms in certain commutative
and noncommutative polynomial domains. The first of these, the ring of
integro-differential operators, is used for both stating and solving linear
boundary problems. The other structure, called integro-differential
polynomials, is the key tool for describing extensions of integro-differential
algebras. We use the canonical simplifier for integro-differential polynomials
for generating an automated proof establishing a canonical simplifier for
integro-differential operators. Our approach is fully implemented in the
Theorema system; some code fragments and sample computations are included.
"
290,Regular and Singular Boundary Problems in Maple,"  We describe a new Maple package for treating boundary problems for linear
ordinary differential equations, allowing two-/multipoint as well as Stieltjes
boundary conditions. For expressing differential operators, boundary
conditions, and Green's operators, we employ the algebra of
integro-differential operators. The operations implemented for regular boundary
problems include computing Green's operators as well as composing and factoring
boundary problems. Our symbolic approach to singular boundary problems is new;
it provides algorithms for computing compatibility conditions and generalized
Green's operators.
"
291,A Robust Complex Division in Scilab,"  The most widely used algorithm for floating point complex division, known as
Smith's method, may fail more often than expected. This document presents two
improved complex division algorithms. We present a proof of the robustness of
the first improved algorithm. Numerical simulations show that this algorithm
performs well in practice and is significantly more robust than other known
implementations. By combining additionnal scaling methods with this first
algorithm, we were able to create a second algorithm, which rarely fails.
"
292,A New Recursive Algorithm For Inverting A General Comrade Matrix,"  In this paper, the author present a reliable symbolic computational algorithm
for inverting a general comrade matrix by using parallel computing along with
recursion. The computational cost of our algorithm is O(n^2). The algorithm is
implementable to the Computer Algebra System (CAS) such as MAPLE, MATLAB and
MATHEMATICA. Three examples are presented for the sake of illustration.
"
293,MLPACK: A Scalable C++ Machine Learning Library,"  MLPACK is a state-of-the-art, scalable, multi-platform C++ machine learning
library released in late 2011 offering both a simple, consistent API accessible
to novice users and high performance and flexibility to expert users by
leveraging modern features of C++. MLPACK provides cutting-edge algorithms
whose benchmarks exhibit far better performance than other leading machine
learning libraries. MLPACK version 1.0.3, licensed under the LGPL, is available
at http://www.mlpack.org.
"
294,"Optimized M2L Kernels for the Chebyshev Interpolation based Fast
  Multipole Method","  A fast multipole method (FMM) for asymptotically smooth kernel functions
(1/r, 1/r^4, Gauss and Stokes kernels, radial basis functions, etc.) based on a
Chebyshev interpolation scheme has been introduced in [Fong et al., 2009]. The
method has been extended to oscillatory kernels (e.g., Helmholtz kernel) in
[Messner et al., 2012]. Beside its generality this FMM turns out to be
favorable due to its easy implementation and its high performance based on
intensive use of highly optimized BLAS libraries. However, one of its
bottlenecks is the precomputation of the multiple-to-local (M2L) operator, and
its higher number of floating point operations (flops) compared to other FMM
formulations. Here, we present several optimizations for that operator, which
is known to be the costliest FMM operator. The most efficient ones do not only
reduce the precomputation time by a factor up to 340 but they also speed up the
matrix-vector product. We conclude with comparisons and numerical validations
of all presented optimizations.
"
295,"Solving Sequences of Generalized Least-Squares Problems on
  Multi-threaded Architectures","  Generalized linear mixed-effects models in the context of genome-wide
association studies (GWAS) represent a formidable computational challenge: the
solution of millions of correlated generalized least-squares problems, and the
processing of terabytes of data. We present high performance in-core and
out-of-core shared-memory algorithms for GWAS: By taking advantage of
domain-specific knowledge, exploiting multi-core parallelism, and handling data
efficiently, our algorithms attain unequalled performance. When compared to
GenABEL, one of the most widely used libraries for GWAS, on a 12-core processor
we obtain 50-fold speedups. As a consequence, our routines enable genome
studies of unprecedented size.
"
296,"Computing Petaflops over Terabytes of Data: The Case of Genome-Wide
  Association Studies","  In many scientific and engineering applications, one has to solve not one but
a sequence of instances of the same problem. Often times, the problems in the
sequence are linked in a way that allows intermediate results to be reused. A
characteristic example for this class of applications is given by the
Genome-Wide Association Studies (GWAS), a widely spread tool in computational
biology. GWAS entails the solution of up to trillions ($10^{12}$) of correlated
generalized least-squares problems, posing a daunting challenge: the
performance of petaflops ($10^{15}$ floating-point operations) over terabytes
of data.
  In this paper, we design an algorithm for performing GWAS on multi-core
architectures. This is accomplished in three steps. First, we show how to
exploit the relation among successive problems, thus reducing the overall
computational complexity. Then, through an analysis of the required data
transfers, we identify how to eliminate any overhead due to input/output
operations. Finally, we study how to decompose computation into tasks to be
distributed among the available cores, to attain high performance and
scalability. With our algorithm, a GWAS that currently requires the use of a
supercomputer may now be performed in matter of hours on a single multi-core
node.
  The discussion centers around the methodology to develop the algorithm rather
than the specific application. We believe the paper contributes valuable
guidelines of general applicability for computational scientists on how to
develop and optimize numerical algorithms.
"
297,"Demonstrating the Usefulness of CAELinux for Computer Aided Engineering
  using an Example of the Three Dimensional Reconstruction of a Pig Liver","  CAELinux is a Linux distribution which is bundled with free software packages
related to Computer Aided Engineering (CAE). The free software packages include
software that can build a three dimensional solid model, programs that can mesh
a geometry, software for carrying out Finite Element Analysis (FEA), programs
that can carry out image processing etc. Present work has two goals: 1) To give
a brief description of CAELinux 2) To demonstrate that CAELinux could be useful
for Computer Aided Engineering, using an example of the three dimensional
reconstruction of a pig liver from a stack of CT-scan images. One can note that
instead of using CAELinux, using commercial software for reconstructing the
liver would cost a lot of money. One can also note that CAELinux is a free and
open source operating system and all software packages that are included in the
operating system are also free. Hence one can conclude that CAELinux could be a
very useful tool in application areas like surgical simulation which require
three dimensional reconstructions of biological organs. Also, one can see that
CAELinux could be a very useful tool for Computer Aided Engineering, in
general.
"
298,High-Order Discontinuous Galerkin Methods by GPU Metaprogramming,"  Discontinuous Galerkin (DG) methods for the numerical solution of partial
differential equations have enjoyed considerable success because they are both
flexible and robust: They allow arbitrary unstructured geometries and easy
control of accuracy without compromising simulation stability. In a recent
publication, we have shown that DG methods also adapt readily to execution on
modern, massively parallel graphics processors (GPUs). A number of qualities of
the method contribute to this suitability, reaching from locality of reference,
through regularity of access patterns, to high arithmetic intensity. In this
article, we illuminate a few of the more practical aspects of bringing DG onto
a GPU, including the use of a Python-based metaprogramming infrastructure that
was created specifically to support DG, but has found many uses across all
disciplines of computational science.
"
299,A multi-scale code for flexible hybrid simulations,"  Multi-scale computer simulations combine the computationally efficient
classical algorithms with more expensive but also more accurate ab-initio
quantum mechanical algorithms. This work describes one implementation of
multi-scale computations using the Atomistic Simulation Environment (ASE). This
implementation can mix classical codes like LAMMPS and the Density Functional
Theory-based GPAW. Any combination of codes linked via the ASE interface
however can be mixed. We also introduce a framework to easily add classical
force fields calculators for ASE using LAMMPS, which also allows harnessing the
full performance of classical-only molecular dynamics. Our work makes it
possible to combine different simulation codes, quantum mechanical or
classical, with great ease and minimal coding effort.
"
300,GPU-accelerated generation of correctly-rounded elementary functions,"  The IEEE 754-2008 standard recommends the correct rounding of some elementary
functions. This requires to solve the Table Maker's Dilemma which implies a
huge amount of CPU computation time. We consider in this paper accelerating
such computations, namely Lefe'vre algorithm on Graphics Processing Units
(GPUs) which are massively parallel architectures with a partial SIMD execution
(Single Instruction Multiple Data). We first propose an analysis of the
Lef\`evre hard-to-round argument search using the concept of continued
fractions. We then propose a new parallel search algorithm much more efficient
on GPU thanks to its more regular control flow. We also present an efficient
hybrid CPU-GPU deployment of the generation of the polynomial approximations
required in Lef\`evre algorithm. In the end, we manage to obtain overall
speedups up to 53.4x on one GPU over a sequential CPU execution, and up to 7.1x
over a multi-core CPU, which enable a much faster solving of the Table Maker's
Dilemma for the double precision format.
"
301,"A Bernstein Polynomial Collocation Method for the Solution of Elliptic
  Boundary Value Problems","  In this article, a formulation of a point-collocation method in which the
unknown function is approximated using global expansion in tensor product
Bernstein polynomial basis is presented. Bernstein polynomials used in this
study are defined over general interval [a,b]. Method incorporates several
ideas that enable higher numerical efficiency compared to Bernstein polynomial
methods that have been previously presented. The approach is illustrated by a
solution of Poisson, Helmholtz and Biharmonic equations with Dirichlet and
Neumann type boundary conditions. Comparisons with analytical solutions are
given to demonstrate the accuracy and convergence properties of the current
procedure. The method is implemented in an open-source code, and a library for
manipulation of Bernstein polynomials bernstein-poly, developed by the authors.
"
302,"Unified Form Language: A domain-specific language for weak formulations
  of partial differential equations","  We present the Unified Form Language (UFL), which is a domain-specific
language for representing weak formulations of partial differential equations
with a view to numerical approximation. Features of UFL include support for
variational forms and functionals, automatic differentiation of forms and
expressions, arbitrary function space hierarchies for multi-field problems,
general differential operators and flexible tensor algebra. With these
features, UFL has been used to effortlessly express finite element methods for
complex systems of partial differential equations in near-mathematical
notation, resulting in compact, intuitive and readable programs. We present in
this work the language and its construction. An implementation of UFL is freely
available as an open-source software library. The library generates abstract
syntax tree representations of variational problems, which are used by other
software libraries to generate concrete low-level implementations. Some
application examples are presented and libraries that support UFL are
highlighted.
"
303,"Confusion of Tagged Perturbations in Forward Automatic Differentiation
  of Higher-Order Functions","  Forward Automatic Differentiation (AD) is a technique for augmenting programs
to compute derivatives. The essence of Forward AD is to attach perturbations to
each number, and propagate these through the computation. When derivatives are
nested, the distinct derivative calculations, and their associated
perturbations, must be distinguished. This is typically accomplished by
creating a unique tag for each derivative calculation, tagging the
perturbations, and overloading the arithmetic operators. We exhibit a subtle
bug, present in fielded implementations, in which perturbations are confused
despite the tagging machinery. The essence of the bug is this: each invocation
of a derivative creates a unique tag but a unique tag is needed for each
derivative calculation. When taking derivatives of higher-order functions,
these need not correspond! The derivative of a higher-order function $f$ that
returns a function $g$ will be a function $f'$ that returns a function
$\bar{g}$ that performs a derivative calculation. A single invocation of $f'$
will create a single fresh tag but that same tag will be used for each
derivative calculation resulting from an invocation of $\bar{g}$. This
situation arises when taking derivatives of curried functions. Two potential
solutions are presented, and their serious deficiencies discussed. One requires
eta expansion to delay the creation of fresh tags from the invocation of $f'$
to the invocation of $\bar{g}$, which can be difficult or even impossible in
some circumstances. The other requires $f'$ to wrap $\bar{g}$ with tag
renaming, which is difficult to implement without violating the desirable
complexity properties of forward AD.
"
304,Application-tailored Linear Algebra Algorithms: A search-based Approach,"  In this paper, we tackle the problem of automatically generating algorithms
for linear algebra operations by taking advantage of problem-specific
knowledge. In most situations, users possess much more information about the
problem at hand than what current libraries and computing environments accept;
evidence shows that if properly exploited, such information leads to
uncommon/unexpected speedups. We introduce a knowledge-aware linear algebra
compiler that allows users to input matrix equations together with properties
about the operands and the problem itself; for instance, they can specify that
the equation is part of a sequence, and how successive instances are related to
one another. The compiler exploits all this information to guide the generation
of algorithms, to limit the size of the search space, and to avoid redundant
computations. We applied the compiler to equations arising as part of
sensitivity and genome studies; the algorithms produced exhibit, respectively,
100- and 1000-fold speedups.
"
305,A framework for the automation of generalised stability theory,"  The traditional approach to investigating the stability of a physical system
is to linearise the equations about a steady base solution, and to examine the
eigenvalues of the linearised operator. Over the past several decades, it has
been recognised that this approach only determines the asymptotic stability of
the system, and neglects the possibility of transient perturbation growth
arising due to the nonnormality of the system. This observation motivated the
development of a more powerful generalised stability theory (GST), which
focusses instead on the singular value decomposition of the linearised
propagator of the system. While GST has had significant successes in
understanding the stability of phenomena in geophysical fluid dynamics, its
more widespread applicability has been hampered by the fact that computing the
SVD requires both the tangent linear operator and its adjoint: deriving the
tangent linear and adjoint models is usually a considerable challenge, and
manually embedding them inside an eigensolver is laborious. In this paper, we
present a framework for the automation of generalised stability theory, which
overcomes these difficulties. Given a compact high-level symbolic
representation of a finite element discretisation implemented in the FEniCS
system, efficient C++ code is automatically generated to assemble the forward,
tangent linear and adjoint models; these models are then used to calculate the
optimally growing perturbations to the forward model, and their growth rates.
By automating the stability computations, we hope to make these powerful tools
a more routine part of computational analysis. The efficiency and generality of
the framework is demonstrated with applications drawn from geophysical fluid
dynamics, phase separation and quantum mechanics.
"
306,"Algorithms for discovering and proving theorems about permutation
  patterns","  We present an algorithm, called BiSC, that describes the patterns avoided by
a given set of permutations. It automatically conjectures the statements of
known theorems such as the descriptions of stack-sortable (Knuth 1975) and
West-2-stack-sortable permutations (West 1990), smooth (Lakshmibai and Sandhya
1990) and forest-like permutations (Bousquet-Melou and Butler 2007), and simsun
permutations (Branden and Claesson 2011). The algorithm has also been used to
discover new theorems and conjectures related to Young tableaux,
Wilf-equivalences and sorting devices. We further give algorithms to prove a
complete description of preimages of pattern classes under certain sorting
devices. These generalize an algorithm of Claesson and Ulfarsson (2012) and
allow us to prove a linear time algorithm for finding occurrences of the
pattern 4312.
"
307,"A modular framework for randomness extraction based on Trevisan's
  construction","  Informally, an extractor delivers perfect randomness from a source that may
be far away from the uniform distribution, yet contains some randomness. This
task is a crucial ingredient of any attempt to produce perfectly random
numbers---required, for instance, by cryptographic protocols, numerical
simulations, or randomised computations. Trevisan's extractor raised
considerable theoretical interest not only because of its data parsimony
compared to other constructions, but particularly because it is secure against
quantum adversaries, making it applicable to quantum key distribution.
  We discuss a modular, extensible and high-performance implementation of the
construction based on various building blocks that can be flexibly combined to
satisfy the requirements of a wide range of scenarios. Besides quantitatively
analysing the properties of many combinations in practical settings, we improve
previous theoretical proofs, and give explicit results for non-asymptotic
cases. The self-contained description does not assume familiarity with
extractors.
"
308,Automated verification of termination certificates,"  In order to increase user confidence, many automated theorem provers provide
certificates that can be independently verified. In this paper, we report on
our progress in developing a standalone tool for checking the correctness of
certificates for the termination of term rewrite systems, and formally proving
its correctness in the proof assistant Coq. To this end, we use the extraction
mechanism of Coq and the library on rewriting theory and termination called
CoLoR.
"
309,Programming CUDA and OpenCL: A Case Study Using Modern C++ Libraries,"  We present a comparison of several modern C++ libraries providing high-level
interfaces for programming multi- and many-core architectures on top of CUDA or
OpenCL. The comparison focuses on the solution of ordinary differential
equations and is based on odeint, a framework for the solution of systems of
ordinary differential equations. Odeint is designed in a very flexible way and
may be easily adapted for effective use of libraries such as Thrust, MTL4,
VexCL, or ViennaCL, using CUDA or OpenCL technologies. We found that CUDA and
OpenCL work equally well for problems of large sizes, while OpenCL has higher
overhead for smaller problems. Furthermore, we show that modern high-level
libraries allow to effectively use the computational resources of many-core
GPUs or multi-core CPUs without much knowledge of the underlying technologies.
"
310,"Formal Model-Driven Engineering: Generating Data and Behavioural
  Components","  Model-driven engineering is the automatic production of software artefacts
from abstract models of structure and functionality. By targeting a specific
class of system, it is possible to automate aspects of the development process,
using model transformations and code generators that encode domain knowledge
and implementation strategies. Using this approach, questions of correctness
for a complex, software system may be answered through analysis of abstract
models of lower complexity, under the assumption that the transformations and
generators employed are themselves correct. This paper shows how formal
techniques can be used to establish the correctness of model transformations
used in the generation of software components from precise object models. The
source language is based upon existing, formal techniques; the target language
is the widely-used SQL notation for database programming. Correctness is
established by giving comparable, relational semantics to both languages, and
checking that the transformations are semantics-preserving.
"
311,Tree-based Arithmetic and Compressed Representations of Giant Numbers,"  Can we do arithmetic in a completely different way, with a radically
different data structure? Could this approach provide practical benefits, like
operations on giant numbers while having an average performance similar to
traditional bitstring representations?
  While answering these questions positively, our tree based representation
described in this paper comes with a few extra benefits: it compresses giant
numbers such that, for instance, the largest known prime number as well as its
related perfect number are represented as trees of small sizes. The same also
applies to Fermat numbers and important computations like exponentiation of two
become constant time operations.
  At the same time, succinct representations of sparse sets, multisets and
sequences become possible through bijections to our tree-represented natural
numbers.
"
312,Binary Tree Arithmetic with Generalized Constructors,"  We describe arithmetic computations in terms of operations on some well known
free algebras (S1S, S2S and ordered rooted binary trees) while emphasizing the
common structure present in all them when seen as isomorphic with the set of
natural numbers.
  Constructors and deconstructors seen through an initial algebra semantics are
generalized to recursively defined functions obeying similar laws.
  Implementation using Scala's apply and unapply are discussed together with an
application to a realistic arbitrary size arithmetic package written in Scala,
based on the free algebra of rooted ordered binary trees, which also supports
rational number operations through an extension to signed rationals of the
Calkin-Wilf bijection.
"
313,On Two Infinite Families of Pairing Bijections,"  We describe two general mechanisms for producing pairing bijections
(bijective functions defined from N x N to N).
  The first mechanism, using n-adic valuations results in parameterized
algorithms generating a countable family of distinct pairing bijections.
  The second mechanism, using characteristic functions of subsets of N provides
2^N distinct pairing bijections.
  Mechanisms to combine such pairing functions and their application to
generate families of permutations of N are also described.
  The paper uses a small subset of the functional language Haskell to provide
type checked executable specifications of all the functions defined in a
literate programming style. The self-contained Haskell code extracted from the
paper is available at http://logic.cse.unt.edu/tarau/research/2012/infpair.hs .
"
314,Improved QFT algorithm for power-of-two FFT,"  This paper shows that it is possible to improve the computational cost, the
memory requirements and the accuracy of Quick Fourier Transform (QFT) algorithm
for power-of-two FFT (Fast Fourier Transform) just introducing a slight
modification in this algorithm. The new algorithm requires the same number of
additions and multiplications of split-radix 3add/3mul, one of the most
appreciated FFT algorithms appeared in the literature, but employing only half
of the trigonometric constants. These results can elevate the QFT approach to
the level of most used FFT procedures. A new quite general way to describe FFT
algorithms, based on signal types and on a particular notation, is also
proposed and used, highligting its advantages.
"
315,"Object-oriented implementations of the MPDATA advection equation solver
  in C++, Python and Fortran","  Three object-oriented implementations of a prototype solver of the advection
equation are introduced. The presented programs are based on Blitz++ (C++),
NumPy (Python), and Fortran's built-in array containers. The solvers include an
implementation of the Multidimensional Positive-Definite Advective Transport
Algorithm (MPDATA). The introduced codes exemplify how the application of
object-oriented programming (OOP) techniques allows to reproduce the
mathematical notation used in the literature within the program code. A
discussion on the tradeoffs of the programming language choice is presented.
The main angles of comparison are code brevity and syntax clarity (and hence
maintainability and auditability) as well as performance. In the case of
Python, a significant performance gain is observed when switching from the
standard interpreter (CPython) to the PyPy implementation of Python. Entire
source code of all three implementations is embedded in the text and is
licensed under the terms of the GNU GPL license.
"
316,"Parallel Algorithms for Constructing Data Structures for Fast Multipole
  Methods","  We present efficient algorithms to build data structures and the lists needed
for fast multipole methods. The algorithms are capable of being efficiently
implemented on both serial, data parallel GPU and on distributed architectures.
With these algorithms it is possible to map the FMM efficiently on to the GPU
or distributed heterogeneous CPU-GPU systems. Further, in dynamic problems, as
the distribution of the particles change, the reduced cost of building the data
structures improves performance. Using these algorithms, we demonstrate example
high fidelity simulations with large problem sizes by using FMM on both single
and multiple heterogeneous computing facilities equipped with multi-core CPU
and many-core GPUs.
"
317,A block MINRES algorithm based on the banded Lanczos method,"  We develop a block minimum residual (MINRES) algorithm for symmetric
indefinite matrices. This version is built upon the band Lanczos method that
generates one basis vector of the block Krylov subspace per iteration rather
than a whole block as in the block Lanczos process. However, we modify the
method such that the most expensive operations are still performed in a block
fashion. The benefit of using the band Lanczos method is that one can detect
breakdowns from scalar values arising in the computation, allowing for a
handling of breakdown which is straightforward to implement.
  We derive a progressive formulation of the MINRES method based on the band
Lanczos process and give some implementation details. Specifically, a simple
reordering of the steps allows us to perform many of the operations at the
block level in order to take advantage of communication efficiencies offered by
the block Lanczos process. This is an important concern in the context of
next-generation super computing applications.
  We also present a technique allowing us to maintain the block size by
replacing dependent Lanczos vectors with pregenerated random vectors whose
orthogonality against all Lanczos vectors is maintained. Numerical results
illustrate the performance on some sample problems. We present experiments that
show how the relationship between right-hand sides can effect the performance
of the method.
"
318,Krylov Subspace Recycling for Sequences of Shifted Linear Systems,"  We study the use of Krylov subspace recycling for the solution of a sequence
of slowly-changing families of linear systems, where each family consists of
shifted linear systems that differ in the coefficient matrix only by multiples
of the identity. Our aim is to explore the simultaneous solution of each family
of shifted systems within the framework of subspace recycling, using one
augmented subspace to extract candidate solutions for all the shifted systems.
The ideal method would use the same augmented subspace for all systems and have
fixed storage requirements, independent of the number of shifted systems per
family. We show that a method satisfying both requirements cannot exist in this
framework.
  As an alternative, we introduce two schemes. One constructs a separate
deflation space for each shifted system but solves each family of shifted
systems simultaneously. The other builds only one recycled subspace and
constructs approximate corrections to the solutions of the shifted systems at
each cycle of the iterative linear solver while only minimizing the base system
residual. At convergence of the base system solution, we apply the method
recursively to the remaining unconverged systems. We present numerical examples
involving systems arising in lattice quantum chromodynamics.
"
319,"ALGORITHM 937: MINRES-QLP for Singular Symmetric and Hermitian Linear
  Equations and Least-Squares Problems","  We describe algorithm MINRES-QLP and its FORTRAN 90 implementation for
solving symmetric or Hermitian linear systems or least-squares problems. If the
system is singular, MINRES-QLP computes the unique minimum-length solution
(also known as the pseudoinverse solution), which generally eludes MINRES. In
all cases, it overcomes a potential instability in the original MINRES
algorithm. A positive-definite preconditioner may be supplied. Our FORTRAN 90
implementation illustrates a design pattern that allows users to make problem
data known to the solver but hidden and secure from other program units. In
particular, we circumvent the need for reverse communication. While we focus
here on a FORTRAN 90 implementation, we also provide and maintain MATLAB
versions of MINRES and MINRES-QLP.
"
320,YGGDRASIL - A Statistical Package for Learning Split Models,"  There are two main objectives of this paper. The first is to present a
statistical framework for models with context specific independence structures,
i.e., conditional independences holding only for sepcific values of the
conditioning variables. This framework is constituted by the class of split
models. Split models are extension of graphical models for contigency tables
and allow for a more sophisticiated modelling than graphical models. The
treatment of split models include estimation, representation and a Markov
property for reading off those independencies holding in a specific context.
The second objective is to present a software package named YGGDRASIL which is
designed for statistical inference in split models, i.e., for learning such
models on the basis of data.
"
321,Simultaneous computation of the row and column rank profiles,"  Gaussian elimination with full pivoting generates a PLUQ matrix
decomposition. Depending on the strategy used in the search for pivots, the
permutation matrices can reveal some information about the row or the column
rank profiles of the matrix. We propose a new pivoting strategy that makes it
possible to recover at the same time both row and column rank profiles of the
input matrix and of any of its leading sub-matrices. We propose a
rank-sensitive and quad-recursive algorithm that computes the latter PLUQ
triangular decomposition of an m \times n matrix of rank r in O(mnr^{\omega-2})
field operations, with \omega the exponent of matrix multiplication. Compared
to the LEU decomposition by Malashonock, sharing a similar recursive structure,
its time complexity is rank sensitive and has a lower leading constant. Over a
word size finite field, this algorithm also improveLs the practical efficiency
of previously known implementations.
"
322,"NIFTY - Numerical Information Field Theory - a versatile Python library
  for signal inference","  NIFTY, ""Numerical Information Field Theory"", is a software package designed
to enable the development of signal inference algorithms that operate
regardless of the underlying spatial grid and its resolution. Its
object-oriented framework is written in Python, although it accesses libraries
written in Cython, C++, and C for efficiency. NIFTY offers a toolkit that
abstracts discretized representations of continuous spaces, fields in these
spaces, and operators acting on fields into classes. Thereby, the correct
normalization of operations on fields is taken care of automatically without
concerning the user. This allows for an abstract formulation and programming of
inference algorithms, including those derived within information field theory.
Thus, NIFTY permits its user to rapidly prototype algorithms in 1D, and then
apply the developed code in higher-dimensional settings of real world problems.
The set of spaces on which NIFTY operates comprises point sets, n-dimensional
regular grids, spherical spaces, their harmonic counterparts, and product
spaces constructed as combinations of those. The functionality and diversity of
the package is demonstrated by a Wiener filter code example that successfully
runs without modification regardless of the space on which the inference
problem is defined.
"
323,A Unified Software Framework for Empirical Gramians,"  A common approach in model reduction is balanced truncation, which is based
on gramian matrices classifiying certain attributes of states or parameters of
a given dynamic system. Initially restricted to linear systems, the empirical
gramians not only extended this concept to nonlinear systems, but also provide
a uniform computational method. This work introduces a unified software
framework supplying routines for six types of empirical gramians. The gramian
types will be discussed and applied in a model reduction framework for
multiple-input-multiple-output (MIMO) systems.
"
324,On the effects of scaling on the performance of Ipopt,"  The open-source nonlinear solver Ipopt (https://projects.coin-or.org/Ipopt)
is a widely-used software package for the solution of large-scale non-linear
optimization problems. At its heart, it employs a third-party linear solver to
solve a series of sparse symmetric indefinite systems. The speed, accuracy and
robustness of the chosen linear solver is critical to the overall performance
of Ipopt. In some instances, it can be beneficial to scale the linear system
before it is solved.
  In this paper, different scaling algorithms are employed within Ipopt with a
new linear solver HSL_MA97 from the HSL mathematical software library
(http://www.hsl.rl.ac.uk). An extensive collection of problems from the CUTEr
test set (http://www.cuter.rl.ac.uk) is used to illustrate the effects of
scaling.
"
325,"Exploiting Symmetry in Tensors for High Performance: Multiplication with
  Symmetric Tensors","  Symmetric tensor operations arise in a wide variety of computations. However,
the benefits of exploiting symmetry in order to reduce storage and computation
is in conflict with a desire to simplify memory access patterns. In this paper,
we propose a blocked data structure (Blocked Compact Symmetric Storage) wherein
we consider the tensor by blocks and store only the unique blocks of a
symmetric tensor. We propose an algorithm-by-blocks, already shown of benefit
for matrix computations, that exploits this storage format by utilizing a
series of temporary tensors to avoid redundant computation. Further, partial
symmetry within temporaries is exploited to further avoid redundant storage and
redundant computation. A detailed analysis shows that, relative to storing and
computing with tensors without taking advantage of symmetry and partial
symmetry, storage requirements are reduced by a factor of $ O\left( m! \right)$
and computational requirements by a factor of $O\left( (m+1)!/2^m \right)$,
where $ m $ is the order of the tensor. However, as the analysis shows, care
must be taken in choosing the correct block size to ensure these storage and
computational benefits are achieved (particularly for low-order tensors). An
implementation demonstrates that storage is greatly reduced and the complexity
introduced by storing and computing with tensors by blocks is manageable.
Preliminary results demonstrate that computational time is also reduced. The
paper concludes with a discussion of how insights in this paper point to
opportunities for generalizing recent advances in the domain of linear algebra
libraries to the field of multi-linear computation.
"
326,"FEAST as a Subspace Iteration Eigensolver Accelerated by Approximate
  Spectral Projection","  The calculation of a segment of eigenvalues and their corresponding
eigenvectors of a Hermitian matrix or matrix pencil has many applications. A
new density-matrix-based algorithm has been proposed recently and a software
package FEAST has been developed. The density-matrix approach allows FEAST's
implementation to exploit a key strength of modern computer architectures,
namely, multiple levels of parallelism. Consequently, the software package has
been well received, especially in the electronic structure community.
Nevertheless, theoretical analysis of FEAST has lagged. For instance, the FEAST
algorithm has not been proven to converge. This paper offers a detailed
numerical analysis of FEAST. In particular, we show that the FEAST algorithm
can be understood as an accelerated subspace iteration algorithm in conjunction
with the Rayleigh-Ritz procedure. The novelty of FEAST lies in its accelerator
which is a rational matrix function that approximates the spectral projector
onto the eigenspace in question. Analysis of the numerical nature of this
approximate spectral projector and the resulting subspaces generated in the
FEAST algorithm establishes the algorithm's convergence. This paper shows that
FEAST is resilient against rounding errors and establishes properties that can
be leveraged to enhance the algorithm's robustness. Finally, we propose an
extension of FEAST to handle non-Hermitian problems and suggest some future
research directions.
"
327,Kleene Algebra with Tests and Coq Tools for While Programs,"  We present a Coq library about Kleene algebra with tests, including a proof
of their completeness over the appropriate notion of languages, a decision
procedure for their equational theory, and tools for exploiting hypotheses of a
particular shape in such a theory. Kleene algebra with tests make it possible
to represent if-then-else statements and while loops in most imperative
programming languages. They were actually introduced by Kozen as an alternative
to propositional Hoare logic. We show how to exploit the corresponding Coq
tools in the context of program verification by proving equivalences of while
programs, correctness of some standard compiler optimisations, Hoare rules for
partial correctness, and a particularly challenging equivalence of flowchart
schemes.
"
328,"RandFile package for Mathematica for accessing file-based sources of
  randomness","  We present a package for Mathematica computer algebra system which allows the
exploitation of local files as sources of random data. We provide the
description of the package and illustrate its usage by showing some examples.
We also compare the provided functionality with alternative sources of
randomness, namely a built-in pseudo-random generator and the package for
accessing hardware true random number generators.
"
329,A framework for automated PDE-constrained optimisation,"  A generic framework for the solution of PDE-constrained optimisation problems
based on the FEniCS system is presented. Its main features are an intuitive
mathematical interface, a high degree of automation, and an efficient
implementation of the generated adjoint model. The framework is based upon the
extension of a domain-specific language for variational problems to cleanly
express complex optimisation problems in a compact, high-level syntax. For
example, optimisation problems constrained by the time-dependent Navier-Stokes
equations can be written in tens of lines of code. Based on this high-level
representation, the framework derives the associated adjoint equations in the
same domain-specific language, and uses the FEniCS code generation technology
to emit parallel optimised low-level C++ code for the solution of the forward
and adjoint systems. The functional and gradient information so computed is
then passed to the optimisation algorithm to update the parameter values. This
approach works both for steady-state as well as transient, and for linear as
well as nonlinear governing PDEs and a wide range of functionals and control
parameters. We demonstrate the applicability and efficiency of this approach on
classical textbook optimisation problems and advanced examples.
"
330,Streaming Data from HDD to GPUs for Sustained Peak Performance,"  In the context of the genome-wide association studies (GWAS), one has to
solve long sequences of generalized least-squares problems; such a task has two
limiting factors: execution time --often in the range of days or weeks-- and
data management --data sets in the order of Terabytes. We present an algorithm
that obviates both issues. By pipelining the computation, and thanks to a
sophisticated transfer strategy, we stream data from hard disk to main memory
to GPUs and achieve sustained peak performance; with respect to a
highly-optimized CPU implementation, our algorithm shows a speedup of 2.6x.
Moreover, the approach lends itself to multiple GPUs and attains almost perfect
scalability. When using 4 GPUs, we observe speedups of 9x over the
aforementioned implementation, and 488x over a widespread biology library.
"
331,"Q#, a quantum computation package for the .NET platform","  Quantum computing is a promising approach of computation that is based on
equations from Quantum Mechanics. A simulator for quantum algorithms must be
capable of performing heavy mathematical matrix transforms. The design of the
simulator itself takes one of three forms: Quantum Turing Machine, Network
Model or circuit model of connected gates or, Quantum Programming Language,
yet, some simulators are hybrid. We studied previous simulators and then we
adopt features from three simulators of different implementation languages,
different paradigms, and for different platforms. They are Quantum Computing
Language (QCL), QUASI, and Quantum Optics Toolbox for Matlab 5. Our simulator
for quantum algorithms takes the form of a package or a programming library for
Quantum computing, with a case study showing the ability of using it in the
circuit model. The .NET is a promising platform for computing. VB.NET is an
easy, high productive programming language with the full power and
functionality provided by the .NET framework. It is highly readable, writeable,
and flexible language, compared to another language such as C#.NET in many
aspects. We adopted VB.NET although its shortage in built-in mathematical
complex and matrix operations, compared to Matlab. For implementation, we first
built a mathematical core of matrix operations. Then, we built a quantum core
which contains: basic qubits and register operations, basic 1D, 2D, and 3D
quantum gates, and multi-view visualization of the quantum state, then a window
for demos to show you how to use and get the most of the package.
"
332,Factorization of Z-homogeneous polynomials in the First (q)-Weyl Algebra,"  We present algorithms to factorize weighted homogeneous elements in the first
polynomial Weyl algebra and $q$-Weyl algebra, which are both viewed as a
$\mathbb{Z}$-graded rings. We show, that factorization of homogeneous
polynomials can be almost completely reduced to commutative univariate
factorization over the same base field with some additional uncomplicated
combinatorial steps. This allows to deduce the complexity of our algorithms in
detail. Furthermore, we will show for homogeneous polynomials that
irreducibility in the polynomial first Weyl algebra also implies irreducibility
in the rational one, which is of interest for practical reasons. We report on
our implementation in the computer algebra system \textsc{Singular}. It
outperforms for homogeneous polynomials currently available implementations
dealing with factorization in the first Weyl algebra both in speed and elegancy
of the results.
"
333,GURLS: a Least Squares Library for Supervised Learning,"  We present GURLS, a least squares, modular, easy-to-extend software library
for efficient supervised learning. GURLS is targeted to machine learning
practitioners, as well as non-specialists. It offers a number state-of-the-art
training strategies for medium and large-scale learning, and routines for
efficient model selection. The library is particularly well suited for
multi-output problems (multi-category/multi-label). GURLS is currently
available in two independent implementations: Matlab and C++. It takes
advantage of the favorable properties of regularized least squares algorithm to
exploit advanced tools in linear algebra. Routines to handle computations with
very large matrices by means of memory-mapped storage and distributed task
execution are available. The package is distributed under the BSD licence and
is available for download at https://github.com/CBCL/GURLS.
"
334,"Model-guided Performance Analysis of the Sparse Matrix-Matrix
  Multiplication","  Achieving high efficiency with numerical kernels for sparse matrices is of
utmost importance, since they are part of many simulation codes and tend to use
most of the available compute time and resources. In addition, especially in
large scale simulation frameworks the readability and ease of use of
mathematical expressions are essential components for the continuous
maintenance, modification, and extension of software. In this context, the
sparse matrix-matrix multiplication is of special interest. In this paper we
thoroughly analyze the single-core performance of sparse matrix-matrix
multiplication kernels in the Blaze Smart Expression Template (SET) framework.
We develop simple models for estimating the achievable maximum performance, and
use them to assess the efficiency of our implementations. Additionally, we
compare these kernels with several commonly used SET-based C++ libraries,
which, just as Blaze, aim at combining the requirements of high performance
with an elegant user interface. For the different sparse matrix structures
considered here, we show that our implementations are competitive or faster
than those of the other SET libraries for most problem sizes on a current Intel
multicore processor.
"
335,Possible Directions for Improving Dependency Versioning in R,"  One of the most powerful features of R is its infrastructure for contributed
code. The built-in package manager and complementary repositories provide a
great system for development and exchange of code, and have played an important
role in the growth of the platform towards the de-facto standard in statistical
computing that it is today. However, the number of packages on CRAN and other
repositories has increased beyond what might have been foreseen, and is
revealing some limitations of the current design. One such problem is the
general lack of dependency versioning in the infrastructure. This paper
explores this problem in greater detail, and suggests approaches taken by other
open source communities that might work for R as well. Three use cases are
defined that exemplify the issue, and illustrate how improving this aspect of
package management could increase reliability while supporting further growth
of the R community.
"
336,Tiled Algorithms for Matrix Computations on Multicore Architectures,"  The current computer architecture has moved towards the multi/many-core
structure. However, the algorithms in the current sequential dense numerical
linear algebra libraries (e.g. LAPACK) do not parallelize well on
multi/many-core architectures. A new family of algorithms, the tile algorithms,
has recently been introduced to circumvent this problem. Previous research has
shown that it is possible to write efficient and scalable tile algorithms for
performing a Cholesky factorization, a (pseudo) LU factorization, and a QR
factorization. The goal of this thesis is to study tiled algorithms in a
multi/many-core setting and to provide new algorithms which exploit the current
architecture to improve performance relative to current state-of-the-art
libraries while maintaining the stability and robustness of these libraries.
"
337,Update report: LEO-II version 1.5,"  Recent improvements of the LEO-II theorem prover are presented. These
improvements include a revised ATP interface, new translations into first-order
logic, rule support for the axiom of choice, detection of defined equality, and
more flexible strategy scheduling.
"
338,"A Qualitative Comparison of the Suitability of Four Theorem Provers for
  Basic Auction Theory","  Novel auction schemes are constantly being designed. Their design has
significant consequences for the allocation of goods and the revenues
generated. But how to tell whether a new design has the desired properties,
such as efficiency, i.e. allocating goods to those bidders who value them most?
We say: by formal, machine-checked proofs. We investigated the suitability of
the Isabelle, Theorema, Mizar, and Hets/CASL/TPTP theorem provers for
reproducing a key result of auction theory: Vickrey's 1961 theorem on the
properties of second-price auctions. Based on our formalisation experience,
taking an auction designer's perspective, we give recommendations on what
system to use for formalising auctions, and outline further steps towards a
complete auction theory toolbox.
"
339,"The RAppArmor Package: Enforcing Security Policies in R Using Dynamic
  Sandboxing on Linux","  The increasing availability of cloud computing and scientific super computers
brings great potential for making R accessible through public or shared
resources. This allows us to efficiently run code requiring lots of cycles and
memory, or embed R functionality into, e.g., systems and web services. However
some important security concerns need to be addressed before this can be put in
production. The prime use case in the design of R has always been a single
statistician running R on the local machine through the interactive console.
Therefore the execution environment of R is entirely unrestricted, which could
result in malicious behavior or excessive use of hardware resources in a shared
environment. Properly securing an R process turns out to be a complex problem.
We describe various approaches and illustrate potential issues using some of
our personal experiences in hosting public web services. Finally we introduce
the RAppArmor package: a Linux based reference implementation for dynamic
sandboxing in R on the level of the operating system.
"
340,Parameter identification in large kinetic networks with BioPARKIN,"  Modelling, parameter identification, and simulation play an important role in
systems biology. Usually, the goal is to determine parameter values that
minimise the difference between experimental measurement values and model
predictions in a least-squares sense. Large-scale biological networks, however,
often suffer from missing data for parameter identification. Thus, the
least-squares problems are rank-deficient and solutions are not unique. Many
common optimisation methods ignore this detail because they do not take into
account the structure of the underlying inverse problem. These algorithms
simply return a ""solution"" without additional information on identifiability or
uniqueness. This can yield misleading results, especially if parameters are
co-regulated and data are noisy.
"
341,"ZKCM: a C++ library for multiprecision matrix computation with
  applications in quantum information","  ZKCM is a C++ library developed for the purpose of multiprecision matrix
computation, on the basis of the GNU MP and MPFR libraries. It provides an
easy-to-use syntax and convenient functions for matrix manipulations including
those often used in numerical simulations in quantum physics. Its extension
library, ZKCM_QC, is developed for simulating quantum computing using the
time-dependent matrix-product-state simulation method. This paper gives an
introduction about the libraries with practical sample programs.
"
342,Sampling exactly from the normal distribution,"  An algorithm for sampling exactly from the normal distribution is given. The
algorithm reads some number of uniformly distributed random digits in a given
base and generates an initial portion of the representation of a normal deviate
in the same base. Thereafter, uniform random digits are copied directly into
the representation of the normal deviate. Thus, in contrast to existing
methods, it is possible to generate normal deviates exactly rounded to any
precision with a mean cost that scales linearly in the precision. The method
performs no extended precision arithmetic, calls no transcendental functions,
and, indeed, uses no floating point arithmetic whatsoever; it uses only simple
integer operations. It can easily be adapted to sample exactly from the
discrete normal distribution whose parameters are rational numbers.
"
343,"Highly Scalable Multiplication for Distributed Sparse Multivariate
  Polynomials on Many-core Systems","  We present a highly scalable algorithm for multiplying sparse multivariate
polynomials represented in a distributed format. This algo- rithm targets not
only the shared memory multicore computers, but also computers clusters or
specialized hardware attached to a host computer, such as graphics processing
units or many-core coprocessors. The scal- ability on the large number of cores
is ensured by the lacks of synchro- nizations, locks and false-sharing during
the main parallel step.
"
344,"Efficient Generation of Correctness Certificates for the Abstract Domain
  of Polyhedra","  Polyhedra form an established abstract domain for inferring runtime
properties of programs using abstract interpretation. Computations on them need
to be certified for the whole static analysis results to be trusted. In this
work, we look at how far we can get down the road of a posteriori verification
to lower the overhead of certification of the abstract domain of polyhedra. We
demonstrate methods for making the cost of inclusion certificate generation
negligible. From a performance point of view, our single-representation,
constraints-based implementation compares with state-of-the-art
implementations.
"
345,C Language Extensions for Hybrid CPU/GPU Programming with StarPU,"  Modern platforms used for high-performance computing (HPC) include machines
with both general-purpose CPUs, and ""accelerators"", often in the form of
graphical processing units (GPUs). StarPU is a C library to exploit such
platforms. It provides users with ways to define ""tasks"" to be executed on CPUs
or GPUs, along with the dependencies among them, and by automatically
scheduling them over all the available processing units. In doing so, it also
relieves programmers from the need to know the underlying architecture details:
it adapts to the available CPUs and GPUs, and automatically transfers data
between main memory and GPUs as needed. While StarPU's approach is successful
at addressing run-time scheduling issues, being a C library makes for a poor
and error-prone programming interface. This paper presents an effort started in
2011 to promote some of the concepts exported by the library as C language
constructs, by means of an extension of the GCC compiler suite. Our main
contribution is the design and implementation of language extensions that map
to StarPU's task programming paradigm. We argue that the proposed extensions
make it easier to get started with StarPU,eliminate errors that can occur when
using the C library, and help diagnose possible mistakes. We conclude on future
work.
"
346,"The Graph Grammar Library - a generic framework for chemical graph
  rewrite systems","  Graph rewrite systems are powerful tools to model and study complex problems
in various fields of research. Their successful application to chemical
reaction modelling on a molecular level was shown but no appropriate and simple
system is available at the moment.
  The presented Graph Grammar Library (GGL) implements a generic Double Push
Out approach for general graph rewrite systems. The framework focuses on a high
level of modularity as well as high performance, using state-of-the-art
algorithms and data structures, and comes with extensive documentation. The
large GGL chemistry module enables extensive and detailed studies of chemical
systems. It well meets the requirements and abilities envisioned by Yadav et
al. (2004) for such chemical rewrite systems. Here, molecules are represented
as undirected labeled graphs while chemical reactions are described by
according graph grammar rules. Beside the graph transformation, the GGL offers
advanced cheminformatics algorithms for instance to estimate energies
ofmolecules or aromaticity perception. These features are illustrated using a
set of reactions from polyketide chemistry a huge class of natural compounds of
medical relevance.
  The graph grammar based simulation of chemical reactions offered by the GGL
is a powerful tool for extensive cheminformatics studies on a molecular level.
The GGL already provides rewrite rules for all enzymes listed in the KEGG
LIGAND database is freely available at
http://www.tbi.univie.ac.at/software/GGL/.
"
347,"Improved Accuracy and Parallelism for MRRR-based Eigensolvers -- A Mixed
  Precision Approach","  The real symmetric tridiagonal eigenproblem is of outstanding importance in
numerical computations; it arises frequently as part of eigensolvers for
standard and generalized dense Hermitian eigenproblems that are based on a
reduction to tridiagonal form. For its solution, the algorithm of Multiple
Relatively Robust Representations (MRRR) is among the fastest methods. Although
fast, the solvers based on MRRR do not deliver the same accuracy as competing
methods like Divide & Conquer or the QR algorithm. In this paper, we
demonstrate that the use of mixed precisions leads to improved accuracy of
MRRR-based eigensolvers with limited or no performance penalty. As a result, we
obtain eigensolvers that are not only equally or more accurate than the best
available methods, but also -in most circumstances- faster and more scalable
than the competition.
"
348,Algorithms for Large-scale Whole Genome Association Analysis,"  In order to associate complex traits with genetic polymorphisms, genome-wide
association studies process huge datasets involving tens of thousands of
individuals genotyped for millions of polymorphisms. When handling these
datasets, which exceed the main memory of contemporary computers, one faces two
distinct challenges: 1) Millions of polymorphisms come at the cost of hundreds
of Gigabytes of genotype data, which can only be kept in secondary storage; 2)
the relatedness of the test population is represented by a covariance matrix,
which, for large populations, can only fit in the combined main memory of a
distributed architecture. In this paper, we present solutions for both
challenges: The genotype data is streamed from and to secondary storage using a
double buffering technique, while the covariance matrix is kept across the main
memory of a distributed memory system. We show that these methods sustain
high-performance and allow the analysis of enormous dataset
"
349,Solving Wave Equations on Unstructured Geometries,"  Waves are all around us--be it in the form of sound, electromagnetic
radiation, water waves, or earthquakes. Their study is an important basic tool
across engineering and science disciplines. Every wave solver serving the
computational study of waves meets a trade-off of two figures of merit--its
computational speed and its accuracy. Discontinuous Galerkin (DG) methods fall
on the high-accuracy end of this spectrum. Fortuitously, their computational
structure is so ideally suited to GPUs that they also achieve very high
computational speeds. In other words, the use of DG methods on GPUs
significantly lowers the cost of obtaining accurate solutions. This article
aims to give the reader an easy on-ramp to the use of this technology, based on
a sample implementation which demonstrates a highly accurate, GPU-capable,
real-time visualizing finite element solver in about 1500 lines of code.
"
350,"Minimal Residual Methods for Complex Symmetric, Skew Symmetric, and Skew
  Hermitian Systems","  While there is no lack of efficient Krylov subspace solvers for Hermitian
systems, there are few for complex symmetric, skew symmetric, or skew Hermitian
systems, which are increasingly important in modern applications including
quantum dynamics, electromagnetics, and power systems. For a large consistent
complex symmetric system, one may apply a non-Hermitian Krylov subspace method
disregarding the symmetry of $A$, or a Hermitian Krylov solver on the
equivalent normal equation or an augmented system twice the original dimension.
These have the disadvantages of increasing either memory, conditioning, or
computational costs. An exception is a special version of QMR by Freund (1992),
but that may be affected by non-benign breakdowns unless look-ahead is
implemented; furthermore, it is designed for only consistent and nonsingular
problems. For skew symmetric systems, Greif and Varah (2009) adapted CG for
nonsingular skew symmetric linear systems that are necessarily and
restrictively of even order.
  We extend the symmetric and Hermitian algorithms MINRES and MINRES-QLP by
Choi, Paige and Saunders (2011) to complex symmetric, skew symmetric, and skew
Hermitian systems. In particular, MINRES-QLP uses a rank-revealing QLP
decomposition of the tridiagonal matrix from a three-term recurrent
complex-symmetric Lanczos process. Whether the systems are real or complex,
singular or invertible, compatible or inconsistent, MINRES-QLP computes the
unique minimum-length, i.e., pseudoinverse, solutions. It is a significant
extension of MINRES by Paige and Saunders (1975) with enhanced stability and
capability.
"
351,An implementation of the relational k-means algorithm,"  A C# implementation of a generalized k-means variant called relational
k-means is described here. Relational k-means is a generalization of the
well-known k-means clustering method which works for non-Euclidean scenarios as
well. The input is an arbitrary distance matrix, as opposed to the traditional
k-means method, where the clustered objects need to be identified with vectors.
"
352,"Subspace-preserving sparsification of matrices with minimal perturbation
  to the near null-space. Part I: Basics","  This is the first of two papers to describe a matrix sparsification algorithm
that takes a general real or complex matrix as input and produces a sparse
output matrix of the same size. The non-zero entries in the output are chosen
to minimize changes to the singular values and singular vectors corresponding
to the near null-space of the input. The output matrix is constrained to
preserve left and right null-spaces exactly. The sparsity pattern of the output
matrix is automatically determined or can be given as input.
  If the input matrix belongs to a common matrix subspace, we prove that the
computed sparse matrix belongs to the same subspace. This works without
imposing explicit constraints pertaining to the subspace. This property holds
for the subspaces of Hermitian, complex-symmetric, Hamiltonian, circulant,
centrosymmetric, and persymmetric matrices, and for each of the skew
counterparts.
  Applications of our method include computation of reusable sparse
preconditioning matrices for reliable and efficient solution of high-order
finite element systems. The second paper in this series describes our
open-source implementation, and presents further technical details.
"
353,"Subspace-preserving sparsification of matrices with minimal perturbation
  to the near null-space. Part II: Approximation and Implementation","  This is the second of two papers to describe a matrix sparsification
algorithm that takes a general real or complex matrix as input and produces a
sparse output matrix of the same size. The first paper presented the original
algorithm, its features, and theoretical results.
  Since the output of this sparsification algorithm is a matrix rather than a
vector, it can be costly in memory and run-time if an implementation does not
exploit the structural properties of the algorithm and the matrix. Here we show
how to modify the original algorithm to increase its efficiency. This is
possible by computing an approximation to the exact result. We introduce extra
constraints that are automatically determined based on the input matrix. This
addition reduces the number of unknown degrees of freedom but still preserves
many matrix subspaces. We also describe our open-source library that implements
this sparsification algorithm and has interfaces in C++, C, and MATLAB.
"
354,"A GEMM interface and implementation on NVIDIA GPUs for multiple small
  matrices","  We present an interface and an implementation of the General Matrix Multiply
(GEMM) routine for multiple small matrices processed simultaneously on NVIDIA
graphics processing units (GPUs). We focus on matrix sizes under 16. The
implementation can be easily extended to larger sizes. For single precision
matrices, our implementation is 30% to 600% faster than the batched cuBLAS
implementation distributed in the CUDA Toolkit 5.0 on NVIDIA Tesla K20c. For
example, we obtain 104 GFlop/s and 216 GFlop/s when multiplying 100,000
independent matrix pairs of size 10 and 16, respectively. Similar improvement
in performance is obtained for other sizes, in single and double precision for
real and complex types, and when the number of matrices is smaller. Apart from
our implementation, our different function interface also plays an important
role in the improved performance. Applications of this software include Finite
Element computation on GPUs.
"
355,Batched Kronecker product for 2-D matrices and 3-D arrays on NVIDIA GPUs,"  We describe an interface and an implementation for performing Kronecker
product actions on NVIDIA GPUs for multiple small 2-D matrices and 3-D arrays
processed in parallel as a batch. This method is suited to cases where the
Kronecker product component matrices are identical but the operands in a
matrix-free application vary in the batch. Any batched GEMM (General Matrix
Multiply) implementation, for example ours [1] or the one in cuBLAS, can also
be used for performing batched Kronecker products on GPUs. However, the
specialized implementation presented here is faster and uses less memory.
Partly this is because a simple GEMM based approach would require extra copies
to and from main memory. We focus on matrix sizes less than or equal to 16,
since these are the typical polynomial degrees in Finite Elements, but the
implementation can be easily extended for other sizes. We obtain 143 and 285
GFlop/s for single precision real when processing matrices of size 10 and 16,
respectively on NVIDIA Tesla K20c using CUDA 5.0. The corresponding speeds for
3-D array Kronecker products are 126 and 268 GFlop/s, respectively. Double
precision is easily supported using the C++ template mechanism.
"
356,"Proceedings International Workshop on the ACL2 Theorem Prover and its
  Applications","  This volume contains the proceedings of the Eleventh International Workshop
on the ACL2 Theorem Prover and its Applications, held on May 30 and 31, 2013,
in Laramie, Wyoming, USA.
  ACL2 is an industrial-strength automated reasoning system, the latest in the
Boyer-Moore family of theorem provers. The ACL2 workshop is the major technical
forum for users of the ACL2 theorem proving system to present research on the
prover and its applications.
  This year's workshop received 15 submissions covering a wide range of
applications, libraries, prover enhancements, interfaces, and experience
reports. 11 papers were selected by the program committee for presentation at
the workshop.
"
357,Understanding Branch Cuts of Expressions,"  We assume some standard choices for the branch cuts of a group of functions
and consider the problem of then calculating the branch cuts of expressions
involving those functions. Typical examples include the addition formulae for
inverse trigonometric functions. Understanding these cuts is essential for
working with the single-valued counterparts, the common approach to encoding
multi-valued functions in computer algebra systems. While the defining choices
are usually simple (typically portions of either the real or imaginary axes)
the cuts induced by the expression may be surprisingly complicated. We have
made explicit and implemented techniques for calculating the cuts in the
computer algebra programme Maple. We discuss the issues raised, classifying the
different cuts produced. The techniques have been gathered in the BranchCuts
package, along with tools for visualising the cuts. The package is included in
Maple 17 as part of the FunctionAdvisor tool.
"
358,"Enhancements to ACL2 in Versions 5.0, 6.0, and 6.1","  We report on highlights of the ACL2 enhancements introduced in ACL2 releases
since the 2011 ACL2 Workshop. Although many enhancements are critical for
soundness or robustness, we focus in this paper on those improvements that
could benefit users who are aware of them, but that might not be discovered in
everyday practice.
"
359,Verified AIG Algorithms in ACL2,"  And-Inverter Graphs (AIGs) are a popular way to represent Boolean functions
(like circuits). AIG simplification algorithms can dramatically reduce an AIG,
and play an important role in modern hardware verification tools like
equivalence checkers. In practice, these tricky algorithms are implemented with
optimized C or C++ routines with no guarantee of correctness. Meanwhile, many
interactive theorem provers can now employ SAT or SMT solvers to automatically
solve finite goals, but no theorem prover makes use of these advanced,
AIG-based approaches.
  We have developed two ways to represent AIGs within the ACL2 theorem prover.
One representation, Hons-AIGs, is especially convenient to use and reason
about. The other, Aignet, is the opposite; it is styled after modern AIG
packages and allows for efficient algorithms. We have implemented functions for
converting between these representations, random vector simulation, conversion
to CNF, etc., and developed reasoning strategies for verifying these
algorithms.
  Aside from these contributions towards verifying AIG algorithms, this work
has an immediate, practical benefit for ACL2 users who are using GL to
bit-blast finite ACL2 theorems: they can now optionally trust an off-the-shelf
SAT solver to carry out the proof, instead of using the built-in BDD package.
Looking to the future, it is a first step toward implementing verified AIG
simplification algorithms that might further improve GL performance.
"
360,Somoclu: An Efficient Parallel Library for Self-Organizing Maps,"  Somoclu is a massively parallel tool for training self-organizing maps on
large data sets written in C++. It builds on OpenMP for multicore execution,
and on MPI for distributing the workload across the nodes in a cluster. It is
also able to boost training by using CUDA if graphics processing units are
available. A sparse kernel is included, which is useful for high-dimensional
but sparse data, such as the vector spaces common in text mining workflows.
Python, R and MATLAB interfaces facilitate interactive use. Apart from fast
execution, memory use is highly optimized, enabling training large emergent
maps even on a single computer.
"
361,"HERMES: towards an integrated toolbox to characterize functional and
  effective brain connectivity","  The analysis of the interdependence between time series has become an
important field of research in the last years, mainly as a result of advances
in the characterization of dynamical systems from the signals they produce, the
introduction of concepts such as generalized and phase synchronization and the
application of information theory to time series analysis. In neurophysiology,
different analytical tools stemming from these concepts have added to the
'traditional' set of linear methods, which includes the cross-correlation and
the coherency function in the time and frequency domain, respectively, or more
elaborated tools such as Granger Causality. This increase in the number of
approaches to tackle the existence of functional (FC) or effective connectivity
(EC) between two (or among many) neural networks, along with the mathematical
complexity of the corresponding time series analysis tools, makes it desirable
to arrange them into a unified-easy-to-use software package. The goal is to
allow neuroscientists, neurophysiologists and researchers from related fields
to easily access and make use of these analysis methods from a single
integrated toolbox. Here we present HERMES (http://hermes.ctb.upm.es), a
toolbox for the Matlab environment (The Mathworks, Inc), which is designed for
the analysis functional and effective brain connectivity from
neurophysiological data such as multivariate EEG and/or MEG records. It
includes also visualization tools and statistical methods to address the
problem of multiple comparisons. We believe that this toolbox will be very
helpful to all the researchers working in the emerging field of brain
connectivity analysis.
"
362,"An efficient way to perform the assembly of finite element matrices in
  Matlab and Octave","  We describe different optimization techniques to perform the assembly of
finite element matrices in Matlab and Octave, from the standard approach to
recent vectorized ones, without any low level language used. We finally obtain
a simple and efficient vectorized algorithm able to compete in performance with
dedicated software such as FreeFEM++. The principle of this assembly algorithm
is general, we present it for different matrices in the P1 finite elements case
and in linear elasticity. We present numerical results which illustrate the
computational costs of the different approaches
"
363,A computer algebra user interface manifesto,"  Many computer algebra systems have more than 1000 built-in functions, making
expertise difficult. Using mock dialog boxes, this article describes a proposed
interactive general-purpose wizard for organizing optional transformations and
allowing easy fine grain control over the form of the result even by amateurs.
This wizard integrates ideas including:
  * flexible subexpression selection;
  * complete control over the ordering of variables and commutative operands,
with well-chosen defaults;
  * interleaving the choice of successively less main variables with applicable
function choices to provide detailed control without incurring a combinatorial
number of applicable alternatives at any one level;
  * quick applicability tests to reduce the listing of inapplicable
transformations;
  * using an organizing principle to order the alternatives in a helpful
manner;
  * labeling quickly-computed alternatives in dialog boxes with a preview of
their results,
  * using ellipsis elisions if necessary or helpful;
  * allowing the user to retreat from a sequence of choices to explore other
branches of the tree of alternatives or to return quickly to branches already
visited;
  * allowing the user to accumulate more than one of the alternative forms;
  * integrating direct manipulation into the wizard; and
  * supporting not only the usual input-result pair mode, but also the useful
alternative derivational and in situ replacement modes in a unified window.
"
364,Making the case of GPUs in courses on computational physics,"  Most relatively modern desktop or even laptop computers contain a graphics
card useful for more than showing colors on a screen. In this paper, we make a
case for why you should learn enough about GPU (graphics processing unit)
computing to use as an accelerator or even replacement to your CPU code. We
include an example of our own as a case study to show what can be realistically
expected.
"
365,PetIGA: A Framework for High-Performance Isogeometric Analysis,"  We present PetIGA, a code framework to approximate the solution of partial
differential equations using isogeometric analysis. PetIGA can be used to
assemble matrices and vectors which come from a Galerkin weak form, discretized
with Non-Uniform Rational B-spline basis functions. We base our framework on
PETSc, a high-performance library for the scalable solution of partial
differential equations, which simplifies the development of large-scale
scientific codes, provides a rich environment for prototyping, and separates
parallelism from algorithm choice. We describe the implementation of PetIGA,
and exemplify its use by solving a model nonlinear problem. To illustrate the
robustness and flexibility of PetIGA, we solve some challenging nonlinear
partial differential equations that include problems in both solid and fluid
mechanics. We show strong scaling results on up to 4096 cores, which confirm
the suitability of PetIGA for large scale simulations.
"
366,Parallelizing Gaussian Process Calculations in R,"  We consider parallel computation for Gaussian process calculations to
overcome computational and memory constraints on the size of datasets that can
be analyzed. Using a hybrid parallelization approach that uses both threading
(shared memory) and message-passing (distributed memory), we implement the core
linear algebra operations used in spatial statistics and Gaussian process
regression in an R package called bigGP that relies on C and MPI. The approach
divides the matrix into blocks such that the computational load is balanced
across processes while communication between processes is limited. The package
provides an API enabling R programmers to implement Gaussian process-based
methods by using the distributed linear algebra operations without any C or MPI
coding. We illustrate the approach and software by analyzing an astrophysics
dataset with n=67,275 observations.
"
367,"A Parallel and Scalable Iterative Solver for Sequences of Dense
  Eigenproblems Arising in FLAPW","  In one of the most important methods in Density Functional Theory - the
Full-Potential Linearized Augmented Plane Wave (FLAPW) method - dense
generalized eigenproblems are organized in long sequences. Moreover each
eigenproblem is strongly correlated to the next one in the sequence. We propose
a novel approach which exploits such correlation through the use of an
eigensolver based on subspace iteration and accelerated with Chebyshev
polynomials. The resulting solver, parallelized using the Elemental library
framework, achieves excellent scalability and is competitive with current dense
parallel eigensolvers.
"
368,Formal Mathematics on Display: A Wiki for Flyspeck,"  The Agora system is a prototype ""Wiki for Formal Mathematics"", with an aim to
support developing and documenting large formalizations of mathematics in a
proof assistant. The functions implemented in Agora include in-browser editing,
strong AI/ATP proof advice, verification, and HTML rendering. The HTML
rendering contains hyperlinks and provides on-demand explanation of the proof
state for each proof step. In the present paper we show the prototype Flyspeck
Wiki as an instance of Agora for HOL Light formalizations. The wiki can be used
for formalizations of mathematics and for writing informal wiki pages about
mathematics. Such informal pages may contain islands of formal text, which is
used here for providing an initial cross-linking between Hales's informal
Flyspeck book, and the formal Flyspeck development.
  The Agora platform intends to address distributed wiki-style collaboration on
large formalization projects, in particular both the aspect of immediate
editing, verification and rendering of formal code, and the aspect of gradual
and mutual refactoring and correspondence of the initial informal text and its
formalization. Here, we highlight these features within the Flyspeck Wiki.
"
369,swMATH - a new information service for mathematical software,"  An information service for mathematical software is presented. Publications
and software are two closely connected facets of mathematical knowledge. This
relation can be used to identify mathematical software and find relevant
information about it. The approach and the state of the art of the information
service are described here.
"
370,Arithmetic Algorithms for Hereditarily Binary Natural Numbers,"  We study some essential arithmetic properties of a new tree-based number
representation, {\em hereditarily binary numbers}, defined by applying
recursively run-length encoding of bijective base-2 digits.
  Our representation expresses giant numbers like the largest known prime
number and its related perfect number as well as the largest known Woodall,
Cullen, Proth, Sophie Germain and twin primes as trees of small sizes.
  More importantly, our number representation supports novel algorithms that,
in the best case, collapse the complexity of various computations by
super-exponential factors and in the worse case are within a constant factor of
their traditional counterparts.
  As a result, it opens the door to a new world, where arithmetic operations
are limited by the structural complexity of their operands, rather than their
bitsizes.
"
371,MathGR: a tensor and GR computation package to keep it simple,"  We introduce the MathGR package, written in Mathematica. The package can
manipulate tensor and GR calculations with either abstract or explicit indices,
simplify tensors with permutational symmetries, decompose tensors from abstract
indices to partially or completely explicit indices and convert partial
derivatives into total derivatives. Frequently used GR tensors and a model of
FRW universe with ADM type perturbations are predefined. The package is built
around the philosophy to ""keep it simple"", and makes use of latest tensor
technologies of Mathematica.
"
372,A Universal Machine for Biform Theory Graphs,"  Broadly speaking, there are two kinds of semantics-aware assistant systems
for mathematics: proof assistants express the semantic in logic and emphasize
deduction, and computer algebra systems express the semantics in programming
languages and emphasize computation. Combining the complementary strengths of
both approaches while mending their complementary weaknesses has been an
important goal of the mechanized mathematics community for some time. We pick
up on the idea of biform theories and interpret it in the MMTt/OMDoc framework
which introduced the foundations-as-theories approach, and can thus represent
both logics and programming languages as theories. This yields a formal,
modular framework of biform theory graphs which mixes specifications and
implementations sharing the module system and typing information. We present
automated knowledge management work flows that interface to existing
specification/programming tools and enable an OpenMath Machine, that
operationalizes biform theories, evaluating expressions by exhaustively
applying the implementations of the respective operators. We evaluate the new
biform framework by adding implementations to the OpenMath standard content
dictionaries.
"
373,Programs in C++ for matrix computations in min plus algebra,"  The main purpose of this paper is to propose six programs in C++ for matrix
computations and solving recurrent equations systems with entries in min plus
algebra.
"
374,vSMC: Parallel Sequential Monte Carlo in C++,"  Sequential Monte Carlo is a family of algorithms for sampling from a sequence
of distributions. Some of these algorithms, such as particle filters, are
widely used in the physics and signal processing researches. More recent
developments have established their application in more general inference
problems such as Bayesian modeling.
  These algorithms have attracted considerable attentions in recent years as
they admit natural and scalable parallelizations. However, these algorithms are
perceived to be difficult to implement. In addition, parallel programming is
often unfamiliar to many researchers though conceptually appealing, especially
for sequential Monte Carlo related fields.
  A C++ template library is presented for the purpose of implementing general
sequential Monte Carlo algorithms on parallel hardware. Two examples are
presented: a simple particle filter and a classic Bayesian modeling problem.
"
375,Panphasia: a user guide,"  We make a very large realisation of a Gaussian white noise field, called
PANPHASIA, public by releasing software that computes this field. Panphasia is
designed specifically for setting up Gaussian initial conditions for
cosmological simulations and resimulations of structure formation. We make
available both software to compute the field itself and codes to illustrate
applications including a modified version of a public serial initial conditions
generator. We document the software and present the results of a few basic
tests of the field. The properties and method of construction of Panphasia are
described in full in a companion paper Jenkins 2013.
"
376,A Method for Fast Diagonalization of a 2x2 or 3x3 Real Symmetric Matrix,"  A method is presented for fast diagonalization of a 2x2 or 3x3 real symmetric
matrix, that is determination of its eigenvalues and eigenvectors. The Euler
angles of the eigenvectors are computed. A small computer algebra program is
used to compute some of the identities, and a C++ program for testing the
formulas has been uploaded to arXiv.
"
377,"Next generation input-output data format for HEP using Google's protocol
  buffers","  We propose a data format for Monte Carlo (MC) events, or any structural data,
including experimental data, in a compact binary form using variable-size
integer encoding as implemented in the Google's Protocol Buffers package. This
approach is implemented in the so-called ProMC library which produces smaller
file sizes for MC records compared to the existing input-output libraries used
in high-energy physics (HEP). Other important features are a separation of
abstract data layouts from concrete programming implementations,
self-description and random access. Data stored in ProMC files can be written,
read and manipulated in a number of programming languages, such C++, Java and
Python.
"
378,"Investigating independent subsets of graphs, with Mathematica","  With this work we aim to show how Mathematica can be a useful tool to
investigate properties of combinatorial structures. Specifically, we will face
enumeration problems on independent subsets of powers of paths and cycles,
trying to highlight the correspondence with other combinatorial objects with
the same cardinality. Then we will study the structures obtained by ordering
properly independent subsets of paths and cycles. We will approach some
enumeration problems on the resulting partially ordered sets, putting in
evidence the correspondences with structures known as Fibonacci and Lucas
Cubes.
"
379,"Building Bricks with Bricks, with Mathematica","  In this work we solve a special case of the problem of building an
n-dimensional parallelepiped using a given set of n-dimensional
parallelepipeds. Consider the identity x^3 = x(x-1)(x-2)+3x(x-1+x). For
sufficiently large x, we associate with x^3 a cube with edges of size x, with
x(x-1)(x-2) a parallelepiped with edges x, x-1, x-2, with 3x(x-1+x) three
parallelepipeds of edges x, x-1, 1, and with x a parallelepiped of edges x, 1,
1. The problem we takle is the actual construction of the cube using the given
parallelepipeds. In [DDNP90] it was shown how to solve this specific problem
and all similar instances in which a (monic) polynomial is expressed as a
linear combination of a persistent basis. That is to say a sequence of
polynomials q_0 = 1, and q_k(x) = q_{k-1}(x)(x-r_k) for k > 0. Here, after
[Fil10], we deal with a multivariate version of the problem with respect to a
basis of polynomials of the same degree (binomial basis). We show that it is
possible to build the parallelepiped associated with a multivariate polynomial
P(x_1, ..., x_n)=(x_1- s_1)...(x_n-s_n) with integer roots, using the
parallelepipeds described by the elements of the basis. We provide an algorithm
in Mathematica to solve the problem for each n. Moreover, for n = 2, 3, 4 (in
the latter case, only when a projection is possible) we use Mathematica to
display a step by step construction of the parallelepiped P(x1,...,x_n).
"
380,Making simple proofs simpler,"  An open partition \pi{} [Cod09a, Cod09b] of a tree T is a partition of the
vertices of T with the property that, for each block B of \pi, the upset of B
is a union of blocks of \pi. This paper deals with the number, NP(n), of open
partitions of the tree, V_n, made of two chains with n points each, that share
the root.
"
381,A Mathematica package to cope with partially ordered sets,"  Mathematica offers, by way of the package Combinatorics, many useful
functions to work on graphs and ordered structures, but none of these functions
was specific enough to meet the needs of our research group. Moreover, the
existing functions are not always helpful when one has to work on new concepts.
  In this paper we present a package of features developed in Mathematica which
we consider particularly useful for the study of certain categories of
partially ordered sets. Among the features offered, the package includes: (1)
some basic features to treat partially ordered sets; (2) the ability to
enumerate, create, and display monotone and regular partitions of partially
ordered sets; (3) the capability of constructing the lattices of partitions of
a poset, and of doing some useful computations on these structures; (4) the
possibility of computing products and coproducts in the category of partially
ordered sets and monotone maps; (5) the possibility of computing products and
coproducts in the category of forests (disjoint union of trees) and open maps
(cf. [DM06] for the product between forests).
"
382,"Proceedings 10th International Workshop On User Interfaces for Theorem
  Provers","  This EPTCS volume collects the post-proceedings of the 10th International
Workshop On User Interfaces for Theorem Provers (UITP 2012), held as part of
the Conferences on Intelligent Computer Mathematics (CICM 2012) in Bremen on
July 11th 2012. The UITP workshop series aims at bringing together reasearchers
interested in designing, developing and evaluating interfaces for interactive
proof systems, such as theorem provers, formal method tools, and other tools
manipulating and presenting mathematical formulae. Started in 1995, it can look
back on seventeen years of history by now.
  The papers in the present volume give a good indication of the range of
questions currently addressed in the UITP community; this ranges from interface
design (Windsteiger; Dunchev et al) to using technologies such as machine
learning to assist the user (Komendantskaya et al). The web features
prominently (Tankink), and new technology necessitates changes right down to
the very basic modes of interaction (Wenzel) - the old REPL (read, evaluate,
print, loop) mode of interaction can not take advantage of modern technology,
such as the web and multi-core machines.
"
383,PROOFTOOL: a GUI for the GAPT Framework,"  This paper introduces PROOFTOOL, the graphical user interface for the General
Architecture for Proof Theory (GAPT) framework. Its features are described with
a focus not only on the visualization but also on the analysis and
transformation of proofs and related tree-like structures, and its
implementation is explained. Finally, PROOFTOOL is compared with three other
graphical interfaces for proofs.
"
384,"Theorema 2.0: A Graphical User Interface for a Mathematical Assistant
  System","  Theorema 2.0 stands for a re-design including a complete re-implementation of
the Theorema system, which was originally designed, developed, and implemented
by Bruno Buchberger and his Theorema group at RISC. In this paper, we present
the first prototype of a graphical user interface (GUI) for the new system. It
heavily relies on powerful interactive capabilities introduced in recent
releases of the underlying Mathematica system, most importantly the possibility
of having dynamic objects connected to interface elements like sliders, menus,
check-boxes, radio-buttons and the like. All these features are fully
integrated into the Mathematica programming environment and allow the
implementation of a modern user interface.
"
385,"Towards an Efficient Use of the BLAS Library for Multilinear Tensor
  Contractions","  Mathematical operators whose transformation rules constitute the building
blocks of a multi-linear algebra are widely used in physics and engineering
applications where they are very often represented as tensors. In the last
century, thanks to the advances in tensor calculus, it was possible to uncover
new research fields and make remarkable progress in the existing ones, from
electromagnetism to the dynamics of fluids and from the mechanics of rigid
bodies to quantum mechanics of many atoms. By now, the formal mathematical and
geometrical properties of tensors are well defined and understood; conversely,
in the context of scientific and high-performance computing, many tensor-
related problems are still open. In this paper, we address the problem of
efficiently computing contractions among two tensors of arbitrary dimension by
using kernels from the highly optimized BLAS library. In particular, we
establish precise conditions to determine if and when GEMM, the kernel for
matrix products, can be used. Such conditions take into consideration both the
nature of the operation and the storage scheme of the tensors, and induce a
classification of the contractions into three groups. For each group, we
provide a recipe to guide the users towards the most effective use of BLAS.
"
386,"The Declaratron, semantic specification for scientific computation using
  MathML","  We introduce the Declaratron, a system which takes a declarative approach to
specifying mathematically based scientific computation. This uses displayable
mathematical notation (Content MathML) and is both executable and semantically
well defined. We combine domain specific representations of physical science
(e.g. CML, Chemical Markup Language), MathML formulae and computational
specifications (DeXML) to create executable documents which include scientific
data and mathematical formulae. These documents preserve the provenance of the
data used, and build tight semantic links between components of mathematical
formulae and domain objects---in effect grounding the mathematical semantics in
the scientific domain. The Declaratron takes these specifications and i)
carries out entity resolution and decoration to prepare for computation ii)
uses a MathML execution engine to run calculations over the revised tree iii)
outputs domain objects and the complete document to give both results and an
encapsulated history of the computation. A short description of a case study is
given to illustrate how the system can be used. Many scientific problems
require frequent change of the mathematical functional form and the Declaratron
provides this without requiring changes to code. Additionally, it supports
reproducible science, machine indexing and semantic search of computations,
makes implicit assumptions visible, and separates domain knowledge from
computational techniques. We believe that the Declaratron could replace much
conventional procedural code in science.
"
387,"Acceleration of univariate global optimization algorithms working with
  Lipschitz functions and Lipschitz first derivatives","  This paper deals with two kinds of the one-dimensional global optimization
problems over a closed finite interval: (i) the objective function $f(x)$
satisfies the Lipschitz condition with a constant $L$; (ii) the first
derivative of $f(x)$ satisfies the Lipschitz condition with a constant $M$. In
the paper, six algorithms are presented for the case (i) and six algorithms for
the case (ii). In both cases, auxiliary functions are constructed and
adaptively improved during the search. In the case (i), piece-wise linear
functions are constructed and in the case (ii) smooth piece-wise quadratic
functions are used. The constants $L$ and $M$ either are taken as values known
a priori or are dynamically estimated during the search. A recent technique
that adaptively estimates the local Lipschitz constants over different zones of
the search region is used to accelerate the search. A new technique called the
\emph{local improvement} is introduced in order to accelerate the search in
both cases (i) and (ii). The algorithms are described in a unique framework,
their properties are studied from a general viewpoint, and convergence
conditions of the proposed algorithms are given. Numerical experiments executed
on 120 test problems taken from the literature show quite a promising
performance of the new accelerating techniques.
"
388,"Solving ordinary differential equations on the Infinity Computer by
  working with infinitesimals numerically","  There exists a huge number of numerical methods that iteratively construct
approximations to the solution $y(x)$ of an ordinary differential equation
(ODE) $y'(x)=f(x,y)$ starting from an initial value $y_0=y(x_0)$ and using a
finite approximation step $h$ that influences the accuracy of the obtained
approximation. In this paper, a new framework for solving ODEs is presented for
a new kind of a computer -- the Infinity Computer (it has been patented and its
working prototype exists). The new computer is able to work numerically with
finite, infinite, and infinitesimal numbers giving so the possibility to use
different infinitesimals numerically and, in particular, to take advantage of
infinitesimal values of $h$. To show the potential of the new framework a
number of results is established. It is proved that the Infinity Computer is
able to calculate derivatives of the solution $y(x)$ and to reconstruct its
Taylor expansion of a desired order numerically without finding the respective
derivatives analytically (or symbolically) by the successive derivation of the
ODE as it is usually done when the Taylor method is applied. Methods using
approximations of derivatives obtained thanks to infinitesimals are discussed
and a technique for an automatic control of rounding errors is introduced.
Numerical examples are given.
"
389,"Lipschitz gradients for global optimization in a one-point-based
  partitioning scheme","  A global optimization problem is studied where the objective function $f(x)$
is a multidimensional black-box function and its gradient $f'(x)$ satisfies the
Lipschitz condition over a hyperinterval with an unknown Lipschitz constant
$K$. Different methods for solving this problem by using an a priori given
estimate of $K$, its adaptive estimates, and adaptive estimates of local
Lipschitz constants are known in the literature. Recently, the authors have
proposed a one-dimensional algorithm working with multiple estimates of the
Lipschitz constant for $f'(x)$ (the existence of such an algorithm was a
challenge for 15 years). In this paper, a new multidimensional geometric method
evolving the ideas of this one-dimensional scheme and using an efficient
one-point-based partitioning strategy is proposed. Numerical experiments
executed on 800 multidimensional test functions demonstrate quite a promising
performance in comparison with popular DIRECT-based methods.
"
390,"FullSWOF_Paral: Comparison of two parallelization strategies (MPI and
  SKELGIS) on a software designed for hydrology applications","  In this paper, we perform a comparison of two approaches for the
parallelization of an existing, free software, FullSWOF 2D (http://www.
univ-orleans.fr/mapmo/soft/FullSWOF/ that solves shallow water equations for
applications in hydrology) based on a domain decomposition strategy. The first
approach is based on the classical MPI library while the second approach uses
Parallel Algorithmic Skeletons and more precisely a library named SkelGIS
(Skeletons for Geographical Information Systems). The first results presented
in this article show that the two approaches are similar in terms of
performance and scalability. The two implementation strategies are however very
different and we discuss the advantages of each one.
"
391,"RNGSSELIB: Program library for random number generation. More
  generators, parallel streams of random numbers and Fortran compatibility","  In this update, we present the new version of the random number generator
(RNG) library RNGSSELIB, which, in particular, contains fast SSE realizations
of a number of modern and most reliable generators \cite{RNGSSELIB1}. The new
features are: i) Fortran compatibility and examples of using the library in
Fortran; ii) new modern and reliable generators; iii) the abilities to jump
ahead inside RNG sequence and to initialize up to $10^{19}$ independent random
number streams with block splitting method.
"
392,"PRAND: GPU accelerated parallel random number generation library: Using
  most reliable algorithms and applying parallelism of modern GPUs and CPUs","  The library PRAND for pseudorandom number generation for modern CPUs and GPUs
is presented. It contains both single-threaded and multi-threaded realizations
of a number of modern and most reliable generators recently proposed and
studied in [1,2,3,4,5] and the efficient SIMD realizations proposed in [6]. One
of the useful features for using PRAND in parallel simulations is the ability
to initialize up to $10^{19}$ independent streams. Using massive parallelism of
modern GPUs and SIMD parallelism of modern CPUs substantially improves
performance of the generators.
"
393,"A unified sparse matrix data format for efficient general sparse
  matrix-vector multiply on modern processors with wide SIMD units","  Sparse matrix-vector multiplication (spMVM) is the most time-consuming kernel
in many numerical algorithms and has been studied extensively on all modern
processor and accelerator architectures. However, the optimal sparse matrix
data storage format is highly hardware-specific, which could become an obstacle
when using heterogeneous systems. Also, it is as yet unclear how the wide
single instruction multiple data (SIMD) units in current multi- and many-core
processors should be used most efficiently if there is no structure in the
sparsity pattern of the matrix. We suggest SELL-C-sigma, a variant of Sliced
ELLPACK, as a SIMD-friendly data format which combines long-standing ideas from
General Purpose Graphics Processing Units (GPGPUs) and vector computer
programming. We discuss the advantages of SELL-C-sigma compared to established
formats like Compressed Row Storage (CRS) and ELLPACK and show its suitability
on a variety of hardware platforms (Intel Sandy Bridge, Intel Xeon Phi and
Nvidia Tesla K20) for a wide range of test matrices from different application
areas. Using appropriate performance models we develop deep insight into the
data transfer properties of the SELL-C-sigma spMVM kernel. SELL-C-sigma comes
with two tuning parameters whose performance impact across the range of test
matrices is studied and for which reasonable choices are proposed. This leads
to a hardware-independent (""catch-all"") sparse matrix format, which achieves
very high efficiency for all test matrices across all hardware platforms.
"
394,"From Physics Model to Results: An Optimizing Framework for
  Cross-Architecture Code Generation","  Starting from a high-level problem description in terms of partial
differential equations using abstract tensor notation, the Chemora framework
discretizes, optimizes, and generates complete high performance codes for a
wide range of compute architectures. Chemora extends the capabilities of
Cactus, facilitating the usage of large-scale CPU/GPU systems in an efficient
manner for complex applications, without low-level code tuning. Chemora
achieves parallelism through MPI and multi-threading, combining OpenMP and
CUDA. Optimizations include high-level code transformations, efficient loop
traversal strategies, dynamically selected data and instruction cache usage
strategies, and JIT compilation of GPU code tailored to the problem
characteristics. The discretization is based on higher-order finite differences
on multi-block domains. Chemora's capabilities are demonstrated by simulations
of black hole collisions. This problem provides an acid test of the framework,
as the Einstein equations contain hundreds of variables and thousands of terms.
"
395,"Supporting 64-bit global indices in Epetra and other Trilinos packages
  -- Techniques used and lessons learned","  The Trilinos Project is an effort to facilitate the design, development,
integration and ongoing support of mathematical software libraries within an
object-oriented framework. It is intended for large-scale, complex multiphysics
engineering and scientific applications. Epetra is one of its basic packages.
It provides serial and parallel linear algebra capabilities. Before Trilinos
version 11.0, released in 2012, Epetra used the C++ int data-type for storing
global and local indices for degrees of freedom (DOFs). Since int is typically
32-bit, this limited the largest problem size to be smaller than approximately
two billion DOFs. This was true even if a distributed memory machine could
handle larger problems. We have added optional support for C++ long long
data-type, which is at least 64-bit wide, for global indices. To save memory,
maintain the speed of memory-bound operations, and reduce further changes to
the code, the local indices are still 32-bit. We document the changes required
to achieve this feature and how the new functionality can be used. We also
report on the lessons learned in modifying a mature and popular package from
various perspectives -- design goals, backward compatibility, engineering
decisions, C++ language features, effects on existing users and other packages,
and build integration.
"
396,Python for education: permutations,"  Python implementation of permutations is presented. Three classes are
introduced: Perm for permutations, Group for permutation groups, and PermError
to report any errors for both classes. The class Perm is based on Python
dictionaries and utilize cycle notation. The methods of calculation for the
perm order, parity, ranking and unranking are given. A random permutation
generation is also shown. The class Group is very simple and it is also based
on dictionaries. It is mainly the presentation of the permutation groups
interface with methods for the group order, subgroups (normalizer, centralizer,
center, stabilizer), orbits, and several tests. The corresponding Python code
is contained in the modules perms and groups.
"
397,"ManyClaw: Slicing and dicing Riemann solvers for next generation highly
  parallel architectures","  Next generation computer architectures will include order of magnitude more
intra-node parallelism; however, many application programmers have a difficult
time keeping their codes current with the state-of-the-art machines. In this
context, we analyze Hyperbolic PDE solvers, which are used in the solution of
many important applications in science and engineering. We present ManyClaw, a
project intended to explore the exploitation of intra-node parallelism in
hyperbolic PDE solvers via the Clawpack software package for solving hyperbolic
PDEs. Our goal is to separate the low level parallelism and the physical
equations thus providing users the capability to leverage intra-node
parallelism without explicitly writing code to take advantage of newer
architectures.
"
398,"ForestClaw: Hybrid forest-of-octrees AMR for hyperbolic conservation
  laws","  We present a new hybrid paradigm for parallel adaptive mesh refinement (AMR)
that combines the scalability and lightweight architecture of tree-based AMR
with the computational efficiency of patch-based solvers for hyperbolic
conservation laws. The key idea is to interpret each leaf of the AMR hierarchy
as one uniform compute patch in $\sR^d$ with $m^d$ degrees of freedom, where
$m$ is customarily between 8 and 32. Thus, computation on each patch can be
optimized for speed, while we inherit the flexibility of adaptive meshes. In
our work we choose to integrate with the p4est AMR library since it allows us
to compose the mesh from multiple mapped octrees and enables the cubed sphere
and other nontrivial multiblock geometries. We describe aspects of the parallel
implementation and close with scalings for both MPI-only and OpenMP/MPI hybrid
runs, where the largest MPI run executes on 16,384 CPU cores.
"
399,"A Parallel Algorithm for Calculation of Large Determinants with High
  Accuracy for GPUs and MPI clusters","  We present a parallel algorithm for calculating very large determinants with
arbitrary precision on computer clusters. This algorithm minimises data
movements between the nodes and computes not only the determinant but also all
minors corresponding to a particular row or column at a little extra cost, and
also the determinants and minors of all submatrices in the top left corner at
no extra cost. We implemented the algorithm in arbitrary precision arithmetic,
suitable for very ill conditioned matrices, and empirically estimated the loss
of precision. The algorithm was applied to studies of Riemann's zeta function.
"
400,xTras: a field-theory inspired xAct package for Mathematica,"  We present the tensor computer algebra package xTras, which provides
functions and methods frequently needed when doing (classical) field theory.
Amongst others, it can compute contractions, make Ans\""atze, and solve
tensorial equations. It is built upon the tensor computer algebra system xAct,
a collection of packages for Mathematica.
"
401,Pylearn2: a machine learning research library,"  Pylearn2 is a machine learning research library. This does not just mean that
it is a collection of machine learning algorithms that share a common API; it
means that it has been designed for flexibility and extensibility in order to
facilitate research projects that involve new or unusual use cases. In this
paper we give a brief history of the library, an overview of its basic
philosophy, a summary of the library's architecture, and a description of how
the Pylearn2 community functions socially.
"
402,"Manopt, a Matlab toolbox for optimization on manifolds","  Optimization on manifolds is a rapidly developing branch of nonlinear
optimization. Its focus is on problems where the smooth geometry of the search
space can be leveraged to design efficient numerical algorithms. In particular,
optimization on manifolds is well-suited to deal with rank and orthogonality
constraints. Such structured constraints appear pervasively in machine learning
applications, including low-rank matrix completion, sensor network
localization, camera network registration, independent component analysis,
metric learning, dimensionality reduction and so on. The Manopt toolbox,
available at www.manopt.org, is a user-friendly, documented piece of software
dedicated to simplify experimenting with state of the art Riemannian
optimization algorithms. We aim particularly at reaching practitioners outside
our field.
"
403,"A Domain Decomposition Approach to Implementing Fault Slip in
  Finite-Element Models of Quasi-static and Dynamic Crustal Deformation","  We employ a domain decomposition approach with Lagrange multipliers to
implement fault slip in a finite-element code, PyLith, for use in both
quasi-static and dynamic crustal deformation applications. This integrated
approach to solving both quasi-static and dynamic simulations leverages common
finite-element data structures and implementations of various boundary
conditions, discretization schemes, and bulk and fault rheologies. We have
developed a custom preconditioner for the Lagrange multiplier portion of the
system of equations that provides excellent scalability with problem size
compared to conventional additive Schwarz methods. We demonstrate application
of this approach using benchmarks for both quasi-static viscoelastic
deformation and dynamic spontaneous rupture propagation that verify the
numerical implementation in PyLith.
"
404,"Algorithm 950: Ncpol2sdpa---Sparse Semidefinite Programming Relaxations
  for Polynomial Optimization Problems of Noncommuting Variables","  A hierarchy of semidefinite programming (SDP) relaxations approximates the
global optimum of polynomial optimization problems of noncommuting variables.
Generating the relaxation, however, is a computationally demanding task, and
only problems of commuting variables have efficient generators. We develop an
implementation for problems of noncommuting problems that creates the
relaxation to be solved by SDPA -- a high-performance solver that runs in a
distributed environment. We further exploit the inherent sparsity of
optimization problems in quantum physics to reduce the complexity of the
resulting relaxations. Constrained problems with a relaxation of order two may
contain up to a hundred variables. The implementation is available in Python.
The tool helps solve problems such as finding the ground state energy or
testing quantum correlations.
"
405,Branch Cuts in Maple 17,"  Accurate and comprehensible knowledge about the position of branch cuts is
essential for correctly working with multi-valued functions, such as the square
root and logarithm. We discuss the new tools in Maple 17 for calculating and
visualising the branch cuts of such functions, and others built up from them.
The cuts are described in an intuitive and accurate form, offering substantial
improvement on the descriptions previously available.
"
406,"API design for machine learning software: experiences from the
  scikit-learn project","  Scikit-learn is an increasingly popular machine learning li- brary. Written
in Python, it is designed to be simple and efficient, accessible to
non-experts, and reusable in various contexts. In this paper, we present and
discuss our design choices for the application programming interface (API) of
the project. In particular, we describe the simple and elegant interface shared
by all learning and processing units in the library and then discuss its
advantages in terms of composition and reusability. The paper also comments on
implementation details specific to the Python ecosystem and analyzes obstacles
faced by users and developers of the library.
"
407,BayesOpt: A Library for Bayesian optimization with Robotics Applications,"  The purpose of this paper is twofold. On one side, we present a general
framework for Bayesian optimization and we compare it with some related fields
in active learning and Bayesian numerical analysis. On the other hand, Bayesian
optimization and related problems (bandits, sequential experimental design) are
highly dependent on the surrogate model that is selected. However, there is no
clear standard in the literature. Thus, we present a fast and flexible toolbox
that allows to test and combine different models and criteria with little
effort. It includes most of the state-of-the-art contributions, algorithms and
models. Its speed also removes part of the stigma that Bayesian optimization
methods are only good for ""expensive functions"". The software is free and it
can be used in many operating systems and computer languages.
"
408,"Experiences with Automated Build and Test for Geodynamics Simulation
  Codes","  The Computational Infrastructure for Geodynamics (CIG) is an NSF funded
project that develops, supports, and disseminates community-accessible software
for the geodynamics research community. CIG software supports a variety of
computational geodynamic research from mantle and core dynamics, to crustal and
earthquake dynamics, to magma migration and seismology. To support this type of
project a backend computational infrastructure is necessary.
  Part of this backend infrastructure is an automated build and testing system
to ensure codes and changes to them are compatible with multiple platforms and
that the changes do not significantly affect the scientific results. In this
paper we describe the build and test infrastructure for CIG based on the BaTLab
system, how it is organized, and how it assists in operations. We demonstrate
the use of this type of testing for a suite of geophysics codes, show why codes
may compile on one platform but not on another, and demonstrate how minor
changes may alter the computed results in unexpected ways that can influence
the scientific interpretation. Finally, we examine result comparison between
platforms and show how the compiler or operating system may affect results.
"
409,Achieving High Performance with Unified Residual Evaluation,"  We examine residual evaluation, perhaps the most basic operation in numerical
simulation. By raising the level of abstraction in this operation, we can
eliminate specialized code, enable optimization, and greatly increase the
extensibility of existing code.
"
410,"Software Abstractions and Methodologies for HPC Simulation Codes on
  Future Architectures","  Large, complex, multi-scale, multi-physics simulation codes, running on high
performance com-puting (HPC) platforms, have become essential to advancing
science and engineering. These codes simulate multi-scale, multi-physics
phenomena with unprecedented fidelity on petascale platforms, and are used by
large communities. Continued ability of these codes to run on future platforms
is as crucial to their communities as continued improvements in instruments and
facilities are to experimental scientists. However, the ability of code
developers to do these things faces a serious challenge with the paradigm shift
underway in platform architecture. The complexity and uncertainty of the future
platforms makes it essential to approach this challenge cooperatively as a
community. We need to develop common abstractions, frameworks, programming
models and software development methodologies that can be applied across a
broad range of complex simulation codes, and common software infrastructure to
support them. In this position paper we express and discuss our belief that
such an infrastructure is critical to the deployment of existing and new large,
multi-scale, multi-physics codes on future HPC platforms.
"
411,"Experiences from Software Engineering of Large Scale AMR Multiphysics
  Code Frameworks","  Among the present generation of multiphysics HPC simulation codes there are
many that are built upon general infrastructural frameworks. This is especially
true of the codes that make use of structured adaptive mesh refinement (SAMR)
because of unique demands placed on the housekeeping aspects of the code. They
have varying degrees of abstractions between the infrastructure such as mesh
management and IO and the numerics of the physics solvers. In this experience
report we summarize the experiences and lessons learned from two of such major
software efforts, FLASH and Chombo.
"
412,"DUNE as an Example of Sustainable Open Source Scientific Software
  Development","  In this paper we describe how DUNE, an open source scientific software
framework, is developed. Having a sustainable software framework for the
solution of partial differential equations is the main driver of DUNE's
development. We take a look how DUNE strives to stay sustainable software.
"
413,Cactus: Issues for Sustainable Simulation Software,"  The Cactus Framework is an open-source, modular, portable programming
environment for the collaborative development and deployment of scientific
applications using high-performance computing. Its roots reach back to 1996 at
the National Center for Supercomputer Applications and the Albert Einstein
Institute in Germany, where its development jumpstarted. Since then, the Cactus
framework has witnessed major changes in hardware infrastructure as well as its
own community. This paper describes its endurance through these past changes
and, drawing upon lessons from its past, also discusses future
"
414,HOL(y)Hammer: Online ATP Service for HOL Light,"  HOL(y)Hammer is an online AI/ATP service for formal (computer-understandable)
mathematics encoded in the HOL Light system. The service allows its users to
upload and automatically process an arbitrary formal development (project)
based on HOL Light, and to attack arbitrary conjectures that use the concepts
defined in some of the uploaded projects. For that, the service uses several
automated reasoning systems combined with several premise selection methods
trained on all the project proofs. The projects that are readily available on
the server for such query answering include the recent versions of the
Flyspeck, Multivariate Analysis and Complex Analysis libraries. The service
runs on a 48-CPU server, currently employing in parallel for each task 7 AI/ATP
combinations and 4 decision procedures that contribute to its overall
performance. The system is also available for local installation by interested
users, who can customize it for their own proof development. An Emacs interface
allowing parallel asynchronous queries to the service is also provided. The
overall structure of the service is outlined, problems that arise and their
solutions are discussed, and an initial account of using the system is given.
"
415,"Advanced Techniques for Scientific Programming and Collaborative
  Development of Open Source Software Packages at the International Centre for
  Theoretical Physics (ICTP)","  A large number of computational scientific research projects make use of open
source software packages. However, the development process of such tools
frequently differs from conventional software development; partly because of
the nature of research, where the problems being addressed are not always fully
understood; partly because the majority of the development is often carried out
by scientists with limited experience and exposure to best practices of
software engineering. Often the software development suffers from the pressure
to publish scientific results and that credit for software development is
limited in comparison. Fundamental components of software engineering like
modular and reusable design, validation, documentation, and software
integration as well as effective maintenance and user support tend to be
disregarded due to lack of resources and qualified specialists. Thus innovative
developments are often hindered by steep learning curves required to master
development for legacy software packages full of ad hoc solutions. The growing
complexity of research, however, requires suitable and maintainable
computational tools, resulting in a widening gap between the potential users
(often growing in number) and contributors to the development of such a
package. In this paper we share our experiences aiming to improve the situation
by training particularly young scientists, through disseminating our own
experiences at contributing to open source software packages and practicing key
components of software engineering adapted for scientists and scientific
software development. Specifically we summarize the outcome of the Workshop in
Advanced Techniques for Scientific Programming and Collaborative Development of
Open Source Software Packages run at the Abdus Salam International Centre for
Theoretical Physics in March 2013, and discuss our conclusions for future
efforts.
"
416,"Higher-order Reverse Automatic Differentiation with emphasis on the
  third-order","  It is commonly assumed that calculating third order information is too
expensive for most applications. But we show that the directional derivative of
the Hessian ($D^3f(x)\cdot d$) can be calculated at a cost proportional to that
of a state-of-the-art method for calculating the Hessian matrix. We do this by
first presenting a simple procedure for designing high order reverse methods
and applying it to deduce several methods including a reverse method that
calculates $D^3f(x)\cdot d$. We have implemented this method taking into
account symmetry and sparsity, and successfully calculated this derivative for
functions with a million variables. These results indicate that the use of
third order information in a general nonlinear solver, such as Halley-Chebyshev
methods, could be a practical alternative to Newton's method.
"
417,High Precision Arithmetic for Scientific Applications,"  All but a few digital computers used for scientific computations have
supported floating-point and digital arithmetic of rather limited numerical
precision. The underlying assumptions were that the systems being studied were
basically deterministic and of limited complexity. The ideal scientific
paradigm was the orbits of the major planets, which could be observed with high
precision, predicted for thousands of years into the future, and extrapolated
for thousands of years into the past. Much the same technology that has made
computers possible has also provided instrumentation that has vastly expanded
the scope and precision of scientific analysis. Complex nonlinear systems
exhibiting so-called chaotic dynamics are now fair game for scientists and
engineers in every discipline. Today it seems that computers need to enhance
the precision of their numerical computations to support the needs of science.
However, there is no need to wait for the necessary updates in both hardware
and software; it is easy enough to monitor numerical precision with a few minor
modifications to existing software.
"
418,Modernizing PHCpack through phcpy,"  PHCpack is a large software package for solving systems of polynomial
equations. The executable phc is menu driven and file oriented. This paper
describes the development of phcpy, a Python interface to PHCpack. Instead of
navigating through menus, users of phcpy solve systems in the Python shell or
via scripts. Persistent objects replace intermediate files.
"
419,Numerical integration on GPUs for higher order finite elements,"  The paper considers the problem of implementation on graphics processors of
numerical integration routines for higher order finite element approximations.
The design of suitable GPU kernels is investigated in the context of general
purpose integration procedures, as well as particular example applications. The
most important characteristic of the problem investigated is the large
variation of required processor and memory resources associated with different
degrees of approximating polynomials. The questions that we try to answer are
whether it is possible to design a single integration kernel for different GPUs
and different orders of approximation and what performance can be expected in
such a case.
"
420,"Vectorized OpenCL implementation of numerical integration for higher
  order finite elements","  In our work we analyze computational aspects of the problem of numerical
integration in finite element calculations and consider an OpenCL
implementation of related algorithms for processors with wide vector registers.
  As a platform for testing the implementation we choose the PowerXCell
processor, being an example of the Cell Broadband Engine (CellBE) architecture.
Although the processor is considered old for today's standards (its design
dates back to year 2001), we investigate its performance due to two features
that it shares with recent Xeon Phi family of coprocessors: wide vector units
and relatively slow connection of computing cores with main global memory. The
performed analysis of parallelization options can also be used for designing
numerical integration algorithms for other processors with vector registers,
such as contemporary x86 microprocessors.
"
421,MizAR 40 for Mizar 40,"  As a present to Mizar on its 40th anniversary, we develop an AI/ATP system
that in 30 seconds of real time on a 14-CPU machine automatically proves 40% of
the theorems in the latest official version of the Mizar Mathematical Library
(MML). This is a considerable improvement over previous performance of large-
theory AI/ATP methods measured on the whole MML. To achieve that, a large suite
of AI/ATP methods is employed and further developed. We implement the most
useful methods efficiently, to scale them to the 150000 formulas in MML. This
reduces the training times over the corpus to 1-3 seconds, allowing a simple
practical deployment of the methods in the online automated reasoning service
for the Mizar users (MizAR).
"
422,Bertini for Macaulay2,"  Numerical algebraic geometry is the field of computational mathematics
concerning the numerical solution of polynomial systems of equations. Bertini,
a popular software package for computational applications of this field,
includes implementations of a variety of algorithms based on polynomial
homotopy continuation. The Macaulay2 package Bertini.m2 provides an interface
to Bertini, making it possible to access the core run modes of Bertini in
Macaulay2. With these run modes, users can find approximate solutions to
zero-dimensional systems and positive-dimensional systems, test numerically
whether a point lies on a variety, sample numerically from a variety, and
perform parameter homotopy runs.
"
423,SOSTOOLS Version 3.00 Sum of Squares Optimization Toolbox for MATLAB,"  SOSTOOLS v3.00 is the latest release of the freely available MATLAB toolbox
for formulating and solving sum of squares (SOS) optimization problems. Such
problems arise naturally in the analysis and control of nonlinear dynamical
systems, but also in other areas such as combinatorial optimization. Highlights
of the new release include the ability to create polynomial matrices and
formulate polynomial matrix inequalities, compatibility with MuPAD, the new
MATLAB symbolic engine, as well as the multipoly toolbox v2.01. SOSTOOLS v3.00
can interface with five semidefinite programming solvers, and includes ten
demonstration examples.
"
424,SymbolicData:SDEval - Benchmarking for Everyone,"  In this paper we will present SDeval, a software project that contains tools
for creating and running benchmarks with a focus on problems in computer
algebra. It is built on top of the Symbolic Data project, able to translate
problems in the database into executable code for various computer algebra
systems. The included tools are designed to be very flexible to use and to
extend, such that they can be utilized even in contexts of other communities.
With the presentation of SDEval, we will also address particularities of
benchmarking in the field of computer algebra. Furthermore, with SDEval, we
provide a feasible and automatizable way of reproducing benchmarks published in
current research works, which appears to be a difficult task in general due to
the customizability of the available programs. We will simultaneously present
the current developments in the Symbolic Data project.
"
425,"Composing and Factoring Generalized Green's Operators and Ordinary
  Boundary Problems","  We consider solution operators of linear ordinary boundary problems with ""too
many"" boundary conditions, which are not always solvable. These generalized
Green's operators are a certain kind of generalized inverses of differential
operators. We answer the question when the product of two generalized Green's
operators is again a generalized Green's operator for the product of the
corresponding differential operators and which boundary problem it solves.
Moreover, we show that---provided a factorization of the underlying
differential operator---a generalized boundary problem can be factored into
lower order problems corresponding to a factorization of the respective Green's
operators. We illustrate our results by examples using the Maple package
IntDiffOp, where the presented algorithms are implemented.
"
426,Computation of the Marcum Q-function,"  Methods and an algorithm for computing the generalized Marcum $Q-$function
($Q_{\mu}(x,y)$) and the complementary function ($P_{\mu}(x,y)$) are described.
These functions appear in problems of different technical and scientific areas
such as, for example, radar detection and communications, statistics and
probability theory, where they are called the non-central chi-square or the non
central gamma cumulative distribution functions.
  The algorithm for computing the Marcum functions combines different methods
of evaluation in different regions: series expansions, integral
representations, asymptotic expansions, and use of three-term homogeneous
recurrence relations. A relative accuracy close to $10^{-12}$ can be obtained
in the parameter region $(x,y,\mu) \in [0,\,A]\times [0,\,A]\times [1,\,A]$,
$A=200$, while for larger parameters the accuracy decreases (close to
$10^{-11}$ for $A=1000$ and close to $5\times 10^{-11}$ for $A=10000$).
"
427,GooFit: A library for massively parallelising maximum-likelihood fits,"  Fitting complicated models to large datasets is a bottleneck of many
analyses. We present GooFit, a library and tool for constructing
arbitrarily-complex probability density functions (PDFs) to be evaluated on
nVidia GPUs or on multicore CPUs using OpenMP. The massive parallelisation of
dividing up event calculations between hundreds of processors can achieve
speedups of factors 200-300 in real-world problems.
"
428,Lattice Simulations using OpenACC compilers,"  OpenACC compilers allow one to use Graphics Processing Units without having
to write explicit CUDA codes. Programs can be modified incrementally using
OpenMP like directives which causes the compiler to generate CUDA kernels to be
run on the GPUs. In this article we look at the performance gain in lattice
simulations with dynamical fermions using OpenACC compilers.
"
429,"A Study of Speed of the Boundary Element Method as applied to the
  Realtime Computational Simulation of Biological Organs","  In this work, possibility of simulating biological organs in realtime using
the Boundary Element Method (BEM) is investigated. Biological organs are
assumed to follow linear elastostatic material behavior, and constant boundary
element is the element type used. First, a Graphics Processing Unit (GPU) is
used to speed up the BEM computations to achieve the realtime performance.
Next, instead of the GPU, a computer cluster is used. Results indicate that BEM
is fast enough to provide for realtime graphics if biological organs are
assumed to follow linear elastostatic material behavior. Although the present
work does not conduct any simulation using nonlinear material models, results
from using the linear elastostatic material model imply that it would be
difficult to obtain realtime performance if highly nonlinear material models
that properly characterize biological organs are used. Although the use of BEM
for the simulation of biological organs is not new, the results presented in
the present study are not found elsewhere in the literature.
"
430,"MEIGO: an open-source software suite based on metaheuristics for global
  optimization in systems biology and bioinformatics","  Optimization is key to solve many problems in computational biology. Global
optimization methods provide a robust methodology, and metaheuristics in
particular have proven to be the most efficient methods for many applications.
Despite their utility, there is limited availability of metaheuristic tools. We
present MEIGO, an R and Matlab optimization toolbox (also available in Python
via a wrapper of the R version), that implements metaheuristics capable of
solving diverse problems arising in systems biology and bioinformatics:
enhanced scatter search method (eSS) for continuous nonlinear programming
(cNLP) and mixed-integer programming (MINLP) problems, and variable
neighborhood search (VNS) for Integer Programming (IP) problems. Both methods
can be run on a single-thread or in parallel using a cooperative strategy. The
code is supplied under GPLv3 and is available at
\url{http://www.iim.csic.es/~gingproc/meigo.html}. Documentation and examples
are included. The R package has been submitted to Bioconductor. We evaluate
MEIGO against optimization benchmarks, and illustrate its applicability to a
series of case studies in bioinformatics and systems biology, outperforming
other state-of-the-art methods. MEIGO provides a free, open-source platform for
optimization, that can be applied to multiple domains of systems biology and
bioinformatics. It includes efficient state of the art metaheuristics, and its
open and modular structure allows the addition of further methods.
"
431,Radix Conversion for IEEE754-2008 Mixed Radix Floating-Point Arithmetic,"  Conversion between binary and decimal floating-point representations is
ubiquitous. Floating-point radix conversion means converting both the exponent
and the mantissa. We develop an atomic operation for FP radix conversion with
simple straight-line algorithm, suitable for hardware design. Exponent
conversion is performed with a small multiplication and a lookup table. It
yields the correct result without error. Mantissa conversion uses a few
multiplications and a small lookup table that is shared amongst all types of
conversions. The accuracy changes by adjusting the computing precision.
"
432,"The deal.II Library, Version 8.1","  This paper provides an overview of the new features of the finite element
library deal.II version 8.1.
"
433,Silent error detection in numerical time-stepping schemes,"  Errors due to hardware or low level software problems, if detected, can be
fixed by various schemes, such as recomputation from a checkpoint. Silent
errors are errors in application state that have escaped low-level error
detection. At extreme scale, where machines can perform astronomically many
operations per second, silent errors threaten the validity of computed results.
  We propose a new paradigm for detecting silent errors at the application
level. Our central idea is to frequently compare computed values to those
provided by a cheap checking computation, and to build error detectors based on
the difference between the two output sequences. Numerical analysis provides us
with usable checking computations for the solution of initial-value problems in
ODEs and PDEs, arguably the most common problems in computational science.
Here, we provide, optimize, and test methods based on Runge-Kutta and linear
multistep methods for ODEs, and on implicit and explicit finite difference
schemes for PDEs. We take the heat equation and Navier-Stokes equations as
examples. In tests with artificially injected errors, this approach effectively
detects almost all meaningful errors, without significant slowdown.
"
434,Efficient Random-Walk Methods for Approximating Polytope Volume,"  We experimentally study the fundamental problem of computing the volume of a
convex polytope given as an intersection of linear inequalities. We implement
and evaluate practical randomized algorithms for accurately approximating the
polytope's volume in high dimensions (e.g. one hundred). To carry out this
efficiently we experimentally correlate the effect of parameters, such as
random walk length and number of sample points, on accuracy and runtime.
Moreover, we exploit the problem's geometry by implementing an iterative
rounding procedure, computing partial generations of random points and
designing fast polytope boundary oracles. Our publicly available code is
significantly faster than exact computation and more accurate than existing
approximation methods. We provide volume approximations for the Birkhoff
polytopes B_11,...,B_15, whereas exact methods have only computed that of B_10.
"
435,Sparse Allreduce: Efficient Scalable Communication for Power-Law Data,"  Many large datasets exhibit power-law statistics: The web graph, social
networks, text data, click through data etc. Their adjacency graphs are termed
natural graphs, and are known to be difficult to partition. As a consequence
most distributed algorithms on these graphs are communication intensive. Many
algorithms on natural graphs involve an Allreduce: a sum or average of
partitioned data which is then shared back to the cluster nodes. Examples
include PageRank, spectral partitioning, and many machine learning algorithms
including regression, factor (topic) models, and clustering. In this paper we
describe an efficient and scalable Allreduce primitive for power-law data. We
point out scaling problems with existing butterfly and round-robin networks for
Sparse Allreduce, and show that a hybrid approach improves on both.
Furthermore, we show that Sparse Allreduce stages should be nested instead of
cascaded (as in the dense case). And that the optimum throughput Allreduce
network should be a butterfly of heterogeneous degree where degree decreases
with depth into the network. Finally, a simple replication scheme is introduced
to deal with node failures. We present experiments showing significant
improvements over existing systems such as PowerGraph and Hadoop.
"
436,"Misfortunes of a mathematicians' trio using Computer Algebra Systems:
  Can we trust?","  Computer algebra systems are a great help for mathematical research but
sometimes unexpected errors in the software can also badly affect it. As an
example, we show how we have detected an error of Mathematica computing
determinants of matrices of integer numbers: not only it computes the
determinants wrongly, but also it produces different results if one evaluates
the same determinant twice.
"
437,Large-Scale Paralleled Sparse Principal Component Analysis,"  Principal component analysis (PCA) is a statistical technique commonly used
in multivariate data analysis. However, PCA can be difficult to interpret and
explain since the principal components (PCs) are linear combinations of the
original variables. Sparse PCA (SPCA) aims to balance statistical fidelity and
interpretability by approximating sparse PCs whose projections capture the
maximal variance of original data. In this paper we present an efficient and
paralleled method of SPCA using graphics processing units (GPUs), which can
process large blocks of data in parallel. Specifically, we construct parallel
implementations of the four optimization formulations of the generalized power
method of SPCA (GP-SPCA), one of the most efficient and effective SPCA
approaches, on a GPU. The parallel GPU implementation of GP-SPCA (using CUBLAS)
is up to eleven times faster than the corresponding CPU implementation (using
CBLAS), and up to 107 times faster than a MatLab implementation. Extensive
comparative experiments in several real-world datasets confirm that SPCA offers
a practical advantage.
"
438,"Early Observations on Performance of Google Compute Engine for
  Scientific Computing","  Although Cloud computing emerged for business applications in industry,
public Cloud services have been widely accepted and encouraged for scientific
computing in academia. The recently available Google Compute Engine (GCE) is
claimed to support high-performance and computationally intensive tasks, while
little evaluation studies can be found to reveal GCE's scientific capabilities.
Considering that fundamental performance benchmarking is the strategy of
early-stage evaluation of new Cloud services, we followed the Cloud Evaluation
Experiment Methodology (CEEM) to benchmark GCE and also compare it with Amazon
EC2, to help understand the elementary capability of GCE for dealing with
scientific problems. The experimental results and analyses show both potential
advantages of, and possible threats to applying GCE to scientific computing.
For example, compared to Amazon's EC2 service, GCE may better suit applications
that require frequent disk operations, while it may not be ready yet for single
VM-based parallel computing. Following the same evaluation methodology,
different evaluators can replicate and/or supplement this fundamental
evaluation of GCE. Based on the fundamental evaluation results, suitable GCE
environments can be further established for case studies of solving real
science problems.
"
439,"A Study of Successive Over-relaxation Method Parallelization Over Modern
  HPC Languages","  Successive over-relaxation (SOR) is a computationally intensive, yet
extremely important iterative solver for solving linear systems. Due to recent
trends of exponential growth in amount of data generated and increasing problem
sizes, serial platforms have proved to be insufficient in providing the
required computational power. In this paper, we present parallel
implementations of red-black SOR method using three modern programming
languages namely Chapel, D and Go. We employ SOR method for solving 2D
steady-state heat conduction problem. We discuss the optimizations incorporated
and the features of these languages which are crucial for improving the program
performance. Experiments have been performed using 2, 4, and 8 threads and
performance results are compared with serial execution. The analysis of results
provides important insights into working of SOR method.
"
440,"Interaction entre math\'ematique et informatique Libre/Open Source par
  le logiciel math\'ematique","  This article focuses on the application of model development and opening the
source code available and implemented by the Free Software and Open Source
FLOSS to the instructional and teaching has both mathematics and computer by
the read-write(R/W) of mathematical software, including the most famous cases
are numerical and symbolic computation. The article analysis the development of
the mathematical model of Free/Open Source(math FLOSS) software has proven its
importance in the area of research in mathematics and computer science .
However, although their actual use, is very readable in higher education
courses. We discuss the feasibility of this model to the characteristics of the
domain, actors, interaction they have and the communities they form during the
development of the software. Finally, we propose a mathematical example of
Free/Open Source(Math FlOSS) software as analysis device .
"
441,Program Verification of Numerical Computation,"  These notes outline a formal method for program verification of numerical
computation. It forms the basis of the software package VPC in its initial
phase of development. Much of the style of presentation is in the form of notes
that outline the definitions and rules upon which VPC is based. The initial
motivation of this project was to address some practical issues of computation,
especially of numerically intensive programs that are commonplace in computer
models. The project evolved into a wider area for program construction as
proofs leading to a model of inference in a more general sense. Some basic
results of machine arithmetic are derived as a demonstration of VPC.
"
442,Test Problem Construction for Single-Objective Bilevel Optimization,"  In this paper, we propose a procedure for designing controlled test problems
for single-objective bilevel optimization. The construction procedure is
flexible and allows its user to control the different complexities that are to
be included in the test problems independently of each other. In addition to
properties that control the difficulty in convergence, the procedure also
allows the user to introduce difficulties caused by interaction of the two
levels. As a companion to the test problem construction framework, the paper
presents a standard test suite of twelve problems, which includes eight
unconstrained and four constrained problems. Most of the problems are scalable
in terms of variables and constraints. To provide baseline results, we have
solved the proposed test problems using a nested bilevel evolutionary
algorithm. The results can be used for comparison, while evaluating the
performance of any other bilevel optimization algorithm. The codes related to
the paper may be accessed from the website \url{http://bilevel.org}.
"
443,"Boolean Functions, Quantum Gates, Hamilton Operators, Spin Systems and
  Computer Algebra","  We describe the construction of quantum gates (unitary operators) from
boolean functions and give a number of applications. Both non-reversible and
reversible boolean functions are considered. The construction of the Hamilton
operator for a quantum gate is also described with the Hamilton operator
expressed as spin system. Computer algebra implementations are provided.
"
444,"A hierarchically blocked Jacobi SVD algorithm for single and multiple
  graphics processing units","  We present a hierarchically blocked one-sided Jacobi algorithm for the
singular value decomposition (SVD), targeting both single and multiple graphics
processing units (GPUs). The blocking structure reflects the levels of GPU's
memory hierarchy. The algorithm may outperform MAGMA's dgesvd, while retaining
high relative accuracy. To this end, we developed a family of parallel pivot
strategies on GPU's shared address space, but applicable also to inter-GPU
communication. Unlike common hybrid approaches, our algorithm in a single GPU
setting needs a CPU for the controlling purposes only, while utilizing GPU's
resources to the fullest extent permitted by the hardware. When required by the
problem size, the algorithm, in principle, scales to an arbitrary number of GPU
nodes. The scalability is demonstrated by more than twofold speedup for
sufficiently large matrices on a Tesla S2050 system with four GPUs vs. a single
Fermi card.
"
445,"Resilience in Numerical Methods: A Position on Fault Models and
  Methodologies","  Future extreme-scale computer systems may expose silent data corruption (SDC)
to applications, in order to save energy or increase performance. However,
resilience research struggles to come up with useful abstract programming
models for reasoning about SDC. Existing work randomly flips bits in running
applications, but this only shows average-case behavior for a low-level,
artificial hardware model. Algorithm developers need to understand worst-case
behavior with the higher-level data types they actually use, in order to make
their algorithms more resilient. Also, we know so little about how SDC may
manifest in future hardware, that it seems premature to draw conclusions about
the average case. We argue instead that numerical algorithms can benefit from a
numerical unreliability fault model, where faults manifest as unbounded
perturbations to floating-point data. Algorithms can use inexpensive ""sanity""
checks that bound or exclude error in the results of computations. Given a
selective reliability programming model that requires reliability only when and
where needed, such checks can make algorithms reliable despite unbounded
faults. Sanity checks, and in general a healthy skepticism about the
correctness of subroutines, are wise even if hardware is perfectly reliable.
"
446,An efficient way to assemble finite element matrices in vector languages,"  Efficient Matlab codes in 2D and 3D have been proposed recently to assemble
finite element matrices. In this paper we present simple, compact and efficient
vectorized algorithms, which are variants of these codes, in arbitrary
dimension, without the use of any lower level language. They can be easily
implemented in many vector languages (e.g. Matlab, Octave, Python, Scilab, R,
Julia, C++ with STL,...). The principle of these techniques is general, we
present it for the assembly of several finite element matrices in arbitrary
dimension, in the P1 finite element case. We also provide an extension of the
algorithms to the case of a system of PDE's. Then we give an extension to
piecewise polynomials of higher order. We compare numerically the performance
of these algorithms in Matlab, Octave and Python, with that in FreeFEM++ and in
a compiled language such as C. Examples show that, unlike what is commonly
believed, the performance is not radically worse than that of C : in the
best/worst cases, selected vector languages are respectively 2.3/3.5 and
2.9/4.1 times slower than C in the scalar and vector cases. We also present
numerical results which illustrate the computational costs of these algorithms
compared to standard algorithms and to other recent ones.
"
447,MRRR-based Eigensolvers for Multi-core Processors and Supercomputers,"  The real symmetric tridiagonal eigenproblem is of outstanding importance in
numerical computations; it arises frequently as part of eigensolvers for
standard and generalized dense Hermitian eigenproblems that are based on a
reduction to tridiagonal form. For its solution, the algorithm of Multiple
Relatively Robust Representations (MRRR or MR3 in short) - introduced in the
late 1990s - is among the fastest methods. To compute k eigenpairs of a real
n-by-n tridiagonal T, MRRR only requires O(kn) arithmetic operations; in
contrast, all the other practical methods require O(k^2 n) or O(n^3) operations
in the worst case. This thesis centers around the performance and accuracy of
MRRR.
"
448,"STABLAB Documentation for KdV : Numerical proof of stability of roll
  waves in the small-amplitude limit for inclined thin film flow","  We document the MATLAB code used in the following study: Numerical proof of
stability of roll waves in the small-amplitude limit for inclined thin film
flow.
"
449,"Multivariate sparse interpolation using randomized Kronecker
  substitutions","  We present new techniques for reducing a multivariate sparse polynomial to a
univariate polynomial. The reduction works similarly to the classical and
widely-used Kronecker substitution, except that we choose the degrees randomly
based on the number of nonzero terms in the multivariate polynomial, that is,
its sparsity. The resulting univariate polynomial often has a significantly
lower degree than the Kronecker substitution polynomial, at the expense of a
small number of term collisions. As an application, we give a new algorithm for
multivariate interpolation which uses these new techniques along with any
existing univariate interpolation algorithm.
"
450,RProtoBuf: Efficient Cross-Language Data Serialization in R,"  Modern data collection and analysis pipelines often involve a sophisticated
mix of applications written in general purpose and specialized programming
languages. Many formats commonly used to import and export data between
different programs or systems, such as CSV or JSON, are verbose, inefficient,
not type-safe, or tied to a specific programming language. Protocol Buffers are
a popular method of serializing structured data between applications - while
remaining independent of programming languages or operating systems. They offer
a unique combination of features, performance, and maturity that seems
particularly well suited for data-driven applications and numerical computing.
The RProtoBuf package provides a complete interface to Protocol Buffers from
the R environment for statistical computing. This paper outlines the general
class of data serialization requirements for statistical computing, describes
the implementation of the RProtoBuf package, and illustrates its use with
example applications in large-scale data collection pipelines and web services.
"
451,Numerical application and Turbo C program using the Gauss-Jordan Method,"  The article presents the general notions and algorithm about the Gauss-Jordan
method. An eloquent example is given and the Turbo C program illustrated this
method. We conclude that we can obtain by this method the determinant, by
simple calculations and reducing the rounding errors
"
452,Increasing precision of uniform pseudorandom number generators,"  A general method to produce uniformly distributed pseudorandom numbers with
extended precision by combining two pseudorandom numbers with lower precision
is proposed. In particular, this method can be used for pseudorandom number
generation with extended precision on graphics processing units (GPU), where
the performance of single and double precision operations can vary
significantly.
"
453,Divide-And-Conquer Computation of Cylindrical Algebraic Decomposition,"  We present a divide-and-conquer version of the Cylindrical Algebraic
Decomposition (CAD) algorithm. The algorithm represents the input as a Boolean
combination of subformulas, computes cylindrical algebraic decompositions of
solution sets of the subformulas, and combines the results. We propose a
graph-based heuristic to find a suitable partitioning of the input and present
empirical comparison with direct CAD computation.
"
454,"Constructing Performance Models for Dense Linear Algebra Algorithms on
  Cray XE Systems","  Hiding or minimizing the communication cost is key in order to obtain good
performance on large-scale systems. While communication overlapping attempts to
hide communications cost, 2.5D communication avoiding algorithms improve
performance scalability by reducing the volume of data transfers at the cost of
extra memory usage. Both approaches can be used together or separately and the
best choice depends on the machine, the algorithm and the problem size. Thus,
the development of performance models is crucial to determine the best option
for each scenario. In this paper, we present a methodology for constructing
performance models for parallel numerical routines on Cray XE systems. Our
models use portable benchmarks that measure computational cost and network
characteristics, as well as performance degradation caused by simultaneous
accesses to the network. We validate our methodology by constructing the
performance models for the 2D and 2.5D approaches, with and without
overlapping, of two matrix multiplication algorithms (Cannon's and SUMMA),
triangular solve (TRSM) and Cholesky. We compare the estimations provided by
these models with the experimental results using up to 24,576 cores of a Cray
XE6 system and predict the performance of the algorithms on larger systems.
Results prove that the estimations significantly improve when taking into
account network contention.
"
455,"GPU acceleration of Newton's method for large systems of polynomial
  equations in double double and quad double arithmetic","  In order to compensate for the higher cost of double double and quad double
arithmetic when solving large polynomial systems, we investigate the
application of NVIDIA Tesla K20C general purpose graphics processing unit. The
focus on this paper is on Newton's method, which requires the evaluation of the
polynomials, their derivatives, and the solution of a linear system to compute
the update to the current approximation for the solution. The reverse mode of
algorithmic differentiation for a product of variables is rewritten in a binary
tree fashion so all threads in a block can collaborate in the computation. For
double arithmetic, the evaluation and differentiation problem is memory bound,
whereas for complex quad double arithmetic the problem is compute bound. With
acceleration we can double the dimension and get results that are twice as
accurate in about the same time.
"
456,Toward Resilient Algorithms and Applications,"  Over the past decade, the high performance computing community has become
increasingly concerned that preserving the reliable, digital machine model will
become too costly or infeasible. In this paper we discuss four approaches for
developing new algorithms that are resilient to hard and soft failures.
"
457,Symmetric QR Algorithm with Permutations,"  In this paper, we present the QR Algorithm with Permutations that shows an
improved convergence rate compared to the classical QR algorithm. We determine
a bound for performance based on best instantaneous convergence, and develop
low complexity methods for computing the permutation matrices at every
iteration. We use simulations to verify the improvement, and to compare the
performance of proposed algorithms to the classical QR algorithm.
"
458,"Polcovar: Software for Computing the Mean and Variance of Subgraph
  Counts in Random Graphs","  The mean and variance of the number of appearances of a given subgraph $H$ in
an Erd\H{o}s--R\'enyi random graph over $n$ nodes are rational polynomials in
$n$. We present a piece of software named Polcovar (from ""polynomial"" and
""covariance"") that computes the exact rational coefficients of these
polynomials in function of $H$.
"
459,"A Study on the Influence of Caching: Sequences of Dense Linear Algebra
  Kernels","  It is universally known that caching is critical to attain high- performance
implementations: In many situations, data locality (in space and time) plays a
bigger role than optimizing the (number of) arithmetic floating point
operations. In this paper, we show evidence that at least for linear algebra
algorithms, caching is also a crucial factor for accurate performance modeling
and performance prediction.
"
460,Machine Learning at Scale,"  It takes skill to build a meaningful predictive model even with the abundance
of implementations of modern machine learning algorithms and readily available
computing resources. Building a model becomes challenging if hundreds of
terabytes of data need to be processed to produce the training data set. In a
digital advertising technology setting, we are faced with the need to build
thousands of such models that predict user behavior and power advertising
campaigns in a 24/7 chaotic real-time production environment. As data
scientists, we also have to convince other internal departments critical to
implementation success, our management, and our customers that our machine
learning system works. In this paper, we present the details of the design and
implementation of an automated, robust machine learning platform that impacts
billions of advertising impressions monthly. This platform enables us to
continuously optimize thousands of campaigns over hundreds of millions of
users, on multiple continents, against varying performance objectives.
"
461,"An experimental exploration of Marsaglia's xorshift generators,
  scrambled","  Marsaglia proposed recently xorshift generators as a class of very fast,
good-quality pseudorandom number generators. Subsequent analysis by Panneton
and L'Ecuyer has lowered the expectations raised by Marsaglia's paper, showing
several weaknesses of such generators, verified experimentally using the
TestU01 suite. Nonetheless, many of the weaknesses of xorshift generators fade
away if their result is scrambled by a non-linear operation (as originally
suggested by Marsaglia). In this paper we explore the space of possible
generators obtained by multiplying the result of a xorshift generator by a
suitable constant. We sample generators at 100 equispaced points of their state
space and obtain detailed statistics that lead us to choices of parameters that
improve on the current ones. We then explore for the first time the space of
high-dimensional xorshift generators, following another suggestion in
Marsaglia's paper, finding choices of parameters providing periods of length
$2^{1024} - 1$ and $2^{4096} - 1$. The resulting generators are of extremely
high quality, faster than current similar alternatives, and generate
long-period sequences passing strong statistical tests using only eight logical
operations, one addition and one multiplication by a constant.
"
462,Tensor computations in computer algebra systems,"  This paper considers three types of tensor computations. On their basis, we
attempt to formulate criteria that must be satisfied by a computer algebra
system dealing with tensors. We briefly overview the current state of tensor
computations in different computer algebra systems. The tensor computations are
illustrated with appropriate examples implemented in specific systems: Cadabra
and Maxima.
"
463,Matrix Methods for Solving Algebraic Systems,"  We present our public-domain software for the following tasks in sparse (or
toric) elimination theory, given a well-constrained polynomial system. First, C
code for computing the mixed volume of the system. Second, Maple code for
defining an overconstrained system and constructing a Sylvester-type matrix of
its sparse resultant. Third, C code for a Sylvester-type matrix of the sparse
resultant and a superset of all common roots of the initial well-constrained
system by computing the eigen-decomposition of a square matrix obtained from
the resultant matrix. We conclude with experiments in computing molecular
conformations.
"
464,"Recent software developments for special functions in the
  Santander-Amsterdam project","  We give an overview of published algorithms by our group and of current
activities and future plans. In particular, we give details on methods for
computing special functions and discuss in detail two current lines of
research. Firstly, we describe the recent developments for the computation of
central and non-central chi-square cumulative distributions (also called Marcum
Q-functions), and we present a new quadrature method for computing them.
Secondly, we describe the fourth-order methods for computing zeros of special
functions recently developed, and we provide an explicit example for the
computation of complex zeros of Bessel functions. We end with an overview of
published software by our group for computing special functions.
"
465,Straightforward Bibliography Management in R with the RefManageR Package,"  This work introduces the R package RefManageR, which provides tools for
importing and working with bibliographic references. It extends the bibentry
class in R in a number of useful ways, including providing R with previously
unavailable support for BibLaTeX. BibLaTeX provides a superset of the
functionality of BibTeX, including full Unicode support, no memory limitations,
additional fields and entry types, and more sophisticated sorting of
references. RefManageR provides functions for citing and generating a
bibliography with hyperlinks for documents prepared with RMarkdown or RHTML.
Existing .bib files can be read into R and converted from BibTeX to BibLaTeX
and vice versa. References can also be imported via queries to NCBI's Entrez,
Zotero libraries, Google Scholar, and CrossRef. Additionally, references can be
created by reading PDFs stored on the user's machine with the help of Poppler.
Entries stored in the reference manager can be easily searched by any field, by
date ranges, and by various formats for name lists (author by last names,
translator by full names, etc.). Entries can also be updated, combined, sorted,
printed in a number of styles, and exported.
"
466,A SageTeX Hypermatrix Algebra Package,"  We describe here a rudimentary sage implementation of the Bhattacharya-Mesner
hypermatrix algebra package.
"
467,"The jsonlite Package: A Practical and Consistent Mapping Between JSON
  Data and R Objects","  A naive realization of JSON data in R maps JSON arrays to an unnamed list,
and JSON objects to a named list. However, in practice a list is an awkward,
inefficient type to store and manipulate data. Most statistical applications
work with (homogeneous) vectors, matrices or data frames. Therefore JSON
packages in R typically define certain special cases of JSON structures which
map to simpler R types. Currently there exist no formal guidelines, or even
consensus between implementations on how R data should be represented in JSON.
Furthermore, upon closer inspection, even the most basic data structures in R
actually do not perfectly map to their JSON counterparts and leave some
ambiguity for edge cases. These problems have resulted in different behavior
between implementations and can lead to unexpected output. This paper
explicitly describes a mapping between R classes and JSON data, highlights
potential problems, and proposes conventions that generalize the mapping to
cover all common structures. We emphasize the importance of type consistency
when using JSON to exchange dynamic data, and illustrate using examples and
anecdotes. The jsonlite R package is used throughout the paper as a reference
implementation.
"
468,"Computer Vision Accelerators for Mobile Systems based on OpenCL GPGPU
  Co-Processing","  In this paper, we present an OpenCL-based heterogeneous implementation of a
computer vision algorithm -- image inpainting-based object removal algorithm --
on mobile devices. To take advantage of the computation power of the mobile
processor, the algorithm workflow is partitioned between the CPU and the GPU
based on the profiling results on mobile devices, so that the
computationally-intensive kernels are accelerated by the mobile GPGPU
(general-purpose computing using graphics processing units). By exploring the
implementation trade-offs and utilizing the proposed optimization strategies at
different levels including algorithm optimization, parallelism optimization,
and memory access optimization, we significantly speed up the algorithm with
the CPU-GPU heterogeneous implementation, while preserving the quality of the
output images. Experimental results show that heterogeneous computing based on
GPGPU co-processing can significantly speed up the computer vision algorithms
and makes them practical on real-world mobile devices.
"
469,The MIXMAX random number generator,"  In this note, we give a practical solution to the problem of determining the
maximal period of matrix generators of pseudo-random numbers which are based on
an integer-valued unimodular matrix of size NxN known as MIXMAX and arithmetic
defined on a Galois field GF[p] with large prime modulus p. The existing theory
of Galois finite fields is adapted to the present case, and necessary and
sufficient condition to attain the maximum period is formulated. Three
efficient algorithms are presented. First, allowing to compute the
multiplication by the MIXMAX matrix with O(N) operations. Second, to
recursively compute the characteristic polynomial with O(N^2) operations, and
third, to apply skips of large number of steps S to the sequence in O(N^2
log(S)) operations. It is demonstrated that the dynamical properties of this
generator dramatically improve with the size of the matrix N, as compared to
the classes of generators based on sparse matrices and/or sparse characteristic
polynomials. Finally, we present the implementation details of the generator
and the results of rigorous statistical testing.
"
470,High Performance Solutions for Big-data GWAS,"  In order to associate complex traits with genetic polymorphisms, genome-wide
association studies process huge datasets involving tens of thousands of
individuals genotyped for millions of polymorphisms. When handling these
datasets, which exceed the main memory of contemporary computers, one faces two
distinct challenges: 1) Millions of polymorphisms and thousands of phenotypes
come at the cost of hundreds of gigabytes of data, which can only be kept in
secondary storage; 2) the relatedness of the test population is represented by
a relationship matrix, which, for large populations, can only fit in the
combined main memory of a distributed architecture. In this paper, by using
distributed resources such as Cloud or clusters, we address both challenges:
The genotype and phenotype data is streamed from secondary storage using a
double buffer- ing technique, while the relationship matrix is kept across the
main memory of a distributed memory system. With the help of these solutions,
we develop separate algorithms for studies involving only one or a multitude of
traits. We show that these algorithms sustain high-performance and allow the
analysis of enormous datasets.
"
471,"A modified ziggurat algorithm for generating exponentially- and
  normally-distributed pseudorandom numbers","  The Ziggurat Algorithm is a very fast rejection sampling method for
generating PseudoRandom Numbers (PRNs) from common statistical distributions.
The algorithm divides a distribution into rectangular layers that stack on top
of each other (resembling a Ziggurat), subsuming the desired distribution.
Random values within these rectangular layers are then sampled by rejection.
This implementation splits layers into two types: those constituting the
majority that fall completely under the distribution and can be sampled
extremely fast without a rejection test, and a few additional layers that
encapsulate the fringe of the distribution and require a rejection test. This
method offers speedups of 65% for exponentially- and 82% for
normally-distributed PRNs when compared to the best available C implementations
of these generators. Even greater speedups are obtained when the algorithm is
extended to the Python and MATLAB/OCTAVE programming environments.
"
472,Using RngStreams for Parallel Random Number Generation in C++ and R,"  The RngStreams software package provides one viable solution to the problem
of creating independent random number streams for simulations in parallel
processing environments. Techniques are presented for effectively using
RngStreams with C++ programs that are parallelized via OpenMP or MPI. Ways to
access the backbone generator from RngStreams in R through the parallel and
rstream packages are also described. The ideas in the paper are illustrated
with both a simple running example and a Monte Carlo integration application.
"
473,Further scramblings of Marsaglia's xorshift generators,"  xorshift* generators are a variant of Marsaglia's xorshift generators that
eliminate linear artifacts typical of generators based on $\mathbf Z/2\mathbf
Z$-linear operations using multiplication by a suitable constant. Shortly after
high-dimensional xorshift* generators were introduced, Saito and Matsumoto
suggested a different way to eliminate linear artifacts based on addition in
$\mathbf Z/2^{32}\mathbf Z$, leading to the XSadd generator. Starting from the
observation that the lower bits of XSadd are very weak, as its reverse fails
systematically several statistical tests, we explore xorshift+, a variant of
XSadd using 64-bit operations, which leads, in small dimension, to extremely
fast high-quality generators.
"
474,A New Highly Parallel Non-Hermitian Eigensolver,"  Calculating portions of eigenvalues and eigenvectors of matrices or matrix
pencils has many applications. An approach to this calculation for Hermitian
problems based on a density matrix has been proposed in 2009 and a software
package called FEAST has been developed. The density-matrix approach allows
FEAST's implementation to exploit a key strength of modern computer
architectures, namely, multiple levels of parallelism. Consequently, the
software package has been well received and subsequently commercialized. A
detailed theoretical analysis of Hermitian FEAST has also been established very
recently. This paper generalizes the FEAST algorithm and theory, for the first
time, to tackle non-Hermitian problems. Fundamentally, the new algorithm is
basic subspace iteration or Bauer bi-iteration, except applied with a novel
accelerator based on Cauchy integrals. The resulting algorithm retains the
multi-level parallelism of Hermitian FEAST, making it a valuable new tool for
large-scale computational science and engineering problems on leading-edge
computing platforms.
"
475,"Knowledge-Based Automatic Generation of Linear Algebra Algorithms and
  Code","  This dissertation focuses on the design and the implementation of
domain-specific compilers for linear algebra matrix equations. The development
of efficient libraries for such equations, which lie at the heart of most
software for scientific computing, is a complex process that requires expertise
in a variety of areas, including the application domain, algorithms, numerical
analysis and high-performance computing. Moreover, the process involves the
collaboration of several people for a considerable amount of time. With our
compilers, we aim to relieve the developers from both designing algorithms and
writing code, and to generate routines that match or even surpass the
performance of those written by human experts.
"
476,"An Optimized and Scalable Eigensolver for Sequences of Eigenvalue
  Problems","  In many scientific applications the solution of non-linear differential
equations are obtained through the set-up and solution of a number of
successive eigenproblems. These eigenproblems can be regarded as a sequence
whenever the solution of one problem fosters the initialization of the next. In
addition, in some eigenproblem sequences there is a connection between the
solutions of adjacent eigenproblems. Whenever it is possible to unravel the
existence of such a connection, the eigenproblem sequence is said to be
correlated. When facing with a sequence of correlated eigenproblems the current
strategy amounts to solving each eigenproblem in isolation. We propose a
alternative approach which exploits such correlation through the use of an
eigensolver based on subspace iteration and accelerated with Chebyshev
polynomials (ChFSI). The resulting eigensolver is optimized by minimizing the
number of matrix-vector multiplications and parallelized using the Elemental
library framework. Numerical results show that ChFSI achieves excellent
scalability and is competitive with current dense linear algebra parallel
eigensolvers.
"
477,A heuristic prover for real inequalities,"  We describe a general method for verifying inequalities between real-valued
expressions, especially the kinds of straightforward inferences that arise in
interactive theorem proving. In contrast to approaches that aim to be complete
with respect to a particular language or class of formulas, our method
establishes claims that require heterogeneous forms of reasoning, relying on a
Nelson-Oppen-style architecture in which special-purpose modules collaborate
and share information. The framework is thus modular and extensible. A
prototype implementation shows that the method works well on a variety of
examples, and complements techniques that are used by contemporary interactive
provers.
"
478,CTBNCToolkit: Continuous Time Bayesian Network Classifier Toolkit,"  Continuous time Bayesian network classifiers are designed for temporal
classification of multivariate streaming data when time duration of events
matters and the class does not change over time. This paper introduces the
CTBNCToolkit: an open source Java toolkit which provides a stand-alone
application for temporal classification and a library for continuous time
Bayesian network classifiers. CTBNCToolkit implements the inference algorithm,
the parameter learning algorithm, and the structural learning algorithm for
continuous time Bayesian network classifiers. The structural learning algorithm
is based on scoring functions: the marginal log-likelihood score and the
conditional log-likelihood score are provided. CTBNCToolkit provides also an
implementation of the expectation maximization algorithm for clustering
purpose. The paper introduces continuous time Bayesian network classifiers. How
to use the CTBNToolkit from the command line is described in a specific
section. Tutorial examples are included to facilitate users to understand how
the toolkit must be used. A section dedicate to the Java library is proposed to
help further code extensions.
"
479,"Bloscpack: a compressed lightweight serialization format for numerical
  data","  This paper introduces the Bloscpack file format and the accompanying Python
reference implementation. Bloscpack is a lightweight, compressed binary
file-format based on the Blosc codec and is designed for lightweight, fast
serialization of numerical data. This article presents the features of the
file-format and some some API aspects of the reference implementation, in
particular the ability to handle Numpy ndarrays. Furthermore, in order to
demonstrate its utility, the format is compared both feature- and
performance-wise to a few alternative lightweight serialization solutions for
Numpy ndarrays. The performance comparisons take the form of some comprehensive
benchmarks over a range of different artificial datasets with varying size and
complexity, the results of which are presented as the last section of this
article.
"
480,Performance of Python runtimes on a non-numeric scientific code,"  The Python library FatGHol FatGHoL used in Murri2012 to reckon the rational
homology of the moduli space of Riemann surfaces is an example of a non-numeric
scientific code: most of the processing it does is generating graphs
(represented by complex Python objects) and computing their isomorphisms (a
triple of Python lists; again a nested data structure). These operations are
repeated many times over: for example, the spaces and are triangulated by
4'583'322 and 747'664 graphs, respectively. This is an opportunity for every
Python runtime to prove its strength in optimization. The purpose of this
experiment was to assess the maturity of alternative Python runtimes, in terms
of: compatibility with the language as implemented in CPython 2.7, and
performance speedup. This paper compares the results and experiences from
running FatGHol with different Python runtimes: CPython 2.7.5, PyPy 2.1, Cython
0.19, Numba 0.11, Nuitka 0.4.4 and Falcon.
"
481,Computing all Affine Solution Sets of Binomial Systems,"  To compute solutions of sparse polynomial systems efficiently we have to
exploit the structure of their Newton polytopes. While the application of
polyhedral methods naturally excludes solutions with zero components, an
irreducible decomposition of a variety is typically understood in affine space,
including also those components with zero coordinates. For the problem of
computing solution sets in the intersection of some coordinate planes, the
direct application of a polyhedral method fails, because the original facial
structure of the Newton polytopes may alter completely when selected variables
become zero. Our new proposed method enumerates all factors contributing to a
generalized permanent and toric solutions as a special case of this
enumeration. For benchmark problems such as the adjacent 2-by-2 minors of a
general matrix, our methods scale much better than the witness set
representations of numerical algebraic geometry.
"
482,PLQCD library for Lattice QCD on multi-core machines,"  PLQCD is a stand-alone software library developed under PRACE for lattice
QCD. It provides an implementation of the Dirac operator for Wilson type
fermions and few efficient linear solvers. The library is optimized for
multi-core machines using a hybrid parallelization with OpenMP+MPI. The main
objectives of the library is to provide a scalable implementation of the Dirac
operator for efficient computation of the quark propagator. In this
contribution, a description of the PLQCD library is given together with some
benchmark results.
"
483,Hipster: Integrating Theory Exploration in a Proof Assistant,"  This paper describes Hipster, a system integrating theory exploration with
the proof assistant Isabelle/HOL. Theory exploration is a technique for
automatically discovering new interesting lemmas in a given theory development.
Hipster can be used in two main modes. The first is exploratory mode, used for
automatically generating basic lemmas about a given set of datatypes and
functions in a new theory development. The second is proof mode, used in a
particular proof attempt, trying to discover the missing lemmas which would
allow the current goal to be proved. Hipster's proof mode complements and
boosts existing proof automation techniques that rely on automatically
selecting existing lemmas, by inventing new lemmas that need induction to be
proved. We show example uses of both modes.
"
484,DDscat.C++ User and programmer guide,"  DDscat.C++ 7.3.0 is a freely available open-source C++ software package
applying the ""discrete dipole approximation"" (DDA) to calculate scattering and
absorption of electromagnetic waves by targets with arbitrary geometries and a
complex refractive index. DDscat.C++ is a clone of well known DDscat Fortran-90
software. We refer to DDscat as to the parent code in this document. Versions
7.3.0 of both codes have the identical functionality but the quite different
implementation. Started as a teaching project, the DDscat.C++ code differs from
the parent code DDscat in programming techniques and features, essential for
C++ but quite seldom in Fortran.
  As DDscat.C++ in its current version is just a clone, usage of DDscat.C++ for
electromagnetic calculations is the same as of DDscat. Please, refer to ""User
Guide for the Discrete Dipole Approximation Code DDSCAT 7.3"" to start using the
code(s).
  This document consists of two parts. In the first part we present Quick start
guide for users who want to begin to use the code. Only differencies between
DDscat.C++ and DDscat are explained. The second part of the document explains
programming tips for the persons who want to change the code, to add the
functionality or help the author with code refactoring and debugging.
"
485,Search Interfaces for Mathematicians,"  Access to mathematical knowledge has changed dramatically in recent years,
therefore changing mathematical search practices. Our aim with this study is to
scrutinize professional mathematicians' search behavior. With this
understanding we want to be able to reason why mathematicians use which tool
for what search problem in what phase of the search process. To gain these
insights we conducted 24 repertory grid interviews with mathematically inclined
people (ranging from senior professional mathematicians to non-mathematicians).
From the interview data we elicited patterns for the user group
""mathematicians"" that can be applied when understanding design issues or
creating new designs for mathematical search interfaces.
"
486,Changing Computing Paradigms Towards Power Efficiency,"  Power awareness is fast becoming immensely important in computing, ranging
from the traditional High Performance Computing applications, to the new
generation of data centric workloads.
  In this work we describe our efforts towards a power efficient computing
paradigm that combines low precision and high precision arithmetic. We showcase
our ideas for the widely used kernel of solving systems of linear equations
that finds numerous applications in scientific and engineering disciplines as
well as in large scale data analytics, statistics and machine learning.
  Towards this goal we developed tools for the seamless power profiling of
applications at a fine grain level. In addition, we verify here previous work
on post FLOPS/Watt metrics and show that these can shed much more light in the
power/energy profile of important applications.
"
487,Zgoubi: A startup guide for the complete beginner,"  Zgoubi is a code which can be used to model accelerators and beam lines,
comprised of magnetic and electrostatic elements. It has been extensively
developed since the mid-1980s to include circular accelerators and related beam
physics. It has been made freely available by its author on a code development
site, including a Users' Guide, a data treatment/graphic interfacing tool, and
many examples. This startup guide give directions to install the required
elements onto a Windows or Unix system to enable running of the Zgoubi code
with examples of code written to model the EMMA accelerator based at the
Cockcroft Institute.
"
488,NLCertify: A Tool for Formal Nonlinear Optimization,"  NLCertify is a software package for handling formal certification of
nonlinear inequalities involving transcendental multivariate functions. The
tool exploits sparse semialgebraic optimization techniques with approximation
methods for transcendental functions, as well as formal features. Given a box
and a transcendental multivariate function as input, NLCertify provides OCaml
libraries that produce nonnegativity certificates for the function over the
box, which can be ultimately proved correct inside the Coq proof assistant.
"
489,"Realms: A Structure for Consolidating Knowledge about Mathematical
  Theories","  Since there are different ways of axiomatizing and developing a mathematical
theory, knowledge about a such a theory may reside in many places and in many
forms within a library of formalized mathematics. We introduce the notion of a
realm as a structure for consolidating knowledge about a mathematical theory. A
realm contains several axiomatizations of a theory that are separately
developed. Views interconnect these developments and establish that the
axiomatizations are equivalent in the sense of being mutually interpretable. A
realm also contains an external interface that is convenient for users of the
library who want to apply the concepts and facts of the theory without delving
into the details of how the concepts and facts were developed. We illustrate
the utility of realms through a series of examples. We also give an outline of
the mechanisms that are needed to create and maintain realms.
"
490,A formally verified proof of the Central Limit Theorem,"  We describe a proof of the Central Limit Theorem that has been formally
verified in the Isabelle proof assistant. Our formalization builds upon and
extends Isabelle's libraries for analysis and measure-theoretic probability.
The proof of the theorem uses characteristic functions, which are a kind of
Fourier transform, to demonstrate that, under suitable hypotheses, sums of
random variables converge weakly to the standard normal distribution. We also
discuss the libraries and infrastructure that supported the formalization, and
reflect on some of the lessons we have learned from the effort.
"
491,"PyRDM: A Python-based library for automating the management and online
  publication of scientific software and data","  The recomputability and reproducibility of results from scientific software
requires access to both the source code and all associated input and output
data. However, the full collection of these resources often does not accompany
the key findings published in journal articles, thereby making it difficult or
impossible for the wider scientific community to verify the correctness of a
result or to build further research on it. This paper presents a new
Python-based library, PyRDM, whose functionality aims to automate the process
of sharing the software and data via online, citable repositories such as
Figshare. The library is integrated into the workflow of an open-source
computational fluid dynamics package, Fluidity, to demonstrate an example of
its usage.
"
492,Loo.py: transformation-based code generation for GPUs and CPUs,"  Today's highly heterogeneous computing landscape places a burden on
programmers wanting to achieve high performance on a reasonably broad
cross-section of machines. To do so, computations need to be expressed in many
different but mathematically equivalent ways, with, in the worst case, one
variant per target machine.
  Loo.py, a programming system embedded in Python, meets this challenge by
defining a data model for array-style computations and a library of
transformations that operate on this model. Offering transformations such as
loop tiling, vectorization, storage management, unrolling, instruction-level
parallelism, change of data layout, and many more, it provides a convenient way
to capture, parametrize, and re-unify the growth among code variants. Optional,
deep integration with numpy and PyOpenCL provides a convenient computing
environment where the transition from prototype to high-performance
implementation can occur in a gradual, machine-assisted form.
"
493,"Kahler: An Implementation of Discrete Exterior Calculus on Hermitian
  Manifolds","  This paper details the techniques and algorithms implemented in Kahler, a
Python library that implements discrete exterior calculus on arbitrary
Hermitian manifolds. Borrowing techniques and ideas first implemented in PyDEC,
Kahler provides a uniquely general framework for computation using discrete
exterior calculus. Manifolds can have arbitrary dimension, topology, bilinear
Hermitian metrics, and embedding dimension. Kahler comes equipped with tools
for generating triangular meshes in arbitrary dimensions with arbitrary
topology. Kahler can also generate discrete sharp operators and implement de
Rham maps. Computationally intensive tasks are automatically parallelized over
the number of cores detected. The program itself is written in Cython--a
superset of the Python language that is translated to C and compiled for extra
speed. Kahler is applied to several example problems: normal modes of a
vibrating membrane, electromagnetic resonance in a cavity, the quantum harmonic
oscillator, and the Dirac-Kahler equation. Convergence is demonstrated on
random meshes.
"
494,Recursive Algorithms for Distributed Forests of Octrees,"  The forest-of-octrees approach to parallel adaptive mesh refinement and
coarsening (AMR) has recently been demonstrated in the context of a number of
large-scale PDE-based applications. Although linear octrees, which store only
leaf octants, have an underlying tree structure by definition, it is not often
exploited in previously published mesh-related algorithms. This is because the
branches are not explicitly stored, and because the topological relationships
in meshes, such as the adjacency between cells, introduce dependencies that do
not respect the octree hierarchy. In this work we combine hierarchical and
topological relationships between octree branches to design efficient recursive
algorithms.
  We present three important algorithms with recursive implementations. The
first is a parallel search for leaves matching any of a set of multiple search
criteria. The second is a ghost layer construction algorithm that handles
arbitrarily refined octrees that are not covered by previous algorithms, which
require a 2:1 condition between neighboring leaves. The third is a universal
mesh topology iterator. This iterator visits every cell in a domain partition,
as well as every interface (face, edge and corner) between these cells. The
iterator calculates the local topological information for every interface that
it visits, taking into account the nonconforming interfaces that increase the
complexity of describing the local topology. To demonstrate the utility of the
topology iterator, we use it to compute the numbering and encoding of
higher-order $C^0$ nodal basis functions.
  We analyze the complexity of the new recursive algorithms theoretically, and
assess their performance, both in terms of single-processor efficiency and in
terms of parallel scalability, demonstrating good weak and strong scaling up to
458k cores of the JUQUEEN supercomputer.
"
495,Interactive Simplifier Tracing and Debugging in Isabelle,"  The Isabelle proof assistant comes equipped with a very powerful tactic for
term simplification. While tremendously useful, the results of simplifying a
term do not always match the user's expectation: sometimes, the resulting term
is not in the form the user expected, or the simplifier fails to apply a rule.
We describe a new, interactive tracing facility which offers insight into the
hierarchical structure of the simplification with user-defined filtering,
memoization and search. The new simplifier trace is integrated into the
Isabelle/jEdit Prover IDE.
"
496,Fast Matlab compatible sparse assembly on multicore computers,"  We develop and implement in this paper a fast sparse assembly algorithm, the
fundamental operation which creates a compressed matrix from raw index data.
Since it is often a quite demanding and sometimes critical operation, it is of
interest to design a highly efficient implementation. We show how to do this,
and moreover, we show how our implementation can be parallelized to utilize the
power of modern multicore computers. Our freely available code, fully Matlab
compatible, achieves about a factor of 5 times in speedup on a typical 6-core
machine and 10 times on a dual-socket 16 core machine compared to the built-in
serial implementation.
"
497,"Proceedings Twelfth International Workshop on the ACL2 Theorem Prover
  and its Applications","  This volume contains the proceedings of the Twelfth International Workshop on
the ACL2 Theorem Prover and Its Applications, ACL2'14, a two-day workshop held
in Vienna, Austria, on July 12-13, 2014. ACL2 workshops occur at approximately
18-month intervals and provide a major technical forum for researchers to
present and discuss improvements and extensions to the theorem prover,
comparisons of ACL2 with other systems, and applications of ACL2 in formal
verification. These proceedings include 13 peer reviewed technical papers.
  ACL2 is a state-of-the-art automated reasoning system that has been
successfully applied in academia, government, and industry for specification
and verification of computing systems and in teaching computer science courses.
In 2005, Boyer, Kaufmann, and Moore were awarded the 2005 ACM Software System
Award for their work in ACL2 and the other theorem provers in the Boyer-Moore
family.
"
498,"Enhancements to ACL2 in Versions 6.2, 6.3, and 6.4","  We report on improvements to ACL2 made since the 2013 ACL2 Workshop.
"
499,"Formal Verification of Medina's Sequence of Polynomials for
  Approximating Arctangent","  The verification of many algorithms for calculating transcendental functions
is based on polynomial approximations to these functions, often Taylor series
approximations. However, computing and verifying approximations to the
arctangent function are very challenging problems, in large part because the
Taylor series converges very slowly to arctangent-a 57th-degree polynomial is
needed to get three decimal places for arctan(0.95). Medina proposed a series
of polynomials that approximate arctangent with far faster convergence-a
7th-degree polynomial is all that is needed to get three decimal places for
arctan(0.95). We present in this paper a proof in ACL2(r) of the correctness
and convergence rate of this sequence of polynomials. The proof is particularly
beautiful, in that it uses many results from real analysis. Some of these
necessary results were proven in prior work, but some were proven as part of
this effort.
"
500,"A Generic Numbering System based on Catalan Families of Combinatorial
  Objects","  We describe arithmetic algorithms on a canonical number representation based
on the Catalan family of combinatorial objects specified as a Haskell type
class.
  Our algorithms work on a {\em generic} representation that we illustrate on
instances members of the Catalan family, like ordered binary and multiway
trees. We validate the correctness of our algorithms by defining an instance of
the same type class based the usual bitstring-based natural numbers.
  While their average and worst case complexity is within constant factors of
their traditional counterparts, our algorithms provide super-exponential gains
for numbers corresponding to Catalan objects of low representation size.
"
501,Program Verification of Numerical Computation - Part 2,"  These notes present some extensions of a formal method introduced in an
earlier paper. The formal method is designed as a tool for program verification
of numerical computation and forms the basis of the software package VPC.
Included in the extensions that are presented here are disjunctions and methods
for detecting non-computable programs. A more comprehensive list of the
construction rules as higher order constructs is also presented.
"
502,Industrial-Strength Documentation for ACL2,"  The ACL2 theorem prover is a complex system. Its libraries are vast.
Industrial verification efforts may extend this base with hundreds of thousands
of lines of additional modeling tools, specifications, and proof scripts. High
quality documentation is vital for teams that are working together on projects
of this scale. We have developed XDOC, a flexible, scalable documentation tool
for ACL2 that can incorporate the documentation for ACL2 itself, the Community
Books, and an organization's internal formal verification projects, and which
has many features that help to keep the resulting manuals up to date. Using
this tool, we have produced a comprehensive, publicly available ACL2+Books
Manual that brings better documentation to all ACL2 users. We have also
developed an extended manual for use within Centaur Technology that extends the
public manual to cover Centaur's internal books. We expect that other
organizations using ACL2 will wish to develop similarly extended manuals.
"
503,"The OpenCPU System: Towards a Universal Interface for Scientific
  Computing through Separation of Concerns","  Applications integrating analysis components require a programmable interface
which defines statistical operations independently of any programming language.
By separating concerns of scientific computing from application and
implementation details we can derive an interoperable API for data analysis.
But what exactly are the concerns of scientific computing? To answer this
question, the paper starts with an exploration of the purpose, problems,
characteristics, struggles, culture, and community of this unique branch of
computing. By mapping out the domain logic, we try to unveil the fundamental
principles and concepts behind statistical software. Along the way we highlight
important problems and bottlenecks that need to be addressed by the system in
order to facilitate reliable and scalable analysis units. Finally, the OpenCPU
software is introduced as an example implementation that builds on HTTP and R
to expose a simple, abstracted interface for scientific computing.
"
504,"Achieving 100,000,000 database inserts per second using Accumulo and D4M","  The Apache Accumulo database is an open source relaxed consistency database
that is widely used for government applications. Accumulo is designed to
deliver high performance on unstructured data such as graphs of network data.
This paper tests the performance of Accumulo using data from the Graph500
benchmark. The Dynamic Distributed Dimensional Data Model (D4M) software is
used to implement the benchmark on a 216-node cluster running the MIT
SuperCloud software stack. A peak performance of over 100,000,000 database
inserts per second was achieved which is 100x larger than the highest
previously published value for any other database. The performance scales
linearly with the number of ingest clients, number of database servers, and
data size. The performance was achieved by adapting several supercomputing
techniques to this application: distributed arrays, domain decomposition,
adaptive load balancing, and single-program-multiple-data programming.
"
505,"A Scala Prototype to Generate Multigrid Solver Implementations for
  Different Problems and Target Multi-Core Platforms","  Many problems in computational science and engineering involve partial
differential equations and thus require the numerical solution of large, sparse
(non)linear systems of equations. Multigrid is known to be one of the most
efficient methods for this purpose. However, the concrete multigrid algorithm
and its implementation highly depend on the underlying problem and hardware.
Therefore, changes in the code or many different variants are necessary to
cover all relevant cases. In this article we provide a prototype implementation
in Scala for a framework that allows abstract descriptions of PDEs, their
discretization, and their numerical solution via multigrid algorithms. From
these, one is able to generate data structures and implementations of multigrid
components required to solve elliptic PDEs on structured grids. Two different
test problems showcase our proposed automatic generation of multigrid solvers
for both CPU and GPU target platforms.
"
506,"ViDaExpert: user-friendly tool for nonlinear visualization and analysis
  of multidimensional vectorial data","  ViDaExpert is a tool for visualization and analysis of multidimensional
vectorial data. ViDaExpert is able to work with data tables of ""object-feature""
type that might contain numerical feature values as well as textual labels for
rows (objects) and columns (features). ViDaExpert implements several
statistical methods such as standard and weighted Principal Component Analysis
(PCA) and the method of elastic maps (non-linear version of PCA), Linear
Discriminant Analysis (LDA), multilinear regression, K-Means clustering, a
variant of decision tree construction algorithm. Equipped with several
user-friendly dialogs for configuring data point representations (size, shape,
color) and fast 3D viewer, ViDaExpert is a handy tool allowing to construct an
interactive 3D-scene representing a table of data in multidimensional space and
perform its quick and insightfull statistical analysis, from basic to advanced
methods.
"
507,An Open Source Pattern Recognition Toolbox for MATLAB,"  Pattern recognition and machine learning are becoming integral parts of
algorithms in a wide range of applications. Different algorithms and approaches
for machine learning include different tradeoffs between performance and
computation, so during algorithm development it is often necessary to explore a
variety of different approaches to a given task. A toolbox with a unified
framework across multiple pattern recognition techniques enables algorithm
developers the ability to rapidly evaluate different choices prior to
deployment. MATLAB is a widely used environment for algorithm development and
prototyping, and although several MATLAB toolboxes for pattern recognition are
currently available these are either incomplete, expensive, or restrictively
licensed. In this work we describe a MATLAB toolbox for pattern recognition and
machine learning known as the PRT (Pattern Recognition Toolbox), licensed under
the permissive MIT license. The PRT includes many popular techniques for data
preprocessing, supervised learning, clustering, regression and feature
selection, as well as a methodology for combining these components using a
simple, uniform syntax. The resulting algorithms can be evaluated using
cross-validation and a variety of scoring metrics to ensure robust performance
when the algorithm is deployed. This paper presents an overview of the PRT as
well as an example of usage on Fisher's Iris dataset.
"
508,Transpose-free Fast Fourier Transform for Turbulence Simulation,"  Pseudo-spectral method is one of the most accurate techniques for simulating
turbulent flows. Fast Fourier transform (FFT) is an integral part of this
method. In this paper, we present a new procedure to compute FFT in which we
save operations during interprocess communications by avoiding transpose of the
array. As a result, our transpose-free FFT is 15\% to 20\% faster than FFTW.
"
509,"Efficient Gluing of Numerical Continuation and a Multiple Solution
  Method for Elliptic PDEs","  Numerical continuation calculations for ordinary differential equations
(ODEs) are, by now, an established tool for bifurcation analysis in dynamical
systems theory as well as across almost all natural and engineering sciences.
Although several excellent standard software packages are available for ODEs,
there are - for good reasons - no standard numerical continuation toolboxes
available for partial differential equations (PDEs), which cover a broad range
of different classes of PDEs automatically. A natural approach to this problem
is to look for efficient gluing computation approaches, with independent
components developed by researchers in numerical analysis, dynamical systems,
scientific computing and mathematical modelling. In this paper, we shall study
several elliptic PDEs (Lane-Emden-Fowler, Lane-Emden-Fowler with microscopic
force, Caginalp) via the numerical continuation software pde2path and develop a
gluing component to determine a set of starting solutions for the continuation
by exploting the variational structures of the PDEs. In particular, we solve
the initialization problem of numerical continuation for PDEs via a minimax
algorithm to find multiple unstable solution. Furthermore, for the Caginalp
system, we illustrate the efficient gluing link of pde2path to the underlying
mesh generation and the FEM MatLab pdetoolbox. Even though the approach works
efficiently due to the high-level programming language and without developing
any new algorithms, we still obtain interesting bifurcation diagrams and
directly applicable conclusions about the three elliptic PDEs we study, in
particular with respect to symmetry-breaking. In particular, we show for a
modified Lane-Emden-Fowler equation with an asymmetric microscopic force, how a
fully connected bifurcation diagram splits up into C-shaped isolas on which
localized pattern deformation appears towards two different regimes.
"
510,Strongly stable ideals and Hilbert polynomials,"  The \texttt{StronglyStableIdeals} package for \textit{Macaulay2} provides a
method to compute all saturated strongly stable ideals in a given polynomial
ring with a fixed Hilbert polynomial. A description of the main method and
auxiliary tools is given.
"
511,"Bayesian Network Constraint-Based Structure Learning Algorithms:
  Parallel and Optimised Implementations in the bnlearn R Package","  It is well known in the literature that the problem of learning the structure
of Bayesian networks is very hard to tackle: its computational complexity is
super-exponential in the number of nodes in the worst case and polynomial in
most real-world scenarios.
  Efficient implementations of score-based structure learning benefit from past
and current research in optimisation theory, which can be adapted to the task
by using the network score as the objective function to maximise. This is not
true for approaches based on conditional independence tests, called
constraint-based learning algorithms. The only optimisation in widespread use,
backtracking, leverages the symmetries implied by the definitions of
neighbourhood and Markov blanket.
  In this paper we illustrate how backtracking is implemented in recent
versions of the bnlearn R package, and how it degrades the stability of
Bayesian network structure learning for little gain in terms of speed. As an
alternative, we describe a software architecture and framework that can be used
to parallelise constraint-based structure learning algorithms (also implemented
in bnlearn) and we demonstrate its performance using four reference networks
and two real-world data sets from genetics and systems biology. We show that on
modern multi-core or multiprocessor hardware parallel implementations are
preferable over backtracking, which was developed when single-processor
machines were the norm.
"
512,Integer formula encoding SageTeX package,"  The paper describes a SageTeX implementation of an integer encoding
procedures.
"
513,COFFEE: an Optimizing Compiler for Finite Element Local Assembly,"  The numerical solution of partial differential equations using the finite
element method is one of the key applications of high performance computing.
Local assembly is its characteristic operation. This entails the execution of a
problem-specific kernel to numerically evaluate an integral for each element in
the discretized problem domain. Since the domain size can be huge, executing
efficient kernels is fundamental. Their op- timization is, however, a
challenging issue. Even though affine loop nests are generally present, the
short trip counts and the complexity of mathematical expressions make it hard
to determine a single or unique sequence of successful transformations.
Therefore, we present the design and systematic evaluation of COF- FEE, a
domain-specific compiler for local assembly kernels. COFFEE manipulates
abstract syntax trees generated from a high-level domain-specific language for
PDEs by introducing domain-aware composable optimizations aimed at improving
instruction-level parallelism, especially SIMD vectorization, and register
locality. It then generates C code including vector intrinsics. Experiments
using a range of finite-element forms of increasing complexity show that
significant performance improvement is achieved.
"
514,Run-time extensibility and librarization of simulation software,"  Build-time configuration and environment assumptions are hampering progress
and usability in scientific software. That which would be utterly unacceptable
in non-scientific software somehow passes for the norm in scientific packages.
The community needs reusable software packages that are easy use and flexible
enough to accommodate next-generation simulation and analysis demands.
"
515,"A data porting tool for coupling models with different discretization
  needs","  The presented work is part of a larger research program dealing with
developing tools for coupling biogeochemical models in contaminated landscapes.
The specific objective of this article is to provide the researchers a tool to
build hexagonal raster using information from a rectangular raster data (e.g.
GIS format), data porting. This tool involves a computational algorithm and an
open source software (written in C). The method of extending the reticulated
functions defined on 2D networks is an essential key of this algorithm and can
also be used for other purposes than data porting. The algorithm allows one to
build the hexagonal raster with a cell size independent from the geometry of
the rectangular raster. The extended function is a bi-cubic spline which can
exactly reconstruct polynomials up to degree three in each variable. We
validate the method by analyzing errors in some theoretical case studies
followed by other studies with real terrain elevation data. We also introduce
and briefly present an iterative water routing method and use it for validation
on a case with concrete terrain data.
"
516,"A modern resistive magnetohydrodynamics solver using C++ and the Boost
  library","  In this paper we describe the implementation of our C++ resistive
magnetohydrodynamics solver. The framework developed facilitates the separation
of the code implementing the specific numerical method and the physical model,
on the one hand, from the handling of boundary conditions and the management of
the computational domain, on the other hand. In particular, this will allow us
to use finite difference stencils which are only defined in the interior of the
domain (the boundary conditions are handled automatically). We will discuss
this and other design considerations and their impact on performance in some
detail. In addition, we provide a documentation of the code developed and
demonstrate that a performance comparable to Fortran can be achieved, while
still maintaining a maximum of code readability and extensibility.
"
517,Elements of Design for Containers and Solutions in the LinBox Library,"  We describe in this paper new design techniques used in the \cpp exact linear
algebra library \linbox, intended to make the library safer and easier to use,
while keeping it generic and efficient. First, we review the new simplified
structure for containers, based on our \emph{founding scope allocation} model.
We explain design choices and their impact on coding: unification of our matrix
classes, clearer model for matrices and submatrices, \etc Then we present a
variation of the \emph{strategy} design pattern that is comprised of a
controller--plugin system: the controller (solution) chooses among plug-ins
(algorithms) that always call back the controllers for subtasks. We give
examples using the solution \mul. Finally we present a benchmark architecture
that serves two purposes: Providing the user with easier ways to produce
graphs; Creating a framework for automatically tuning the library and
supporting regression testing.
"
518,Modular SIMD arithmetic in Mathemagix,"  Modular integer arithmetic occurs in many algorithms for computer algebra,
cryptography, and error correcting codes. Although recent microprocessors
typically offer a wide range of highly optimized arithmetic functions, modular
integer operations still require dedicated implementations. In this article, we
survey existing algorithms for modular integer arithmetic, and present detailed
vectorized counterparts. We also present several applications, such as fast
modular Fourier transforms and multiplication of integer polynomials and
matrices. The vectorized algorithms have been implemented in C++ inside the
free computer algebra and analysis system Mathemagix. The performance of our
implementation is illustrated by various benchmarks.
"
519,Implementing cryptographic pairings at standard security levels,"  This study reports on an implementation of cryptographic pairings in a
general purpose computer algebra system. For security levels equivalent to the
different AES flavours, we exhibit suitable curves in parametric families and
show that optimal ate and twisted ate pairings exist and can be efficiently
evaluated. We provide a correct description of Miller's algorithm for signed
binary expansions such as the NAF and extend a recent variant due to Boxall et
al. to addition-subtraction chains. We analyse and compare several algorithms
proposed in the literature for the final exponentiation. Finally, we ive
recommendations on which curve and pairing to choose at each security level.
"
520,scikit-image: Image processing in Python,"  scikit-image is an image processing library that implements algorithms and
utilities for use in research, education and industry applications. It is
released under the liberal ""Modified BSD"" open source license, provides a
well-documented API in the Python programming language, and is developed by an
active, international team of collaborators. In this paper we highlight the
advantages of open source to achieve the goals of the scikit-image library, and
we showcase several real-world image processing applications that use
scikit-image.
"
521,The DUNE-ALUGrid Module,"  In this paper we present the new DUNE-ALUGrid module. This module contains a
major overhaul of the sources from the ALUgrid library and the binding to the
DUNE software framework. The main changes include user defined load balancing,
parallel grid construction, and an redesign of the 2d grid which can now also
be used for parallel computations. In addition many improvements have been
introduced into the code to increase the parallel efficiency and to decrease
the memory footprint.
  The original ALUGrid library is widely used within the DUNE community due to
its good parallel performance for problems requiring local adaptivity and
dynamic load balancing. Therefore, this new model will benefit a number of DUNE
users. In addition we have added features to increase the range of problems for
which the grid manager can be used, for example, introducing a 3d tetrahedral
grid using a parallel newest vertex bisection algorithm for conforming grid
refinement. In this paper we will discuss the new features, extensions to the
DUNE interface, and explain for various examples how the code is used in
parallel environments.
"
522,"Numerical Methods for the Computation of the Confluent and Gauss
  Hypergeometric Functions","  The two most commonly used hypergeometric functions are the confluent
hypergeometric function and the Gauss hypergeometric function. We review the
available techniques for accurate, fast, and reliable computation of these two
hypergeometric functions in different parameter and variable regimes. The
methods that we investigate include Taylor and asymptotic series computations,
Gauss-Jacobi quadrature, numerical solution of differential equations,
recurrence relations, and others. We discuss the results of numerical
experiments used to determine the best methods, in practice, for each parameter
and variable regime considered. We provide 'roadmaps' with our recommendation
for which methods should be used in each situation.
"
523,Zolotarev Quadrature Rules and Load Balancing for the FEAST Eigensolver,"  The FEAST method for solving large sparse eigenproblems is equivalent to
subspace iteration with an approximate spectral projector and implicit
orthogonalization. This relation allows to characterize the convergence of this
method in terms of the error of a certain rational approximant to an indicator
function. We propose improved rational approximants leading to FEAST variants
with faster convergence, in particular, when using rational approximants based
on the work of Zolotarev. Numerical experiments demonstrate the possible
computational savings especially for pencils whose eigenvalues are not well
separated and when the dimension of the search space is only slightly larger
than the number of wanted eigenvalues. The new approach improves both
convergence robustness and load balancing when FEAST runs on multiple search
intervals in parallel.
"
524,"Software for Computing the Spheroidal Wave Functions Using Arbitrary
  Precision Arithmetic","  The spheroidal wave functions, which are the solutions to the Helmholtz
equation in spheroidal coordinates, are notoriously difficult to compute.
Because of this, practically no programming language comes equipped with the
means to compute them. This makes problems that require their use hard to
tackle. We have developed computational software for calculating these special
functions. Our software is called spheroidal and includes several novel
features, such as: using arbitrary precision arithmetic; adaptively choosing
the number of expansion coefficients to compute and use; and using the
Wronskian to choose from several different methods for computing the spheroidal
radial functions to improve their accuracy. There are two types of spheroidal
wave functions: the prolate kind when prolate spheroidal coordinates are used;
and the oblate kind when oblate spheroidal coordinate are used. In this paper,
we describe both, methods for computing them, and our software. We have made
our software freely available on our webpage.
"
525,Standards for Graph Algorithm Primitives,"  It is our view that the state of the art in constructing a large collection
of graph algorithms in terms of linear algebraic operations is mature enough to
support the emergence of a standard set of primitive building blocks. This
paper is a position paper defining the problem and announcing our intention to
launch an open effort to define this standard.
"
526,"Semi-Analytical Computation of Acoustic Scattering by Spheroids and
  Disks","  Analytical solutions to acoustic scattering problems involving nonspherical
shapes, such as spheroids and disks, have long been known and have many
applications. However, these solutions require special functions that are not
easily computable. For this reason, their asymptotic forms are typically used
since they are more readily available. We explore these solutions and provide
computational software for calculating their nonasymptotic forms, which are
accurate over a wide range of frequencies and distances. This software, which
runs in MATLAB, computes the solutions to acoustic scattering problems
involving spheroids and disks by semi-analytical means, and is freely available
from our webpage.
"
527,Lighthouse: A User-Centered Web Service for Linear Algebra Software,"  Various fields of science and engineering rely on linear algebra for large
scale data analysis, modeling and simulation, machine learning, and other
applied problems. Linear algebra computations often dominate the execution time
of such applications. Meanwhile, experts in these domains typically lack the
training or time required to develop efficient, high-performance
implementations of linear algebra algorithms. In the Lighthouse project, we
enable developers with varied backgrounds to readily discover and effectively
apply the best available numerical software for their problems. We have
developed a search-based expert system that combines expert knowledge, machine
learningbased classification of existing numerical software collections, and
automated code generation and optimization. Lighthouse provides a novel
software engineering environment aimed at maximizing both developer
productivity and application performance for dense and sparse linear algebra
computations.
"
528,"Cluster-level tuning of a shallow water equation solver on the Intel MIC
  architecture","  The paper demonstrates the optimization of the execution environment of a
hybrid OpenMP+MPI computational fluid dynamics code (shallow water equation
solver) on a cluster enabled with Intel Xeon Phi coprocessors. The discussion
includes: (1) Controlling the number and affinity of OpenMP threads to optimize
access to memory bandwidth; (2) Tuning the inter-operation of OpenMP and MPI to
partition the problem for better data locality; (3) Ordering the MPI ranks in a
way that directs some of the traffic into faster communication channels; (4)
Using efficient peer-to-peer communication between Xeon Phi coprocessors based
on the InfiniBand fabric.
  With tuning, the application has 90% percent efficiency of parallel scaling
up to 8 Intel Xeon Phi coprocessors in 2 compute nodes. For larger problems,
scalability is even better, because of the greater computation to communication
ratio. However, problems of that size do not fit in the memory of one
coprocessor. The performance of the solver on one Intel Xeon Phi coprocessor
7120P exceeds the performance on a dual-socket Intel Xeon E5-2697 v2 CPU by a
factor of 1.6x. In a 2-node cluster with 4 coprocessors per compute node, the
MIC architecture yields 5.8x more performance than the CPUs. Only one line of
legacy Fortran code had to be changed in order to achieve the reported
performance on the MIC architecture (not counting changes to the command-line
interface). The methodology discussed in this paper is directly applicable to
other bandwidth-bound stencil algorithms utilizing a hybrid OpenMP+MPI
approach.
"
529,"A Report of a Significant Error On a Frequently Used Pseudo Random
  Number Generator","  Emergence of stochastic simulations as an extensively used computational tool
for scientific purposes intensified the need for more accurate ways of
generating sufficiently long sequences of uncorrelated random numbers. Even
though several different methods have been proposed for this end, deterministic
algorithms known as pseudo-random number generators (PRNGs) emerged to be the
most widely used tool as a replicable, portable and easy to use method to
generate such random number sequences. Here, we introduce a simple Poisson
process whose simulation gives systematic errors when the very commonly used
random number generator of the GNU C Library (Glibc) is utilised. The PRNG of
Glibc is an additive lagged Fibonacci generator, the family of such PRNGs are
accepted as relatively safe among other PRNGs. The systematic errors indicate
complex correlation relations among random numbers which requires a further
explanation.
"
530,"Experimental Evaluation of Multi-Round Matrix Multiplication on
  MapReduce","  A common approach in the design of MapReduce algorithms is to minimize the
number of rounds. Indeed, there are many examples in the literature of
monolithic MapReduce algorithms, which are algorithms requiring just one or two
rounds. However, we claim that the design of monolithic algorithms may not be
the best approach in cloud systems. Indeed, multi-round algorithms may exploit
some features of cloud platforms by suitably setting the round number according
to the execution context. In this paper we carry out an experimental study of
multi-round MapReduce algorithms aiming at investigating the performance of the
multi-round approach. We use matrix multiplication as a case study. We first
propose a scalable Hadoop library, named M$_3$, for matrix multiplication in
the dense and sparse cases which allows to tradeoff round number with the
amount of data shuffled in each round and the amount of memory required by
reduce functions. Then, we present an extensive study of this library on an
in-house cluster and on Amazon Web Services aiming at showing its performance
and at comparing monolithic and multi-round approaches. The experiments show
that, even without a low level optimization, it is possible to design
multi-round algorithms with a small running time overhead.
"
531,Algorithm xxx: RIDC Methods -- A Family of Parallel Time-Integrators,"  Revisionist integral deferred correction (RIDC) methods are a family of
parallel--in--time methods to solve systems of initial values problems. The
approach is able to bootstrap lower order time integrators to provide high
order approximations in approximately the same wall clock time, hence providing
a multiplicative increase in the number of compute cores utilized. Here we
provide a C++ framework which automatically produces a parallel--in--time
solution of a system of initial value problems given user supplied code for the
right hand side of the system and a sequential code for a first-order time
step. The user supplied time step routine may be explicit or implicit and may
make use of any auxiliary libraries which take care of the solution of any
nonlinear algebraic systems which may arise or the numerical linear algebra
required. The code contains six examples of increasing complexity which also
serve as templates to solve user defined problems.
"
532,"A brief survey on deep belief networks and introducing a new object
  oriented toolbox (DeeBNet)","  Nowadays, this is very popular to use the deep architectures in machine
learning. Deep Belief Networks (DBNs) are deep architectures that use stack of
Restricted Boltzmann Machines (RBM) to create a powerful generative model using
training data. DBNs have many ability like feature extraction and
classification that are used in many applications like image processing, speech
processing and etc. This paper introduces a new object oriented MATLAB toolbox
with most of abilities needed for the implementation of DBNs. In the new
version, the toolbox can be used in Octave. According to the results of the
experiments conducted on MNIST (image), ISOLET (speech), and 20 Newsgroups
(text) datasets, it was shown that the toolbox can learn automatically a good
representation of the input from unlabeled data with better discrimination
between different classes. Also on all datasets, the obtained classification
errors are comparable to those of state of the art classifiers. In addition,
the toolbox supports different sampling methods (e.g. Gibbs, CD, PCD and our
new FEPCD method), different sparsity methods (quadratic, rate distortion and
our new normal method), different RBM types (generative and discriminative),
using GPU, etc. The toolbox is a user-friendly open source software and is
freely available on the website
http://ceit.aut.ac.ir/~keyvanrad/DeeBNet%20Toolbox.html .
"
533,"JIDT: An information-theoretic toolkit for studying the dynamics of
  complex systems","  Complex systems are increasingly being viewed as distributed information
processing systems, particularly in the domains of computational neuroscience,
bioinformatics and Artificial Life. This trend has resulted in a strong uptake
in the use of (Shannon) information-theoretic measures to analyse the dynamics
of complex systems in these fields. We introduce the Java Information Dynamics
Toolkit (JIDT): a Google code project which provides a standalone, (GNU GPL v3
licensed) open-source code implementation for empirical estimation of
information-theoretic measures from time-series data. While the toolkit
provides classic information-theoretic measures (e.g. entropy, mutual
information, conditional mutual information), it ultimately focusses on
implementing higher-level measures for information dynamics. That is, JIDT
focusses on quantifying information storage, transfer and modification, and the
dynamics of these operations in space and time. For this purpose, it includes
implementations of the transfer entropy and active information storage, their
multivariate extensions and local or pointwise variants. JIDT provides
implementations for both discrete and continuous-valued data for each measure,
including various types of estimator for continuous data (e.g. Gaussian,
box-kernel and Kraskov-Stoegbauer-Grassberger) which can be swapped at run-time
due to Java's object-oriented polymorphism. Furthermore, while written in Java,
the toolkit can be used directly in MATLAB, GNU Octave, Python and other
environments. We present the principles behind the code design, and provide
several examples to guide users.
"
534,"EURETILE D7.3 - Dynamic DAL benchmark coding, measurements on MPI
  version of DPSNN-STDP (distributed plastic spiking neural net) and
  improvements to other DAL codes","  The EURETILE project required the selection and coding of a set of dedicated
benchmarks. The project is about the software and hardware architecture of
future many-tile distributed fault-tolerant systems. We focus on dynamic
workloads characterised by heavy numerical processing requirements. The
ambition is to identify common techniques that could be applied to both the
Embedded Systems and HPC domains. This document is the first public deliverable
of Work Package 7: Challenging Tiled Applications.
"
535,"Orbital-Free Density Functional Theory Implementation with the Projector
  Augmented-Wave Method","  We present a computational scheme for orbital-free density functional theory
(OFDFT) that simultaneously provides access to all-electron values and
preserves the OFDFT linear scaling as a function of the system size. Using the
projector augmented-wave method (PAW) in combination with real-space methods we
overcome some obstacles faced by other available implementation schemes.
Specifically, the advantages of using the PAW method are two fold. First, PAW
reproduces all-electron values offering freedom in adjusting the convergence
parameters and the atomic setups allow tuning the numerical accuracy per
element. Second, PAW can provide a solution to some of the convergence problems
exhibited in other OFDFT implementations based on Kohn-Sham codes. Using PAW
and real-space methods, our orbital-free results agree with the reference
all-electron values with a mean absolute error of 10~meV and the number of
iterations required by the self-consistent cycle is comparable to the KS
method. The comparison of all-electron and pseudopotential bulk modulus and
lattice constant reveal an enormous difference, demonstrating that in order to
assess the performance of OFDFT functionals it is necessary to use
implementations that obtain all-electron values. The proposed combination of
methods is the most promising route currently available. We finally show that a
parametrized kinetic energy functional can give lattice constants and bulk
moduli comparable in accuracy to those obtained by the KS PBE method,
exemplified with the case of diamond.
"
536,"A Preconditioned Hybrid SVD Method for Computing Accurately Singular
  Triplets of Large Matrices","  The computation of a few singular triplets of large, sparse matrices is a
challenging task, especially when the smallest magnitude singular values are
needed in high accuracy. Most recent efforts try to address this problem
through variations of the Lanczos bidiagonalization method, but they are still
challenged even for medium matrix sizes due to the difficulty of the problem.
We propose a novel SVD approach that can take advantage of preconditioning and
of any well designed eigensolver to compute both largest and smallest singular
triplets. Accuracy and efficiency is achieved through a hybrid, two-stage
meta-method, PHSVDS. In the first stage, PHSVDS solves the normal equations up
to the best achievable accuracy. If further accuracy is required, the method
switches automatically to an eigenvalue problem with the augmented matrix. Thus
it combines the advantages of the two stages, faster convergence and accuracy,
respectively. For the augmented matrix, solving the interior eigenvalue is
facilitated by a proper use of the good initial guesses from the first stage
and an efficient implementation of the refined projection method. We also
discuss how to precondition PHSVDS and to cope with some issues that arise.
Numerical experiments illustrate the efficiency and robustness of the method.
"
537,A Framework for Lattice QCD Calculations on GPUs,"  Computing platforms equipped with accelerators like GPUs have proven to
provide great computational power. However, exploiting such platforms for
existing scientific applications is not a trivial task. Current GPU programming
frameworks such as CUDA C/C++ require low-level programming from the developer
in order to achieve high performance code. As a result porting of applications
to GPUs is typically limited to time-dominant algorithms and routines, leaving
the remainder not accelerated which can open a serious Amdahl's law issue. The
lattice QCD application Chroma allows to explore a different porting strategy.
The layered structure of the software architecture logically separates the
data-parallel from the application layer. The QCD Data-Parallel software layer
provides data types and expressions with stencil-like operations suitable for
lattice field theory and Chroma implements algorithms in terms of this
high-level interface. Thus by porting the low-level layer one can effectively
move the whole application in one swing to a different platform. The
QDP-JIT/PTX library, the reimplementation of the low-level layer, provides a
framework for lattice QCD calculations for the CUDA architecture. The complete
software interface is supported and thus applications can be run unaltered on
GPU-based parallel computers. This reimplementation was possible due to the
availability of a JIT compiler (part of the NVIDIA Linux kernel driver) which
translates an assembly-like language (PTX) to GPU code. The expression template
technique is used to build PTX code generators and a software cache manages the
GPU memory. This reimplementation allows us to deploy an efficient
implementation of the full gauge-generation program with dynamical fermions on
large-scale GPU-based machines such as Titan and Blue Waters which accelerates
the algorithm by more than an order of magnitude.
"
538,Concurrent Cuba,"  The parallel version of the multidimensional numerical integration package
Cuba is presented and achievable speed-ups discussed.
"
539,Performance Portability Study of Linear Algebra Kernels in OpenCL,"  The performance portability of OpenCL kernel implementations for common
memory bandwidth limited linear algebra operations across different hardware
generations of the same vendor as well as across vendors is studied. Certain
combinations of kernel implementations and work sizes are found to exhibit good
performance across compute kernels, hardware generations, and, to a lesser
degree, vendors. As a consequence, it is demonstrated that the optimization of
a single kernel is often sufficient to obtain good performance for a large
class of more complicated operations.
"
540,CosmoMC Installation and Running Guidelines,"  CosmoMC is a Fortran 95 Markov-Chain Monte-Carlo (MCMC) engine to explore the
cosmological parameter space, plus a Python suite for plotting and presenting
results (see http://cosmologist.info/cosmomc/). This document describes the
installation of the CosmoMC on a Linux system (Ubuntu 14.04.1 LTS 64-bit
version). It is written for those who want to use it in their scientific
research but without much training on Linux and the program. Besides a
step-by-step installation guide, we also give a brief introduction of how to
run the program on both a desktop and a cluster. We share our way to generate
the plots that are commonly used in the references of cosmology. For more
information, one can refer to the CosmoCoffee forum
(http://cosmocoffee.info/viewforum.php?f=11) or contact the authors of this
document. Questions and comments would be much appreciated.
"
541,"Computing the coefficients for the power series solution of the
  Lane-Emden equation with the Python library SymPy","  It is shown how the Python library Sympy can be used to compute symbolically
the coefficients of the power series solution of the Lane-Emden equation (LEE).
Sympy is an open source Python library for symbolic mathematics. The power
series solutions are compared to the numerically computed solutions using
matplotlib. The results of a run time measurement of the implemented algorithm
are discussed at the end.
"
542,A Framework for Practical Parallel Fast Matrix Multiplication,"  Matrix multiplication is a fundamental computation in many scientific
disciplines. In this paper, we show that novel fast matrix multiplication
algorithms can significantly outperform vendor implementations of the classical
algorithm and Strassen's fast algorithm on modest problem sizes and shapes.
Furthermore, we show that the best choice of fast algorithm depends not only on
the size of the matrices but also the shape. We develop a code generation tool
to automatically implement multiple sequential and shared-memory parallel
variants of each fast algorithm, including our novel parallelization scheme.
This allows us to rapidly benchmark over 20 fast algorithms on several problem
sizes. Furthermore, we discuss a number of practical implementation issues for
these algorithms on shared-memory machines that can direct further research on
making fast algorithms practical.
"
543,Enhancing R with Advanced Compilation Tools and Methods,"  I describe an approach to compiling common idioms in R code directly to
native machine code and illustrate it with several examples. Not only can this
yield significant performance gains, but it allows us to use new approaches to
computing in R. Importantly, the compilation requires no changes to R itself,
but is done entirely via R packages. This allows others to experiment with
different compilation strategies and even to define new domain-specific
languages within R. We use the Low-Level Virtual Machine (LLVM) compiler
toolkit to create the native code and perform sophisticated optimizations on
the code. By adopting this widely used software within R, we leverage its
ability to generate code for different platforms such as CPUs and GPUs, and
will continue to benefit from its ongoing development. This approach
potentially allows us to develop high-level R code that is also fast, that can
be compiled to work with different data representations and sources, and that
could even be run outside of R. The approach aims to both provide a compiler
for a limited subset of the R language and also to enable R programmers to
write other compilers. This is another approach to help us write high-level
descriptions of what we want to compute, not how.
"
544,Fast MATLAB assembly of FEM matrices in 2D and 3D: Edge elements,"  We propose an effective and flexible way to assemble finite element stiffness
and mass matrices in MATLAB. We apply this for problems discretized by edge
finite elements. Typical edge finite elements are Raviart-Thomas elements used
in discretizations of H(div) spaces and Nedelec elements in discretizations of
H(curl) spaces. We explain vectorization ideas and comment on a freely
available MATLAB code which is fast and scalable with respect to time.
"
545,"Intel Cilk Plus for Complex Parallel Algorithms: ""Enormous Fast Fourier
  Transform"" (EFFT) Library","  In this paper we demonstrate the methodology for parallelizing the
computation of large one-dimensional discrete fast Fourier transforms (DFFTs)
on multi-core Intel Xeon processors. DFFTs based on the recursive Cooley-Tukey
method have to control cache utilization, memory bandwidth and vector hardware
usage, and at the same time scale across multiple threads or compute nodes. Our
method builds on single-threaded Intel Math Kernel Library (MKL) implementation
of DFFT, and uses the Intel Cilk Plus framework for thread parallelism. We
demonstrate the ability of Intel Cilk Plus to handle parallel recursion with
nested loop-centric parallelism without tuning the code to the number of cores
or cache metrics. The result of our work is a library called EFFT that performs
1D DFTs of size 2^N for N>=21 faster than the corresponding Intel MKL parallel
DFT implementation by up to 1.5x, and faster than FFTW by up to 2.5x. The code
of EFFT is available for free download under the GPLv3 license. This work
provides a new efficient DFFT implementation, and at the same time demonstrates
an educational example of how computer science problems with complex parallel
patterns can be optimized for high performance using the Intel Cilk Plus
framework.
"
546,An Analysis of Publication Venues for Automatic Differentiation Research,"  We present the results of our analysis of publication venues for papers on
automatic differentiation (AD), covering academic journals and conference
proceedings. Our data are collected from the AD publications database
maintained by the autodiff.org community website. The database is purpose-built
for the AD field and is expanding via submissions by AD researchers. Therefore,
it provides a relatively noise-free list of publications relating to the field.
However, it does include noise in the form of variant spellings of journal and
conference names. We handle this by manually correcting and merging these
variants under the official names of corresponding venues. We also share the
raw data we get after these corrections.
"
547,"$\mu$-diff: an open-source Matlab toolbox for computing multiple
  scattering problems by disks","  The aim of this paper is to describe a Matlab toolbox, called $\mu$-diff, for
modeling and numerically solving two-dimensional complex multiple scattering by
a large collection of circular cylinders. The approximation methods in
$\mu$-diff are based on the Fourier series expansions of the four basic
integral operators arising in scattering theory. Based on these expressions, an
efficient spectrally accurate finite-dimensional solution of multiple
scattering problems can be simply obtained for complex media even when many
scatterers are considered as well as large frequencies. The solution of the
global linear system to solve can use either direct solvers or preconditioned
iterative Krylov subspace solvers for block Toeplitz matrices. Based on this
approach, this paper explains how the code is built and organized. Some
complete numerical examples of applications (direct and inverse scattering) are
provided to show that $\mu$-diff is a flexible, efficient and robust toolbox
for solving some complex multiple scattering problems.
"
548,On the Performance Prediction of BLAS-based Tensor Contractions,"  Tensor operations are surging as the computational building blocks for a
variety of scientific simulations and the development of high-performance
kernels for such operations is known to be a challenging task. While for
operations on one- and two-dimensional tensors there exist standardized
interfaces and highly-optimized libraries (BLAS), for higher dimensional
tensors neither standards nor highly-tuned implementations exist yet. In this
paper, we consider contractions between two tensors of arbitrary dimensionality
and take on the challenge of generating high-performance implementations by
resorting to sequences of BLAS kernels. The approach consists in breaking the
contraction down into operations that only involve matrices or vectors. Since
in general there are many alternative ways of decomposing a contraction, we are
able to methodically derive a large family of algorithms. The main contribution
of this paper is a systematic methodology to accurately identify the fastest
algorithms in the bunch, without executing them. The goal is instead
accomplished with the help of a set of cache-aware micro-benchmarks for the
underlying BLAS kernels. The predictions we construct from such benchmarks
allow us to reliably single out the best-performing algorithms in a tiny
fraction of the time taken by the direct execution of the algorithms.
"
549,Automatic Generation of Loop-Invariants for Matrix Operations,"  In recent years it has been shown that for many linear algebra operations it
is possible to create families of algorithms following a very systematic
procedure. We do not refer to the fine tuning of a known algorithm, but to a
methodology for the actual generation of both algorithms and routines to solve
a given target matrix equation. Although systematic, the methodology relies on
complex algebraic manipulations and non-obvious pattern matching, making the
procedure challenging to be performed by hand, our goal is the development of a
fully automated system that from the sole description of a target equation
creates multiple algorithms and routines. We present CL1ck, a symbolic system
written in Mathematica, that starts with an equation, decomposes it into
multiple equations, and returns a set of loop-invariants for the algorithms --
yet to be generated -- that will solve the equation. In a successive step each
loop-invariant is then mapped to its corresponding algorithm and routine. For a
large class of equations, the methodology generates known algorithms as well as
many previously unknown ones. Most interestingly, the methodology unifies
algorithms traditionally developed in isolation. As an example, the five well
known algorithms for the LU factorization are for the first time unified under
a common root.
"
550,Knowledge-Based Automatic Generation of Partitioned Matrix Expressions,"  In a series of papers it has been shown that for many linear algebra
operations it is possible to generate families of algorithms by following a
systematic procedure. Although powerful, such a methodology involves complex
algebraic manipulation, symbolic computations and pattern matching, making the
generation a process challenging to be performed by hand. We aim for a fully
automated system that from the sole description of a target operation creates
multiple algorithms without any human intervention. Our approach consists of
three main stages. The first stage yields the core object for the entire
process, the Partitioned Matrix Expression (PME), which establishes how the
target problem may be decomposed in terms of simpler sub-problems. In the
second stage the PME is inspected to identify predicates, the Loop-Invariants,
to be used to set up the skeleton of a family of proofs of correctness. In the
third and last stage the actual algorithms are constructed so that each of them
satisfies its corresponding proof of correctness. In this paper we focus on the
first stage of the process, the automatic generation of Partitioned Matrix
Expressions. In particular, we discuss the steps leading to a PME and the
knowledge necessary for a symbolic system to perform such steps. We also
introduce Cl1ck, a prototype system written in Mathematica that generates PMEs
automatically.
"
551,cuDNN: Efficient Primitives for Deep Learning,"  We present a library of efficient implementations of deep learning
primitives. Deep learning workloads are computationally intensive, and
optimizing their kernels is difficult and time-consuming. As parallel
architectures evolve, kernels must be reoptimized, which makes maintaining
codebases difficult over time. Similar issues have long been addressed in the
HPC community by libraries such as the Basic Linear Algebra Subroutines (BLAS).
However, there is no analogous library for deep learning. Without such a
library, researchers implementing deep learning workloads on parallel
processors must create and optimize their own implementations of the main
computational kernels, and this work must be repeated as new parallel
processors emerge. To address this problem, we have created a library similar
in intent to BLAS, with optimized routines for deep learning workloads. Our
implementation contains routines for GPUs, although similarly to the BLAS
library, these routines could be implemented for other platforms. The library
is easy to integrate into existing frameworks, and provides optimized
performance and memory usage. For example, integrating cuDNN into Caffe, a
popular framework for convolutional networks, improves performance by 36% on a
standard model while also reducing memory consumption.
"
552,High-Order Finite-differences on multi-threaded architectures using OCCA,"  High-order finite-difference methods are commonly used in wave propagators
for industrial subsurface imaging algorithms. Computational aspects of the
reduced linear elastic vertical transversely isotropic propagator are
considered. Thread parallel algorithms suitable for implementing this
propagator on multi-core and many-core processing devices are introduced.
Portability is addressed through the use of the \OCCA runtime programming
interface. Finally, performance results are shown for various architectures on
a representative synthetic test case.
"
553,"KBLAS: An Optimized Library for Dense Matrix-Vector Multiplication on
  GPU Accelerators","  KBLAS is a new open source high performance library that provides optimized
kernels for a subset of Level 2 BLAS functionalities on CUDA-enabled GPUs.
Since performance of dense matrix-vector multiplication is hindered by the
overhead of memory accesses, a double-buffering optimization technique is
employed to overlap data motion with computation. After identifying a proper
set of tuning parameters, KBLAS is able to efficiently run on various GPU
architectures across different generations, avoiding the time-consuming step of
code rewriting, while still being compliant with the standard BLAS API. Another
advanced optimization technique allows to ensure coalesced memory access when
dealing with submatrices, especially in the context of high level dense linear
algebra algorithms. All four precisions KBLAS kernels have been leveraged to
multi-GPUs environment, which requires the introduction of new APIs to ease
users' experiences on these challenging systems. The KBLAS performance
outperforms existing state-of-the-art implementations on all matrix sizes,
achieves asymptotically up to 50% and 60% speedup on single GPU and multi-GPUs
systems, respectively, and validates our performance model. A subset of KBLAS
high performance kernels has been integrated into NVIDIA's standard BLAS
implementation (cuBLAS) for larger dissemination, starting version 6.0.
"
554,Chemora: A PDE Solving Framework for Modern HPC Architectures,"  Modern HPC architectures consist of heterogeneous multi-core, many-node
systems with deep memory hierarchies. Modern applications employ ever more
advanced discretisation methods to study multi-physics problems. Developing
such applications that explore cutting-edge physics on cutting-edge HPC systems
has become a complex task that requires significant HPC knowledge and
experience. Unfortunately, this combined knowledge is currently out of reach
for all but a few groups of application developers.
  Chemora is a framework for solving systems of Partial Differential Equations
(PDEs) that targets modern HPC architectures. Chemora is based on Cactus, which
sees prominent usage in the computational relativistic astrophysics community.
In Chemora, PDEs are expressed either in a high-level \LaTeX-like language or
in Mathematica. Discretisation stencils are defined separately from equations,
and can include Finite Differences, Discontinuous Galerkin Finite Elements
(DGFE), Adaptive Mesh Refinement (AMR), and multi-block systems.
  We use Chemora in the Einstein Toolkit to implement the Einstein Equations on
CPUs and on accelerators, and study astrophysical systems such as black hole
binaries, neutron stars, and core-collapse supernovae.
"
555,"Pipelined Iterative Solvers with Kernel Fusion for Graphics Processing
  Units","  We revisit the implementation of iterative solvers on discrete graphics
processing units and demonstrate the benefit of implementations using extensive
kernel fusion for pipelined formulations over conventional implementations of
classical formulations. The proposed implementations with both CUDA and OpenCL
are freely available in ViennaCL and are shown to be competitive with or even
superior to other solver packages for graphics processing units. Highest
performance gains are obtained for small to medium-sized systems, while our
implementations are on par with vendor-tuned implementations for very large
systems. Our results are especially beneficial for transient problems, where
many small to medium-sized systems instead of a single big system need to be
solved.
"
556,HOPE: A Python Just-In-Time compiler for astrophysical computations,"  The Python programming language is becoming increasingly popular for
scientific applications due to its simplicity, versatility, and the broad range
of its libraries. A drawback of this dynamic language, however, is its low
runtime performance which limits its applicability for large simulations and
for the analysis of large data sets, as is common in astrophysics and
cosmology. While various frameworks have been developed to address this
limitation, most focus on covering the complete language set, and either force
the user to alter the code or are not able to reach the full speed of an
optimised native compiled language. In order to combine the ease of Python and
the speed of C++, we developed HOPE, a specialised Python just-in-time (JIT)
compiler designed for numerical astrophysical applications. HOPE focuses on a
subset of the language and is able to translate Python code into C++ while
performing numerical optimisation on mathematical expressions at runtime. To
enable the JIT compilation, the user only needs to add a decorator to the
function definition. We assess the performance of HOPE by performing a series
of benchmarks and compare its execution speed with that of plain Python, C++
and the other existing frameworks. We find that HOPE improves the performance
compared to plain Python by a factor of 2 to 120, achieves speeds comparable to
that of C++, and often exceeds the speed of the existing solutions. We discuss
the differences between HOPE and the other frameworks, as well as future
extensions of its capabilities. The fully documented HOPE package is available
at http://hope.phys.ethz.ch and is published under the GPLv3 license on PyPI
and GitHub.
"
557,Convex Optimization in Julia,"  This paper describes Convex, a convex optimization modeling framework in
Julia. Convex translates problems from a user-friendly functional language into
an abstract syntax tree describing the problem. This concise representation of
the global structure of the problem allows Convex to infer whether the problem
complies with the rules of disciplined convex programming (DCP), and to pass
the problem to a suitable solver. These operations are carried out in Julia
using multiple dispatch, which dramatically reduces the time required to verify
DCP compliance and to parse a problem into conic form. Convex then
automatically chooses an appropriate backend solver to solve the conic form
problem.
"
558,Building pattern recognition applications with the SPARE library,"  This paper presents the SPARE C++ library, an open source software tool
conceived to build pattern recognition and soft computing systems. The library
follows the requirement of the generality: most of the implemented algorithms
are able to process user-defined input data types transparently, such as
labeled graphs and sequences of objects, as well as standard numeric vectors.
Here we present a high-level picture of the SPARE library characteristics,
focusing instead on the specific practical possibility of constructing pattern
recognition systems for different input data types. In particular, as a proof
of concept, we discuss two application instances involving clustering of
real-valued multidimensional sequences and classification of labeled graphs.
"
559,SPIKY: A graphical user interface for monitoring spike train synchrony,"  Techniques for recording large-scale neuronal spiking activity are developing
very fast. This leads to an increasing demand for algorithms capable of
analyzing large amounts of experimental spike train data. One of the most
crucial and demanding tasks is the identification of similarity patterns with a
very high temporal resolution and across different spatial scales. To address
this task, in recent years three time-resolved measures of spike train
synchrony have been proposed, the ISI-distance, the SPIKE-distance, and event
synchronization. The Matlab source codes for calculating and visualizing these
measures have been made publicly available. However, due to the many different
possible representations of the results the use of these codes is rather
complicated and their application requires some basic knowledge of Matlab. Thus
it became desirable to provide a more user-friendly and interactive interface.
Here we address this need and present SPIKY, a graphical user interface which
facilitates the application of time-resolved measures of spike train synchrony
to both simulated and real data. SPIKY includes implementations of the
ISI-distance, the SPIKE-distance and SPIKE-synchronization (an improved and
simplified extension of event synchronization) which have been optimized with
respect to computation speed and memory demand. It also comprises a spike train
generator and an event detector which makes it capable of analyzing continuous
data. Finally, the SPIKY package includes additional complementary programs
aimed at the analysis of large numbers of datasets and the estimation of
significance levels.
"
560,"Efficient implementation of elementary functions in the medium-precision
  range","  We describe a new implementation of the elementary transcendental functions
exp, sin, cos, log and atan for variable precision up to approximately 4096
bits. Compared to the MPFR library, we achieve a maximum speedup ranging from a
factor 3 for cos to 30 for atan. Our implementation uses table-based argument
reduction together with rectangular splitting to evaluate Taylor series. We
collect denominators to reduce the number of divisions in the Taylor series,
and avoid overhead by doing all multiprecision arithmetic using the mpn layer
of the GMP library. Our implementation provides rigorous error bounds.
"
561,External Use of TOPCAT's Plotting Library,"  The table analysis application TOPCAT uses a custom Java plotting library for
highly configurable high-performance interactive or exported visualisations in
two and three dimensions. We present here a variety of ways for end users or
application developers to make use of this library outside of the TOPCAT
application: via the command-line suite STILTS or its Jython variant JyStilts,
via a traditional Java API, or by programmatically assigning values to a set of
parameters in java code or using some form of inter-process communication. The
library has been built with large datasets in mind; interactive plots scale
well up to several million points, and static output to standard graphics
formats is possible for unlimited sized input data.
"
562,Programming the Adapteva Epiphany 64-core Network-on-chip Coprocessor,"  In the construction of exascale computing systems energy efficiency and power
consumption are two of the major challenges. Low-power high performance
embedded systems are of increasing interest as building blocks for large scale
high- performance systems. However, extracting maximum performance out of such
systems presents many challenges. Various aspects from the hardware
architecture to the programming models used need to be explored. The Epiphany
architecture integrates low-power RISC cores on a 2D mesh network and promises
up to 70 GFLOPS/Watt of processing efficiency. However, with just 32 KB of
memory per eCore for storing both data and code, and only low level inter-core
communication support, programming the Epiphany system presents several
challenges. In this paper we evaluate the performance of the Epiphany system
for a variety of basic compute and communication operations. Guided by this
data we explore strategies for implementing scientific applications on memory
constrained low-powered devices such as the Epiphany. With future systems
expected to house thousands of cores in a single chip, the merits of such
architectures as a path to exascale is compared to other competing systems.
"
563,Julia: A Fresh Approach to Numerical Computing,"  Bridging cultures that have often been distant, Julia combines expertise from
the diverse fields of computer science and computational science to create a
new approach to numerical computing. Julia is designed to be easy and fast.
Julia questions notions generally held as ""laws of nature"" by practitioners of
numerical computing:
  1. High-level dynamic programs have to be slow.
  2. One must prototype in one language and then rewrite in another language
for speed or deployment, and
  3. There are parts of a system for the programmer, and other parts best left
untouched as they are built by the experts.
  We introduce the Julia programming language and its design --- a dance
between specialization and abstraction. Specialization allows for custom
treatment. Multiple dispatch, a technique from computer science, picks the
right algorithm for the right circumstance. Abstraction, what good computation
is really about, recognizes what remains the same after differences are
stripped away. Abstractions in mathematics are captured as code through another
technique from computer science, generic programming.
  Julia shows that one can have machine performance without sacrificing human
convenience.
"
564,Introduction to the R package TDA,"  We present a short tutorial and introduction to using the R package TDA,
which provides some tools for Topological Data Analysis. In particular, it
includes implementations of functions that, given some data, provide
topological information about the underlying space, such as the distance
function, the distance to a measure, the kNN density estimator, the kernel
density estimator, and the kernel distance. The salient topological features of
the sublevel sets (or superlevel sets) of these functions can be quantified
with persistent homology. We provide an R interface for the efficient
algorithms of the C++ libraries GUDHI, Dionysus and PHAT, including a function
for the persistent homology of the Rips filtration, and one for the persistent
homology of sublevel sets (or superlevel sets) of arbitrary functions evaluated
over a grid of points. The significance of the features in the resulting
persistence diagrams can be analyzed with functions that implement recently
developed statistical methods. The R package TDA also includes the
implementation of an algorithm for density clustering, which allows us to
identify the spatial organization of the probability mass associated to a
density function and visualize it by means of a dendrogram, the cluster tree.
"
565,"Precision-Energy-Throughput Scaling Of Generic Matrix Multiplication and
  Convolution Kernels Via Linear Projections","  Generic matrix multiplication (GEMM) and one-dimensional
convolution/cross-correlation (CONV) kernels often constitute the bulk of the
compute- and memory-intensive processing within image/audio recognition and
matching systems. We propose a novel method to scale the energy and processing
throughput of GEMM and CONV kernels for such error-tolerant multimedia
applications by adjusting the precision of computation. Our technique employs
linear projections to the input matrix or signal data during the top-level GEMM
and CONV blocking and reordering. The GEMM and CONV kernel processing then uses
the projected inputs and the results are accumulated to form the final outputs.
Throughput and energy scaling takes place by changing the number of projections
computed by each kernel, which in turn produces approximate results, i.e.
changes the precision of the performed computation. Results derived from a
voltage- and frequency-scaled ARM Cortex A15 processor running face recognition
and music matching algorithms demonstrate that the proposed approach allows for
280%~440% increase of processing throughput and 75%~80% decrease of energy
consumption against optimized GEMM and CONV kernels without any impact in the
obtained recognition or matching accuracy. Even higher gains can be obtained if
one is willing to tolerate some reduction in the accuracy of the recognition
and matching applications.
"
566,"Automated generation and symbolic manipulation of tensor product finite
  elements","  We describe and implement a symbolic algebra for scalar and vector-valued
finite elements, enabling the computer generation of elements with tensor
product structure on quadrilateral, hexahedral and triangular prismatic cells.
The algebra is implemented as an extension to the domain-specific language UFL,
the Unified Form Language. This allows users to construct many finite element
spaces beyond those supported by existing software packages. We have made
corresponding extensions to FIAT, the FInite element Automatic Tabulator, to
enable numerical tabulation of such spaces. This tabulation is consequently
used during the automatic generation of low-level code that carries out local
assembly operations, within the wider context of solving finite element
problems posed over such function spaces. We have done this work within the
code-generation pipeline of the software package Firedrake; we make use of the
full Firedrake package to present numerical examples.
"
567,"Simple, Parallel, High-Performance Virtual Machines for Extreme
  Computations","  We introduce a high-performance virtual machine (VM) written in a numerically
fast language like Fortran or C to evaluate very large expressions. We discuss
the general concept of how to perform computations in terms of a VM and present
specifically a VM that is able to compute tree-level cross sections for any
number of external legs, given the corresponding byte code from the optimal
matrix element generator, O'Mega. Furthermore, this approach allows to
formulate the parallel computation of a single phase space point in a simple
and obvious way. We analyze hereby the scaling behaviour with multiple threads
as well as the benefits and drawbacks that are introduced with this method. Our
implementation of a VM can run faster than the corresponding native, compiled
code for certain processes and compilers, especially for very high
multiplicities, and has in general runtimes in the same order of magnitude. By
avoiding the tedious compile and link steps, which may fail for source code
files of gigabyte sizes, new processes or complex higher order corrections that
are currently out of reach could be evaluated with a VM given enough computing
power.
"
568,Conjugate gradient solvers on Intel Xeon Phi and NVIDIA GPUs,"  Lattice Quantum Chromodynamics simulations typically spend most of the
runtime in inversions of the Fermion Matrix. This part is therefore frequently
optimized for various HPC architectures. Here we compare the performance of the
Intel Xeon Phi to current Kepler-based NVIDIA Tesla GPUs running a conjugate
gradient solver. By exposing more parallelism to the accelerator through
inverting multiple vectors at the same time, we obtain a performance greater
than 300 GFlop/s on both architectures. This more than doubles the performance
of the inversions. We also give a short overview of the Knights Corner
architecture, discuss some details of the implementation and the effort
required to obtain the achieved performance.
"
569,"An Infra-Structure for Performance Estimation and Experimental
  Comparison of Predictive Models in R","  This document describes an infra-structure provided by the R package
performanceEstimation that allows to estimate the predictive performance of
different approaches (workflows) to predictive tasks. The infra-structure is
generic in the sense that it can be used to estimate the values of any
performance metrics, for any workflow on different predictive tasks, namely,
classification, regression and time series tasks. The package also includes
several standard workflows that allow users to easily set up their experiments
limiting the amount of work and information they need to provide. The overall
goal of the infra-structure provided by our package is to facilitate the task
of estimating the predictive performance of different modeling approaches to
predictive tasks in the R environment.
"
570,Minkowski sum of HV-polytopes in Rn,"  Minkowski sums cover a wide range of applications in many different fields
like algebra, morphing, robotics, mechanical CAD/CAM systems ... This paper
deals with sums of polytopes in a n dimensional space provided that both
H-representation and V-representation are available i.e. the polytopes are
described by both their half-spaces and vertices. The first method uses the
polytope normal fans and relies on the ability to intersect dual polyhedral
cones. Then we introduce another way of considering Minkowski sums of polytopes
based on the primal polyhedral cones attached to each vertex.
"
571,Minkowski Sum of Polytopes Defined by Their Vertices,"  Minkowski sums are of theoretical interest and have applications in fields
related to industrial backgrounds. In this paper we focus on the specific case
of summing polytopes as we want to solve the tolerance analysis problem
described in [1]. Our approach is based on the use of linear programming and is
solvable in polynomial time. The algorithm we developed can be implemented and
parallelized in a very easy way.
"
572,"An implementation of a randomized algorithm for principal component
  analysis","  Recent years have witnessed intense development of randomized methods for
low-rank approximation. These methods target principal component analysis (PCA)
and the calculation of truncated singular value decompositions (SVD). The
present paper presents an essentially black-box, fool-proof implementation for
Mathworks' MATLAB, a popular software platform for numerical computation. As
illustrated via several tests, the randomized algorithms for low-rank
approximation outperform or at least match the classical techniques (such as
Lanczos iterations) in basically all respects: accuracy, computational
efficiency (both speed and memory usage), ease-of-use, parallelizability, and
reliability. However, the classical procedures remain the methods of choice for
estimating spectral norms, and are far superior for calculating the least
singular values and corresponding singular vectors (or singular subspaces).
"
573,MatConvNet - Convolutional Neural Networks for MATLAB,"  MatConvNet is an implementation of Convolutional Neural Networks (CNNs) for
MATLAB. The toolbox is designed with an emphasis on simplicity and flexibility.
It exposes the building blocks of CNNs as easy-to-use MATLAB functions,
providing routines for computing linear convolutions with filter banks, feature
pooling, and many more. In this manner, MatConvNet allows fast prototyping of
new CNN architectures; at the same time, it supports efficient computation on
CPU and GPU allowing to train complex models on large datasets such as ImageNet
ILSVRC. This document provides an overview of CNNs and how they are implemented
in MatConvNet and gives the technical details of each computational block in
the toolbox.
"
574,GPTIPS 2: an open-source software platform for symbolic data mining,"  GPTIPS is a free, open source MATLAB based software platform for symbolic
data mining (SDM). It uses a multigene variant of the biologically inspired
machine learning method of genetic programming (MGGP) as the engine that drives
the automatic model discovery process. Symbolic data mining is the process of
extracting hidden, meaningful relationships from data in the form of symbolic
equations. In contrast to other data-mining methods, the structural
transparency of the generated predictive equations can give new insights into
the physical systems or processes that generated the data. Furthermore, this
transparency makes the models very easy to deploy outside of MATLAB. The
rationale behind GPTIPS is to reduce the technical barriers to using,
understanding, visualising and deploying GP based symbolic models of data,
whilst at the same time remaining highly customisable and delivering robust
numerical performance for power users. In this chapter, notable new features of
the latest version of the software are discussed with these aims in mind.
Additionally, a simplified variant of the MGGP high level gene crossover
mechanism is proposed. It is demonstrated that the new functionality of GPTIPS
2 (a) facilitates the discovery of compact symbolic relationships from data
using multiple approaches, e.g. using novel gene-centric visualisation analysis
to mitigate horizontal bloat and reduce complexity in multigene symbolic
regression models (b) provides numerous methods for visualising the properties
of symbolic models (c) emphasises the generation of graphically navigable
libraries of models that are optimal in terms of the Pareto trade off surface
of model performance and complexity and (d) expedites real world applications
by the simple, rapid and robust deployment of symbolic models outside the
software environment they were developed in.
"
575,Efficient SIMD RNG for Varying-Parameter Streams: C++ Class BatchRNG,"  Single-Instruction, Multiple-Data (SIMD) random number generators (RNGs) take
advantage of vector units to offer significant performance gain over
non-vectorized libraries, but they often rely on batch production of deviates
from distributions with fixed parameters. In many statistical applications such
as Gibbs sampling, parameters of sampled distributions change from one
iteration to the next, requiring that random deviates be generated
one-at-a-time. This situation can render vectorized RNGs inefficient, and even
inferior to their scalar counterparts. The C++ class BatchRNG uses buffers of
base distributions such uniform, Gaussian and exponential to take advantage of
vector units while allowing for sequences of deviates to be generated with
varying parameters. These small buffers are consumed and replenished as needed
during a program execution. Performance tests using Intel Vector Statistical
Library (VSL) on various probability distributions illustrates the
effectiveness of the proposed batching strategy.
"
576,Twofolds in C and C++,"  Here I propose C and C++ interfaces and experimental implementation for
twofolds arithmetic. I introduce twofolds in my previous article entitled
""Twofold fast arithmetic"" for tracking floating-point inaccuracy. Testing
shows, plain C enables high-performance computing with twofolds. C++ interface
enables coding as easily as ordinary floating-point numbers. My goal is
convincing you to try twofolds; I think assuring accuracy of math computations
is worth its cost. Code and use examples available at my web site, references
inside.
"
577,FlexDM: Enabling robust and reliable parallel data mining using WEKA,"  Performing massive data mining experiments with multiple datasets and methods
is a common task faced by most bioinformatics and computational biology
laboratories. WEKA is a machine learning package designed to facilitate this
task by providing tools that allow researchers to select from several
classification methods and specific test strategies. Despite its popularity,
the current WEKA environment for batch experiments, namely Experimenter, has
four limitations that impact its usability: the selection of value ranges for
methods options lacks flexibility and is not intuitive; there is no support for
parallelisation when running large-scale data mining tasks; the XML schema is
difficult to read, necessitating the use of the Experimenter's graphical user
interface for generation and modification; and robustness is limited by the
fact that results are not saved until the last test has concluded.
  FlexDM implements an interface to WEKA to run batch processing tasks in a
simple and intuitive way. In a short and easy-to-understand XML file, one can
define hundreds of tests to be performed on several datasets. FlexDM also
allows those tests to be executed asynchronously in parallel to take advantage
of multi-core processors, significantly increasing usability and productivity.
Results are saved incrementally for better robustness and reliability.
  FlexDM is implemented in Java and runs on Windows, Linux and OSX. As we
encourage other researchers to explore and adopt our software, FlexDM is made
available as a pre-configured bootable reference environment. All code,
supporting documentation and usage examples are also available for download at
http://sourceforge.net/projects/flexdm.
"
578,"PyFAI: a Python library for high performance azimuthal integration on
  GPU","  The pyFAI package has been designed to reduce X-ray diffraction images into
powder diffraction curves to be further processed by scientists. This
contribution describes how to convert an image into a radial profile using the
Numpy package, how the process was accelerated using Cython. The algorithm was
parallelised, needing a complete re-design to benefit from massively parallel
devices like graphical processing units or accelerators like the Intel Xeon Phi
using the PyOpenCL library.
"
579,"SClib, a hack for straightforward embedded C functions in Python","  We present SClib, a simple hack that allows easy and straightforward
evaluation of C functions within Python code, boosting flexibility for better
trade-off between computation power and feature availability, such as
visualization and existing computation routines in SciPy. We also present two
cases were SClib has been used. In the first set of applications we use SClib
to write a port to Python of a Schr\""odinger equation solver that has been
extensively used the literature, the resulting script presents a speed-up of
about 150x with respect to the original one. A review of the situations where
the speeded-up script has been used is presented. We also describe the solution
to the related problem of solving a set of coupled Schr\""odinger-like equations
where SClib is used to implement the speed-critical parts of the code. We argue
that when using SClib within IPython we can use NumPy and Matplotlib for the
manipulation and visualization of the solutions in an interactive environment
with no performance compromise. The second case is an engineering application.
We use SClib to evaluate the control and system derivatives in a feedback
control loop for electrical motors. With this and the integration routines
available in SciPy, we can run simulations of the control loop a la Simulink.
The use of C code not only boosts the speed of the simulations, but also
enables to test the exact same code that we use in the test rig to get
experimental results. Again, integration with IPython gives us the flexibility
to analyze and visualize the data.
"
580,Enhancing SfePy with Isogeometric Analysis,"  In the paper a recent enhancement to the open source package SfePy (Simple
Finite Elements in Python, http://sfepy.org) is introduced, namely the addition
of another numerical discretization scheme, the isogeometric analysis, to the
original implementation based on the nowadays standard and well-established
numerical solution technique, the finite element method. The isogeometric
removes the need of the solution domain approximation by a piece-wise polygonal
domain covered by the finite element mesh, and allows approximation of unknown
fields with a higher smoothness then the finite element method, which can be
advantageous in many applications. Basic numerical examples illustrating the
implementation and use of the isogeometric analysis in SfePy are shown.
"
581,"Software for Distributed Computation on Medical Databases: A
  Demonstration Project","  Bringing together the information latent in distributed medical databases
promises to personalize medical care by enabling reliable, stable modeling of
outcomes with rich feature sets (including patient characteristics and
treatments received). However, there are barriers to aggregation of medical
data, due to lack of standardization of ontologies, privacy concerns,
proprietary attitudes toward data, and a reluctance to give up control over end
use. Aggregation of data is not always necessary for model fitting. In models
based on maximizing a likelihood, the computations can be distributed, with
aggregation limited to the intermediate results of calculations on local data,
rather than raw data. Distributed fitting is also possible for singular value
decomposition. There has been work on the technical aspects of shared
computation for particular applications, but little has been published on the
software needed to support the ""social networking"" aspect of shared computing,
to reduce the barriers to collaboration. We describe a set of software tools
that allow the rapid assembly of a collaborative computational project, based
on the flexible and extensible R statistical software and other open source
packages, that can work across a heterogeneous collection of database
environments, with full transparency to allow local officials concerned with
privacy protections to validate the safety of the method. We describe the
principles, architecture, and successful test results for the site-stratified
Cox model and rank-k Singular Value Decomposition (SVD).
"
582,"Proceedings of the 7th European Conference on Python in Science
  (EuroSciPy 2014)","  These are the proceedings of the 7th European Conference on Python in
Science, EuroSciPy 2014, that was held in Cambridge, UK (27-30 August 2014).
"
583,The NIFTY way of Bayesian signal inference,"  We introduce NIFTY, ""Numerical Information Field Theory"", a software package
for the development of Bayesian signal inference algorithms that operate
independently from any underlying spatial grid and its resolution. A large
number of Bayesian and Maximum Entropy methods for 1D signal reconstruction, 2D
imaging, as well as 3D tomography, appear formally similar, but one often finds
individualized implementations that are neither flexible nor easily
transferable. Signal inference in the framework of NIFTY can be done in an
abstract way, such that algorithms, prototyped in 1D, can be applied to real
world problems in higher-dimensional settings. NIFTY as a versatile library is
applicable and already has been applied in 1D, 2D, 3D and spherical settings. A
recent application is the D3PO algorithm targeting the non-trivial task of
denoising, deconvolving, and decomposing photon observations in high energy
astronomy.
"
584,A persistence landscapes toolbox for topological statistics,"  Topological data analysis provides a multiscale description of the geometry
and topology of quantitative data. The persistence landscape is a topological
summary that can be easily combined with tools from statistics and machine
learning. We give efficient algorithms for calculating persistence landscapes,
their averages, and distances between such averages. We discuss an
implementation of these algorithms and some related procedures. These are
intended to facilitate the combination of statistics and machine learning with
topological data analysis. We present an experiment showing that the
low-dimensional persistence landscapes of points sampled from spheres (and
boxes) of varying dimensions differ.
"
585,"A New Sparse Matrix Vector Multiplication GPU Algorithm Designed for
  Finite Element Problems","  Recently, graphics processors (GPUs) have been increasingly leveraged in a
variety of scientific computing applications. However, architectural
differences between CPUs and GPUs necessitate the development of algorithms
that take advantage of GPU hardware. As sparse matrix vector multiplication
(SPMV) operations are commonly used in finite element analysis, a new SPMV
algorithm and several variations are developed for unstructured finite element
meshes on GPUs. The effective bandwidth of current GPU algorithms and the newly
proposed algorithms are measured and analyzed for 15 sparse matrices of varying
sizes and varying sparsity structures. The effects of optimization and
differences between the new GPU algorithm and its variants are then
subsequently studied. Lastly, both new and current SPMV GPU algorithms are
utilized in the GPU CG Solver in GPU finite element simulations of the heart.
These results are then compared against parallel PETSc finite element
implementation results. The effective bandwidth tests indicate that the new
algorithms compare very favorably with current algorithms for a wide variety of
sparse matrices and can yield very notable benefits. GPU finite element
simulation results demonstrate the benefit of using GPUs for finite element
analysis, and also show that the proposed algorithms can yield speedup factors
up to 12-fold for real finite element applications.
"
586,"GammaCHI: a package for the inversion and computation of the gamma and
  chi-square cumulative distribution functions (central and noncentral)","  A Fortran 90 module (GammaCHI) for computing and inverting the gamma and
chi-square cumulative distribution functions (central and noncentral) is
presented. The main novelty of this package are the reliable and accurate
inversion routines for the noncentral cumulative distribution functions.
Additionally, the package also provides routines for computing the gamma
function, the error function and other functions related to the gamma function.
The module includes the routines cdfgamC, invcdfgamC, cdfgamNC, invcdfgamNC,
errorfunction, inverfc, gamma, loggam, gamstar and quotgamm for the computation
of the central gamma distribution function (and its complementary function),
the inversion of the central gamma distribution function, the computation of
the noncentral gamma distribution function (and its complementary function),
the inversion of the noncentral gamma distribution function, the computation of
the error function and its complementary function, the inversion of the
complementary error function, the computation of: the gamma function, the
logarithm of the gamma function, the regulated gamma function and the ratio of
two gamma functions, respectively.
"
587,"Firedrake: automating the finite element method by composing
  abstractions","  Firedrake is a new tool for automating the numerical solution of partial
differential equations. Firedrake adopts the domain-specific language for the
finite element method of the FEniCS project, but with a pure Python
runtime-only implementation centred on the composition of several existing and
new abstractions for particular aspects of scientific computing. The result is
a more complete separation of concerns which eases the incorporation of
separate contributions from computer scientists, numerical analysts and
application specialists. These contributions may add functionality, or improve
performance.
  Firedrake benefits from automatically applying new optimisations. This
includes factorising mixed function spaces, transforming and vectorising inner
loops, and intrinsically supporting block matrix operations. Importantly,
Firedrake presents a simple public API for escaping the UFL abstraction. This
allows users to implement common operations that fall outside pure variational
formulations, such as flux-limiters.
"
588,"Solving Polynomial Systems by Penetrating Gradient Algorithm Applying
  Deepest Descent Strategy","  An algorithm and associated strategy for solving polynomial systems within
the optimization framework is presented. The algorithm and strategy are named,
respectively, the penetrating gradient algorithm and the deepest descent
strategy. The most prominent feature of penetrating gradient algorithm, after
which it was named, is its ability to see and penetrate through the obstacles
in error space along the line of search direction and to jump to the global
minimizer in a single step. The ability to find the deepest point in an
arbitrary direction, no matter how distant the point is and regardless of the
relief of error space between the current and the best point, motivates
movements in directions in which cost function can be maximally reduced, rather
than in directions that seem to be the best locally (like, for instance, the
steepest descent, i.e., negative gradient direction). Therefore, the strategy
is named the deepest descent, in contrast but alluding to the steepest descent.
Penetrating gradient algorithm is derived and its properties are proven
mathematically, while features of the deepest descent strategy are shown by
comparative simulations. Extensive benchmark tests confirm that the proposed
algorithm and strategy jointly form an effective solver of polynomial systems.
In addition, further theoretical considerations in Section 5 about solving
linear systems by the proposed method reveal a surprising and interesting
relation of proposed and Gauss-Seidel method.
"
589,FASTA: A Generalized Implementation of Forward-Backward Splitting,"  This is a user manual for the software package FASTA.
"
590,"Associative Arrays: Unified Mathematics for Spreadsheets, Databases,
  Matrices, and Graphs","  Data processing systems impose multiple views on data as it is processed by
the system. These views include spreadsheets, databases, matrices, and graphs.
The common theme amongst these views is the need to store and operate on data
as whole sets instead of as individual data elements. This work describes a
common mathematical representation of these data sets (associative arrays) that
applies across a wide range of applications and technologies. Associative
arrays unify and simplify these different approaches for representing and
manipulating data into common two-dimensional view of data. Specifically,
associative arrays (1) reduce the effort required to pass data between steps in
a data processing system, (2) allow steps to be interchanged with full
confidence that the results will be unchanged, and (3) make it possible to
recognize when steps can be simplified or eliminated. Most database system
naturally support associative arrays via their tabular interfaces. The D4M
implementation of associative arrays uses this feature to provide a common
interface across SQL, NoSQL, and NewSQL databases.
"
591,"Accelerating Polynomial Homotopy Continuation on a Graphics Processing
  Unit with Double Double and Quad Double Arithmetic","  Numerical continuation methods track a solution path defined by a homotopy.
The systems we consider are defined by polynomials in several variables with
complex coefficients. For larger dimensions and degrees, the numerical
conditioning worsens and hardware double precision becomes often insufficient
to reach the end of the solution path. With double double and quad double
arithmetic, we can solve larger problems that we could not solve with hardware
double arithmetic, but at a higher computational cost. This cost overhead can
be compensated by acceleration on a Graphics Processing Unit (GPU). We describe
our implementation and report on computational results on benchmark polynomial
systems.
"
592,Performance Tuning of a Parallel 3-D FFT Package OpenFFT,"  The fast Fourier transform (FFT) is a primitive kernel in numerous fields of
science and engineering. OpenFFT is an open-source parallel package for 3-D
FFTs, built on a communication-optimal domain decomposition method for
achieving minimal volume of communication. In this paper, we analyze and tune
the performance of OpenFFT, paying a particular attention to tuning of
communication that dominates the run time of large-scale calculations. We first
analyze its performance on different machines for an understanding of the
behaviors of the package and machines. Based on the performance analysis, we
develop six communication methods for performing communication with the aim of
covering varied calculation scales on a variety of computational platforms.
OpenFFT is then augmented with an auto-tuning of communication to select the
best method in run time depending on their performance. Numerical results
demonstrate that the optimized OpenFFT is able to deliver relatively good
performance in comparison with other state-of-the-art packages at different
computational scales on a number of parallel machines.
"
593,Visualizing Marden's theorem with Scilab,"  A theorem which is named after the American Mathematician Moris Marden states
a very surprising and interesting fact concerning the relationship between the
points of a triangle in the complex plane and the zeros of two complex
polynomials related to this triangle: ""Suppose the zeroes z1, z2, and z3 of a
third-degree polynomial p(z) are non-collinear. There is a unique ellipse
inscribed in the triangle with vertices z1, z2, z3 and tangent to the sides at
their midpoints: the Steiner in-ellipse. The foci of that ellipse are the
zeroes of the derivative p'(z)."" (Wikipedia contributors, ""Marden's theorem"",
http://en.wikipedia.org/wiki/Marden%27s_theorem). This document describes how
Scilab, a popular and powerful open source alternative to MATLAB, can be used
to visualize the above stated theorem for arbitrary complex numbers z1, z2, and
z3 which are not collinear. It is further demonstrated how the equations of the
Steiner ellipses of a triangle in the complex plane can be calculated and
plotted by applying this theorem.
"
594,Twofold exp and log,"  This article is about twofold arithmetic. Here I introduce algorithms and
experimental code for twofold variant of C/C++ standard functions exp() and
log(), and expm1() and log1p(). Twofold function $y_0+y_1 \approx f(x_0+x_1)$
is nearly 2x-precise so can assess accuracy of standard one. Performance allows
assessing on-fly: twofold texp() over double is ~10x times faster than expq()
by GNU quadmath.
"
595,"RSVDPACK: An implementation of randomized algorithms for computing the
  singular value, interpolative, and CUR decompositions of matrices on
  multi-core and GPU architectures","  RSVDPACK is a library of functions for computing low rank approximations of
matrices. The library includes functions for computing standard (partial)
factorizations such as the Singular Value Decomposition (SVD), and also so
called ""structure preserving"" factorizations such as the Interpolative
Decomposition (ID) and the CUR decomposition. The ID and CUR factorizations
pick subsets of the rows/columns of a matrix to use as bases for its row/column
space. Such factorizations preserve properties of the matrix such as sparsity
or non-negativity, are helpful in data interpretation, and require in certain
contexts less memory than a partial SVD. The package implements highly
efficient computational algorithms based on randomized sampling, as described
and analyzed in [N. Halko, P.G. Martinsson, J. Tropp, ""Finding structure with
randomness: Probabilistic algorithms for constructing approximate matrix
decompositions,"" SIAM Review, 53(2), 2011], and subsequent papers. This
manuscript presents some modifications to the basic algorithms that improve
performance and ease of use. The library is written in C and supports both
multi-core CPU and GPU architectures.
"
596,"MILJS : Brand New JavaScript Libraries for Matrix Calculation and
  Machine Learning","  MILJS is a collection of state-of-the-art, platform-independent, scalable,
fast JavaScript libraries for matrix calculation and machine learning. Our core
library offering a matrix calculation is called Sushi, which exhibits far
better performance than any other leading machine learning libraries written in
JavaScript. Especially, our matrix multiplication is 177 times faster than the
fastest JavaScript benchmark. Based on Sushi, a machine learning library called
Tempura is provided, which supports various algorithms widely used in machine
learning research. We also provide Soba as a visualization library. The
implementations of our libraries are clearly written, properly documented and
thus can are easy to get started with, as long as there is a web browser. These
libraries are available from http://mil-tokyo.github.io/ under the MIT license.
"
597,"Construction and implementation of asymptotic expansions for
  Jacobi--type orthogonal polynomials","  We are interested in the asymptotic behavior of orthogonal polynomials of the
generalized Jacobi type as their degree $n$ goes to $\infty$. These are defined
on the interval $[-1,1]$ with weight function
$w(x)=(1-x)^{\alpha}(1+x)^{\beta}h(x)$, $\alpha,\beta>-1$ and $h(x)$ a real,
analytic and strictly positive function on $[-1,1]$. This information is
available in the work of Kuijlaars, McLaughlin, Van Assche and Vanlessen, where
the authors use the Riemann--Hilbert formulation and the Deift--Zhou non-linear
steepest descent method. We show that computing higher-order terms can be
simplified, leading to their efficient construction. The resulting asymptotic
expansions in every region of the complex plane are implemented both
symbolically and numerically, and the code is made publicly available. The main
advantage of these expansions is that they lead to increasing accuracy for
increasing degree of the polynomials, at a computational cost that is actually
independent of the degree. In contrast, the typical use of the recurrence
relation for orthogonal polynomials in computations leads to a cost that is at
least linear in the degree. Furthermore, the expansions may be used to compute
Gaussian quadrature rules in $\mathcal{O}(n)$ operations, rather than
$\mathcal{O}(n^2)$ based on the recurrence relation.
"
598,"An efficient multi-core implementation of a novel HSS-structured
  multifrontal solver using randomized sampling","  We present a sparse linear system solver that is based on a multifrontal
variant of Gaussian elimination, and exploits low-rank approximation of the
resulting dense frontal matrices. We use hierarchically semiseparable (HSS)
matrices, which have low-rank off-diagonal blocks, to approximate the frontal
matrices. For HSS matrix construction, a randomized sampling algorithm is used
together with interpolative decompositions. The combination of the randomized
compression with a fast ULV HSS factorization leads to a solver with lower
computational complexity than the standard multifrontal method for many
applications, resulting in speedups up to 7 fold for problems in our test
suite. The implementation targets many-core systems by using task parallelism
with dynamic runtime scheduling. Numerical experiments show performance
improvements over state-of-the-art sparse direct solvers. The implementation
achieves high performance and good scalability on a range of modern shared
memory parallel systems, including the Intel Xeon Phi (MIC). The code is part
of a software package called STRUMPACK -- STRUctured Matrices PACKage, which
also has a distributed memory component for dense rank-structured matrices.
"
599,How to speed up R code: an introduction,"  Most calculations performed by the average R user are unremarkable in the
sense that nowadays, any computer can crush the related code in a matter of
seconds. But more and more often, heavy calculations are also performed using
R, something especially true in some fields such as statistics. The user then
faces total execution times of his codes that are hard to work with: hours,
days, even weeks. In this paper, how to reduce the total execution time of
various codes will be shown and typical bottlenecks will be discussed. As a
last resort, how to run your code on a cluster of computers (most workplaces
have one) in order to make use of a larger processing power than the one
available on an average computer will also be discussed through two examples.
"
600,Quantomatic: A Proof Assistant for Diagrammatic Reasoning,"  Monoidal algebraic structures consist of operations that can have multiple
outputs as well as multiple inputs, which have applications in many areas
including categorical algebra, programming language semantics, representation
theory, algebraic quantum information, and quantum groups. String diagrams
provide a convenient graphical syntax for reasoning formally about such
structures, while avoiding many of the technical challenges of a term-based
approach. Quantomatic is a tool that supports the (semi-)automatic construction
of equational proofs using string diagrams. We briefly outline the theoretical
basis of Quantomatic's rewriting engine, then give an overview of the core
features and architecture and give a simple example project that computes
normal forms for commutative bialgebras.
"
601,T3PS: Tool for Parallel Processing in Parameter Scans,"  T3PS is a program that can be used to quickly design and perform parameter
scans while easily taking advantage of the multi-core architecture of current
processors. It takes an easy to read and write parameter scan definition file
format as input. Based on the parameter ranges and other options contained
therein, it distributes the calculation of the parameter space over multiple
processes and possibly computers. The derived data is saved in a plain text
file format readable by most plotting software. The supported scanning
strategies include: grid scan, random scan, Markov Chain Monte Carlo, numerical
optimization. Several example parameter scans are shown and compared with
results in the literature.
"
602,libRoadRunner: A High Performance SBML Simulation and Analysis Library,"  This paper presents libRoadRunner, an extensible, high-performance,
cross-platform, open-source software library for the simulation and analysis of
models \ expressed using Systems Biology Markup Language (SBML). SBML is the
most widely used standard for representing dynamic networks, especially
biochemical networks. libRoadRunner supports solution of both large models and
multiple replicas of a single model on desktop, mobile and cluster computers.
libRoadRunner is a self-contained library, able to run both as a component
inside other tools via its C++ and C bindings andnteractively through its
Python interface. The Python Application Programming Interface (API) is similar
to the APIs of Matlab and SciPy, making it fast and easy to learn, even for new
users. libRoadRunner uses a custom Just-In-Time (JIT) compiler built on the
widely-used LLVM JIT compiler framework to compile SBML-specified models
directly into very fast native machine code for a variety of processors, making
it appropriate for solving very large models or multiple replicas of smaller
models. libRoadRunner is flexible, supporting the bulk of the SBML
specification (except for delay and nonlinear algebraic equations) and several
of its extensions. It offers multiple deterministic and stochastic integrators,
as well as tools for steady-state, stability analyses and flux balance
analysis. We regularly update libRoadRunner binary distributions for Mac OS X,
Linux and Windows and license them under Apache License Version 2.0.
http://www.libroadrunner.org provides online documentation, full build
instructions, binaries and a git source repository.
"
603,Algorithms and complexity for Turaev-Viro invariants,"  The Turaev-Viro invariants are a powerful family of topological invariants
for distinguishing between different 3-manifolds. They are invaluable for
mathematical software, but current algorithms to compute them require
exponential time.
  The invariants are parameterised by an integer $r \geq 3$. We resolve the
question of complexity for $r=3$ and $r=4$, giving simple proofs that computing
Turaev-Viro invariants for $r=3$ is polynomial time, but for $r=4$ is \#P-hard.
Moreover, we give an explicit fixed-parameter tractable algorithm for arbitrary
$r$, and show through concrete implementation and experimentation that this
algorithm is practical---and indeed preferable---to the prior state of the art
for real computation.
"
604,Computer Assisted Parallel Program Generation,"  Parallel computation is widely employed in scientific researches, engineering
activities and product development. Parallel program writing itself is not
always a simple task depending on problems solved. Large-scale scientific
computing, huge data analyses and precise visualizations, for example, would
require parallel computations, and the parallel computing needs the
parallelization techniques. In this Chapter a parallel program generation
support is discussed, and a computer-assisted parallel program generation
system P-NCAS is introduced. Computer assisted problem solving is one of key
methods to promote innovations in science and engineering, and contributes to
enrich our society and our life toward a programming-free environment in
computing science. Problem solving environments (PSE) research activities had
started to enhance the programming power in 1970's. The P-NCAS is one of the
PSEs; The PSE concept provides an integrated human-friendly computational
software and hardware system to solve a target class of problems
"
605,"Fast Multiplication of Large Integers: Implementation and Analysis of
  the DKSS Algorithm","  The Sch\""onhage-Strassen algorithm (SSA) is the de-facto standard for
multiplication of large integers. For $N$-bit numbers it has a time bound of
$O(N \cdot \log N \cdot \log \log N)$. De, Kurur, Saha and Saptharishi (DKSS)
presented an asymptotically faster algorithm with a better time bound of $N
\cdot \log N \cdot 2^{O(\log^* N)}$. In this diploma thesis, results of an
implementation of DKSS multiplication are presented: run-time is about 30 times
larger than SSA, while memory requirements are about 3.75 times higher than
SSA. A possible crossover point is estimated to be out of reach even if we
utilized the whole universe for computer memory.
"
606,"CSR5: An Efficient Storage Format for Cross-Platform Sparse
  Matrix-Vector Multiplication","  Sparse matrix-vector multiplication (SpMV) is a fundamental building block
for numerous applications. In this paper, we propose CSR5 (Compressed Sparse
Row 5), a new storage format, which offers high-throughput SpMV on various
platforms including CPUs, GPUs and Xeon Phi. First, the CSR5 format is
insensitive to the sparsity structure of the input matrix. Thus the single
format can support an SpMV algorithm that is efficient both for regular
matrices and for irregular matrices. Furthermore, we show that the overhead of
the format conversion from the CSR to the CSR5 can be as low as the cost of a
few SpMV operations. We compare the CSR5-based SpMV algorithm with 11
state-of-the-art formats and algorithms on four mainstream processors using 14
regular and 10 irregular matrices as a benchmark suite. For the 14 regular
matrices in the suite, we achieve comparable or better performance over the
previous work. For the 10 irregular matrices, the CSR5 obtains average
performance improvement of 17.6\%, 28.5\%, 173.0\% and 293.3\% (up to 213.3\%,
153.6\%, 405.1\% and 943.3\%) over the best existing work on dual-socket Intel
CPUs, an nVidia GPU, an AMD GPU and an Intel Xeon Phi, respectively. For
real-world applications such as a solver with only tens of iterations, the CSR5
format can be more practical because of its low-overhead for format conversion.
The source code of this work is downloadable at
https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR5
"
607,"A distributed-memory package for dense Hierarchically Semi-Separable
  matrix computations using randomization","  We present a distributed-memory library for computations with dense
structured matrices. A matrix is considered structured if its off-diagonal
blocks can be approximated by a rank-deficient matrix with low numerical rank.
Here, we use Hierarchically Semi-Separable representations (HSS). Such matrices
appear in many applications, e.g., finite element methods, boundary element
methods, etc. Exploiting this structure allows for fast solution of linear
systems and/or fast computation of matrix-vector products, which are the two
main building blocks of matrix computations. The compression algorithm that we
use, that computes the HSS form of an input dense matrix, relies on randomized
sampling with a novel adaptive sampling mechanism. We discuss the
parallelization of this algorithm and also present the parallelization of
structured matrix-vector product, structured factorization and solution
routines. The efficiency of the approach is demonstrated on large problems from
different academic and industrial applications, on up to 8,000 cores.
  This work is part of a more global effort, the STRUMPACK (STRUctured Matrices
PACKage) software package for computations with sparse and dense structured
matrices. Hence, although useful on their own right, the routines also
represent a step in the direction of a distributed-memory sparse solver.
"
608,"Implementation of a Practical Distributed Calculation System with
  Browsers and JavaScript, and Application to Distributed Deep Learning","  Deep learning can achieve outstanding results in various fields. However, it
requires so significant computational power that graphics processing units
(GPUs) and/or numerous computers are often required for the practical
application. We have developed a new distributed calculation framework called
""Sashimi"" that allows any computer to be used as a distribution node only by
accessing a website. We have also developed a new JavaScript neural network
framework called ""Sukiyaki"" that uses general purpose GPUs with web browsers.
Sukiyaki performs 30 times faster than a conventional JavaScript library for
deep convolutional neural networks (deep CNNs) learning. The combination of
Sashimi and Sukiyaki, as well as new distribution algorithms, demonstrates the
distributed deep learning of deep CNNs only with web browsers on various
devices. The libraries that comprise the proposed methods are available under
MIT license at http://mil-tokyo.github.io/.
"
609,A Multi-Threaded Version of MCFM,"  We report on our findings modifying MCFM using OpenMP to implement
multi-threading. By using OpenMP, the modified MCFM will execute on any
processor, automatically adjusting to the number of available threads. We
modified the integration routine VEGAS to distribute the event evaluation over
the threads, while combining all events at the end of every iteration to
optimize the numerical integration. Special care has been taken that the
results of the Monte Carlo integration are independent of the number of threads
used, to facilitate the validation of the OpenMP version of MCFM.
"
610,"GAIL---Guaranteed Automatic Integration Library in MATLAB: Documentation
  for Version 2.1","  Automatic and adaptive approximation, optimization, or integration of
functions in a cone with guarantee of accuracy is a relatively new paradigm.
Our purpose is to create an open-source MATLAB package, Guaranteed Automatic
Integration Library (GAIL), following the philosophy of reproducible research
and sustainable practices of robust scientific software development. For our
conviction that true scholarship in computational sciences are characterized by
reliable reproducibility, we employ the best practices in mathematical research
and software engineering known to us and available in MATLAB. This document
describes the key features of functions in GAIL, which includes one-dimensional
function approximation and minimization using linear splines, one-dimensional
numerical integration using trapezoidal rule, and last but not least, mean
estimation and multidimensional integration by Monte Carlo methods or Quasi
Monte Carlo methods.
"
611,"Loo.py: From Fortran to performance via transformation and substitution
  rules","  A large amount of numerically-oriented code is written and is being written
in legacy languages. Much of this code could, in principle, make good use of
data-parallel throughput-oriented computer architectures. Loo.py, a
transformation-based programming system targeted at GPUs and general
data-parallel architectures, provides a mechanism for user-controlled
transformation of array programs. This transformation capability is designed to
not just apply to programs written specifically for Loo.py, but also those
imported from other languages such as Fortran. It eases the trade-off between
achieving high performance, portability, and programmability by allowing the
user to apply a large and growing family of transformations to an input
program. These transformations are expressed in and used from Python and may be
applied from a variety of settings, including a pragma-like manner from other
languages.
"
612,Assessing Excel VBA Suitability for Monte Carlo Simulation,"  Monte Carlo (MC) simulation includes a wide range of stochastic techniques
used to quantitatively evaluate the behavior of complex systems or processes.
Microsoft Excel spreadsheets with Visual Basic for Applications (VBA) software
is, arguably, the most commonly employed general purpose tool for MC
simulation. Despite the popularity of the Excel in many industries and
educational institutions, it has been repeatedly criticized for its flaws and
often described as questionable, if not completely unsuitable, for statistical
problems. The purpose of this study is to assess suitability of the Excel
(specifically its 2010 and 2013 versions) with VBA programming as a tool for MC
simulation. The results of the study indicate that Microsoft Excel (versions
2010 and 2013) is a strong Monte Carlo simulation application offering a solid
framework of core simulation components including spreadsheets for data input
and output, VBA development environment and summary statistics functions. This
framework should be complemented with an external high-quality pseudo-random
number generator added as a VBA module. A large and diverse category of Excel
incidental simulation components that includes statistical distributions,
linear and non-linear regression and other statistical, engineering and
business functions require execution of due diligence to determine their
suitability for a specific MC project.
"
613,"Finite element numerical integration for first order approximations on
  multi-core architectures","  The paper presents investigations on the implementation and performance of
the finite element numerical integration algorithm for first order
approximations and three processor architectures, popular in scientific
computing, classical CPU, Intel Xeon Phi and NVIDIA Kepler GPU. A unifying
programming model and portable OpenCL implementation is considered for all
architectures. Variations of the algorithm due to different problems solved and
different element types are investigated and several optimizations aimed at
proper optimization and mapping of the algorithm to computer architectures are
demonstrated. Performance models of execution are developed for different
processors and tested in practical experiments. The results show the varying
levels of performance for different architectures, but indicate that the
algorithm can be effectively ported to all of them. The general conclusion is
that the finite element numerical integration can achieve sufficient
performance on different multi- and many-core architectures and should not
become a performance bottleneck for finite element simulation codes. Specific
observations lead to practical advises on how to optimize the kernels and what
performance can be expected for the tested architectures.
"
614,Python bindings for libcloudph++,"  This technical note introduces the Python bindings for libcloudph++. The
libcloudph++ is a C++ library of algorithms for representing atmospheric cloud
microphysics in numerical models. The bindings expose the complete
functionality of the library to the Python users. The bindings are implemented
using the Boost.Python C++ library and use NumPy arrays. This note includes
listings with Python scripts exemplifying the use of selected library
components. An example solution for using the Python bindings to access
libcloudph++ from Fortran is presented.
"
615,"Achieving algorithmic resilience for temporal integration through
  spectral deferred corrections","  Spectral deferred corrections (SDC) is an iterative approach for constructing
higher- order accurate numerical approximations of ordinary differential
equations. SDC starts with an initial approximation of the solution defined at
a set of Gaussian or spectral collocation nodes over a time interval and uses
an iterative application of lower-order time discretizations applied to a
correction equation to improve the solution at these nodes. Each deferred
correction sweep increases the formal order of accuracy of the method up to the
limit inherent in the accuracy defined by the collocation points. In this
paper, we demonstrate that SDC is well suited to recovering from soft
(transient) hardware faults in the data. A strategy where extra correction
iterations are used to recover from soft errors and provide algorithmic
resilience is proposed. Specifically, in this approach the iteration is
continued until the residual (a measure of the error in the approximation) is
small relative to the residual on the first correction iteration and changes
slowly between successive iterations. We demonstrate the effectiveness of this
strategy for both canonical test problems and a comprehen- sive situation
involving a mature scientific application code that solves the reacting
Navier-Stokes equations for combustion research.
"
616,The swept rule for breaking the latency barrier in time advancing PDEs,"  This article investigates the swept rule of space-time domain decomposition,
an idea to break the latency barrier via communicating less often when
explicitly solving time-dependent PDEs. The swept rule decomposes space and
time among computing nodes in ways that exploit the domains of influence and
the domain of dependency, making it possible to communicate once per many
timesteps without redundant computation. The article presents simple
theoretical analysis to the performance of the swept rule which then was shown
to be accurate by conducting numerical experiments.
"
617,"A Collection of Challenging Optimization Problems in Science,
  Engineering and Economics","  Function optimization and finding simultaneous solutions of a system of
nonlinear equations (SNE) are two closely related and important optimization
problems. However, unlike in the case of function optimization in which one is
required to find the global minimum and sometimes local minima, a database of
challenging SNEs where one is required to find stationary points (extrama and
saddle points) is not readily available. In this article, we initiate building
such a database of important SNE (which also includes related function
optimization problems), arising from Science, Engineering and Economics. After
providing a short review of the most commonly used mathematical and
computational approaches to find solutions of such systems, we provide a
preliminary list of challenging problems by writing the Mathematical
formulation down, briefly explaning the origin and importance of the problem
and giving a short account on the currently known results, for each of the
problems. We anticipate that this database will not only help benchmarking
novel numerical methods for solving SNEs and function optimization problems but
also will help advancing the corresponding research areas.
"
618,Representing numeric data in 32 bits while preserving 64-bit precision,"  Data files often consist of numbers having only a few significant decimal
digits, whose information content would allow storage in only 32 bits. However,
we may require that arithmetic operations involving these numbers be done with
64-bit floating-point precision, which precludes simply representing the data
as 32-bit floating-point values. Decimal floating point gives a compact and
exact representation, but requires conversion with a slow division operation
before it can be used. Here, I show that interesting subsets of 64-bit
floating-point values can be compactly and exactly represented by the 32 bits
consisting of the sign, exponent, and high-order part of the mantissa, with the
lower-order 32 bits of the mantissa filled in by table lookup, indexed by bits
from the part of the mantissa retained, and possibly from the exponent. For
example, decimal data with 4 or fewer digits to the left of the decimal point
and 2 or fewer digits to the right of the decimal point can be represented in
this way using the lower-order 5 bits of the retained part of the mantissa as
the index. Data consisting of 6 decimal digits with the decimal point in any of
the 7 positions before or after one of the digits can also be represented this
way, and decoded using 19 bits from the mantissa and exponent as the index.
Encoding with such a scheme is a simple copy of half the 64-bit value, followed
if necessary by verification that the value can be represented, by checking
that it decodes correctly. Decoding requires only extraction of index bits and
a table lookup. Lookup in a small table will usually reference cache; even with
larger tables, decoding is still faster than conversion from decimal floating
point with a division operation. I discuss how such schemes perform on recent
computer systems, and how they might be used to automatically compress large
arrays in interpretive languages such as R.
"
619,"Enhancing the scalability and load balancing of the parallel selected
  inversion algorithm via tree-based asynchronous communication","  We develop a method for improving the parallel scalability of the recently
developed parallel selected inversion algorithm [Jacquelin, Lin and Yang 2014],
named PSelInv, on massively parallel distributed memory machines. In the
PSelInv method, we compute selected elements of the inverse of a sparse matrix
A that can be decomposed as A = LU, where L is lower triangular and U is upper
triangular. Updating these selected elements of A-1 requires restricted
collective communications among a subset of processors within each column or
row communication group created by a block cyclic distribution of L and U. We
describe how this type of restricted collective communication can be
implemented by using asynchronous point-to-point MPI communication functions
combined with a binary tree based data propagation scheme. Because multiple
restricted collective communications may take place at the same time in the
parallel selected inversion algorithm, we need to use a heuristic to prevent
processors participating in multiple collective communications from receiving
too many messages. This heuristic allows us to reduce communication load
imbalance and improve the overall scalability of the selected inversion
algorithm. For instance, when 6,400 processors are used, we observe over 5x
speedup for test matrices. It also mitigates the performance variability
introduced by an inhomogeneous network topology.
"
620,"A Framework for General Sparse Matrix-Matrix Multiplication on GPUs and
  Heterogeneous Processors","  General sparse matrix-matrix multiplication (SpGEMM) is a fundamental
building block for numerous applications such as algebraic multigrid method
(AMG), breadth first search and shortest path problem. Compared to other sparse
BLAS routines, an efficient parallel SpGEMM implementation has to handle extra
irregularity from three aspects: (1) the number of nonzero entries in the
resulting sparse matrix is unknown in advance, (2) very expensive parallel
insert operations at random positions in the resulting sparse matrix dominate
the execution time, and (3) load balancing must account for sparse data in both
input matrices.
  In this work we propose a framework for SpGEMM on GPUs and emerging CPU-GPU
heterogeneous processors. This framework particularly focuses on the above
three problems. Memory pre-allocation for the resulting matrix is organized by
a hybrid method that saves a large amount of global memory space and
efficiently utilizes the very limited on-chip scratchpad memory. Parallel
insert operations of the nonzero entries are implemented through the GPU merge
path algorithm that is experimentally found to be the fastest GPU merge
approach. Load balancing builds on the number of necessary arithmetic
operations on the nonzero entries and is guaranteed in all stages.
  Compared with the state-of-the-art CPU and GPU SpGEMM methods, our approach
delivers excellent absolute performance and relative speedups on various
benchmarks multiplying matrices with diverse sparsity structures. Furthermore,
on heterogeneous processors, our SpGEMM approach achieves higher throughput by
using re-allocatable shared virtual memory.
  The source code of this work is available at
https://github.com/bhSPARSE/Benchmark_SpGEMM_using_CSR
"
621,"Speculative Segmented Sum for Sparse Matrix-Vector Multiplication on
  Heterogeneous Processors","  Sparse matrix-vector multiplication (SpMV) is a central building block for
scientific software and graph applications. Recently, heterogeneous processors
composed of different types of cores attracted much attention because of their
flexible core configuration and high energy efficiency. In this paper, we
propose a compressed sparse row (CSR) format based SpMV algorithm utilizing
both types of cores in a CPU-GPU heterogeneous processor. We first
speculatively execute segmented sum operations on the GPU part of a
heterogeneous processor and generate a possibly incorrect results. Then the CPU
part of the same chip is triggered to re-arrange the predicted partial sums for
a correct resulting vector. On three heterogeneous processors from Intel, AMD
and nVidia, using 20 sparse matrices as a benchmark suite, the experimental
results show that our method obtains significant performance improvement over
the best existing CSR-based SpMV algorithms. The source code of this work is
downloadable at https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR
"
622,Symmetric matrix inversion using modified Gaussian elimination,"  In this paper we present two different variants of method for symmetric
matrix inversion, based on modified Gaussian elimination. Both methods avoid
computation of square roots and have a reduced machine time's spending.
Further, both of them can be used efficiently not only for positive (semi-)
definite, but for any non-singular symmetric matrix inversion. We use
simulation to verify results, which represented in this paper.
"
623,Large-scale linear regression: Development of high-performance routines,"  In statistics, series of ordinary least squares problems (OLS) are used to
study the linear correlation among sets of variables of interest; in many
studies, the number of such variables is at least in the millions, and the
corresponding datasets occupy terabytes of disk space. As the availability of
large-scale datasets increases regularly, so does the challenge in dealing with
them. Indeed, traditional solvers---which rely on the use of black-box""
routines optimized for one single OLS---are highly inefficient and fail to
provide a viable solution for big-data analyses. As a case study, in this paper
we consider a linear regression consisting of two-dimensional grids of related
OLS problems that arise in the context of genome-wide association analyses, and
give a careful walkthrough for the development of {\sc ols-grid}, a
high-performance routine for shared-memory architectures; analogous steps are
relevant for tailoring OLS solvers to other applications. In particular, we
first illustrate the design of efficient algorithms that exploit the structure
of the OLS problems and eliminate redundant computations; then, we show how to
effectively deal with datasets that do not fit in main memory; finally, we
discuss how to cast the computation in terms of efficient kernels and how to
achieve scalability. Importantly, each design decision along the way is
justified by simple performance models. {\sc ols-grid} enables the solution of
$10^{11}$ correlated OLS problems operating on terabytes of data in a matter of
hours.
"
624,The ELAPS Framework: Experimental Linear Algebra Performance Studies,"  Optimal use of computing resources requires extensive coding, tuning and
benchmarking. To boost developer productivity in these time consuming tasks, we
introduce the Experimental Linear Algebra Performance Studies framework
(ELAPS), a multi-platform open source environment for fast yet powerful
performance experimentation with dense linear algebra kernels, algorithms, and
libraries. ELAPS allows users to construct experiments to investigate how
performance and efficiency vary depending on factors such as caching,
algorithmic parameters, problem size, and parallelism. Experiments are designed
either through Python scripts or a specialized GUI, and run on the whole
spectrum of architectures, ranging from laptops to clusters, accelerators, and
supercomputers. The resulting experiment reports provide various metrics and
statistics that can be analyzed both numerically and visually. We demonstrate
the use of ELAPS in four concrete application scenarios and in as many
computing environments, illustrating its practical value in supporting critical
performance decisions.
"
625,"Fireflies: New software for interactively exploring dynamical systems
  using GPU computing","  In non-linear systems, where explicit analytic solutions usually can't be
found, visualisation is a powerful approach which can give insights into the
dynamical behaviour of models; it is also crucial for teaching this area of
mathematics. In this paper we present new software, Fireflies, which exploits
the power of graphical processing unit (GPU) computing to produce spectacular
interactive visualisations of arbitrary systems of ordinary differential
equations. In contrast to typical phase portraits, Fireflies draws the current
position of trajectories (projected onto 2D or 3D space) as single points of
light, which move as the system is simulated. Due to the massively parallel
nature of GPU hardware, Fireflies is able to simulate millions of trajectories
in parallel (even on standard desktop computer hardware), producing ""swarms"" of
particles that move around the screen in real-time according to the equations
of the system. Particles that move forwards in time reveal stable attractors
(e.g. fixed points and limit cycles), while the option of integrating another
group of trajectories backwards in time can reveal unstable objects
(repellers). Fireflies allows the user to change the parameters of the system
as it is running, in order to see the effect that they have on the dynamics and
to observe bifurcations. We demonstrate the capabilities of the software with
three examples: a two-dimensional ""mean field"" model of neuronal activity, the
classical Lorenz system, and a 15-dimensional model of three interacting
biologically realistic neurons.
"
626,"Tracking Many Solution Paths of a Polynomial Homotopy on a Graphics
  Processing Unit","  Polynomial systems occur in many areas of science and engineering. Unlike
general nonlinear systems, the algebraic structure enables to compute all
solutions of a polynomial system. We describe our massive parallel
predictor-corrector algorithms to track many solution paths of a polynomial
homotopy. The data parallelism that provides the speedups stems from the
evaluation and differentiation of the monomials in the same polynomial system
at different data points, which are the points on the solution paths.
Polynomial homotopies that have tens of thousands of solution paths can keep a
sufficiently large amount of threads occupied. Our accelerated code combines
the reverse mode of algorithmic differentiation with double double and quad
double precision to compute more accurate results faster.
"
627,"Sparse Automatic Differentiation for Large-Scale Computations Using
  Abstract Elementary Algebra","  Most numerical solvers and libraries nowadays are implemented to use
mathematical models created with language-specific built-in data types (e.g.
real in Fortran or double in C) and their respective elementary algebra
implementations. However, built-in elementary algebra typically has limited
functionality and often restricts flexibility of mathematical models and
analysis types that can be applied to those models. To overcome this
limitation, a number of domain-specific languages with more feature-rich
built-in data types have been proposed. In this paper, we argue that if
numerical libraries and solvers are designed to use abstract elementary algebra
rather than language-specific built-in algebra, modern mainstream languages can
be as effective as any domain-specific language. We illustrate our ideas using
the example of sparse Jacobian matrix computation. We implement an automatic
differentiation method that takes advantage of sparse system structures and is
straightforward to parallelize in MPI setting. Furthermore, we show that the
computational cost scales linearly with the size of the system.
"
628,"Documentation Generator Focusing on Symbols for the HTML-ized Mizar
  Library","  The purpose of this project is to collect symbol information in the Mizar
Mathematical Library and manipulate it into practical and organized
documentation. Inspired by the MathWiki project and API reference systems for
computer programs, we developed a documentation generator focusing on symbols
for the HTML-ized Mizar library. The system has several helpful features,
including a symbol list, incremental search, and a referrer list. It targets
those who use proof assistance systems, the volume of whose libraries has been
rapidly increasing year by year.
"
629,"LeoPARD --- A Generic Platform for the Implementation of Higher-Order
  Reasoners","  LeoPARD supports the implementation of knowledge representation and reasoning
tools for higher-order logic(s). It combines a sophisticated data structure
layer (polymorphically typed {\lambda}-calculus with nameless spine notation,
explicit substitutions, and perfect term sharing) with an ambitious multi-agent
blackboard architecture (supporting prover parallelism at the term, clause, and
search level). Further features of LeoPARD include a parser for all TPTP
dialects, a command line interpreter, and generic means for the integration of
external reasoners.
"
630,Applying Sorting Networks to Synthesize Optimized Sorting Libraries,"  This paper shows an application of the theory of sorting networks to
facilitate the synthesis of optimized general purpose sorting libraries.
Standard sorting libraries are often based on combinations of the classic
Quicksort algorithm with insertion sort applied as the base case for small
fixed numbers of inputs. Unrolling the code for the base case by ignoring loop
conditions eliminates branching and results in code which is equivalent to a
sorting network. This enables the application of further program
transformations based on sorting network optimizations, and eventually the
synthesis of code from sorting networks. We show that if considering the number
of comparisons and swaps then theory predicts no real advantage of this
approach. However, significant speed-ups are obtained when taking advantage of
instruction level parallelism and non-branching conditional assignment
instructions, both of which are common in modern CPU architectures. We provide
empirical evidence that using code synthesized from efficient sorting networks
as the base case for Quicksort libraries results in significant real-world
speed-ups.
"
631,A parallel edge orientation algorithm for quadrilateral meshes,"  One approach to achieving correct finite element assembly is to ensure that
the local orientation of facets relative to each cell in the mesh is consistent
with the global orientation of that facet. Rognes et al. have shown how to
achieve this for any mesh composed of simplex elements, and deal.II contains a
serial algorithm to construct a consistent orientation of any quadrilateral
mesh of an orientable manifold.
  The core contribution of this paper is the extension of this algorithm for
distributed memory parallel computers, which facilitates its seamless
application as part of a parallel simulation system.
  Furthermore, our analysis establishes a link between the well-known
Union-Find algorithm and the construction of a consistent orientation of a
quadrilateral mesh. As a result, existing work on the parallelisation of the
Union-Find algorithm can be easily adapted to construct further parallel
algorithms for mesh orientations.
"
632,"Flexible, Scalable Mesh and Data Management using PETSc DMPlex","  Designing a scientific software stack to meet the needs of the
next-generation of mesh-based simulation demands, not only scalable and
efficient mesh and data management on a wide range of platforms, but also an
abstraction layer that makes it useful for a wide range of application codes.
Common utility tasks, such as file I/O, mesh distribution, and work
partitioning, should be delegated to external libraries in order to promote
code re-use, extensibility and software interoperability. In this paper we
demonstrate the use of PETSc's DMPlex data management API to perform mesh input
and domain partitioning in Fluidity, a large scale CFD application. We
demonstrate that raising the level of abstraction adds new functionality to the
application code, such as support for additional mesh file formats and mesh re-
ordering, while improving simulation startup cost through more efficient mesh
distribution. Moreover, the separation of concerns accomplished through this
interface shifts critical performance and interoperability issues, such as
scalable I/O and file format support, to a widely used and supported open
source community library, improving the sustainability, performance, and
functionality of Fluidity.
"
633,"Automatic and Transparent Transfer of Theorems along Isomorphisms in the
  Coq Proof Assistant","  In mathematics, it is common practice to have several constructions for the
same objects. Mathematicians will identify them modulo isomorphism and will not
worry later on which construction they use, as theorems proved for one
construction will be valid for all.
  When working with proof assistants, it is also common to see several
data-types representing the same objects. This work aims at making the use of
several isomorphic constructions as simple and as transparent as it can be done
informally in mathematics. This requires inferring automatically the missing
proof-steps.
  We are designing an algorithm which finds and fills these missing proof-steps
and we are implementing it as a plugin for Coq.
"
634,"Software for the Gale transform of fewnomial systems and a Descartes
  rule for fewnomials","  We give a Descartes'-like bound on the number of positive solutions to a
system of fewnomials that holds when its exponent vectors are not in convex
position and a sign condition is satisfied. This was discovered while
developing algorithms and software for computing the Gale transform of a
fewnomial system, which is our main goal. This software is a component of a
package we are developing for Khovanskii-Rolle continuation, which is a
numerical algorithm to compute the real solutions to a system of fewnomials.
"
635,MLlib: Machine Learning in Apache Spark,"  Apache Spark is a popular open-source platform for large-scale data
processing that is well-suited for iterative machine learning tasks. In this
paper we present MLlib, Spark's open-source distributed machine learning
library. MLlib provides efficient functionality for a wide range of learning
settings and includes several underlying statistical, optimization, and linear
algebra primitives. Shipped with Spark, MLlib supports several languages and
provides a high-level API that leverages Spark's rich ecosystem to simplify the
development of end-to-end machine learning pipelines. MLlib has experienced a
rapid growth due to its vibrant open-source community of over 140 contributors,
and includes extensive documentation to support further growth and to let users
quickly get up to speed.
"
636,"Remark on ""Algorithm 916: Computing the Faddeyeva and Voigt functions"":
  Efficiency Improvements and Fortran Translation","  This remark describes efficiency improvements to Algorithm 916 [Zaghloul and
Ali 2011]. It is shown that the execution time required by the algorithm, when
run at its highest accuracy, may be improved by more than a factor of two. A
better accuracy vs efficiency trade off scheme is also implemented; this
requires the user to supply the number of significant figures desired in the
computed values as an extra input argument to the function. Using this
trade-off, it is shown that the efficiency of the algorithm may be further
improved significantly while maintaining reasonably accurate and safe results
that are free of the pitfalls and complete loss of accuracy seen in other
competitive techniques. The current version of the code is provided in Matlab
and Scilab in addition to a Fortran translation prepared to meet the needs of
real-world problems where very large numbers of function evaluations would
require the use of a compiled language. To fulfill this last requirement, a
recently proposed reformed version of Humlicek's w4 routine, shown to maintain
the claimed accuracy of the algorithm over a wide and fine grid is implemented
in the present Fortran translation for the case of 4 significant figures. This
latter modification assures the reliability of the code to be employed in the
solution of practical problems requiring numerous evaluation of the function
for applications tolerating low accuracy computations (<10-4).
"
637,"A Practical Guide to Randomized Matrix Computations with MATLAB
  Implementations","  Matrix operations such as matrix inversion, eigenvalue decomposition,
singular value decomposition are ubiquitous in real-world applications.
Unfortunately, many of these matrix operations so time and memory expensive
that they are prohibitive when the scale of data is large. In real-world
applications, since the data themselves are noisy, machine-precision matrix
operations are not necessary at all, and one can sacrifice a reasonable amount
of accuracy for computational efficiency.
  In recent years, a bunch of randomized algorithms have been devised to make
matrix computations more scalable. Mahoney (2011) and Woodruff (2014) have
written excellent but very technical reviews of the randomized algorithms.
Differently, the focus of this manuscript is on intuition, algorithm
derivation, and implementation. This manuscript should be accessible to people
with knowledge in elementary matrix algebra but unfamiliar with randomized
matrix computations. The algorithms introduced in this manuscript are all
summarized in a user-friendly way, and they can be implemented in lines of
MATLAB code. The readers can easily follow the implementations even if they do
not understand the maths and algorithms.
"
638,"SYM-ILDL: Incomplete $LDL^{T}$ Factorization of Symmetric Indefinite and
  Skew-Symmetric Matrices","  SYM-ILDL is a numerical software package that computes incomplete $LDL^{T}$
(or `ILDL') factorizations of symmetric indefinite and real skew-symmetric
matrices. The core of the algorithm is a Crout variant of incomplete LU (ILU),
originally introduced and implemented for symmetric matrices by [Li and Saad,
Crout versions of ILU factorization with pivoting for sparse symmetric
matrices, Transactions on Numerical Analysis 20, pp. 75--85, 2005]. Our code is
economical in terms of storage and it deals with real skew-symmetric matrices
as well, in addition to symmetric ones. The package is written in C++ and it is
templated, open source, and includes a MATLAB interface. The code includes
built-in RCM and AMD reordering, two equilibration strategies, threshold
Bunch-Kaufman pivoting and rook pivoting, as well as a wrapper to MC64, a
popular matching based equilibration and reordering algorithm. We also include
two built-in iterative solvers: SQMR preconditioned with ILDL, or MINRES
preconditioned with a symmetric positive definite preconditioner based on the
ILDL factorization.
"
639,Research on the fast Fourier transform of image based on GPU,"  Study of general purpose computation by GPU (Graphics Processing Unit) can
improve the image processing capability of micro-computer system. This paper
studies the parallelism of the different stages of decimation in time radix 2
FFT algorithm, designs the butterfly and scramble kernels and implements 2D FFT
on GPU. The experiment result demonstrates the validity and advantage over
general CPU, especially in the condition of large input size. The approach can
also be generalized to other transforms alike.
"
640,"The Research and Optimization of Parallel Finite Element Algorithm based
  on MiniFE","  Finite element method (FEM) is one of the most important numerical methods in
modern engineering design and analysis. Since traditional serial FEM is
difficult to solve large FE problems efficiently and accurately,
high-performance parallel FEM has become one of the essential way to solve
practical engineering problems. Based on MiniFE program, which is released by
National Energy Research Scientific Computing Center(NERSC), this work analyzes
concrete steps, key computing pattern and parallel mechanism of parallel FEM.
According to experimental results, this work analyzes the proportion of
calculation amount of each module and concludes the main performance bottleneck
of the program. Based on that, we optimize the MiniFE program on a server
platform. The optimization focuses on the bottleneck of the program - SpMV
kernel, and uses an efficient storage format named BCRS. Moreover, an improving
plan of hybrid MPI+OpenMP programming is provided. Experimental results show
that the optimized program performs better in both SpMV kernel and
synchronization. It can increase the performance of the program, on average, by
8.31%. Keywords : finite element, parallel, MiniFE, SpMV, performance
optimization
"
641,"Efficient FFT mapping on GPU for radar processing application: modeling
  and implementation","  General-purpose multiprocessors (as, in our case, Intel IvyBridge and Intel
Haswell) increasingly add GPU computing power to the former multicore
architectures. When used for embedded applications (for us, Synthetic aperture
radar) with intensive signal processing requirements, they must constantly
compute convolution algorithms, such as the famous Fast Fourier Transform. Due
to its ""fractal"" nature (the typical butterfly shape, with larger FFTs defined
as combination of smaller ones with auxiliary data array transpose functions),
one can hope to compute analytically the size of the largest FFT that can be
performed locally on an elementary GPU compute block. Then, the full
application must be organized around this given building block size. Now, due
to phenomena involved in the data transfers between various memory levels
across CPUs and GPUs, the optimality of such a scheme is only loosely
predictable (as communications tend to overcome in time the complexity of
computations). Therefore a mix of (theoretical) analytic approach and
(practical) runtime validation is here needed. As we shall illustrate, this
occurs at both stage, first at the level of deciding on a given elementary FFT
block size, then at the full application level.
"
642,"decimalInfinite: All Decimals In Bits, No Loss, Same Order, Simple","  This paper introduces a binary encoding that supports arbitrarily large,
small and precise decimals. It completely preserves information and order. It
does not rely on any arbitrary use-case-based choice of calibration and is
readily implementable and usable, as is. Finally, it is also simple to explain
and understand.
"
643,"Solving Polynomial Systems in the Cloud with Polynomial Homotopy
  Continuation","  Polynomial systems occur in many fields of science and engineering.
Polynomial homotopy continuation methods apply symbolic-numeric algorithms to
solve polynomial systems. We describe the design and implementation of our web
interface and reflect on the application of polynomial homotopy continuation
methods to solve polynomial systems in the cloud. Via the graph isomorphism
problem we organize and classify the polynomial systems we solved. The
classification with the canonical form of a graph identifies newly submitted
systems with systems that have already been solved.
"
644,Lacunaryx: Computing bounded-degree factors of lacunary polynomials,"  In this paper, we report on an implementation in the free software Mathemagix
of lacunary factorization algorithms, distributed as a library called
Lacunaryx. These algorithms take as input a polynomial in sparse
representation, that is as a list of nonzero monomials, and an integer $d$, and
compute its irreducible degree-$\le d$ factors. The complexity of these
algorithms is polynomial in the sparse size of the input polynomial and $d$.
"
645,"Accurate computation of Galerkin double surface integrals in the 3-D
  boundary element method","  Many boundary element integral equation kernels are based on the Green's
functions of the Laplace and Helmholtz equations in three dimensions. These
include, for example, the Laplace, Helmholtz, elasticity, Stokes, and Maxwell's
equations. Integral equation formulations lead to more compact, but dense
linear systems. These dense systems are often solved iteratively via Krylov
subspace methods, which may be accelerated via the fast multipole method. There
are advantages to Galerkin formulations for such integral equations, as they
treat problems associated with kernel singularity, and lead to symmetric and
better conditioned matrices. However, the Galerkin method requires each entry
in the system matrix to be created via the computation of a double surface
integral over one or more pairs of triangles. There are a number of
semi-analytical methods to treat these integrals, which all have some issues,
and are discussed in this paper. We present novel methods to compute all the
integrals that arise in Galerkin formulations involving kernels based on the
Laplace and Helmholtz Green's functions to any specified accuracy. Integrals
involving completely geometrically separated triangles are non-singular and are
computed using a technique based on spherical harmonics and multipole
expansions and translations, which results in the integration of polynomial
functions over the triangles. Integrals involving cases where the triangles
have common vertices, edges, or are coincident are treated via scaling and
symmetry arguments, combined with automatic recursive geometric decomposition
of the integrals. Example results are presented, and the developed software is
available as open source.
"
646,FEAST Eigensolver for non-Hermitian Problems,"  A detailed new upgrade of the FEAST eigensolver targeting non-Hermitian
eigenvalue problems is presented and thoroughly discussed. It aims at
broadening the class of eigenproblems that can be addressed within the
framework of the FEAST algorithm. The algorithm is ideally suited for computing
selected interior eigenvalues and their associated right/left bi-orthogonal
eigenvectors,located within a subset of the complex plane. It combines subspace
iteration with efficient contour integration techniques that approximate the
left and right spectral projectors. We discuss the various algorithmic choices
that have been made to improve the stability and usability of the new
non-Hermitian eigensolver. The latter retains the convergence property and
multi-level parallelism of Hermitian FEAST, making it a valuable new software
tool for the scientific community.
"
647,"The Peano software - parallel, automaton-based, dynamically adaptive
  grid traversals","  We discuss the design decisions, design alternatives and rationale behind the
third generation of Peano, a framework for dynamically adaptive Cartesian
meshes derived from spacetrees. Peano ties the mesh traversal to the mesh
storage and supports only one element-wise traversal order resulting from
space-filling curves. The user is not free to choose a traversal order herself.
The traversal can exploit regular grid subregions and shared memory as well as
distributed memory systems with almost no modifications to a serial application
code. We formalize the software design by means of two interacting
automata---one automaton for the multiscale grid traversal and one for the
application-specific algorithmic steps. This yields a callback-based
programming paradigm. We further sketch the supported application types and the
two data storage schemes realized, before we detail high-performance computing
aspects and lessons learned. Special emphasis is put on observations regarding
the used programming idioms and algorithmic concepts. This transforms our
report from a ""one way to implement things"" code description into a generic
discussion and summary of some alternatives, rationale and design decisions to
be made for any tree-based adaptive mesh refinement software.
"
648,"Encog: Library of Interchangeable Machine Learning Models for Java and
  C#","  This paper introduces the Encog library for Java and C#, a scalable,
adaptable, multiplatform machine learning framework that was 1st released in
2008. Encog allows a variety of machine learning models to be applied to
datasets using regression, classification, and clustering. Various supported
machine learning models can be used interchangeably with minimal recoding.
Encog uses efficient multithreaded code to reduce training time by exploiting
modern multicore processors. The current version of Encog can be downloaded
from http://www.encog.org.
"
649,A fast exact simulation method for a class of Markov jump processes,"  A new method of the stochastic simulation algorithm (SSA), named the
Hashing-Leaping method (HLM), for exact simulations of a class of Markov jump
processes, is presented in this paper. The HLM has a conditional constant
computational cost per event, which is independent of the number of exponential
clocks in the Markov process. The main idea of the HLM is to repeatedly
implement a hash-table-like bucket sort algorithm for all times of occurrence
covered by a time step with length $\tau$. This paper serves as an introduction
to this new SSA method. We introduce the method, demonstrate its
implementation, analyze its properties, and compare its performance with three
other commonly used SSA methods in four examples. Our performance tests and CPU
operation statistics show certain advantage of the HLM for large scale
problems.
"
650,"Asynchronous processing of Coq documents: from the kernel up to the user
  interface","  The work described in this paper improves the reactivity of the Coq system by
completely redesigning the way it processes a formal document. By subdividing
such work into independent tasks the system can give precedence to the ones of
immediate interest for the user and postpones the others. On the user side, a
modern interface based on the PIDE middleware aggregates and present in a
consistent way the output of the prover. Finally postponed tasks are processed
exploiting modern, parallel, hardware to offer better scalability.
"
651,"GRINS: A Multiphysics Framework Based on the libMesh Finite Element
  Library","  The progression of scientific computing resources has enabled the numerical
approximation of mathematical models describing complex physical phenomena. A
significant portion of researcher time is typically dedicated to the
development of software to compute the numerical solutions. This work describes
a flexible C++ software framework, built on the libMesh finite element library,
designed to alleviate developer burden and provide easy access to modern
computational algorithms, including quantity-of-interest-driven parallel
adaptive mesh refinement on unstructured grids and adjoint-based sensitivities.
Other software environments are highlighted and the current work motivated; in
particular, the present work is an attempt to balance software infrastructure
and user flexibility. The applicable class of problems and design of the
software components is discussed in detail. Several examples demonstrate the
effectiveness of the design, including applications that incorporate
uncertainty. Current and planned developments are discussed.
"
652,Resilience for Multigrid Software at the Extreme Scale,"  Fault tolerant algorithms for the numerical approximation of elliptic partial
differential equations on modern supercomputers play a more and more important
role in the future design of exa-scale enabled iterative solvers. Here, we
combine domain partitioning with highly scalable geometric multigrid schemes to
obtain fast and fault-robust solvers in three dimensions. The recovery strategy
is based on a hierarchical hybrid concept where the values on lower dimensional
primitives such as faces are stored redundantly and thus can be recovered
easily in case of a failure. The lost volume unknowns in the faulty region are
re-computed approximately with multigrid cycles by solving a local Dirichlet
problem on the faulty subdomain. Different strategies are compared and
evaluated with respect to performance, computational cost, and speed up.
Especially effective are strategies in which the local recovery in the faulty
region is executed in parallel with global solves and when the local recovery
is additionally accelerated. This results in an asynchronous multigrid
iteration that can fully compensate faults. Excellent parallel performance on a
current peta-scale system is demonstrated.
"
653,Unstructured Overlapping Mesh Distribution in Parallel,"  We present a simple mathematical framework and API for parallel mesh and data
distribution, load balancing, and overlap generation. It relies on viewing the
mesh as a Hasse diagram, abstracting away information such as cell shape,
dimension, and coordinates. The high level of abstraction makes our interface
both concise and powerful, as the same algorithm applies to any representable
mesh, such as hybrid meshes, meshes embedded in higher dimension, and
overlapped meshes in parallel. We present evidence, both theoretical and
experimental, that the algorithms are scalable and efficient. A working
implementation can be found in the latest release of the PETSc libraries.
"
654,Software realization of the complex spectra analysis algorithm in R,"  Software realization of the complex spectra decomposition on unknown number
of similarcomponents is proposed.The algorithm is based on non-linear
minimizing the sum of squared residuals of the spectrum model. For the adequacy
checking the complex of criteria is used.It tests the model residuals
correspondence with the normal distribution, equality to zero of their mean
value and autocorrelation. Also the closeness of residuals and experimental
data variances is checked.
"
655,GraphMaps: Browsing Large Graphs as Interactive Maps,"  Algorithms for laying out large graphs have seen significant progress in the
past decade. However, browsing large graphs remains a challenge. Rendering
thousands of graphical elements at once often results in a cluttered image, and
navigating these elements naively can cause disorientation. To address this
challenge we propose a method called GraphMaps, mimicking the browsing
experience of online geographic maps.
  GraphMaps creates a sequence of layers, where each layer refines the previous
one. During graph browsing, GraphMaps chooses the layer corresponding to the
zoom level, and renders only those entities of the layer that intersect the
current viewport. The result is that, regardless of the graph size, the number
of entities rendered at each view does not exceed a predefined threshold, yet
all graph elements can be explored by the standard zoom and pan operations.
  GraphMaps preprocesses a graph in such a way that during browsing, the
geometry of the entities is stable, and the viewer is responsive. Our case
studies indicate that GraphMaps is useful in gaining an overview of a large
graph, and also in exploring a graph on a finer level of detail.
"
656,pyMOR - Generic Algorithms and Interfaces for Model Order Reduction,"  Reduced basis methods are projection-based model order reduction techniques
for reducing the computational complexity of solving parametrized partial
differential equation problems. In this work we discuss the design of pyMOR, a
freely available software library of model order reduction algorithms, in
particular reduced basis methods, implemented with the Python programming
language. As its main design feature, all reduction algorithms in pyMOR are
implemented generically via operations on well-defined vector array, operator
and discretization interface classes. This allows for an easy integration with
existing open-source high-performance partial differential equation solvers
without adding any model reduction specific code to these solvers. Besides an
in-depth discussion of pyMOR's design philosophy and architecture, we present
several benchmark results and numerical examples showing the feasibility of our
approach.
"
657,Efficient mesh management in Firedrake using PETSc-DMPlex,"  The use of composable abstractions allows the application of new and
established algorithms to a wide range of problems while automatically
inheriting the benefits of well-known performance optimisations. This work
highlights the composition of the PETSc DMPlex domain topology abstraction with
the Firedrake automated finite element system to create a PDE solving
environment that combines expressiveness, flexibility and high performance. We
describe how Firedrake utilises DMPlex to provide the indirection maps required
for finite element assembly, while supporting various mesh input formats and
runtime domain decomposition. In particular, we describe how DMPlex and its
accompanying data structures allow the generic creation of user-defined
discretisations, while utilising data layout optimisations that improve cache
coherency and ensure overlapped communication during assembly computation.
"
658,"A Java Implementation of the SGA, UMDA, ECGA, and HBOA","  The Simple Genetic Algorithm, the Univariate Marginal Distribution Algorithm,
the Extended Compact Genetic Algorithm, and the Hierarchical Bayesian
Optimization Algorithm are all well known Evolutionary Algorithms.
  In this report we present a Java implementation of these four algorithms with
detailed instructions on how to use each of them to solve a given set of
optimization problems. Additionally, it is explained how to implement and
integrate new problems within the provided set. The source and binary files of
the Java implementations are available for free download at
https://github.com/JoseCPereira/2015EvolutionaryAlgorithmsJava.
"
659,"Trigger detection for adaptive scientific workflows using percentile
  sampling","  Increasing complexity of scientific simulations and HPC architectures are
driving the need for adaptive workflows, where the composition and execution of
computational and data manipulation steps dynamically depend on the
evolutionary state of the simulation itself. Consider for example, the
frequency of data storage. Critical phases of the simulation should be captured
with high frequency and with high fidelity for post-analysis, however we cannot
afford to retain the same frequency for the full simulation due to the high
cost of data movement. We can instead look for triggers, indicators that the
simulation will be entering a critical phase and adapt the workflow
accordingly.
  We present a method for detecting triggers and demonstrate its use in direct
numerical simulations of turbulent combustion using S3D. We show that chemical
explosive mode analysis (CEMA) can be used to devise a noise-tolerant indicator
for rapid increase in heat release. However, exhaustive computation of CEMA
values dominates the total simulation, thus is prohibitively expensive. To
overcome this bottleneck, we propose a quantile-sampling approach. Our
algorithm comes with provable error/confidence bounds, as a function of the
number of samples. Most importantly, the number of samples is independent of
the problem size, thus our proposed algorithm offers perfect scalability. Our
experiments on homogeneous charge compression ignition (HCCI) and reactivity
controlled compression ignition (RCCI) simulations show that the proposed
method can detect rapid increases in heat release, and its computational
overhead is negligible. Our results will be used for dynamic workflow decisions
about data storage and mesh resolution in future combustion simulations.
Proposed framework is generalizable and we detail how it could be applied to a
broad class of scientific simulation workflows.
"
660,A Java Implementation of Parameter-less Evolutionary Algorithms,"  The Parameter-less Genetic Algorithm was first presented by Harik and Lobo in
1999 as an alternative to the usual trial-and-error method of finding, for each
given problem, an acceptable set-up of the parameter values of the genetic
algorithm. Since then, the same strategy has been successfully applied to
create parameter-less versions of other population-based search algorithms such
as the Extended Compact Genetic Algorithm and the Hierarchical Bayesian
Optimization Algorithm. This report describes a Java implementation,
Parameter-less Evolutionary Algorithm (P-EAJava), that integrates several
parameter-less evolutionary algorithms into a single platform. Along with a
brief description of P-EAJava, we also provide detailed instructions on how to
use it, how to implement new problems, and how to generate new parameter-less
versions of evolutionary algorithms.
  At present time, P-EAJava already includes parameter-less versions of the
Simple Genetic Algorithm, the Extended Compact Genetic Algorithm, the
Univariate Marginal Distribution Algorithm, and the Hierarchical Bayesian
Optimization Algorithm. The source and binary files of the Java implementation
of P-EAJava are available for free download at
https://github.com/JoseCPereira/2015ParameterlessEvolutionaryAlgorithmsJava.
"
661,Java Implementation of a Parameter-less Evolutionary Portfolio,"  The Java implementation of a portfolio of parameter-less evolutionary
algorithms is presented. The Parameter-less Evolutionary Portfolio implements a
heuristic that performs adaptive selection of parameter-less evolutionary
algorithms in accordance with performance criteria that are measured during
running time. At present time, the portfolio includes three parameter-less
evolutionary algorithms: Parameter-less Univariate Marginal Distribution
Algorithm, Parameter-less Extended Compact Genetic Algorithm, and
Parameter-less Hierarchical Bayesian Optimization Algorithm. Initial
experiments showed that the parameter-less portfolio can solve various classes
of problems without the need for any prior parameter setting technique and with
an increase in computational effort that can be considered acceptable.
"
662,"Architecture-Aware Configuration and Scheduling of Matrix Multiplication
  on Asymmetric Multicore Processors","  Asymmetric multicore processors (AMPs) have recently emerged as an appealing
technology for severely energy-constrained environments, especially in mobile
appliances where heterogeneity in applications is mainstream. In addition,
given the growing interest for low-power high performance computing, this type
of architectures is also being investigated as a means to improve the
throughput-per-Watt of complex scientific applications.
  In this paper, we design and embed several architecture-aware optimizations
into a multi-threaded general matrix multiplication (gemm), a key operation of
the BLAS, in order to obtain a high performance implementation for ARM
big.LITTLE AMPs. Our solution is based on the reference implementation of gemm
in the BLIS library, and integrates a cache-aware configuration as well as
asymmetric--static and dynamic scheduling strategies that carefully tune and
distribute the operation's micro-kernels among the big and LITTLE cores of the
target processor. The experimental results on a Samsung Exynos 5422, a
system-on-chip with ARM Cortex-A15 and Cortex-A7 clusters that implements the
big.LITTLE model, expose that our cache-aware versions of gemm with asymmetric
scheduling attain important gains in performance with respect to its
architecture-oblivious counterparts while exploiting all the resources of the
AMP to deliver considerable energy efficiency.
"
663,"Graphulo Implementation of Server-Side Sparse Matrix Multiply in the
  Accumulo Database","  The Apache Accumulo database excels at distributed storage and indexing and
is ideally suited for storing graph data. Many big data analytics compute on
graph data and persist their results back to the database. These graph
calculations are often best performed inside the database server. The GraphBLAS
standard provides a compact and efficient basis for a wide range of graph
applications through a small number of sparse matrix operations. In this
article, we implement GraphBLAS sparse matrix multiplication server-side by
leveraging Accumulo's native, high-performance iterators. We compare the
mathematics and performance of inner and outer product implementations, and
show how an outer product implementation achieves optimal performance near
Accumulo's peak write rate. We offer our work as a core component to the
Graphulo library that will deliver matrix math primitives for graph analytics
within Accumulo.
"
664,"MADNESS: A Multiresolution, Adaptive Numerical Environment for
  Scientific Simulation","  MADNESS (multiresolution adaptive numerical environment for scientific
simulation) is a high-level software environment for solving integral and
differential equations in many dimensions that uses adaptive and fast harmonic
analysis methods with guaranteed precision based on multiresolution analysis
and separated representations. Underpinning the numerical capabilities is a
powerful petascale parallel programming environment that aims to increase both
programmer productivity and code scalability. This paper describes the features
and capabilities of MADNESS and briefly discusses some current applications in
chemistry and several areas of physics.
"
665,"GenASiS Basics: Object-oriented utilitarian functionality for
  large-scale physics simulations (Version 3)","  GenASiS Basics provides Fortran 2003 classes furnishing extensible
object-oriented utilitarian functionality for large-scale physics simulations
on distributed memory supercomputers. This functionality includes physical
units and constants; display to the screen or standard output device; message
passing; I/O to disk; and runtime parameter management and usage statistics.
This revision---Version 3 of Basics---includes a significant name change, some
minor additions to functionality, and a major addition to functionality:
infrastructure facilitating the offloading of computational kernels to devices
such as GPUs.
"
666,"GHOST: Building blocks for high performance sparse linear algebra on
  heterogeneous systems","  While many of the architectural details of future exascale-class high
performance computer systems are still a matter of intense research, there
appears to be a general consensus that they will be strongly heterogeneous,
featuring ""standard"" as well as ""accelerated"" resources. Today, such resources
are available as multicore processors, graphics processing units (GPUs), and
other accelerators such as the Intel Xeon Phi. Any software infrastructure that
claims usefulness for such environments must be able to meet their inherent
challenges: massive multi-level parallelism, topology, asynchronicity, and
abstraction. The ""General, Hybrid, and Optimized Sparse Toolkit"" (GHOST) is a
collection of building blocks that targets algorithms dealing with sparse
matrix representations on current and future large-scale systems. It implements
the ""MPI+X"" paradigm, has a pure C interface, and provides hybrid-parallel
numerical kernels, intelligent resource management, and truly heterogeneous
parallelism for multicore CPUs, Nvidia GPUs, and the Intel Xeon Phi. We
describe the details of its design with respect to the challenges posed by
modern heterogeneous supercomputers and recent algorithmic developments.
Implementation details which are indispensable for achieving high efficiency
are pointed out and their necessity is justified by performance measurements or
predictions based on performance models. The library code and several
applications are available as open source. We also provide instructions on how
to make use of GHOST in existing software packages, together with a case study
which demonstrates the applicability and performance of GHOST as a component
within a larger software stack.
"
667,Accelerating R with high performance linear algebra libraries,"  Linear algebra routines are basic building blocks for the statistical
software. In this paper we analyzed how can we can improve R performance for
matrix computations. We benchmarked few matrix operations using the standard
linear algebra libraries included in the R distribution and high performance
libraries like OpenBLAS, GotoBLAS and MKL. Our tests showed the the best
results are obtained with the MKL library, the other two libraries having
similar performances, but lower than MKL
"
668,JuMP: A Modeling Language for Mathematical Optimization,"  JuMP is an open-source modeling language that allows users to express a wide
range of optimization problems (linear, mixed-integer, quadratic,
conic-quadratic, semidefinite, and nonlinear) in a high-level, algebraic
syntax. JuMP takes advantage of advanced features of the Julia programming
language to offer unique functionality while achieving performance on par with
commercial modeling tools for standard tasks. In this work we will provide
benchmarks, present the novel aspects of the implementation, and discuss how
JuMP can be extended to new problem classes and composed with state-of-the-art
tools for visualization and interactivity.
"
669,Using the VBARMS method in parallel computing,"  The paper describes an improved parallel MPI-based implementation of VBARMS,
a variable block variant of the pARMS preconditioner proposed by Li,~Saad and
Sosonkina [NLAA, 2003] for solving general nonsymmetric linear systems. The
parallel VBARMS solver can detect automatically exact or approximate dense
structures in the linear system, and exploits this information to achieve
improved reliability and increased throughput during the factorization. A novel
graph compression algorithm is discussed that finds these approximate dense
blocks structures and requires only one simple to use parameter. A complete
study of the numerical and parallel performance of parallel VBARMS is presented
for the analysis of large turbulent Navier-Stokes equations on a suite of
three-dimensional test cases.
"
670,Support for Non-conformal Meshes in PETSc's DMPlex Interface,"  PETSc's DMPlex interface for unstructured meshes has been extended to support
non-conformal meshes. The topological construct that DMPlex implements---the
CW-complex---is by definition conformal, so representing non- conformal meshes
in a way that hides complexity requires careful attention to the interface
between DMPlex and numerical methods such as the finite element method. Our
approach---which combines a tree structure for subset- superset relationships
and a ""reference tree"" describing the types of non-conformal
interfaces---allows finite element code written for conformal meshes to extend
automatically: in particular, all ""hanging-node"" constraint calculations are
handled behind the scenes. We give example code demonstrating the use of this
extension, and use it to convert forests of quadtrees and forests of octrees
from the p4est library to DMPlex meshes.
"
671,"Computing accurate Horner form approximations to special functions in
  finite precision arithmetic","  In various applications, computers are required to compute approximations to
univariate elementary and special functions such as $\exp$ and $\arctan$ to
modest accuracy. This paper proposes a new heuristic for automating the design
of such implementations. This heuristic takes a certain restricted
specification of program structure and the desired error properties as input
and takes explicit account of roundoff error during evaluation.
"
672,"Complex additive geometric multilevel solvers for Helmholtz equations on
  spacetrees","  We introduce a family of implementations of low order, additive, geometric
multilevel solvers for systems of Helmholtz equations. Both grid spacing and
arithmetics may comprise complex numbers and we thus can apply complex scaling
techniques to the indefinite Helmholtz operator. Our implementations are based
upon the notion of a spacetree and work exclusively with a finite number of
precomputed local element matrices. They are globally matrix-free.
  Combining various relaxation factors with two grid transfer operators allows
us to switch from pure additive multigrid over a hierarchical basis method into
BPX with several multiscale smoothing variants within one code base. Pipelining
allows us to realise a full approximation storage (FAS) scheme within the
additive environment where, amortised, each grid vertex carrying degrees of
freedom is read/written only once per iteration. The codes thus realise a
single-touch policy. Among the features facilitated by matrix-free FAS is
arbitrary dynamic mesh refinement (AMR) for all solver variants. AMR as enabler
for full multigrid (FMG) cycling---the grid unfolds throughout the
computation---allows us to reduce the cost per unknown per order of accuracy.
  The present paper primary contributes towards software realisation and design
questions. Our experiments show that the consolidation of single-touch FAS,
dynamic AMR and vectorisation-friendly, complex scaled, matrix-free FMG cycles
delivers a mature implementation blueprint for solvers for a non-trivial class
of problems such as Helmholtz equations. Besides this validation, we put
particular emphasis on a strict implementation formalism as well as some
implementation correctness proofs.
"
673,"Marathon: An open source software library for the analysis of
  Markov-Chain Monte Carlo algorithms","  In this paper, we consider the Markov-Chain Monte Carlo (MCMC) approach for
random sampling of combinatorial objects. The running time of such an algorithm
depends on the total mixing time of the underlying Markov chain and is unknown
in general. For some Markov chains, upper bounds on this total mixing time
exist but are too large to be applicable in practice. We try to answer the
question, whether the total mixing time is close to its upper bounds, or if
there is a significant gap between them. In doing so, we present the software
library marathon which is designed to support the analysis of MCMC based
sampling algorithms. The main application of this library is to compute
properties of so-called state graphs which represent the structure of Markov
chains. We use marathon to investigate the quality of several bounding methods
on four well-known Markov chains for sampling perfect matchings and bipartite
graph realizations. In a set of experiments, we compute the total mixing time
and several of its bounds for a large number of input instances. We find that
the upper bound gained by the famous canonical path method is several
magnitudes larger than the total mixing time and deteriorates with growing
input size. In contrast, the spectral bound is found to be a precise
approximation of the total mixing time.
"
674,"POLYANA - A tool for the calculation of molecular radial distribution
  functions based on Molecular Dynamics trajectories","  We present an application for the calculation of radial distribution
functions for molecular centres of mass, based on trajectories generated by
molecular simulation methods (Molecular Dynamics, Monte Carlo). When designing
this application, the emphasis was placed on ease of use as well as ease of
further development. In its current version, the program can read trajectories
generated by the well-known DL_POLY package, but it can be easily extended to
treat other formats. It is also very easy to 'hack' the program so it can
compute intermolecular radial distribution functions for groups of interaction
sites rather than whole molecules.
"
675,Non-Metric Space Library Manual,"  This document covers a library for fast similarity (k-NN)search. It describes
only search methods and distances (spaces). Details about building, installing,
Python bindings can be found
online:https://github.com/searchivarius/nmslib/tree/v1.8/. Even though the
library contains a variety of exact metric-space access methods, our main focus
is on more generic and approximate search methods, in particular, on methods
for non-metric spaces. NMSLIB is possibly the first library with a principled
support for non-metric space searching.
"
676,Clone and graft: Testing scientific applications as they are built,"  This article describes our experience developing and maintaining automated
tests for scientific applications. The main idea evolves around building on
already existing tests by cloning and grafting. The idea is demonstrated on a
minimal model problem written in Python.
"
677,Approximating the Sum of Correlated Lognormals: An Implementation,"  Lognormal random variables appear naturally in many engineering disciplines,
including wireless communications, reliability theory, and finance. So, too,
does the sum of (correlated) lognormal random variables. Unfortunately, no
closed form probability distribution exists for such a sum, and it requires
approximation. Some approximation methods date back over 80 years and most take
one of two approaches, either: 1) an approximate probability distribution is
derived mathematically, or 2) the sum is approximated by a single lognormal
random variable. In this research, we take the latter approach and review a
fairly recent approximation procedure proposed by Mehta, Wu, Molisch, and Zhang
(2007), then implement it using C++. The result is applied to a discrete time
model commonly encountered within the field of financial economics.
"
678,Strong Pseudoprimes to Twelve Prime Bases,"  Let $\psi_m$ be the smallest strong pseudoprime to the first $m$ prime bases.
This value is known for $1 \leq m \leq 11$. We extend this by finding
$\psi_{12}$ and $\psi_{13}$. We also present an algorithm to find all integers
$n\le B$ that are strong pseudoprimes to the first $m$ prime bases; with a
reasonable heuristic assumption we can show that it takes at most
$B^{2/3+o(1)}$ time.
"
679,"Verificarlo: checking floating point accuracy through Monte Carlo
  Arithmetic","  Numerical accuracy of floating point computation is a well studied topic
which has not made its way to the end-user in scientific computing. Yet, it has
become a critical issue with the recent requirements for code modernization to
harness new highly parallel hardware and perform higher resolution computation.
To democratize numerical accuracy analysis, it is important to propose tools
and methodologies to study large use cases in a reliable and automatic way. In
this paper, we propose verificarlo, an extension to the LLVM compiler to
automatically use Monte Carlo Arithmetic in a transparent way for the end-user.
It supports all the major languages including C, C++, and Fortran. Unlike
source-to-source approaches, our implementation captures the influence of
compiler optimizations on the numerical accuracy. We illustrate how Monte Carlo
Arithmetic using the verificarlo tool outperforms the existing approaches on
various use cases and is a step toward automatic numerical analysis.
"
680,Rust-Bio - a fast and safe bioinformatics library,"  We present Rust-Bio, the first general purpose bioinformatics library for the
innovative Rust programming language. Rust-Bio leverages the unique combination
of speed, memory safety and high-level syntax offered by Rust to provide a fast
and safe set of bioinformatics algorithms and data structures with a focus on
sequence analysis.
"
681,"Fundamental concepts in the Cyclus nuclear fuel cycle simulation
  framework","  As nuclear power expands, technical, economic, political, and environmental
analyses of nuclear fuel cycles by simulators increase in importance. To date,
however, current tools are often fleet-based rather than discrete and
restrictively licensed rather than open source. Each of these choices presents
a challenge to modeling fidelity, generality, efficiency, robustness, and
scientific transparency. The Cyclus nuclear fuel cycle simulator framework and
its modeling ecosystem incorporate modern insights from simulation science and
software architecture to solve these problems so that challenges in nuclear
fuel cycle analysis can be better addressed. A summary of the Cyclus fuel cycle
simulator framework and its modeling ecosystem are presented. Additionally, the
implementation of each is discussed in the context of motivating challenges in
nuclear fuel cycle simulation. Finally, the current capabilities of Cyclus are
demonstrated for both open and closed fuel cycles.
"
682,"A deterministic global optimization using smooth diagonal auxiliary
  functions","  In many practical decision-making problems it happens that functions involved
in optimization process are black-box with unknown analytical representations
and hard to evaluate. In this paper, a global optimization problem is
considered where both the goal function~$f(x)$ and its gradient $f'(x)$ are
black-box functions. It is supposed that $f'(x)$ satisfies the Lipschitz
condition over the search hyperinterval with an unknown Lipschitz constant~$K$.
A new deterministic `Divide-the-Best' algorithm based on efficient diagonal
partitions and smooth auxiliary functions is proposed in its basic version, its
convergence conditions are studied and numerical experiments executed on eight
hundred test functions are presented.
"
683,A tetrahedral space-filling curve for non-conforming adaptive meshes,"  We introduce a space-filling curve for triangular and tetrahedral
red-refinement that can be computed using bitwise interleaving operations
similar to the well-known Z-order or Morton curve for cubical meshes. To store
sufficient information for random access, we define a low-memory encoding using
10 bytes per triangle and 14 bytes per tetrahedron. We present algorithms that
compute the parent, children, and face-neighbors of a mesh element in constant
time, as well as the next and previous element in the space-filling curve and
whether a given element is on the boundary of the root simplex or not. Our
presentation concludes with a scalability demonstration that creates and adapts
selected meshes on a large distributed-memory system.
"
684,Scalable Metropolis Monte Carlo for simulation of hard shapes,"  We design and implement HPMC, a scalable hard particle Monte Carlo simulation
toolkit, and release it open source as part of HOOMD-blue. HPMC runs in
parallel on many CPUs and many GPUs using domain decomposition. We employ BVH
trees instead of cell lists on the CPU for fast performance, especially with
large particle size disparity, and optimize inner loops with SIMD vector
intrinsics on the CPU. Our GPU kernel proposes many trial moves in parallel on
a checkerboard and uses a block-level queue to redistribute work among threads
and avoid divergence. HPMC supports a wide variety of shape classes, including
spheres / disks, unions of spheres, convex polygons, convex spheropolygons,
concave polygons, ellipsoids / ellipses, convex polyhedra, convex
spheropolyhedra, spheres cut by planes, and concave polyhedra. NVT and NPT
ensembles can be run in 2D or 3D triclinic boxes. Additional integration
schemes permit Frenkel-Ladd free energy computations and implicit depletant
simulations. In a benchmark system of a fluid of 4096 pentagons, HPMC performs
10 million sweeps in 10 minutes on 96 CPU cores on XSEDE Comet. The same
simulation would take 7.6 hours in serial. HPMC also scales to large system
sizes, and the same benchmark with 16.8 million particles runs in 1.4 hours on
2048 GPUs on OLCF Titan.
"
685,"Direct high-order edge-preserving regularization for tomographic image
  reconstruction","  In this paper we present a new two-level iterative algorithm for tomographic
image reconstruction. The algorithm uses a regularization technique, which we
call edge-preserving Laplacian, that preserves sharp edges between objects
while damping spurious oscillations in the areas where the reconstructed image
is smooth. Our numerical simulations demonstrate that the proposed method
outperforms total variation (TV) regularization and it is competitive with the
combined TV-L2 penalty. Obtained reconstructed images show increased
signal-to-noise ratio and visually appealing structural features. Computer
implementation and parameter control of the proposed technique is
straightforward, which increases the feasibility of it across many tomographic
applications. In this paper, we applied our method to the under-sampled
computed tomography (CT) projection data and also considered a case of
reconstruction in emission tomography The MATLAB code is provided to support
obtained results.
"
686,SnapVX: A Network-Based Convex Optimization Solver,"  SnapVX is a high-performance Python solver for convex optimization problems
defined on networks. For these problems, it provides a fast and scalable
solution with guaranteed global convergence. SnapVX combines the capabilities
of two open source software packages: Snap.py and CVXPY. Snap.py is a large
scale graph processing library, and CVXPY provides a general modeling framework
for small-scale subproblems. SnapVX offers a customizable yet easy-to-use
interface with out-of-the-box functionality. Based on the Alternating Direction
Method of Multipliers (ADMM), it is able to efficiently store, analyze, and
solve large optimization problems from a variety of different applications.
Documentation, examples, and more can be found on the SnapVX website at
http://snap.stanford.edu/snapvx.
"
687,Shared Memory Pipelined Parareal,"  For the parallel-in-time integration method Parareal, pipelining can be used
to hide some of the cost of the serial correction step and improve its
efficiency. The paper introduces a basic OpenMP implementation of pipelined
Parareal and compares it to a standard MPI-based variant. Both versions yield
almost identical runtimes, but, depending on the compiler, the OpenMP variant
consumes about 7% less energy and has a significantly smaller memory footprint.
However, its higher implementation complexity might make it difficult to use in
legacy codes and in combination with spatial parallelisation.
"
688,The Stan Math Library: Reverse-Mode Automatic Differentiation in C++,"  As computational challenges in optimization and statistical inference grow
ever harder, algorithms that utilize derivatives are becoming increasingly more
important. The implementation of the derivatives that make these algorithms so
powerful, however, is a substantial user burden and the practicality of these
algorithms depends critically on tools like automatic differentiation that
remove the implementation burden entirely. The Stan Math Library is a C++,
reverse-mode automatic differentiation library designed to be usable, extensive
and extensible, efficient, scalable, stable, portable, and redistributable in
order to facilitate the construction and utilization of such algorithms.
  Usability is achieved through a simple direct interface and a cleanly
abstracted functional interface. The extensive built-in library includes
functions for matrix operations, linear algebra, differential equation solving,
and most common probability functions. Extensibility derives from a
straightforward object-oriented framework for expressions, allowing users to
easily create custom functions. Efficiency is achieved through a combination of
custom memory management, subexpression caching, traits-based metaprogramming,
and expression templates. Partial derivatives for compound functions are
evaluated lazily for improved scalability. Stability is achieved by taking care
with arithmetic precision in algebraic expressions and providing stable,
compound functions where possible. For portability, the library is
standards-compliant C++ (03) and has been tested for all major compilers for
Windows, Mac OS X, and Linux.
"
689,"A dedicated greedy pursuit algorithm for sparse spectral representation
  of music sound","  A dedicated algorithm for sparse spectral representation of music sound is
presented. The goal is to enable the representation of a piece of music signal,
as a linear superposition of as few spectral components as possible. A
representation of this nature is said to be sparse. In the present context
sparsity is accomplished by greedy selection of the spectral components, from
an overcomplete set called a dictionary. The proposed algorithm is tailored to
be applied with trigonometric dictionaries. Its distinctive feature being that
it avoids the need for the actual construction of the whole dictionary, by
implementing the required operations via the Fast Fourier Transform. The
achieved sparsity is theoretically equivalent to that rendered by the
Orthogonal Matching Pursuit method. The contribution of the proposed dedicated
implementation is to extend the applicability of the standard Orthogonal
Matching Pursuit algorithm, by reducing its storage and computational demands.
The suitability of the approach for producing sparse spectral models is
illustrated by comparison with the traditional method, in the line of the Short
Time Fourier Transform, involving only the corresponding orthonormal
trigonometric basis.
"
690,"Analysis of A Splitting Approach for the Parallel Solution of Linear
  Systems on GPU Cards","  We discuss an approach for solving sparse or dense banded linear systems
${\bf A} {\bf x} = {\bf b}$ on a Graphics Processing Unit (GPU) card. The
matrix ${\bf A} \in {\mathbb{R}}^{N \times N}$ is possibly nonsymmetric and
moderately large; i.e., $10000 \leq N \leq 500000$. The ${\it split\ and\
parallelize}$ (${\tt SaP}$) approach seeks to partition the matrix ${\bf A}$
into diagonal sub-blocks ${\bf A}_i$, $i=1,\ldots,P$, which are independently
factored in parallel. The solution may choose to consider or to ignore the
matrices that couple the diagonal sub-blocks ${\bf A}_i$. This approach, along
with the Krylov subspace-based iterative method that it preconditions, are
implemented in a solver called ${\tt SaP::GPU}$, which is compared in terms of
efficiency with three commonly used sparse direct solvers: ${\tt PARDISO}$,
${\tt SuperLU}$, and ${\tt MUMPS}$. ${\tt SaP::GPU}$, which runs entirely on
the GPU except several stages involved in preliminary row-column permutations,
is robust and compares well in terms of efficiency with the aforementioned
direct solvers. In a comparison against Intel's ${\tt MKL}$, ${\tt SaP::GPU}$
also fares well when used to solve dense banded systems that are close to being
diagonally dominant. ${\tt SaP::GPU}$ is publicly available and distributed as
open source under a permissive BSD3 license.
"
691,"On The Evolution Of User Support Topics in Computational Science and
  Engineering Software","  We investigate ten years of user support emails in the large-scale solver
library PETSc in order to identify changes in user requests. For this purpose
we assign each email thread to one or several categories describing the type of
support request. We find that despite several changes in hardware architecture
as well programming models, the relative share of emails for the individual
categories does not show a notable change over time. This is particularly
remarkable as the total communication volume has increased four-fold in the
considered time frame, indicating a considerable growth of the user base. Our
data also demonstrates that user support cannot be substituted with what is
often referred to as 'better documentation' and that the involvement of core
developers in user support is essential.
"
692,"Comparative computational results for some vertex and facet enumeration
  codes","  We report some computational results comparing parallel and sequential codes
for vertex/facet enumeration problems for convex polyhedra. The problems chosen
span the range from simple to highly degenerate polytopes. We tested one code
(lrs) based on pivoting and four codes (cddr+, ppl, normaliz, PORTA) based on
the double description method. normaliz employs parallelization as do the codes
plrs and mplrs which are based on lrs. We tested these codes using various
hardware configurations with up to 1200 cores. Major speedups were obtained by
parallelization, particularly by the code mplrs which uses MPI and can operate
on clusters of machines.
"
693,"A novel code generation methodology for block diagram modeler and
  simulators Scicos and VSS","  Block operations during simulation in Scicos and VSS environments can
naturally be described as Nsp functions. But the direct use of Nsp functions
for simulation leads to poor performance since the Nsp language is interpreted,
not compiled. The methodology presented in this paper is used to develop a tool
for generating efficient compilable code, such as C and ADA, for Scicos and VSS
models from these block Nsp functions. Operator overloading and partial
evaluation are the key elements of this novel approach. This methodology may be
used in other simulation environments such as Matlab/Simulink.
"
694,Sapporo2: A versatile direct $N$-body library,"  Astrophysical direct $N$-body methods have been one of the first production
algorithms to be implemented using NVIDIA's CUDA architecture. Now, almost
seven years later, the GPU is the most used accelerator device in astronomy for
simulating stellar systems. In this paper we present the implementation of the
Sapporo2 $N$-body library, which allows researchers to use the GPU for $N$-body
simulations with little to no effort. The first version, released five years
ago, is actively used, but lacks advanced features and versatility in numerical
precision and support for higher order integrators. In this updated version we
have rebuilt the code from scratch and added support for OpenCL,
multi-precision and higher order integrators. We show how to tune these codes
for different GPU architectures and present how to continue utilizing the GPU
optimal even when only a small number of particles ($N < 100$) is integrated.
This careful tuning allows Sapporo2 to be faster than Sapporo1 even with the
added options and double precision data loads. The code runs on a range of
NVIDIA and AMD GPUs in single and double precision accuracy. With the addition
of OpenCL support the library is also able to run on CPUs and other
accelerators that support OpenCL.
"
695,"Hybridization of Interval CP and Evolutionary Algorithms for Optimizing
  Difficult Problems","  The only rigorous approaches for achieving a numerical proof of optimality in
global optimization are interval-based methods that interleave branching of the
search-space and pruning of the subdomains that cannot contain an optimal
solution. State-of-the-art solvers generally integrate local optimization
algorithms to compute a good upper bound of the global minimum over each
subspace. In this document, we propose a cooperative framework in which
interval methods cooperate with evolutionary algorithms. The latter are
stochastic algorithms in which a population of candidate solutions iteratively
evolves in the search-space to reach satisfactory solutions.
  Within our cooperative solver Charibde, the evolutionary algorithm and the
interval-based algorithm run in parallel and exchange bounds, solutions and
search-space in an advanced manner via message passing. A comparison of
Charibde with state-of-the-art interval-based solvers (GlobSol, IBBA, Ibex) and
NLP solvers (Couenne, BARON) on a benchmark of difficult COCONUT problems shows
that Charibde is highly competitive against non-rigorous solvers and converges
faster than rigorous solvers by an order of magnitude.
"
696,"Approximation of boundary element matrices using GPGPUs and nested cross
  approximation","  The efficiency of boundary element methods depends crucially on the time
required for setting up the stiffness matrix. The far-field part of the matrix
can be approximated by compression schemes like the fast multipole method or
$\mathcal{H}$-matrix techniques. The near-field part is typically approximated
by special quadrature rules like the Sauter-Schwab technique that can handle
the singular integrals appearing in the diagonal and near-diagonal matrix
elements.
  Since computing one element of the matrix requires only a small amount of
data but a fairly large number of operations, we propose to use general-purpose
graphics processing units (GPGPUs) to handle vectorizable portions of the
computation: near-field computations are ideally suited for vectorization and
can therefore be handled very well by GPGPUs. Modern far-field compression
schemes can be split into a small adaptive portion that exhibits divergent
control flows, and should therefore be handled by the CPU, and a vectorizable
portion that can again be sent to GPGPUs.
  We propose a hybrid algorithm that splits the computation into tasks for CPUs
and GPGPUs. Our method presented in this article is able to reduce the setup
time of boundary integral operators by a significant factor of 19-30 for both
the Laplace and the Helmholtz equation in 3D when using two consumer GPGPUs
compared to a quad-core CPU.
"
697,"Performance evaluation of multiple precision matrix multiplications
  using parallelized Strassen and Winograd algorithms","  It is well known that Strassen and Winograd algorithms can reduce the
computational costs associated with dense matrix multiplication. We have
already shown that they are also very effective for software-based multiple
precision floating-point arithmetic environments such as the MPFR/GMP library.
In this paper, we show that we can obtain the same effectiveness for
double-double (DD) and quadruple-double (QD) environments supported by the QD
library, and that parallelization can increase the speed of these multiple
precision matrix multiplications. Finally, we demonstrate that our implemented
parallelized Strassen and Winograd algorithms can increase the speed of
parallelized LU decomposition.
"
698,Exact diagonalization of quantum lattice models on coprocessors,"  We implement the Lanczos algorithm on an Intel Xeon Phi coprocessor and
compare its performance to a multi-core Intel Xeon CPU and an NVIDIA graphics
processor. The Xeon and the Xeon Phi are parallelized with OpenMP and the
graphics processor is programmed with CUDA. The performance is evaluated by
measuring the execution time of a single step in the Lanczos algorithm. We
study two quantum lattice models with different particle numbers, and conclude
that for small systems, the multi-core CPU is the fastest platform, while for
large systems, the graphics processor is the clear winner, reaching speedups of
up to 7.6 compared to the CPU. The Xeon Phi outperforms the CPU with
sufficiently large particle number, reaching a speedup of 2.5.
"
699,"A quantitative performance analysis for Stokes solvers at the extreme
  scale","  This article presents a systematic quantitative performance analysis for
large finite element computations on extreme scale computing systems. Three
parallel iterative solvers for the Stokes system, discretized by low order
tetrahedral elements, are compared with respect to their numerical efficiency
and their scalability running on up to $786\,432$ parallel threads. A genuine
multigrid method for the saddle point system using an Uzawa-type smoother
provides the best overall performance with respect to memory consumption and
time-to-solution. The largest system solved on a Blue Gene/Q system has more
than ten trillion ($1.1 \cdot 10 ^{13}$) unknowns and requires about 13 minutes
compute time. Despite the matrix free and highly optimized implementation, the
memory requirement for the solution vector and the auxiliary vectors is about
200 TByte. Brandt's notion of ""textbook multigrid efficiency"" is employed to
study the algorithmic performance of iterative solvers. A recent extension of
this paradigm to ""parallel textbook multigrid efficiency"" makes it possible to
assess also the efficiency of parallel iterative solvers for a given hardware
architecture in absolute terms. The efficiency of the method is demonstrated
for simulating incompressible fluid flow in a pipe filled with spherical
obstacles.
"
700,"Evaluation of the Intel Xeon Phi 7120 and NVIDIA K80 as accelerators for
  two-dimensional panel codes","  To optimize the geometry of airfoils for a specific application is an
important engineering problem. In this context genetic algorithms have enjoyed
some success as they are able to explore the search space without getting stuck
in local optima. However, these algorithms require the computation of
aerodynamic properties for a significant number of airfoil geometries.
Consequently, for low-speed aerodynamics, panel methods are most often used as
the inner solver.
  In this paper we evaluate the performance of such an optimization algorithm
on modern accelerators (more specifically, the Intel Xeon Phi 7120 and the
NVIDIA K80). For that purpose, we have implemented an optimized version of the
algorithm on the CPU and Xeon Phi (based on OpenMP, vectorization, and the
Intel MKL library) and on the GPU (based on CUDA and the MAGMA library). We
present timing results for all codes and discuss the similarities and
differences between the three implementations. Overall, we observe a speedup of
approximately $2.5$ for adding an Intel Xeon Phi 7120 to a dual socket
workstation and a speedup between $3.4$ and $3.8$ for adding a NVIDIA K80 to a
dual socket workstation.
"
701,"Multi-Threaded Dense Linear Algebra Libraries for Low-Power Asymmetric
  Multicore Processors","  Dense linear algebra libraries, such as BLAS and LAPACK, provide a relevant
collection of numerical tools for many scientific and engineering applications.
While there exist high performance implementations of the BLAS (and LAPACK)
functionality for many current multi-threaded architectures,the adaption of
these libraries for asymmetric multicore processors (AMPs)is still pending. In
this paper we address this challenge by developing an asymmetry-aware
implementation of the BLAS, based on the BLIS framework, and tailored for AMPs
equipped with two types of cores: fast/power hungry versus slow/energy
efficient. For this purpose, we integrate coarse-grain and fine-grain
parallelization strategies into the library routines which, respectively,
dynamically distribute the workload between the two core types and statically
repartition this work among the cores of the same type.
  Our results on an ARM big.LITTLE processor embedded in the Exynos 5422 SoC,
using the asymmetry-aware version of the BLAS and a plain migration of the
legacy version of LAPACK, experimentally assess the benefits, limitations, and
potential of this approach.
"
702,"BOAT: a cross-platform software for data analysis and numerical
  computing with arbitrary-precision","  BOAT is a free cross-platform software for statistical data analysis and
numerical computing. Thanks to its multiple-precision floating point engine, it
allows arbitrary-precision calculations, whose digits of precision are only
limited by the amount of memory of the host machine. At the core of the
software is a simple and efficient expression language, whose use is
facilitated by the assisted typing, the auto-complete engine and the built-in
help for the syntax. In this paper a quick overview of the software is given.
Detailed information, together with its applications to some case studies, is
available at the BOAT web page.
"
703,The Dune FoamGrid implementation for surface and network grids,"  We present FoamGrid, a new implementation of the DUNE grid interface.
FoamGrid implements one- and two-dimensional grids in a physical space of
arbitrary dimension, which allows for grids for curved domains. Even more, the
grids are not expected to have a manifold structure, i.e., more than two
elements can share a common facet. This makes FoamGrid the grid data structure
of choice for simulating structures such as foams, discrete fracture networks,
or network flow problems. FoamGrid implements adaptive non-conforming
refinement with element parametrizations. As an additional feature it allows
removal and addition of elements in an existing grid, which makes FoamGrid
suitable for network growth problems. We show how to use FoamGrid, with
particular attention to the extensions of the grid interface needed to handle
non-manifold topology and grid growth. Three numerical examples demonstrate the
possibilities offered by FoamGrid.
"
704,FIESTA 4: optimized Feynman integral calculations with GPU support,"  This paper presents a new major release of the program FIESTA (Feynman
Integral Evaluation by a Sector decomposiTion Approach). The new release is
mainly aimed at optimal performance at large scales when one is increasing the
number of sampling points in order to reduce the uncertainty estimates. The
release now supports graphical processor units (GPU) for the numerical
integration, methods to optimize cluster-usage, as well as other speed, memory,
and stability improvements.
"
705,"Embedded Ensemble Propagation for Improving Performance, Portability and
  Scalability of Uncertainty Quantification on Emerging Computational
  Architectures","  Quantifying simulation uncertainties is a critical component of rigorous
predictive simulation. A key component of this is forward propagation of
uncertainties in simulation input data to output quantities of interest.
Typical approaches involve repeated sampling of the simulation over the
uncertain input data, and can require numerous samples when accurately
propagating uncertainties from large numbers of sources. Often simulation
processes from sample to sample are similar and much of the data generated from
each sample evaluation could be reused. We explore a new method for
implementing sampling methods that simultaneously propagates groups of samples
together in an embedded fashion, which we call embedded ensemble propagation.
We show how this approach takes advantage of properties of modern computer
architectures to improve performance by enabling reuse between samples,
reducing memory bandwidth requirements, improving memory access patterns,
improving opportunities for fine-grained parallelization, and reducing
communication costs. We describe a software technique for implementing embedded
ensemble propagation based on the use of C++ templates and describe its
integration with various scientific computing libraries within Trilinos. We
demonstrate improved performance, portability and scalability for the approach
applied to the simulation of partial differential equations on a variety of
CPU, GPU, and accelerator architectures, including up to 131,072 cores on a
Cray XK7 (Titan).
"
706,"GEMMbench: a framework for reproducible and collaborative benchmarking
  of matrix multiplication","  The generic matrix-matrix multiplication (GEMM) is arguably the most popular
computational kernel of the 20th century. Yet, surprisingly, no common
methodology for evaluating GEMM performance has been established over the many
decades of using GEMM for comparing architectures, compilers and ninja-class
programmers.
  We introduce GEMMbench, a framework and methodology for evaluating
performance of GEMM implementations. GEMMbench is implemented on top of
Collective Knowledge (CK), a lightweight framework for reproducible and
collaborative R&D in computer systems. Using CK allows the R&D community to
crowdsource hand-written and compiler-generated GEMM implementations and to
study their performance across multiple platforms, data sizes and data types.
  Our initial implementation supports hand-written OpenCL kernels operating on
matrices consisting of single- and double-precision floating-point values, and
producing single or multiple output elements per work-item (via thread
coarsening and vectorization).
"
707,Computing with Harmonic Functions,"  This document is the manual for a free Mathematica package for computing with
harmonic functions. This package allows the user to make calculations that
would take a prohibitive amount of time if done without a computer. For
example, the Poisson integral of any polynomial can be computed exactly. This
software can find exact solutions to Dirichlet, Neumann, and biDirichlet
problems in R^n with polynomial data on balls, ellipsoids, and annular regions.
It can also find bases for spaces of spherical harmonics, compute projections
onto the harmonic Bergman space, and perform other manipulations with harmonic
functions.
"
708,mplrs: A scalable parallel vertex/facet enumeration code,"  We describe a new parallel implementation, mplrs, of the vertex enumeration
code lrs that uses the MPI parallel environment and can be run on a network of
computers. The implementation makes use of a C wrapper that essentially uses
the existing lrs code with only minor modifications. mplrs was derived from the
earlier parallel implementation plrs, written by G. Roumanis in C++. plrs uses
the Boost library and runs on a shared memory machine. In developing mplrs we
discovered a method of balancing the parallel tree search, called budgeting,
that greatly improves parallelization beyond the bottleneck encountered
previously at around 32 cores.
  This method can be readily adapted for use in other reverse search
enumeration codes. We also report some preliminary computational results
comparing parallel and sequential codes for vertex/facet enumeration problems
for convex polyhedra. The problems chosen span the range from simple to highly
degenerate polytopes. For most problems tested, the results clearly show the
advantage of using the parallel implementation mplrs of the reverse search
based code lrs, even when as few as 8 cores are available. For some problems
almost linear speedup was observed up to 1200 cores, the largest number of
cores tested.
"
709,"Developing a High Performance Software Library with MPI and CUDA for
  Matrix Computations","  Nowadays, the paradigm of parallel computing is changing. CUDA is now a
popular programming model for general purpose computations on GPUs and a great
number of applications were ported to CUDA obtaining speedups of orders of
magnitude comparing to optimized CPU implementations. Hybrid approaches that
combine the message passing model with the shared memory model for parallel
computing are a solution for very large applications. We considered a
heterogeneous cluster that combines the CPU and GPU computations using MPI and
CUDA for developing a high performance linear algebra library. Our library
deals with large linear systems solvers because they are a common problem in
the fields of science and engineering. Direct methods for computing the
solution of such systems can be very expensive due to high memory requirements
and computational cost. An efficient alternative are iterative methods which
computes only an approximation of the solution. In this paper we present an
implementation of a library that uses a hybrid model of computation using MPI
and CUDA implementing both direct and iterative linear systems solvers. Our
library implements LU and Cholesky factorization based solvers and some of the
non-stationary iterative methods using the MPI/CUDA combination. We compared
the performance of our MPI/CUDA implementation with classic programs written to
be run on a single CPU.
"
710,"A Python Extension for the Massively Parallel Multiphysics Simulation
  Framework waLBerla","  We present a Python extension to the massively parallel HPC simulation
toolkit waLBerla. waLBerla is a framework for stencil based algorithms
operating on block-structured grids, with the main application field being
fluid simulations in complex geometries using the lattice Boltzmann method.
Careful performance engineering results in excellent node performance and good
scalability to over 400,000 cores. To increase the usability and flexibility of
the framework, a Python interface was developed. Python extensions are used at
all stages of the simulation pipeline: They simplify and automate scenario
setup, evaluation, and plotting. We show how our Python interface outperforms
the existing text-file-based configuration mechanism, providing features like
automatic nondimensionalization of physical quantities and handling of complex
parameter dependencies. Furthermore, Python is used to process and evaluate
results while the simulation is running, leading to smaller output files and
the possibility to adjust parameters dependent on the current simulation state.
C++ data structures are exported such that a seamless interfacing to other
numerical Python libraries is possible. The expressive power of Python and the
performance of C++ make development of efficient code with low time effort
possible.
"
711,DiffSharp: Automatic Differentiation Library,"  In this paper we introduce DiffSharp, an automatic differentiation (AD)
library designed with machine learning in mind. AD is a family of techniques
that evaluate derivatives at machine precision with only a small constant
factor of overhead, by systematically applying the chain rule of calculus at
the elementary operator level. DiffSharp aims to make an extensive array of AD
techniques available, in convenient form, to the machine learning community.
These including arbitrary nesting of forward/reverse AD operations, AD with
linear algebra primitives, and a functional API that emphasizes the use of
higher-order functions and composition. The library exposes this functionality
through an API that provides gradients, Hessians, Jacobians, directional
derivatives, and matrix-free Hessian- and Jacobian-vector products. Bearing the
performance requirements of the latest machine learning techniques in mind, the
underlying computations are run through a high-performance BLAS/LAPACK backend,
using OpenBLAS by default. GPU support is currently being implemented.
"
712,Sparse Tensor Algebra as a Parallel Programming Model,"  Dense and sparse tensors allow the representation of most bulk data
structures in computational science applications. We show that sparse tensor
algebra can also be used to express many of the transformations on these
datasets, especially those which are parallelizable. Tensor computations are a
natural generalization of matrix and graph computations. We extend the usual
basic operations of tensor summation and contraction to arbitrary functions,
and further operations such as reductions and mapping. The expression of these
transformations in a high-level sparse linear algebra domain specific language
allows our framework to understand their properties at runtime to select the
preferred communication-avoiding algorithm. To demonstrate the efficacy of our
approach, we show how key graph algorithms as well as common numerical kernels
can be succinctly expressed using our interface and provide performance results
of a general library implementation.
"
713,"MXNet: A Flexible and Efficient Machine Learning Library for
  Heterogeneous Distributed Systems","  MXNet is a multi-language machine learning (ML) library to ease the
development of ML algorithms, especially for deep neural networks. Embedded in
the host language, it blends declarative symbolic expression with imperative
tensor computation. It offers auto differentiation to derive gradients. MXNet
is computation and memory efficient and runs on various heterogeneous systems,
ranging from mobile devices to distributed GPU clusters.
  This paper describes both the API design and the system implementation of
MXNet, and explains how embedding of both symbolic expression and tensor
operation is handled in a unified fashion. Our preliminary experiments reveal
promising results on large scale deep neural network applications using
multiple GPU machines.
"
714,"An Extension of Moebius--Lie Geometry with Conformal Ensembles of Cycles
  and Its Implementation in a GiNaC Library","  We propose to consider ensembles of cycles (quadrics), which are
interconnected through conformal-invariant geometric relations (e.g. ""to be
orthogonal"", ""to be tangent"", etc.), as new objects in an extended Moebius--Lie
geometry. It was recently demonstrated in several related papers, that such
ensembles of cycles naturally parameterise many other conformally-invariant
objects, e.g. loxodromes or continued fractions. The paper describes a method,
which reduces a collection of conformally invariant geometric relations to a
system of linear equations, which may be accompanied by one fixed quadratic
relation.
  To show its usefulness, the method is implemented as a C++ library. It
operates with numeric and symbolic data of cycles in spaces of arbitrary
dimensionality and metrics with any signatures. Numeric calculations can be
done in exact or approximate arithmetic. In the two- and three-dimensional
cases illustrations and animations can be produced. An interactive Python
wrapper of the library is provided as well.
"
715,Grid: A next generation data parallel C++ QCD library,"  In this proceedings we discuss the motivation, implementation details, and
performance of a new physics code base called Grid. It is intended to be more
performant, more general, but similar in spirit to QDP++\cite{QDP}. Our
approach is to engineer the basic type system to be consistently fast, rather
than bolt on a few optimised routines, and we are attempt to write all our
optimised routines directly in the Grid framework. It is hoped this will
deliver best known practice performance across the next generation of
supercomputers, which will provide programming challenges to traditional scalar
codes.
  We illustrate the programming patterns used to implement our goals, and
advances in productivity that have been enabled by using new features in C++11.
"
716,The interface for functions in the dune-functions module,"  The dune-functions dune module introduces a new programmer interface for
discrete and non-discrete functions. Unlike the previous interfaces considered
in the existing dune modules, it is based on overloading operator(), and
returning values by-value. This makes user code much more readable, and allows
the incorporation of newer C++ features such as lambda expressions. Run-time
polymorphism is implemented not by inheritance, but by type erasure,
generalizing the ideas of the std::function class from the C++11 standard
library. We describe the new interface, show its possibilities, and measure the
performance impact of type erasure and return-by-value.
"
717,"Dynamic Computation of Runge Kutta Fourth Order Algorithm for First and
  Second Order Ordinary Differential Equation Using Java","  Differential equations arise in mathematics, physics,medicine, pharmacology,
communications, image processing and animation, etc. An Ordinary Differential
Equation (ODE) is a differential equation if it involves derivatives with
respect to only one independent variable which can be studied from different
perspectives, such as: analytical methods, graphical methods and numerical
methods. This research paper therefore revises the standard Runge - Kutta
fourth order algorithm by using compiler techniques to dynamically evaluate the
inputs and implement the algorithm for both first and second order derivatives
of the ODE. We have been able to develop and implement the software that can be
used to evaluate inputs and compute solutions (approximately and analytically)
for the ODE function at a more efficient rate than the traditional method.
"
718,Software for enumerative and analytic combinatorics,"  We survey some general-purpose symbolic software packages that implement
algorithms from enumerative and analytic combinatorics. Software for the
following areas is covered: basic combinatorial objects, symbolic
combinatorics, P\'olya theory, combinatorial species, and asymptotics. We
describe the capabilities that the packages offer as well as some of the
algorithms used, and provide links to original documentation. Most of the
packages are freely downloadable from the web.
"
719,"Evaluation of the Partitioned Global Address Space (PGAS) model for an
  inviscid Euler solver","  In this paper we evaluate the performance of Unified Parallel C (which
implements the partitioned global address space programming model) using a
numerical method that is widely used in fluid dynamics. In order to evaluate
the incremental approach to parallelization (which is possible with UPC) and
its performance characteristics, we implement different levels of optimization
of the UPC code and compare it with an MPI parallelization on four different
clusters of the Austrian HPC infrastructure (LEO3, LEO3E, VSC2, VSC3) and on an
Intel Xeon Phi. We find that UPC is significantly easier to develop in compared
to MPI and that the performance achieved is comparable to MPI in most
situations. The obtained results show worse performance (on VSC2), competitive
performance (on LEO3, LEO3E and VSC3), and superior performance (on the Intel
Xeon Phi).
"
720,"Reducing local minima in fitness landscapes of parameter estimation by
  using piecewise evaluation and state estimation","  Ordinary differential equations (ODE) are widely used for modeling in Systems
Biology. As most commonly only some of the kinetic parameters are measurable or
precisely known, parameter estimation techniques are applied to parametrize the
model to experimental data. A main challenge for the parameter estimation is
the complexity of the parameter space, especially its high dimensionality and
local minima.
  Parameter estimation techniques consist of an objective function, measuring
how well a certain parameter set describes the experimental data, and an
optimization algorithm that optimizes this objective function. A lot of effort
has been spent on developing highly sophisticated optimization algorithms to
cope with the complexity in the parameter space, but surprisingly few articles
address the influence of the objective function on the computational complexity
in finding global optima. We extend a recently developed multiple shooting for
stochastic systems (MSS) objective function for parameter estimation of
stochastic models and apply it to parameter estimation of ODE models. This MSS
objective function treats the intervals between measurement points separately.
This separate treatment allows the ODE trajectory to stay closer to the data
and we show that it reduces the complexity of the parameter space.
  We use examples from Systems Biology, namely a Lotka-Volterra model, a
FitzHugh-Nagumo oscillator and a Calcium oscillation model, to demonstrate the
power of the MSS approach for reducing the complexity and the number of local
minima in the parameter space. The approach is fully implemented in the COPASI
software package and, therefore, easily accessible for a wide community of
researchers.
"
721,"Task Parallel Incomplete Cholesky Factorization using 2D
  Partitioned-Block Layout","  We introduce a task-parallel algorithm for sparse incomplete Cholesky
factorization that utilizes a 2D sparse partitioned-block layout of a matrix.
Our factorization algorithm follows the idea of algorithms-by-blocks by using
the block layout. The algorithm-by-blocks approach induces a task graph for the
factorization. These tasks are inter-related to each other through their data
dependences in the factorization algorithm. To process the tasks on various
manycore architectures in a portable manner, we also present a portable tasking
API that incorporates different tasking backends and device-specific features
using an open-source framework for manycore platforms i.e., Kokkos. A
performance evaluation is presented on both Intel Sandybridge and Xeon Phi
platforms for matrices from the University of Florida sparse matrix collection
to illustrate merits of the proposed task-based factorization. Experimental
results demonstrate that our task-parallel implementation delivers about 26.6x
speedup (geometric mean) over single-threaded incomplete Cholesky-by-blocks and
19.2x speedup over serial Cholesky performance which does not carry tasking
overhead using 56 threads on the Intel Xeon Phi processor for sparse matrices
arising from various application problems.
"
722,Vectorization of Multibyte Floating Point Data Formats,"  We propose a scheme for reduced-precision representation of floating point
data on a continuum between IEEE-754 floating point types. Our scheme enables
the use of lower precision formats for a reduction in storage space
requirements and data transfer volume. We describe how our scheme can be
accelerated using existing hardware vector units on a general-purpose processor
(GPP). Exploiting native vector hardware allows us to support reduced precision
floating point with low overhead. We demonstrate that supporting reduced
precision in the compiler as opposed to using a library approach can yield a
low overhead solution for GPPs.
"
723,"Discontinuous Galerkin methods on graphics processing units for
  nonlinear hyperbolic conservation laws","  We present a novel implementation of the modal discontinuous Galerkin (DG)
method for hyperbolic conservation laws in two dimensions on graphics
processing units (GPUs) using NVIDIA's Compute Unified Device Architecture
(CUDA). Both flexible and highly accurate, DG methods accommodate parallel
architectures well as their discontinuous nature produces element-local
approximations. High performance scientific computing suits GPUs well, as these
powerful, massively parallel, cost-effective devices have recently included
support for double-precision floating point numbers. Computed examples for
Euler equations over unstructured triangle meshes demonstrate the effectiveness
of our implementation on an NVIDIA GTX 580 device. Profiling of our method
reveals performance comparable to an existing nodal DG-GPU implementation for
linear problems.
"
724,Inv-ASKIT: A Parallel Fast Diret Solver for Kernel Matrices,"  We present a parallel algorithm for computing the approximate factorization
of an $N$-by-$N$ kernel matrix. Once this factorization has been constructed
(with $N \log^2 N $ work), we can solve linear systems with this matrix with $N
\log N $ work. Kernel matrices represent pairwise interactions of points in
metric spaces. They appear in machine learning, approximation theory, and
computational physics. Kernel matrices are typically dense (matrix
multiplication scales quadratically with $N$) and ill-conditioned (solves can
require 100s of Krylov iterations). Thus, fast algorithms for matrix
multiplication and factorization are critical for scalability.
  Recently we introduced ASKIT, a new method for approximating a kernel matrix
that resembles N-body methods. Here we introduce INV-ASKIT, a factorization
scheme based on ASKIT. We describe the new method, derive complexity estimates,
and conduct an empirical study of its accuracy and scalability. We report
results on real-world datasets including ""COVTYPE"" ($0.5$M points in 54
dimensions), ""SUSY"" ($4.5$M points in 8 dimensions) and ""MNIST"" (2M points in
784 dimensions) using shared and distributed memory parallelism. In our largest
run we approximately factorize a dense matrix of size 32M $\times$ 32M
(generated from points in 64 dimensions) on 4,096 Sandy-Bridge cores. To our
knowledge these results improve the state of the art by several orders of
magnitude.
"
725,An SSD-based eigensolver for spectral analysis on billion-node graphs,"  Many eigensolvers such as ARPACK and Anasazi have been developed to compute
eigenvalues of a large sparse matrix. These eigensolvers are limited by the
capacity of RAM. They run in memory of a single machine for smaller eigenvalue
problems and require the distributed memory for larger problems.
  In contrast, we develop an SSD-based eigensolver framework called FlashEigen,
which extends Anasazi eigensolvers to SSDs, to compute eigenvalues of a graph
with hundreds of millions or even billions of vertices in a single machine.
FlashEigen performs sparse matrix multiplication in a semi-external memory
fashion, i.e., we keep the sparse matrix on SSDs and the dense matrix in
memory. We store the entire vector subspace on SSDs and reduce I/O to improve
performance through caching the most recent dense matrix. Our result shows that
FlashEigen is able to achieve 40%-60% performance of its in-memory
implementation and has performance comparable to the Anasazi eigensolvers on a
machine with 48 CPU cores. Furthermore, it is capable of scaling to a graph
with 3.4 billion vertices and 129 billion edges. It takes about four hours to
compute eight eigenvalues of the billion-node graph using 120 GB memory.
"
726,"High performance Python for direct numerical simulations of turbulent
  flows","  Direct Numerical Simulations (DNS) of the Navier Stokes equations is an
invaluable research tool in fluid dynamics. Still, there are few publicly
available research codes and, due to the heavy number crunching implied,
available codes are usually written in low-level languages such as C/C++ or
Fortran. In this paper we describe a pure scientific Python pseudo-spectral DNS
code that nearly matches the performance of C++ for thousands of processors and
billions of unknowns. We also describe a version optimized through Cython, that
is found to match the speed of C++. The solvers are written from scratch in
Python, both the mesh, the MPI domain decomposition, and the temporal
integrators. The solvers have been verified and benchmarked on the Shaheen
supercomputer at the KAUST supercomputing laboratory, and we are able to show
very good scaling up to several thousand cores.
  A very important part of the implementation is the mesh decomposition (we
implement both slab and pencil decompositions) and 3D parallel Fast Fourier
Transforms (FFT). The mesh decomposition and FFT routines have been implemented
in Python using serial FFT routines (either NumPy, pyFFTW or any other serial
FFT module), NumPy array manipulations and with MPI communications handled by
MPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFT
in Python for a slab mesh decomposition using 4 lines of compact Python code,
for which the parallel performance on Shaheen is found to be slightly better
than similar routines provided through the FFTW library. For a pencil mesh
decomposition 7 lines of code is required to execute a transform.
"
727,Oasis: a high-level/high-performance open source Navier-Stokes solver,"  Oasis is a high-level/high-performance finite element Navier-Stokes solver
written from scratch in Python using building blocks from the FEniCS project
(fenicsproject.org). The solver is unstructured and targets large-scale
applications in complex geometries on massively parallel clusters. Oasis
utilizes MPI and interfaces, through FEniCS, to the linear algebra backend
PETSc. Oasis advocates a high-level, programmable user interface through the
creation of highly flexible Python modules for new problems. Through the
high-level Python interface the user is placed in complete control of every
aspect of the solver. A version of the solver, that is using piecewise linear
elements for both velocity and pressure, is shown reproduce very well the
classical, spectral, turbulent channel simulations of Moser, Kim and Mansour at
$Re_{\tau}=180$ [Phys. Fluids, vol 11(4), p. 964]. The computational speed is
strongly dominated by the iterative solvers provided by the linear algebra
backend, which is arguably the best performance any similar implicit solver
using PETSc may hope for. Higher order accuracy is also demonstrated and new
solvers may be easily added within the same framework.
"
728,Recursive Algorithms for Dense Linear Algebra: The ReLAPACK Collection,"  To exploit both memory locality and the full performance potential of highly
tuned kernels, dense linear algebra libraries such as LAPACK commonly implement
operations as blocked algorithms. However, to achieve next-to-optimal
performance with such algorithms, significant tuning is required. On the other
hand, recursive algorithms are virtually tuning free, and yet attain similar
performance. In this paper, we first analyze and compare blocked and recursive
algorithms in terms of performance, and then introduce ReLAPACK, an open-source
library of recursive algorithms to seamlessly replace most of LAPACK's blocked
algorithms. In many scenarios, ReLAPACK clearly outperforms reference LAPACK,
and even improves upon the performance of optimizes libraries.
"
729,Differentiation of the Cholesky decomposition,"  We review strategies for differentiating matrix-based computations, and
derive symbolic and algorithmic update rules for differentiating expressions
containing the Cholesky decomposition. We recommend new `blocked' algorithms,
based on differentiating the Cholesky algorithm DPOTRF in the LAPACK library,
which uses `Level 3' matrix-matrix operations from BLAS, and so is
cache-friendly and easy to parallelize. For large matrices, the resulting
algorithms are the fastest way to compute Cholesky derivatives, and are an
order of magnitude faster than the algorithms in common usage. In some
computing environments, symbolically-derived updates are faster for small
matrices than those based on differentiating Cholesky algorithms. The symbolic
and algorithmic approaches can be combined to get the best of both worlds.
"
730,Alpaka - An Abstraction Library for Parallel Kernel Acceleration,"  Porting applications to new hardware or programming models is a tedious and
error prone process. Every help that eases these burdens is saving developer
time that can then be invested into the advancement of the application itself
instead of preserving the status-quo on a new platform.
  The Alpaka library defines and implements an abstract hierarchical redundant
parallelism model. The model exploits parallelism and memory hierarchies on a
node at all levels available in current hardware. By doing so, it allows to
achieve platform and performance portability across various types of
accelerators by ignoring specific unsupported levels and utilizing only the
ones supported on a specific accelerator. All hardware types (multi- and
many-core CPUs, GPUs and other accelerators) are supported for and can be
programmed in the same way. The Alpaka C++ template interface allows for
straightforward extension of the library to support other accelerators and
specialization of its internals for optimization.
  Running Alpaka applications on a new (and supported) platform requires the
change of only one source code line instead of a lot of \#ifdefs.
"
731,Extending DUNE: The dune-xt modules,"  We present our effort to extend and complement the core modules of the
Distributed and Unified Numerics Environment DUNE (http://dune-project.org) by
a well tested and structured collection of utilities and concepts. We describe
key elements of our four modules dune-xt-common, dune-xt-grid, dune-xt-la and
dune-xt-functions, which aim at further enabling the programming of generic
algorithms within DUNE as well as adding an extra layer of usability and
convenience.
"
732,RWebData: A High-Level Interface to the Programmable Web,"  The rise of the programmable web offers new opportunities for the empirically
driven social sciences. The access, compilation and preparation of data from
the programmable web for statistical analysis can, however, involve substantial
up-front costs for the practical researcher. The R-package RWebData provides a
high-level framework that allows data to be easily collected from the
programmable web in a format that can directly be used for statistical analysis
in R (R Core Team 2013) without bothering about the data's initial format and
nesting structure. It was developed specifically for users who have no
experience with web technologies and merely use R as a statistical software.
The core idea and methodological contribution of the package are the
disentangling of parsing web data and mapping them with a generic algorithm
(independent of the initial data structure) to a flat table-like
representation. This paper provides an overview of the high-level functions for
R-users, explains the basic architecture of the package, and illustrates the
implemented data mapping algorithm.
"
733,A New Numerical Method for Solving the Acoustic Radiation Problem,"  A numerical method of solving the problem of acoustic wave radiation in the
presence of a rigid scatterer is described. It combines the finite element
method and the boundary algebraic equations. In the proposed method, the
exterior domain around the scatterer is discretized, so that there appear an
infinite domain with regular discretization and a relatively small layer with
irregular mesh. For the infinite regular mesh, the boundary algebraic equation
method is used with spurious resonance suppression according to Burton and
Miller. In the thin layer with irregular mesh, the finite element method is
used. The proposed method is characterized by simple implementation, fair
accuracy, and absence of spurious resonances.
"
734,TTC: A high-performance Compiler for Tensor Transpositions,"  We present TTC, an open-source parallel compiler for multidimensional tensor
transpositions. In order to generate high-performance C++ code, TTC explores a
number of optimizations, including software prefetching, blocking,
loop-reordering, and explicit vectorization. To evaluate the performance of
multidimensional transpositions across a range of possible use-cases, we also
release a benchmark covering arbitrary transpositions of up to six dimensions.
Performance results show that the routines generated by TTC achieve close to
peak memory bandwidth on both the Intel Haswell and the AMD Steamroller
architectures, and yield significant performance gains over modern compilers.
By implementing a set of pruning heuristics, TTC allows users to limit the
number of potential solutions; this option is especially useful when dealing
with high-dimensional tensors, as the search space might become prohibitively
large. Experiments indicate that when only 100 potential solutions are
considered, the resulting performance is about 99% of that achieved with
exhaustive search.
"
735,Testing fine-grained parallelism for the ADMM on a factor-graph,"  There is an ongoing effort to develop tools that apply distributed
computational resources to tackle large problems or reduce the time to solve
them. In this context, the Alternating Direction Method of Multipliers (ADMM)
arises as a method that can exploit distributed resources like the dual ascent
method and has the robustness and improved convergence of the augmented
Lagrangian method. Traditional approaches to accelerate the ADMM using multiple
cores are problem-specific and often require multi-core programming. By
contrast, we propose a problem-independent scheme of accelerating the ADMM that
does not require the user to write any parallel code. We show that this scheme,
an interpretation of the ADMM as a message-passing algorithm on a factor-graph,
can automatically exploit fine-grained parallelism both in GPUs and
shared-memory multi-core computers and achieves significant speedup in such
diverse application domains as combinatorial optimization, machine learning,
and optimal control. Specifically, we obtain 10-18x speedup using a GPU, and
5-9x using multiple CPU cores, over a serial, optimized C-version of the ADMM,
which is similar to the typical speedup reported for existing GPU-accelerated
libraries, including cuFFT (19x), cuBLAS (17x), and cuRAND (8x).
"
736,"Pymanopt: A Python Toolbox for Optimization on Manifolds using Automatic
  Differentiation","  Optimization on manifolds is a class of methods for optimization of an
objective function, subject to constraints which are smooth, in the sense that
the set of points which satisfy the constraints admits the structure of a
differentiable manifold. While many optimization problems are of the described
form, technicalities of differential geometry and the laborious calculation of
derivatives pose a significant barrier for experimenting with these methods.
  We introduce Pymanopt (available at https://pymanopt.github.io), a toolbox
for optimization on manifolds, implemented in Python, that---similarly to the
Manopt Matlab toolbox---implements several manifold geometries and optimization
algorithms. Moreover, we lower the barriers to users further by using automated
differentiation for calculating derivative information, saving users time and
saving them from potential calculation and implementation errors.
"
737,"Fast calculation of inverse square root with the use of magic constant
  $-$ analytical approach","  We present a mathematical analysis of transformations used in fast
calculation of inverse square root for single-precision floating-point numbers.
Optimal values of the so called magic constants are derived in a systematic
way, minimizing either absolute or relative errors at subsequent stages of the
discussed algorithm.
"
738,States and channels in quantum mechanics without complex numbers,"  In the presented note we aim at exploring the possibility of abandoning
complex numbers in the representation of quantum states and operations. We
demonstrate a simplified version of quantum mechanics in which the states are
represented using real numbers only. The main advantage of this approach is
that the simulation of the $n$-dimensional quantum system requires $n^2$ real
numbers, in contrast to the standard case where $n^4$ real numbers are
required. The main disadvantage is the lack of hermicity in the representation
of quantum states. Using Mathematica computer algebra system we develop a set
of functions for manipulating real-only quantum states. With the help of this
tool we study the properties of the introduced representation and the induced
representation of quantum channels.
"
739,A Flexible Primal-Dual Toolbox,"  \textbf{FlexBox} is a flexible MATLAB toolbox for finite dimensional convex
variational problems in image processing and beyond. Such problems often
consist of non-differentiable parts and involve linear operators. The toolbox
uses a primal-dual scheme to avoid (computationally) inefficient operator
inversion and to get reliable error estimates. From the user-side,
\textbf{FlexBox} expects the primal formulation of the problem, automatically
decouples operators and dualizes the problem. For large-scale problems,
\textbf{FlexBox} also comes with a \cpp-module, which can be used stand-alone
or together with MATLAB via MEX-interfaces. Besides various pre-implemented
data-fidelities and regularization-terms, \textbf{FlexBox} is able to handle
arbitrary operators while being easily extendable, due to its object-oriented
design. The toolbox is available at
\href{http://www.flexbox.im}{http://www.flexbox.im}
"
740,Automatic Theorem Proving in Walnut,"  Walnut is a software package that implements a mechanical decision procedure
for deciding certain combinatorial properties of some special words referred to
as automatic words or automatic sequences. Walnut is written in Java and is
open source. It is licensed under GNU General Public License.
"
741,"Interoperability in the OpenDreamKit Project: The Math-in-the-Middle
  Approach","  OpenDreamKit --- ""Open Digital Research Environment Toolkit for the
Advancement of Mathematics"" --- is an H2020 EU Research Infrastructure project
that aims at supporting, over the period 2015--2019, the ecosystem of
open-source mathematical software systems. From that, OpenDreamKit will deliver
a flexible toolkit enabling research groups to set up Virtual Research
Environments, customised to meet the varied needs of research projects in pure
mathematics and applications.
  An important step in the OpenDreamKit endeavor is to foster the
interoperability between a variety of systems, ranging from computer algebra
systems over mathematical databases to front-ends. This is the mission of the
integration work package (WP6). We report on experiments and future plans with
the \emph{Math-in-the-Middle} approach. This information architecture consists
in a central mathematical ontology that documents the domain and fixes a joint
vocabulary, combined with specifications of the functionalities of the various
systems. Interaction between systems can then be enriched by pivoting off this
information architecture.
"
742,"micompr: An R Package for Multivariate Independent Comparison of
  Observations","  The R package micompr implements a procedure for assessing if two or more
multivariate samples are drawn from the same distribution. The procedure uses
principal component analysis to convert multivariate observations into a set of
linearly uncorrelated statistical measures, which are then compared using a
number of statistical methods. This technique is independent of the
distributional properties of samples and automatically selects features that
best explain their differences. The procedure is appropriate for comparing
samples of time series, images, spectrometric measures or similar
high-dimension multivariate observations.
"
743,SimOutUtils - Utilities for analyzing time series simulation output,"  SimOutUtils is a suite of MATLAB/Octave functions for studying and analyzing
time series-like output from stochastic simulation models. More specifically,
SimOutUtils allows modelers to study and visualize simulation output dynamics,
perform distributional analysis of output statistical summaries, as well as
compare these summaries in order to assert the statistical equivalence of two
or more model implementations. Additionally, the provided functions are able to
produce publication quality figures and tables showcasing results from the
specified simulation output studies.
"
744,"A mixed precision semi-Lagrangian algorithm and its performance on
  accelerators","  In this paper we propose a mixed precision algorithm in the context of the
semi-Lagrangian discontinuous Galerkin method. The performance of this approach
is evaluated on a traditional dual socket workstation as well as on a Xeon Phi
and an NVIDIA K80. We find that the mixed precision algorithm can be
implemented efficiently on these architectures. This implies that, in addition
to the considerable reduction in memory, a substantial increase in performance
can be observed as well. Moreover, we discuss the relative performance of our
implementations.
"
745,BEANS - a software package for distributed Big Data analysis,"  BEANS software is a web based, easy to install and maintain, new tool to
store and analyse data in a distributed way for a massive amount of data. It
provides a clear interface for querying, filtering, aggregating, and plotting
data from an arbitrary number of datasets. Its main purpose is to simplify the
process of storing, examining and finding new relations in the so-called Big
Data.
  Creation of BEANS software is an answer to the growing needs of the
astronomical community to have a versatile tool to store, analyse and compare
the complex astrophysical numerical simulations with observations (e.g.
simulations of the Galaxy or star clusters with the Gaia archive). However,
this software was built in a general form and it is ready to use in any other
research field or open source software.
"
746,A Subdivision Solver for Systems of Large Dense Polynomials,"  We describe here the package {\tt subdivision\\_solver} for the mathematical
software {\tt SageMath}. It provides a solver on real numbers for square
systems of large dense polynomials. By large polynomials we mean multivariate
polynomials with large degrees, which coefficients have large bit-size. While
staying robust, symbolic approaches to solve systems of polynomials see their
performances dramatically affected by high degree and bit-size of input
polynomials.Available numeric approaches suffer from the cost of the evaluation
of large polynomials and their derivatives.Our solver is based on interval
analysis and bisections of an initial compact domain of $\R^n$ where solutions
are sought. Evaluations on intervals with Horner scheme is performed by the
package {\tt fast\\_polynomial} for {\tt SageMath}.The non-existence of a
solution within a box is certified by an evaluation scheme that uses a Taylor
expansion at order 2, and existence and uniqueness of a solution within a box
is certified with krawczyk operator.The precision of the working arithmetic is
adapted on the fly during the subdivision process and we present a new
heuristic criterion to decide if the arithmetic precision has to be increased.
"
747,"COCO: A Platform for Comparing Continuous Optimizers in a Black-Box
  Setting","  We introduce COCO, an open source platform for Comparing Continuous
Optimizers in a black-box setting. COCO aims at automatizing the tedious and
repetitive task of benchmarking numerical optimization algorithms to the
greatest possible extent. The platform and the underlying methodology allow to
benchmark in the same framework deterministic and stochastic solvers for both
single and multiobjective optimization. We present the rationales behind the
(decade-long) development of the platform as a general proposition for
guidelines towards better benchmarking. We detail underlying fundamental
concepts of COCO such as the definition of a problem as a function instance,
the underlying idea of instances, the use of target values, and runtime defined
by the number of function calls as the central performance measure. Finally, we
give a quick overview of the basic code structure and the currently available
test suites.
"
748,"dMath: A Scalable Linear Algebra and Math Library for Heterogeneous
  GP-GPU Architectures","  A new scalable parallel math library, dMath, is presented in this paper that
demonstrates leading scaling when using intranode, or internode,
hybrid-parallelism for deep-learning. dMath provides easy-to-use distributed
base primitives and a variety of domain-specific algorithms. These include
matrix multiplication, convolutions, and others allowing for rapid development
of highly scalable applications, including Deep Neural Networks (DNN), whereas
previously one was restricted to libraries that provided effective primitives
for only a single GPU, like Nvidia cublas and cudnn or DNN primitives from
Nervana neon framework. Development of HPC software is difficult,
labor-intensive work, requiring a unique skill set. dMath allows a wide range
of developers to utilize parallel and distributed hardware easily. One
contribution of this approach is that data is stored persistently on the GPU
hardware, avoiding costly transfers between host and device. Advanced memory
management techniques are utilized, including caching of transferred data and
memory reuse through pooling. A key contribution of dMath is that it delivers
performance, portability, and productivity to its specific domain of support.
It enables algorithm and application programmers to quickly solve problems
without managing the significant complexity associated with multi-level
parallelism.
"
749,"A Left-Looking Selected Inversion Algorithm and Task Parallelism on
  Shared Memory Systems","  Given a sparse matrix $A$, the selected inversion algorithm is an efficient
method for computing certain selected elements of $A^{-1}$. These selected
elements correspond to all or some nonzero elements of the LU factors of $A$.
In many ways, the type of matrix updates performed in the selected inversion
algorithm is similar to that performed in the LU factorization, although the
sequence of operation is different. In the context of LU factorization, it is
known that the left-looking and right-looking algorithms exhibit different
memory access and data communication patterns, and hence different behavior on
shared memory and distributed memory parallel machines. Corresponding to
right-looking and left-looking LU factorization, selected inversion algorithm
can be organized as a left-looking and a right-looking algorithm. The parallel
right-looking version of the algorithm has been developed in [1]. The sequence
of operations performed in this version of the selected inversion algorithm is
similar to those performed in a left-looking LU factorization algorithm. In
this paper, we describe the left-looking variant of the selected inversion
algorithm, and based on task parallel method, present an efficient
implementation of the algorithm for shared memory machines. We demonstrate that
with the task scheduling features provided by OpenMP 4.0, the left-looking
selected inversion algorithm can scale well both on the Intel Haswell multicore
architecture and on the Intel Knights Corner (KNC) manycore architecture.
Compared to the right-looking selected inversion algorithm, the left-looking
formulation facilitates pipelining of work along different branches of the
elimination tree, and can be a promising candidate for future development of
massively parallel selected inversion algorithms on heterogeneous architecture.
"
750,BoxLib with Tiling: An AMR Software Framework,"  In this paper we introduce a block-structured adaptive mesh refinement (AMR)
software framework that incorporates tiling, a well-known loop transformation.
Because the multiscale, multiphysics codes built in BoxLib are designed to
solve complex systems at high resolution, performance on current and next
generation architectures is essential. With the expectation of many more cores
per node on next generation architectures, the ability to effectively utilize
threads within a node is essential, and the current model for parallelization
will not be sufficient. We describe a new version of BoxLib in which the tiling
constructs are embedded so that BoxLib-based applications can easily realize
expected performance gains without extra effort on the part of the application
developer. We also discuss a path forward to enable future versions of BoxLib
to take advantage of NUMA-aware optimizations using the TiDA portable library.
"
751,An algorithm for the optimization of finite element integration loops,"  We present an algorithm for the optimization of a class of finite element
integration loop nests. This algorithm, which exploits fundamental mathematical
properties of finite element operators, is proven to achieve a locally optimal
operation count. In specified circumstances the optimum achieved is global.
Extensive numerical experiments demonstrate significant performance
improvements over the state of the art in finite element code generation in
almost all cases. This validates the effectiveness of the algorithm presented
here, and illustrates its limitations.
"
752,"A structure-exploiting numbering algorithm for finite elements on
  extruded meshes, and its performance evaluation in Firedrake","  We present a generic algorithm for numbering and then efficiently iterating
over the data values attached to an extruded mesh. An extruded mesh is formed
by replicating an existing mesh, assumed to be unstructured, to form layers of
prismatic cells. Applications of extruded meshes include, but are not limited
to, the representation of 3D high aspect ratio domains employed by geophysical
finite element simulations. These meshes are structured in the extruded
direction. The algorithm presented here exploits this structure to avoid the
performance penalty traditionally associated with unstructured meshes. We
evaluate the implementation of this algorithm in the Firedrake finite element
system on a range of low compute intensity operations which constitute worst
cases for data layout performance exploration. The experiments show that having
structure along the extruded direction enables the cost of the indirect data
accesses to be amortized after 10-20 layers as long as the underlying mesh is
well-ordered. We characterise the resulting spatial and temporal reuse in a
representative set of both continuous-Galerkin and discontinuous-Galerkin
discretisations. On meshes with realistic numbers of layers the performance
achieved is between 70% and 90% of a theoretical hardware-specific limit.
"
753,"Convex Hull Calculations: a Matlab Implementation and Correctness Proofs
  for the lrs-Algorithm","  This paper provides full \Matlab-code and informal correctness proofs for the
lexicographic reverse search algorithm for convex hull calculations. The
implementation was tested on a 1993 486-PC for various small and some larger,
partially highly degenerate combinatorial polytopes, one of which (a certain
13-dimensional 24 vertex polyhedron) occurs naturally in the study of a well
known problem posed by Professor Graciano de Oliveira: see end of section 1.
"
754,Extreme-scale Multigrid Components within PETSc,"  Elliptic partial differential equations (PDEs) frequently arise in continuum
descriptions of physical processes relevant to science and engineering.
Multilevel preconditioners represent a family of scalable techniques for
solving discrete PDEs of this type and thus are the method of choice for
high-resolution simulations. The scalability and time-to-solution of massively
parallel multilevel preconditioners can be adversely effected by using a
coarse-level solver with sub-optimal algorithmic complexity. To maintain
scalability, agglomeration techniques applied to the coarse level have been
shown to be necessary.
  In this work, we present a new software component introduced within the
Portable Extensible Toolkit for Scientific computation (PETSc) which permits
agglomeration. We provide an overview of the design and implementation of this
functionality, together with several use cases highlighting the benefits of
agglomeration. Lastly, we demonstrate via numerical experiments employing
geometric multigrid with structured meshes, the flexibility and performance
gains possible using our MPI-rank agglomeration implementation.
"
755,"Implementation of $hp$-adaptive discontinuous finite element methods in
  Dune-Fem","  In this paper we describe generic algorithms and data structures for the
implementation of $hp$-adaptive discontinuous finite element methods in the
Dune-Fem library. Special attention is given to the often tedious and
error-prone task of transferring user data during adaptation. Simultaneously,
we generalize the approach to the restriction and prolongation of data
currently implemented in Dune-Fem to the case of $p$- and $hp$-adaptation. The
dune-fem-hpdg module described in this paper provides an extensible reference
implementation of $hp$-adaptive discontinuous discrete function spaces. We give
details on its implementation and the extended adaptive interface. As proof of
concept we present the practical realization of an $hp$-adaptive interior
penalty method for elliptic problems.
"
756,UBL: an R package for Utility-based Learning,"  This document describes the R package UBL that allows the use of several
methods for handling utility-based learning problems. Classification and
regression problems that assume non-uniform costs and/or benefits pose serious
challenges to predictive analytic tasks. In the context of meteorology,
finance, medicine, ecology, among many other, specific domain information
concerning the preference bias of the users must be taken into account to
enhance the models predictive performance. To deal with this problem, a large
number of techniques was proposed by the research community for both
classification and regression tasks. The main goal of UBL package is to
facilitate the utility-based predictive analytic task by providing a set of
methods to deal with this type of problems in the R environment. It is a
versatile tool that provides mechanisms to handle both regression and
classification (binary and multiclass) tasks. Moreover, UBL package allows the
user to specify his domain preferences, but it also provides some automatic
methods that try to infer those preference bias from the domain, considering
some common known settings.
"
757,Computing Real Roots of Real Polynomials ... and now For Real!,"  Very recent work introduces an asymptotically fast subdivision algorithm,
denoted ANewDsc, for isolating the real roots of a univariate real polynomial.
The method combines Descartes' Rule of Signs to test intervals for the
existence of roots, Newton iteration to speed up convergence against clusters
of roots, and approximate computation to decrease the required precision. It
achieves record bounds on the worst-case complexity for the considered problem,
matching the complexity of Pan's method for computing all complex roots and
improving upon the complexity of other subdivision methods by several
magnitudes.
  In the article at hand, we report on an implementation of ANewDsc on top of
the RS root isolator. RS is a highly efficient realization of the classical
Descartes method and currently serves as the default real root solver in Maple.
We describe crucial design changes within ANewDsc and RS that led to a
high-performance implementation without harming the theoretical complexity of
the underlying algorithm.
  With an excerpt of our extensive collection of benchmarks, available online
at http://anewdsc.mpi-inf.mpg.de/, we illustrate that the theoretical gain in
performance of ANewDsc over other subdivision methods also transfers into
practice. These experiments also show that our new implementation outperforms
both RS and mature competitors by magnitudes for notoriously hard instances
with clustered roots. For all other instances, we avoid almost any overhead by
integrating additional optimizations and heuristics.
"
758,"High level implementation of geometric multigrid solvers for finite
  element problems: applications in atmospheric modelling","  The implementation of efficient multigrid preconditioners for elliptic
partial differential equations (PDEs) is a challenge due to the complexity of
the resulting algorithms and corresponding computer code. For sophisticated
finite element discretisations on unstructured grids an efficient
implementation can be very time consuming and requires the programmer to have
in-depth knowledge of the mathematical theory, parallel computing and
optimisation techniques on manycore CPUs. In this paper we show how the
development of bespoke multigrid preconditioners can be simplified
significantly by using a framework which allows the expression of the each
component of the algorithm at the correct abstraction level. Our approach (1)
allows the expression of the finite element problem in a language which is
close to the mathematical formulation of the problem, (2) guarantees the
automatic generation and efficient execution of parallel optimised low-level
computer code and (3) is flexible enough to support different abstraction
levels and give the programmer control over details of the preconditioner. We
use the composable abstractions of the Firedrake/PyOP2 package to demonstrate
the efficiency of this approach for the solution of strongly anisotropic PDEs
in atmospheric modelling. The weak formulation of the PDE is expressed in
Unified Form Language (UFL) and the lower PyOP2 abstraction layer allows the
manual design of computational kernels for a bespoke geometric multigrid
preconditioner. We compare the performance of this preconditioner to a
single-level method and hypre's BoomerAMG algorithm. The Firedrake/PyOP2 code
is inherently parallel and we present a detailed performance analysis for a
single node (24 cores) on the ARCHER supercomputer. Our implementation utilises
a significant fraction of the available memory bandwidth and shows very good
weak scaling on up to 6,144 compute cores.
"
759,"Blackbox: A procedure for parallel optimization of expensive black-box
  functions","  This note provides a description of a procedure that is designed to
efficiently optimize expensive black-box functions. It uses the response
surface methodology by incorporating radial basis functions as the response
model. A simple method based on a Latin hypercube is used for initial sampling.
A modified version of CORS algorithm with space rescaling is used for the
subsequent sampling. The procedure is able to scale on multicore processors by
performing multiple function evaluations in parallel. The source code of the
procedure is written in Python.
"
760,Implementing Strassen's Algorithm with BLIS,"  We dispel with ""street wisdom"" regarding the practical implementation of
Strassen's algorithm for matrix-matrix multiplication (DGEMM). Conventional
wisdom: it is only practical for very large matrices. Our implementation is
practical for small matrices. Conventional wisdom: the matrices being
multiplied should be relatively square. Our implementation is practical for
rank-k updates, where k is relatively small (a shape of importance for
libraries like LAPACK). Conventional wisdom: it inherently requires substantial
workspace. Our implementation requires no workspace beyond buffers already
incorporated into conventional high-performance DGEMM implementations.
Conventional wisdom: a Strassen DGEMM interface must pass in workspace. Our
implementation requires no such workspace and can be plug-compatible with the
standard DGEMM interface. Conventional wisdom: it is hard to demonstrate
speedup on multi-core architectures. Our implementation demonstrates speedup
over conventional DGEMM even on an Intel(R) Xeon Phi(TM) coprocessor utilizing
240 threads. We show how a distributed memory matrix-matrix multiplication also
benefits from these advances.
"
761,HLinear: Exact Dense Linear Algebra in Haskell,"  We present an implementation in the functional programming language Haskell
of the PLE decomposition of matrices over division rings. Our benchmarks
indicate that it is competitive with the C-based implementation provided in
Flint. Describing the guiding principles of our work, we introduce the reader
to basic ideas from high-performance functional programming.
"
762,"Theano: A Python framework for fast computation of mathematical
  expressions","  Theano is a Python library that allows to define, optimize, and evaluate
mathematical expressions involving multi-dimensional arrays efficiently. Since
its introduction, it has been one of the most used CPU and GPU mathematical
compilers - especially in the machine learning community - and has shown steady
performance improvements. Theano is being actively and continuously developed
since 2008, multiple frameworks have been built on top of it and it has been
used to produce many state-of-the-art machine learning models.
  The present article is structured as follows. Section I provides an overview
of the Theano software and its community. Section II presents the principal
features of Theano and how to use them, and compares them with other similar
projects. Section III focuses on recently-introduced functionalities and
improvements. Section IV compares the performance of Theano against Torch7 and
TensorFlow on several machine learning models. Section V discusses current
limitations of Theano and potential ways of improving it.
"
763,The polymake XML file format,"  We describe an XML file format for storing data from computations in algebra
and geometry. We also present a formal specification based on a RELAX-NG
schema.
"
764,"OPESCI-FD: Automatic Code Generation Package for Finite Difference
  Models","  In this project, we introduce OPESCI-FD, a Python package built on symbolic
mathematics to automatically generate Finite Difference models from a
high-level description of the model equations. We investigate applying this
framework to generate the propagator program used in seismic imaging. We
implement the 3D velocity-stress FD scheme as an example and demonstrate the
advantages of usability, flexibility and accuracy of the framework. The design
of OPESCI-FD aims to allow rapid development, analysis and optimisation of
Finite Difference programs. OPESCI-FD is the foundation for continuing
development by the OPESCI project team, building on the research presented in
this report. This report concludes by reviewing the further developments that
are already under way, as well as the scope for extension to cater for other
equations and numerical schemes.
"
765,"Boda-RTC: Productive Generation of Portable, Efficient Code for
  Convolutional Neural Networks on Mobile Computing Platforms","  The popularity of neural networks (NNs) spans academia, industry, and popular
culture. In particular, convolutional neural networks (CNNs) have been applied
to many image based machine learning tasks and have yielded strong results. The
availability of hardware/software systems for efficient training and deployment
of large and/or deep CNN models has been, and continues to be, an important
consideration for the field. Early systems for NN computation focused on
leveraging existing dense linear algebra techniques and libraries. Current
approaches use low-level machine specific programming and/or closed-source,
purpose-built vendor libraries. In this work, we present an open source system
that, compared to existing approaches, achieves competitive computational speed
while achieving higher portability. We achieve this by targeting the
vendor-neutral OpenCL platform using a code-generation approach. We argue that
our approach allows for both: (1) the rapid development of new computational
kernels for existing hardware targets, and (2) the rapid tuning of existing
computational kernels for new hardware targets. Results are presented for a
case study of targeting the Qualcomm Snapdragon 820 mobile computing platform
for CNN deployment.
"
766,Parallel Triangular Solvers on GPU,"  In this paper, we investigate GPU based parallel triangular solvers
systematically. The parallel triangular solvers are fundamental to incomplete
LU factorization family preconditioners and algebraic multigrid solvers. We
develop a new matrix format suitable for GPU devices. Parallel lower triangular
solvers and upper triangular solvers are developed for this new data structure.
With these solvers, ILU preconditioners and domain decomposition
preconditioners are developed. Numerical results show that we can speed
triangular solvers around seven times faster.
"
767,"Development of Krylov and AMG linear solvers for large-scale sparse
  matrices on GPUs","  This research introduce our work on developing Krylov subspace and AMG
solvers on NVIDIA GPUs. As SpMV is a crucial part for these iterative methods,
SpMV algorithms for single GPU and multiple GPUs are implemented. A HEC matrix
format and a communication mechanism are established. And also, a set of
specific algorithms for solving preconditioned systems in parallel environments
are designed, including ILU(k), RAS and parallel triangular solvers. Based on
these work, several Krylov solvers and AMG solvers are developed. According to
numerical experiments, favorable acceleration performance is acquired from our
Krylov solver and AMG solver under various parameter conditions.
"
768,"Conforming restricted Delaunay mesh generation for piecewise smooth
  complexes","  A Frontal-Delaunay refinement algorithm for mesh generation in piecewise
smooth domains is described. Built using a restricted Delaunay framework, this
new algorithm combines a number of novel features, including: (i) an
unweighted, conforming restricted Delaunay representation for domains specified
as a (non-manifold) collection of piecewise smooth surface patches and curve
segments, (ii) a protection strategy for domains containing curve segments that
subtend sharply acute angles, and (iii) a new class of off-centre refinement
rules designed to achieve high-quality point-placement along embedded curve
features. Experimental comparisons show that the new Frontal-Delaunay algorithm
outperforms a classical (statically weighted) restricted Delaunay-refinement
technique for a number of three-dimensional benchmark problems.
"
769,"Automatic finite element implementation of hyperelastic material with a
  double numerical differentiation algorithm","  In order to accelerate implementation of hyperelastic materials for finite
element analysis, we developed an automatic numerical algorithm that only
requires the strain energy function. This saves the effort on analytical
derivation and coding of stress and tangent modulus, which is time-consuming
and prone to human errors. Using the one-sided Newton difference quotients, the
proposed algorithm first perturbs deformation gradients and calculate the
difference on strain energy to approximate stress. Then, we perturb again to
get difference in stress to approximate tangent modulus. Accuracy of the
approximations were evaluated across the perturbation parameter space, where we
find the optimal amount of perturbation being $10^{-6}$ to obtain stress and
$10^{-4}$ to obtain tangent modulus. Single element verification in ABAQUS with
Neo-Hookean material resulted in a small stress error of only $7\times10^{-5}$
on average across uniaxial compression and tension, biaxial tension and simple
shear situations. A full 3D model with Holzapfel anisotropic material for
artery inflation generated a small relative error of $4\times10^{-6}$ for
inflated radius at $25 kPa$ pressure. Results of the verification tests suggest
that the proposed numerical method has good accuracy and convergence
performance, therefore a good material implementation algorithm in small scale
models and a useful debugging tool for large scale models.
"
770,"D2O - a distributed data object for parallel high-performance computing
  in Python","  We introduce D2O, a Python module for cluster-distributed multi-dimensional
numerical arrays. It acts as a layer of abstraction between the algorithm code
and the data-distribution logic. The main goal is to achieve usability without
losing numerical performance and scalability. D2O's global interface is similar
to the one of a numpy.ndarray, whereas the cluster node's local data is
directly accessible for use in customized high-performance modules. D2O is
written in pure Python which makes it portable and easy to use and modify.
Expensive operations are carried out by dedicated external libraries like numpy
and mpi4py. The performance of D2O is on a par with numpy for serial
applications and scales well when moving to an MPI cluster. D2O is open-source
software available under the GNU General Public License v3 (GPL-3) at
https://gitlab.mpcdf.mpg.de/ift/D2O
"
771,"Computing all Space Curve Solutions of Polynomial Systems by Polyhedral
  Methods","  A polyhedral method to solve a system of polynomial equations exploits its
sparse structure via the Newton polytopes of the polynomials. We propose a
hybrid symbolic-numeric method to compute a Puiseux series expansion for every
space curve that is a solution of a polynomial system. The focus of this paper
concerns the difficult case when the leading powers of the Puiseux series of
the space curve are contained in the relative interior of a higher dimensional
cone of the tropical prevariety. We show that this difficult case does not
occur for polynomials with generic coefficients. To resolve this case, we
propose to apply polyhedral end games to recover tropisms hidden in the
tropical prevariety.
"
772,Mathematical Foundations of the GraphBLAS,"  The GraphBLAS standard (GraphBlas.org) is being developed to bring the
potential of matrix based graph algorithms to the broadest possible audience.
Mathematically the Graph- BLAS defines a core set of matrix-based graph
operations that can be used to implement a wide class of graph algorithms in a
wide range of programming environments. This paper provides an introduction to
the mathematics of the GraphBLAS. Graphs represent connections between vertices
with edges. Matrices can represent a wide range of graphs using adjacency
matrices or incidence matrices. Adjacency matrices are often easier to analyze
while incidence matrices are often better for representing data. Fortunately,
the two are easily connected by matrix mul- tiplication. A key feature of
matrix mathematics is that a very small number of matrix operations can be used
to manipulate a very wide range of graphs. This composability of small number
of operations is the foundation of the GraphBLAS. A standard such as the
GraphBLAS can only be effective if it has low performance overhead. Performance
measurements of prototype GraphBLAS implementations indicate that the overhead
is low.
"
773,Benchmarking Python Tools for Automatic Differentiation,"  In this paper we compare several Python tools for automatic differentiation.
In order to assess the difference in performance and precision, the problem of
finding the optimal geometrical structure of the cluster with identical atoms
is used as follows. First, we compare performance of calculating gradients for
the objective function. We showed that the PyADOL-C and PyCppAD tools have much
better performance for big clusters than the other ones. Second, we assess
precision of these two tools by calculating the difference between the obtained
at the optimal configuration gradient norms. We conclude that PyCppAD has the
best performance among others, while having almost the same precision as the
second- best performing tool - PyADOL-C.
"
774,"Stochastic Runge-Kutta Software Package for Stochastic Differential
  Equations","  As a result of the application of a technique of multistep processes
stochastic models construction the range of models, implemented as a
self-consistent differential equations, was obtained. These are partial
differential equations (master equation, the Fokker--Planck equation) and
stochastic differential equations (Langevin equation). However, analytical
methods do not always allow to research these equations adequately. It is
proposed to use the combined analytical and numerical approach studying these
equations. For this purpose the numerical part is realized within the framework
of symbolic computation. It is recommended to apply stochastic Runge--Kutta
methods for numerical study of stochastic differential equations in the form of
the Langevin. Under this approach, a program complex on the basis of analytical
calculations metasystem Sage is developed. For model verification logarithmic
walks and Black--Scholes two-dimensional model are used. To illustrate the
stochastic ""predator--prey"" type model is used. The utility of the combined
numerical-analytical approach is demonstrated.
"
775,Computing hypergeometric functions rigorously,"  We present an efficient implementation of hypergeometric functions in
arbitrary-precision interval arithmetic. The functions ${}_0F_1$, ${}_1F_1$,
${}_2F_1$ and ${}_2F_0$ (or the Kummer $U$-function) are supported for
unrestricted complex parameters and argument, and by extension, we cover
exponential and trigonometric integrals, error functions, Fresnel integrals,
incomplete gamma and beta functions, Bessel functions, Airy functions, Legendre
functions, Jacobi polynomials, complete elliptic integrals, and other special
functions. The output can be used directly for interval computations or to
generate provably correct floating-point approximations in any format.
Performance is competitive with earlier arbitrary-precision software, and
sometimes orders of magnitude faster. We also partially cover the generalized
hypergeometric function ${}_pF_q$ and computation of high-order parameter
derivatives.
"
776,"From NoSQL Accumulo to NewSQL Graphulo: Design and Utility of Graph
  Algorithms inside a BigTable Database","  Google BigTable's scale-out design for distributed key-value storage inspired
a generation of NoSQL databases. Recently the NewSQL paradigm emerged in
response to analytic workloads that demand distributed computation local to
data storage. Many such analytics take the form of graph algorithms, a trend
that motivated the GraphBLAS initiative to standardize a set of matrix math
kernels for building graph algorithms. In this article we show how it is
possible to implement the GraphBLAS kernels in a BigTable database by
presenting the design of Graphulo, a library for executing graph algorithms
inside the Apache Accumulo database. We detail the Graphulo implementation of
two graph algorithms and conduct experiments comparing their performance to two
main-memory matrix math systems. Our results shed insight into the conditions
that determine when executing a graph algorithm is faster inside a database
versus an external system---in short, that memory requirements and relative I/O
are critical factors.
"
777,jInv -- a flexible Julia package for PDE parameter estimation,"  Estimating parameters of Partial Differential Equations (PDEs) from noisy and
indirect measurements often requires solving ill-posed inverse problems. These
so called parameter estimation or inverse medium problems arise in a variety of
applications such as geophysical, medical imaging, and nondestructive testing.
Their solution is computationally intense since the underlying PDEs need to be
solved numerous times until the reconstruction of the parameters is
sufficiently accurate. Typically, the computational demand grows significantly
when more measurements are available, which poses severe challenges to
inversion algorithms as measurement devices become more powerful.
  In this paper we present jInv, a flexible framework and open source software
that provides parallel algorithms for solving parameter estimation problems
with many measurements. Being written in the expressive programming language
Julia, jInv is portable, easy to understand and extend, cross-platform tested,
and well-documented. It provides novel parallelization schemes that exploit the
inherent structure of many parameter estimation problems and can be used to
solve multiphysics inversion problems as is demonstrated using numerical
experiments motivated by geophysical imaging.
"
778,Design of a high-performance GEMM-like Tensor-Tensor Multiplication,"  We present ""GEMM-like Tensor-Tensor multiplication"" (GETT), a novel approach
to tensor contractions that mirrors the design of a high-performance general
matrix-matrix multiplication (GEMM). The critical insight behind GETT is the
identification of three index sets, involved in the tensor contraction, which
enable us to systematically reduce an arbitrary tensor contraction to loops
around a highly tuned ""macro-kernel"". This macro-kernel operates on suitably
prepared (""packed"") sub-tensors that reside in a specified level of the cache
hierarchy. In contrast to previous approaches to tensor contractions, GETT
exhibits desirable features such as unit-stride memory accesses,
cache-awareness, as well as full vectorization, without requiring auxiliary
memory. To compare our technique with other modern tensor contractions, we
integrate GETT alongside the so called Transpose-Transpose-GEMM-Transpose and
Loops-over-GEMM approaches into an open source ""Tensor Contraction Code
Generator"" (TCCG). The performance results for a wide range of tensor
contractions suggest that GETT has the potential of becoming the method of
choice: While GETT exhibits excellent performance across the board, its
effectiveness for bandwidth-bound tensor contractions is especially impressive,
outperforming existing approaches by up to $12.4\times$. More precisely, GETT
achieves speedups of up to $1.41\times$ over an equivalent-sized GEMM for
bandwidth-bound tensor contractions while attaining up to $91.3\%$ of peak
floating-point performance for compute-bound tensor contractions.
"
779,High-Performance Tensor Contraction without Transposition,"  Tensor computations--in particular tensor contraction (TC)--are important
kernels in many scientific computing applications. Due to the fundamental
similarity of TC to matrix multiplication (MM) and to the availability of
optimized implementations such as the BLAS, tensor operations have
traditionally been implemented in terms of BLAS operations, incurring both a
performance and a storage overhead. Instead, we implement TC using the flexible
BLIS framework, which allows for transposition (reshaping) of the tensor to be
fused with internal partitioning and packing operations, requiring no explicit
transposition operations or additional workspace. This implementation, TBLIS,
achieves performance approaching that of MM, and in some cases considerably
higher than that of traditional TC. Our implementation supports multithreading
using an approach identical to that used for MM in BLIS, with similar
performance characteristics. The complexity of managing tensor-to-matrix
transformations is also handled automatically in our approach, greatly
simplifying its use in scientific applications.
"
780,Distributed-memory Hierarchical Interpolative Factorization,"  The hierarchical interpolative factorization (HIF) offers an efficient way
for solving or preconditioning elliptic partial differential equations. By
exploiting locality and low-rank properties of the operators, the HIF achieves
quasi-linear complexity for factorizing the discrete positive definite elliptic
operator and linear complexity for solving the associated linear system. In
this paper, the distributed-memory HIF (DHIF) is introduced as a parallel and
distributed-memory implementation of the HIF. The DHIF organizes the processes
in a hierarchical structure and keep the communication as local as possible.
The computation complexity is $O\left(\frac{N\log N}{P}\right)$ and
$O\left(\frac{N}{P}\right)$ for constructing and applying the DHIF,
respectively, where $N$ is the size of the problem and $P$ is the number of
processes. The communication complexity is $O\left(\sqrt{P}\log^3
P\right)\alpha + O\left(\frac{N^{2/3}}{\sqrt{P}}\right)\beta$ where $\alpha$ is
the latency and $\beta$ is the inverse bandwidth. Extensive numerical examples
are performed on the NERSC Edison system with up to 8192 processes. The
numerical results agree with the complexity analysis and demonstrate the
efficiency and scalability of the DHIF.
"
781,"Quasi-matrix-free hybrid multigrid on dynamically adaptive Cartesian
  grids","  We present a family of spacetree-based multigrid realizations using the
tree's multiscale nature to derive coarse grids. They align with matrix-free
geometric multigrid solvers as they never assemble the system matrices which is
cumbersome for dynamically adaptive grids and full multigrid. The most
sophisticated realizations use BoxMG to construct operator-dependent
prolongation and restriction in combination with Galerkin/Petrov-Galerkin
coarse-grid operators. This yields robust solvers for nontrivial elliptic
problems. We embed the algebraic, problem- and grid-dependent multigrid
operators as stencils into the grid and evaluate all matrix-vector products
in-situ throughout the grid traversals. While such an approach is not literally
matrix-free---the grid carries the matrix---we propose to switch to a
hierarchical representation of all operators. Only differences of algebraic
operators to their geometric counterparts are held. These hierarchical
differences can be stored and exchanged with small memory footprint. Our
realizations support arbitrary dynamically adaptive grids while they vertically
integrate the multilevel operations through spacetree linearization. This
yields good memory access characteristics, while standard colouring of mesh
entities with domain decomposition allows us to use parallel manycore clusters.
All realization ingredients are detailed such that they can be used by other
codes.
"
782,Using the pyMIC Offload Module in PyFR,"  PyFR is an open-source high-order accurate computational fluid dynamics
solver for unstructured grids. It is designed to efficiently solve the
compressible Navier-Stokes equations on a range of hardware platforms,
including GPUs and CPUs. In this paper we will describe how the Python Offload
Infrastructure for the Intel Many Integrated Core Architecture (pyMIC) was used
to enable PyFR to run with near native performance on the Intel Xeon Phi
coprocessor. We will introduce the architecture of both pyMIC and PyFR and
present a variety of examples showcasing the capabilities of pyMIC. Further, we
will also compare the contrast pyMIC to other approaches including native
execution and OpenCL. The process of adding support for pyMIC into PyFR will be
described in detail. Benchmark results show that for a standard cylinder flow
problem PyFR with pyMIC is able achieve 240 GFLOP/s of sustained double
precision floating point performance; for a 1.85 times improvement over PyFR
with C/OpenMP on a 12 core Intel Xeon E5-2697 v2 CPU.
"
783,"Massively parallel implementation in Python of a pseudo-spectral DNS
  code for turbulent flows","  Direct Numerical Simulations (DNS) of the Navier Stokes equations is a
valuable research tool in fluid dynamics, but there are very few publicly
available codes and, due to heavy number crunching, codes are usually written
in low-level languages. In this work a \textasciitilde{}100 line standard
scientific Python DNS code is described that nearly matches the performance of
pure C for thousands of processors and billions of unknowns. With optimization
of a few routines in Cython, it is found to match the performance of a more or
less identical solver implemented from scratch in C++. Keys to the efficiency
of the solver are the mesh decomposition and three dimensional FFT routines,
implemented directly in Python using MPI, wrapped through MPI for Python, and a
serial FFT module (both numpy.fft or pyFFTW may be used). Two popular
decomposition strategies, slab and pencil, have been implemented and tested.
"
784,"Best Practices for Replicability, Reproducibility and Reusability of
  Computer-Based Experiments Exemplified by Model Reduction Software","  Over the recent years the importance of numerical experiments has gradually
been more recognized. Nonetheless, sufficient documentation of how
computational results have been obtained is often not available. Especially in
the scientific computing and applied mathematics domain this is crucial, since
numerical experiments are usually employed to verify the proposed hypothesis in
a publication. This work aims to propose standards and best practices for the
setup and publication of numerical experiments. Naturally, this amounts to a
guideline for development, maintenance, and publication of numerical research
software. Such a primer will enable the replicability and reproducibility of
computer-based experiments and published results and also promote the
reusability of the associated software.
"
785,TTC: A Tensor Transposition Compiler for Multiple Architectures,"  We consider the problem of transposing tensors of arbitrary dimension and
describe TTC, an open source domain-specific parallel compiler. TTC generates
optimized parallel C++/CUDA C code that achieves a significant fraction of the
system's peak memory bandwidth. TTC exhibits high performance across multiple
architectures, including modern AVX-based systems (e.g.,~Intel Haswell, AMD
Steamroller), Intel's Knights Corner as well as different CUDA-based GPUs such
as NVIDIA's Kepler and Maxwell architectures. We report speedups of TTC over a
meaningful baseline implementation generated by external C++ compilers; the
results suggest that a domain-specific compiler can outperform its general
purpose counterpart significantly: For instance, comparing with Intel's latest
C++ compiler on the Haswell and Knights Corner architecture, TTC yields
speedups of up to $8\times$ and $32\times$, respectively. We also showcase
TTC's support for multiple leading dimensions, making it a suitable candidate
for the generation of performance-critical packing functions that are at the
core of the ubiquitous BLAS 3 routines.
"
786,"PRIMME_SVDS: A High-Performance Preconditioned SVD Solver for Accurate
  Large-Scale Computations","  The increasing number of applications requiring the solution of large scale
singular value problems have rekindled interest in iterative methods for the
SVD. Some promising recent ad- vances in large scale iterative methods are
still plagued by slow convergence and accuracy limitations for computing
smallest singular triplets. Furthermore, their current implementations in
MATLAB cannot address the required large problems. Recently, we presented a
preconditioned, two-stage method to effectively and accurately compute a small
number of extreme singular triplets. In this research, we present a
high-performance software, PRIMME SVDS, that implements our hybrid method based
on the state-of-the-art eigensolver package PRIMME for both largest and
smallest singular values. PRIMME SVDS fills a gap in production level software
for computing the partial SVD, especially with preconditioning. The numerical
experiments demonstrate its superior performance compared to other
state-of-the-art software and its good parallel performance under strong and
weak scaling.
"
787,"Accelerating eigenvector and pseudospectra computation using blocked
  multi-shift triangular solves","  Multi-shift triangular solves are basic linear algebra calculations with
applications in eigenvector and pseudospectra computation. We propose blocked
algorithms that efficiently exploit Level 3 BLAS to perform multi-shift
triangular solves and safe multi-shift triangular solves. Numerical experiments
indicate that computing triangular eigenvectors with a safe multi-shift
triangular solve achieves speedups by a factor of 60 relative to LAPACK. This
algorithm accelerates the calculation of general eigenvectors threefold. When
using multi-shift triangular solves to compute pseudospectra, we report
ninefold speedups relative to EigTool.
"
788,"Form Follows Function -- Do algorithms and applications challenge or
  drag behind the hardware evolution?","  We summarise some of the key statements made at the workshop Form Follows
Function at ISC High Performance 2016. The summary highlights what type of
co-design the presented projects experience; often in the absence of an
explicit co-design agenda. Their software development picks up hardware trends
but it also influences the hardware development. Observations illustrate that
this cycle not always is optimal for both sides as it is not proactively
steered. Key statements characterise ideas how it might be possible to
integrate both hardware and software creation closer to the best of both
worlds---again even without classic co-design in mind where new pieces of
hardware are created. The workshop finally identified three development idioms
that might help to improve software and system design with respect to emerging
hardware.
"
789,"The Vectorization of the Tersoff Multi-Body Potential: An Exercise in
  Performance Portability","  Molecular dynamics simulations, an indispensable research tool in
computational chemistry and materials science, consume a significant portion of
the supercomputing cycles around the world. We focus on multi-body potentials
and aim at achieving performance portability. Compared with well-studied pair
potentials, multibody potentials deliver increased simulation accuracy but are
too complex for effective compiler optimization. Because of this, achieving
cross-platform performance remains an open question. By abstracting from target
architecture and computing precision, we develop a vectorization scheme
applicable to both CPUs and accelerators. We present results for the Tersoff
potential within the molecular dynamics code LAMMPS on several architectures,
demonstrating efficiency gains not only for computational kernels, but also for
large-scale simulations. On a cluster of Intel Xeon Phi's, our optimized solver
is between 3 and 5 times faster than the pure MPI reference.
"
790,"Scheduling massively parallel multigrid for multilevel Monte Carlo
  methods","  The computational complexity of naive, sampling-based uncertainty
quantification for 3D partial differential equations is extremely high.
Multilevel approaches, such as multilevel Monte Carlo (MLMC), can reduce the
complexity significantly, but to exploit them fully in a parallel environment,
sophisticated scheduling strategies are needed. Often fast algorithms that are
executed in parallel are essential to compute fine level samples in 3D, whereas
to compute individual coarse level samples only moderate numbers of processors
can be employed efficiently. We make use of multiple instances of a parallel
multigrid solver combined with advanced load balancing techniques. In
particular, we optimize the concurrent execution across the three layers of the
MLMC method: parallelization across levels, across samples, and across the
spatial grid. The overall efficiency and performance of these methods will be
analyzed. Here the scalability window of the multigrid solver is revealed as
being essential, i.e., the property that the solution can be computed with a
range of process numbers while maintaining good parallel efficiency. We
evaluate the new scheduling strategies in a series of numerical tests, and
conclude the paper demonstrating large 3D scaling experiments.
"
791,Generalized Sampling in Julia,"  Generalized sampling is a numerically stable framework for obtaining
reconstructions of signals in different bases and frames from their samples. In
this paper, we will introduce a carefully documented toolbox for performing
generalized sampling in Julia. Julia is a new language for technical computing
with focus on performance, which is ideally suited to handle the large size
problems often encountered in generalized sampling. The toolbox provides
specialized solutions for the setup of Fourier bases and wavelets. The
performance of the toolbox is compared to existing implementations of
generalized sampling in MATLAB.
"
792,Finite Element Integration with Quadrature on the GPU,"  We present a novel, quadrature-based finite element integration method for
low-order elements on GPUs, using a pattern we call \textit{thread
transposition} to avoid reductions while vectorizing aggressively. On the
NVIDIA GTX580, which has a nominal single precision peak flop rate of 1.5 TF/s
and a memory bandwidth of 192 GB/s, we achieve close to 300 GF/s for element
integration on first-order discretization of the Laplacian operator with
variable coefficients in two dimensions, and over 400 GF/s in three dimensions.
From our performance model we find that this corresponds to 90\% of our
measured achievable bandwidth peak of 310 GF/s. Further experimental results
also match the predicted performance when used with double precision (120 GF/s
in two dimensions, 150 GF/s in three dimensions). Results obtained for the
linear elasticity equations (220 GF/s and 70 GF/s in two dimensions, 180 GF/s
and 60 GF/s in three dimensions) also demonstrate the applicability of our
method to vector-valued partial differential equations.
"
793,Composing Scalable Nonlinear Algebraic Solvers,"  Most efficient linear solvers use composable algorithmic components, with the
most common model being the combination of a Krylov accelerator and one or more
preconditioners. A similar set of concepts may be used for nonlinear algebraic
systems, where nonlinear composition of different nonlinear solvers may
significantly improve the time to solution. We describe the basic concepts of
nonlinear composition and preconditioning and present a number of solvers
applicable to nonlinear partial differential equations. We have developed a
software framework in order to easily explore the possible combinations of
solvers. We show that the performance gains from using composed solvers can be
substantial compared with gains from standard Newton-Krylov methods.
"
794,"Optimized Automatic Code Generation for Geometric Algebra Based
  Algorithms with Ray Tracing Application","  Automatic code generation for low-dimensional geometric algorithms is capable
of producing efficient low-level software code through a high-level geometric
domain specific language. Geometric Algebra (GA) is one of the most suitable
algebraic systems for being the base for such code generator. This work
presents an attempt at realizing such idea in practice. A novel GA-based
geometric code generator, called GMac, is proposed. Comparisons to similar
GA-based code generators are provided. The possibility of fully benefiting from
the symbolic power of GA while obtaining good performance and maintainability
of software implementations is illustrated through a ray tracing application.
"
795,Forward-Mode Automatic Differentiation in Julia,"  We present ForwardDiff, a Julia package for forward-mode automatic
differentiation (AD) featuring performance competitive with low-level languages
like C++. Unlike recently developed AD tools in other popular high-level
languages such as Python and MATLAB, ForwardDiff takes advantage of
just-in-time (JIT) compilation to transparently recompile AD-unaware user code,
enabling efficient support for higher-order differentiation and differentiation
using custom number types (including complex numbers). For gradient and
Jacobian calculations, ForwardDiff provides a variant of vector-forward mode
that avoids expensive heap allocation and makes better use of memory bandwidth
than traditional vector mode. In our numerical experiments, we demonstrate that
for nontrivially large dimensions, ForwardDiff's gradient computations can be
faster than a reverse-mode implementation from the Python-based autograd
package. We also illustrate how ForwardDiff is used effectively within JuMP, a
modeling language for optimization. According to our usage statistics, 41
unique repositories on GitHub depend on ForwardDiff, with users from diverse
fields such as astronomy, optimization, finite element analysis, and
statistics.
  This document is an extended abstract that has been accepted for presentation
at the AD2016 7th International Conference on Algorithmic Differentiation.
"
796,An Asynchronous Task-based Fan-Both Sparse Cholesky Solver,"  Systems of linear equations arise at the heart of many scientific and
engineering applications. Many of these linear systems are sparse; i.e., most
of the elements in the coefficient matrix are zero. Direct methods based on
matrix factorizations are sometimes needed to ensure accurate solutions. For
example, accurate solution of sparse linear systems is needed in shift-invert
Lanczos to compute interior eigenvalues. The performance and resource usage of
sparse matrix factorizations are critical to time-to-solution and maximum
problem size solvable on a given platform. In many applications, the
coefficient matrices are symmetric, and exploiting symmetry will reduce both
the amount of work and storage cost required for factorization. When the
factorization is performed on large-scale distributed memory platforms,
communication cost is critical to the performance of the algorithm. At the same
time, network topologies have become increasingly complex, so that modern
platforms exhibit a high level of performance variability. This makes
scheduling of computations an intricate and performance-critical task. In this
paper, we investigate the use of an asynchronous task paradigm, one-sided
communication and dynamic scheduling in implementing sparse Cholesky
factorization (symPACK) on large-scale distributed memory platforms. Our solver
symPACK relies on efficient and flexible communication primitives provided by
the UPC++ library. Performance evaluation shows good scalability and that
symPACK outperforms state-of-the-art parallel distributed memory factorization
packages, validating our approach on practical cases.
"
797,TRIOT: Faster tensor manipulation in C++11,"  [abridged] Context: Multidimensional arrays are used by many different
algorithms. As such, indexing and broadcasting complex operations over
multidimensional arrays are ubiquitous tasks and can be performance limiting.
Inquiry: Simultaneously indexing two or more multidimensional arrays with
different shapes (e.g., copying data from one tensor to another larger, zero
padded tensor in anticipation of a convolution) is difficult to do efficiently:
Hard-coded nested for loops in C, Fortran, and Go cannot be applied when the
dimension of a tensor is unknown at compile time. Likewise, boost::multi_array
cannot be used unless the dimensions of the array are known at compile time,
and the style of implementation restricts the user from using the index tuple
inside a vectorized operation (as would be required to compute an expected
value of a multidimensional distribution). On the other hand, iteration methods
that do not require the dimensionality or shape to be known at compile time
(e.g., incrementing and applying carry operations to index tuples or remapping
integer indices in the flat array), can be substantially slower than hard-coded
nested for loops. ... Importance: Manipulation of multidimensional arrays is a
common task in software, especially in high performance numerical methods. This
paper proposes a novel way to leverage template recursion to iterate over and
apply operations to multidimensional arrays, and then demonstrates the superior
performance and flexibility of operations that can be achieved using this new
approach.
"
798,"An exact, cache-localized algorithm for the sub-quadratic convolution of
  hypercubes","  Fast multidimensional convolution can be performed naively in quadratic time
and can often be performed more efficiently via the Fourier transform; however,
when the dimensionality is large, these algorithms become more challenging. A
method is proposed for performing exact hypercube convolution in sub-quadratic
time. The method outperforms FFTPACK, called via numpy, and FFTW, called via
pyfftw) for hypercube convolution. Embeddings in hypercubes can be paired with
sub-quadratic hypercube convolution method to construct sub-quadratic
algorithms for variants of vector convolution.
"
799,"R package imputeTestbench to compare imputations methods for univariate
  time series","  This paper describes the R package imputeTestbench that provides a testbench
for comparing imputation methods for missing data in univariate time series.
The imputeTestbench package can be used to simulate the amount and type of
missing data in a complete dataset and compare filled data using different
imputation methods. The user has the option to simulate missing data by
removing observations completely at random or in blocks of different sizes.
Several default imputation methods are included with the package, including
historical means, linear interpolation, and last observation carried forward.
The testbench is not limited to the default functions and users can add or
remove additional methods using a simple two-step process. The testbench
compares the actual missing and imputed data for each method with different
error metrics, including RMSE, MAE, and MAPE. Alternative error metrics can
also be supplied by the user. The simplicity of use and significant reduction
in time to compare imputation methods for missing data in univariate time
series is a significant advantage of the package. This paper provides an
overview of the core functions, including a demonstration with examples.
"
800,Randomized Matrix Decompositions using R,"  Matrix decompositions are fundamental tools in the area of applied
mathematics, statistical computing, and machine learning. In particular,
low-rank matrix decompositions are vital, and widely used for data analysis,
dimensionality reduction, and data compression. Massive datasets, however, pose
a computational challenge for traditional algorithms, placing significant
constraints on both memory and processing power. Recently, the powerful concept
of randomness has been introduced as a strategy to ease the computational load.
The essential idea of probabilistic algorithms is to employ some amount of
randomness in order to derive a smaller matrix from a high-dimensional data
matrix. The smaller matrix is then used to compute the desired low-rank
approximation. Such algorithms are shown to be computationally efficient for
approximating matrices with low-rank structure. We present the \proglang{R}
package rsvd, and provide a tutorial introduction to randomized matrix
decompositions. Specifically, randomized routines for the singular value
decomposition, (robust) principal component analysis, interpolative
decomposition, and CUR decomposition are discussed. Several examples
demonstrate the routines, and show the computational advantage over other
methods implemented in R.
"
801,Julia Implementation of the Dynamic Distributed Dimensional Data Model,"  Julia is a new language for writing data analysis programs that are easy to
implement and run at high performance. Similarly, the Dynamic Distributed
Dimensional Data Model (D4M) aims to clarify data analysis operations while
retaining strong performance. D4M accomplishes these goals through a
composable, unified data model on associative arrays. In this work, we present
an implementation of D4M in Julia and describe how it enables and facilitates
data analysis. Several experiments showcase scalable performance in our new
Julia version as compared to the original Matlab implementation.
"
802,"Computation of the incomplete gamma function for negative values of the
  argument","  An algorithm for computing the incomplete gamma function $\gamma^*(a,z)$ for
real values of the parameter $a$ and negative real values of the argument $z$
is presented. The algorithm combines the use of series expansions,
Poincar\'e-type expansions, uniform asymptotic expansions and recurrence
relations, depending on the parameter region. A relative accuracy $\sim
10^{-13}$ in the parameter region $(a,z) \in [-500,\,500] \times [-500,\,0)$
can be obtained when computing the function $\gamma^*(a,z)$ with the Fortran 90
module IncgamNEG implementing the algorithm.
"
803,"A Functional Package for Automatic Solution of Ordinary Differential
  Equations with Spectral Methods","  We present a Python module named PyCheb, to solve the ordinary differential
equations by using spectral collocation method. PyCheb incorporates
discretization using Chebyshev points, barycentric interpolation and iterate
methods. With this Python module, users can initialize the ODEsolver class by
passing attributes, including the both sides of a given differential equation,
boundary conditions, and the number of Chebyshev points, which can also be
generated automatically by the ideal precision, to the constructor of ODEsolver
class. Then, the instance of the ODEsolver class can be used to automatically
determine the resolution of the differential equation as well as generate the
graph of the high-precision approximate solution. (If you have any questions,
please send me an email and I will reply ASAP.
e-mail:shaohui_liu@qq.com/2013141482143@stu.scu.edu.cn)
"
804,"Containers for portable, productive and performant scientific computing","  Containers are an emerging technology that hold promise for improving
productivity and code portability in scientific computing. We examine Linux
container technology for the distribution of a non-trivial scientific computing
software stack and its execution on a spectrum of platforms from laptop
computers through to high performance computing (HPC) systems. We show on a
workstation and a leadership-class HPC system that when deployed appropriately
there are no performance penalties running scientific programs inside
containers. For Python code run on large parallel computers, the run time is
reduced inside a container due to faster library imports. The software
distribution approach and data that we present will help developers and users
decide on whether container technology is appropriate for them. We also provide
guidance for the vendors of HPC systems that rely on proprietary libraries for
performance on what they can do to make containers work seamlessly and without
performance penalty.
"
805,Devito: automated fast finite difference computation,"  Domain specific languages have successfully been used in a variety of fields
to cleanly express scientific problems as well as to simplify implementation
and performance opti- mization on different computer architectures. Although a
large number of stencil languages are available, finite differ- ence domain
specific languages have proved challenging to design because most practical use
cases require additional features that fall outside the finite difference
abstraction. Inspired by the complexity of real-world seismic imaging problems,
we introduce Devito, a domain specific language in which high level equations
are expressed using symbolic expressions from the SymPy package. Complex
equations are automatically manipulated, optimized, and translated into highly
optimized C code that aims to perform compa- rably or better than hand-tuned
code. All this is transpar- ent to users, who only see concise symbolic
mathematical expressions.
"
806,BLISlab: A Sandbox for Optimizing GEMM,"  Matrix-matrix multiplication is a fundamental operation of great importance
to scientific computing and, increasingly, machine learning. It is a simple
enough concept to be introduced in a typical high school algebra course yet in
practice important enough that its implementation on computers continues to be
an active research topic. This note describes a set of exercises that use this
operation to illustrate how high performance can be attained on modern CPUs
with hierarchical memories (multiple caches). It does so by building on the
insights that underly the BLAS-like Library Instantiation Software (BLIS)
framework by exposing a simplified ""sandbox"" that mimics the implementation in
BLIS. As such, it also becomes a vehicle for the ""crowd sourcing"" of the
optimization of BLIS. We call this set of exercises BLISlab.
"
807,Efficient computation of Laguerre polynomials,"  An efficient algorithm and a Fortran 90 module (LaguerrePol) for computing
Laguerre polynomials $L^{(\alpha)}_n(z)$ are presented. The standard three-term
recurrence relation satisfied by the polynomials and different types of
asymptotic expansions valid for $n$ large and $\alpha$ small, are used
depending on the parameter region.
  Based on tests of contiguous relations in the parameter $\alpha$ and the
degree $n$ satisfied by the polynomials, we claim that a relative accuracy
close or better than $10^{-12}$ can be obtained using the module LaguerrePol
for computing the functions $L^{(\alpha)}_n(z)$ in the parameter range $z \ge
0$, $-1 < \alpha \le 5$, $n \ge 0$.
"
808,Automatic Generation of Vectorized Montgomery Algorithm,"  Modular arithmetic is widely used in crytography and symbolic computation.
This paper presents a vectorized Montgomery algorithm for modular
multiplication, the key to fast modular arithmetic, that fully utilizes the
SIMD instructions. We further show how the vectorized algorithm can be
automatically generated by the {\SPIRAL} system, as part of the effort for
automatic generation of a modular polynomial multiplication library.
"
809,GTApprox: surrogate modeling for industrial design,"  We describe GTApprox - a new tool for medium-scale surrogate modeling in
industrial design. Compared to existing software, GTApprox brings several
innovations: a few novel approximation algorithms, several advanced methods of
automated model selection, novel options in the form of hints. We demonstrate
the efficiency of GTApprox on a large collection of test problems. In addition,
we describe several applications of GTApprox to real engineering problems.
"
810,"OpenSBLI: A framework for the automated derivation and parallel
  execution of finite difference solvers on a range of computer architectures","  Exascale computing will feature novel and potentially disruptive hardware
architectures. Exploiting these to their full potential is non-trivial.
Numerical modelling frameworks involving finite difference methods are
currently limited by the 'static' nature of the hand-coded discretisation
schemes and repeatedly may have to be re-written to run efficiently on new
hardware. In contrast, OpenSBLI uses code generation to derive the model's code
from a high-level specification. Users focus on the equations to solve, whilst
not concerning themselves with the detailed implementation. Source-to-source
translation is used to tailor the code and enable its execution on a variety of
hardware.
"
811,Nanosurveyor: a framework for real-time data processing,"  Scientists are drawn to synchrotrons and accelerator based light sources
because of their brightness, coherence and flux. The rate of improvement in
brightness and detector technology has outpaced Moore's law growth seen for
computers, networks, and storage, and is enabling novel observations and
discoveries with faster frame rates, larger fields of view, higher resolution,
and higher dimensionality. Here we present an integrated software/algorithmic
framework designed to capitalize on high throughput experiments, and describe
the streamlined processing pipeline of ptychography data analysis. The pipeline
provides throughput, compression, and resolution as well as rapid feedback to
the microscope operators.
"
812,Devito: Towards a generic Finite Difference DSL using Symbolic Python,"  Domain specific languages (DSL) have been used in a variety of fields to
express complex scientific problems in a concise manner and provide automated
performance optimization for a range of computational architectures. As such
DSLs provide a powerful mechanism to speed up scientific Python computation
that goes beyond traditional vectorization and pre-compilation approaches,
while allowing domain scientists to build applications within the comforts of
the Python software ecosystem. In this paper we present Devito, a new finite
difference DSL that provides optimized stencil computation from high-level
problem specifications based on symbolic Python expressions. We demonstrate
Devito's symbolic API and performance advantages over traditional Python
acceleration methods before highlighting its use in the scientific context of
seismic inversion problems.
"
813,Math-Aware Search Engines: Physics Applications and Overview,"  Search engines for equations now exist, which return results matching the
query's mathematical meaning or structural presentation. Operating over
scientific papers, online encyclopedias, and math discussion forums, their
content includes physics, math, and other sciences. They enable physicists to
avoid jargon and more easily target mathematical content within and across
disciplines. As a natural extension of keyword-based search, they open up a new
world for discovering both exact and approximate mathematical solutions;
physical systems' analogues and alternative models; and physics' patterns.
  This review presents the existing math-aware search engines, discusses
methods for maximizing their search success, and overviews their math-matching
capabilities. Proposed applications to physics are also given, to contribute
towards developers' and physicists' exploration of the newly available search
horizons.
"
814,cesium: Open-Source Platform for Time-Series Inference,"  Inference on time series data is a common requirement in many scientific
disciplines and internet of things (IoT) applications, yet there are few
resources available to domain scientists to easily, robustly, and repeatably
build such complex inference workflows: traditional statistical models of time
series are often too rigid to explain complex time domain behavior, while
popular machine learning packages require already-featurized dataset inputs.
Moreover, the software engineering tasks required to instantiate the
computational platform are daunting. cesium is an end-to-end time series
analysis framework, consisting of a Python library as well as a web front-end
interface, that allows researchers to featurize raw data and apply modern
machine learning techniques in a simple, reproducible, and extensible way.
Users can apply out-of-the-box feature engineering workflows as well as save
and replay their own analyses. Any steps taken in the front end can also be
exported to a Jupyter notebook, so users can iterate between possible models
within the front end and then fine-tune their analysis using the additional
capabilities of the back-end library. The open-source packages make us of many
use modern Python toolkits, including xarray, dask, Celery, Flask, and
scikit-learn.
"
815,"An object oriented parallel finite element scheme for computations of
  PDEs: Design and implementation","  Parallel finite element algorithms based on object-oriented concepts are
presented. Moreover, the design and implementation of a data structure proposed
are utilized in realizing a parallel geometric multigrid method. The
ParFEMapper and the ParFECommunicator are the key components of the data
structure in the proposed parallel scheme. These classes are constructed based
on the type of finite elements (continuous or nonconforming or discontinuous)
used. The proposed solver is compared with the open source direct solvers,
MUMPS and PasTiX. Further, the performance of the parallel multigrid solver is
analyzed up to 1080 processors. The solver shows a very good speedup up to 960
processors and the problem size has to be increased in order to maintain the
good speedup when the number of processors are increased further. As a result,
the parallel solver is able to handle large scale problems on massively
parallel supercomputers. The proposed parallel finite element algorithms and
multigrid solver are implemented in our in-house package ParMooN.
"
816,"Scaling betweenness centrality using communication-efficient sparse
  matrix multiplication","  Betweenness centrality (BC) is a crucial graph problem that measures the
significance of a vertex by the number of shortest paths leading through it. We
propose Maximal Frontier Betweenness Centrality (MFBC): a succinct BC algorithm
based on novel sparse matrix multiplication routines that performs a factor of
$p^{1/3}$ less communication on $p$ processors than the best known
alternatives, for graphs with $n$ vertices and average degree $k=n/p^{2/3}$. We
formulate, implement, and prove the correctness of MFBC for weighted graphs by
leveraging monoids instead of semirings, which enables a surprisingly succinct
formulation. MFBC scales well for both extremely sparse and relatively dense
graphs. It automatically searches a space of distributed data decompositions
and sparse matrix multiplication algorithms for the most advantageous
configuration. The MFBC implementation outperforms the well-known CombBLAS
library by up to 8x and shows more robust performance. Our design methodology
is readily extensible to other graph problems.
"
817,A Computer Algebra Package for Polynomial Sequence Recognition,"  The software package developed in the MS thesis research implements functions
for the intelligent guessing of polynomial sequence formulas based on
user-defined expected sequence factors of the input coefficients. We present a
specialized hybrid approach to finding exact representations for polynomial
sequences that is motivated by the need for an automated procedures to discover
the precise forms of these sums based on user guidance, or intuition, as to
special sequence factors present in the formulas. In particular, the package
combines the user input on the expected special sequence factors in the
polynomial coefficient formulas with calls to the existing functions as
subroutines that then process formulas for the remaining sequence terms already
recognized by these packages.
  The factorization-based approach to polynomial sequence recognition is unique
to this package and allows the search functions to find expressions for
polynomial sums involving Stirling numbers and other special triangular
sequences that are not readily handled by other software packages. In contrast
to many other sequence recognition and summation software, the package not
provide an explicit proof, or certificate, for the correctness of these
sequence formulas -- only computationally guided educated guesses at a complete
identity generating the sequence over all $n$. The thesis contains a number of
concrete, working examples of the package that are intended to both demonstrate
its usage and to document its current sequence recognition capabilities.
"
818,Benchmarking the Graphulo Processing Framework,"  Graph algorithms have wide applicablity to a variety of domains and are often
used on massive datasets. Recent standardization efforts such as the GraphBLAS
specify a set of key computational kernels that hardware and software
developers can adhere to. Graphulo is a processing framework that enables
GraphBLAS kernels in the Apache Accumulo database. In our previous work, we
have demonstrated a core Graphulo operation called \textit{TableMult} that
performs large-scale multiplication operations of database tables. In this
article, we present the results of scaling the Graphulo engine to larger
problems and scalablity when a greater number of resources is used.
Specifically, we present two experiments that demonstrate Graphulo scaling
performance is linear with the number of available resources. The first
experiment demonstrates cluster processing rates through Graphulo's TableMult
operator on two large graphs, scaled between $2^{17}$ and $2^{19}$ vertices.
The second experiment uses TableMult to extract a random set of rows from a
large graph ($2^{19}$ nodes) to simulate a cued graph analytic. These
benchmarking results are of relevance to Graphulo users who wish to apply
Graphulo to their graph problems.
"
819,Solving polynomial systems via homotopy continuation and monodromy,"  We study methods for finding the solution set of a generic system in a family
of polynomial systems with parametric coefficients. We present a framework for
describing monodromy based solvers in terms of decorated graphs. Under the
theoretical assumption that monodromy actions are generated uniformly, we show
that the expected number of homotopy paths tracked by an algorithm following
this framework is linear in the number of solutions. We demonstrate that our
software implementation is competitive with the existing state-of-the-art
methods implemented in other software packages.
"
820,"GPU Acceleration of Hermite Methods for the Simulation of Wave
  Propagation","  The Hermite methods of Goodrich, Hagstrom, and Lorenz (2006) use Hermite
interpolation to construct high order numerical methods for hyperbolic initial
value problems. The structure of the method has several favorable features for
parallel computing. In this work, we propose algorithms that take advantage of
the many-core architecture of Graphics Processing Units. The algorithm exploits
the compact stencil of Hermite methods and uses data structures that allow for
efficient data load and stores. Additionally the highly localized evolution
operator of Hermite methods allows us to combine multi-stage time-stepping
methods within the new algorithms incurring minimal accesses of global memory.
Using a scalar linear wave equation, we study the algorithm by considering
Hermite interpolation and evolution as individual kernels and alternatively
combined them into a monolithic kernel. For both approaches we demonstrate
strategies to increase performance. Our numerical experiments show that
although a two kernel approach allows for better performance on the hardware, a
monolithic kernel can offer a comparable time to solution with less global
memory usage.
"
821,Density Estimation with Distribution Element Trees,"  The estimation of probability densities based on available data is a central
task in many statistical applications. Especially in the case of large
ensembles with many samples or high-dimensional sample spaces, computationally
efficient methods are needed. We propose a new method that is based on a
decomposition of the unknown distribution in terms of so-called distribution
elements (DEs). These elements enable an adaptive and hierarchical
discretization of the sample space with small or large elements in regions with
smoothly or highly variable densities, respectively. The novel refinement
strategy that we propose is based on statistical goodness-of-fit and pair-wise
(as an approximation to mutual) independence tests that evaluate the local
approximation of the distribution in terms of DEs. The capabilities of our new
method are inspected based on several examples of different dimensionality and
successfully compared with other state-of-the-art density estimators.
"
822,Numerical Implicitization,"  We present the $\textit{NumericalImplicitization}$ package for
$\textit{Macaulay2}$, which allows for user-friendly computation of the
invariants of the image of a polynomial map, such as dimension, degree, and
Hilbert function values. This package relies on methods of numerical algebraic
geometry, including homotopy continuation and monodromy.
"
823,"Efficient Random Sampling -- Parallel, Vectorized, Cache-Efficient, and
  Online","  We consider the problem of sampling $n$ numbers from the range
$\{1,\ldots,N\}$ without replacement on modern architectures. The main result
is a simple divide-and-conquer scheme that makes sequential algorithms more
cache efficient and leads to a parallel algorithm running in expected time
$\mathcal{O}(n/p+\log p)$ on $p$ processors, i.e., scales to massively parallel
machines even for moderate values of $n$. The amount of communication between
the processors is very small (at most $\mathcal{O}(\log p)$) and independent of
the sample size. We also discuss modifications needed for load balancing,
online sampling, sampling with replacement, Bernoulli sampling, and
vectorization on SIMD units or GPUs.
"
824,"OpenMP, OpenMP/MPI, and CUDA/MPI C programs for solving the
  time-dependent dipolar Gross-Pitaevskii equation","  We present new versions of the previously published C and CUDA programs for
solving the dipolar Gross-Pitaevskii equation in one, two, and three spatial
dimensions, which calculate stationary and non-stationary solutions by
propagation in imaginary or real time. Presented programs are improved and
parallelized versions of previous programs, divided into three packages
according to the type of parallelization. First package contains improved and
threaded version of sequential C programs using OpenMP. Second package
additionally parallelizes three-dimensional variants of the OpenMP programs
using MPI, allowing them to be run on distributed-memory systems. Finally,
previous three-dimensional CUDA-parallelized programs are further parallelized
using MPI, similarly as the OpenMP programs. We also present speedup test
results obtained using new versions of programs in comparison with the previous
sequential C and parallel CUDA programs. The improvements to the sequential
version yield a speedup of 1.1 to 1.9, depending on the program. OpenMP
parallelization yields further speedup of 2 to 12 on a 16-core workstation,
while OpenMP/MPI version demonstrates a speedup of 11.5 to 16.5 on a computer
cluster with 32 nodes used. CUDA/MPI version shows a speedup of 9 to 10 on a
computer cluster with 32 nodes.
"
825,"Accelerating BLAS on Custom Architecture through Algorithm-Architecture
  Co-design","  Basic Linear Algebra Subprograms (BLAS) play key role in high performance and
scientific computing applications. Experimentally, yesteryear multicore and
General Purpose Graphics Processing Units (GPGPUs) are capable of achieving up
to 15 to 57% of the theoretical peak performance at 65W to 240W respectively
for compute bound operations like Double/Single Precision General Matrix
Multiplication (XGEMM). For bandwidth bound operations like Single/Double
precision Matrix-vector Multiplication (XGEMV) the performance is merely 5 to
7% of the theoretical peak performance in multicores and GPGPUs respectively.
Achieving performance in BLAS requires moving away from conventional wisdom and
evolving towards customized accelerator tailored for BLAS through
algorithm-architecture co-design. In this paper, we present acceleration of
Level-1 (vector operations), Level-2 (matrix-vector operations), and Level-3
(matrix-matrix operations) BLAS through algorithm architecture co-design on a
Coarse-grained Reconfigurable Architecture (CGRA). We choose REDEFINE CGRA as a
platform for our experiments since REDEFINE can be adapted to support domain of
interest through tailor-made Custom Function Units (CFUs). For efficient
sequential realization of BLAS, we present design of a Processing Element (PE)
and perform micro-architectural enhancements in the PE to achieve up-to 74% of
the theoretical peak performance of PE in DGEMM, 40% in DGEMV and 20% in double
precision inner product (DDOT). We attach this PE to REDEFINE CGRA as a CFU and
show the scalability of our solution. Finally, we show performance improvement
of 3-140x in PE over commercially available Intel micro-architectures,
ClearSpeed CSX700, FPGA, and Nvidia GPGPUs.
"
826,Large Scale Parallel Computations in R through Elemental,"  Even though in recent years the scale of statistical analysis problems has
increased tremendously, many statistical software tools are still limited to
single-node computations. However, statistical analyses are largely based on
dense linear algebra operations, which have been deeply studied, optimized and
parallelized in the high-performance-computing community. To make
high-performance distributed computations available for statistical analysis,
and thus enable large scale statistical computations, we introduce RElem, an
open source package that integrates the distributed dense linear algebra
library Elemental into R. While on the one hand, RElem provides direct wrappers
of Elemental's routines, on the other hand, it overloads various operators and
functions to provide an entirely native R experience for distributed
computations. We showcase how simple it is to port existing R programs to Relem
and demonstrate that Relem indeed allows to scale beyond the single-node
limitation of R with the full performance of Elemental without any overhead.
"
827,IB2d: a Python and MATLAB implementation of the immersed boundary method,"  The development of fluid-structure interaction (FSI) software involves
trade-offs between ease of use, generality, performance, and cost. Typically
there are large learning curves when using low-level software to model the
interaction of an elastic structure immersed in a uniform density fluid. Many
existing codes are not publicly available, and the commercial software that
exists usually requires expensive licenses and may not be as robust or allow
the necessary flexibility that in house codes can provide. We present an open
source immersed boundary software package, IB2d, with full implementations in
both MATLAB and Python, that is capable of running a vast range of biomechanics
models and is accessible to scientists who have experience in high-level
programming environments. IB2d contains multiple options for constructing
material properties of the fiber structure, as well as the advection-diffusion
of a chemical gradient, muscle mechanics models, and artificial forcing to
drive boundaries with a preferred motion.
"
828,The Reverse Cuthill-McKee Algorithm in Distributed-Memory,"  Ordering vertices of a graph is key to minimize fill-in and data structure
size in sparse direct solvers, maximize locality in iterative solvers, and
improve performance in graph algorithms. Except for naturally parallelizable
ordering methods such as nested dissection, many important ordering methods
have not been efficiently mapped to distributed-memory architectures. In this
paper, we present the first-ever distributed-memory implementation of the
reverse Cuthill-McKee (RCM) algorithm for reducing the profile of a sparse
matrix. Our parallelization uses a two-dimensional sparse matrix decomposition.
We achieve high performance by decomposing the problem into a small number of
primitives and utilizing optimized implementations of these primitives. Our
implementation shows strong scaling up to 1024 cores for smaller matrices and
up to 4096 cores for larger matrices.
"
829,The Probabilistic Model Checker Storm (Extended Abstract),"  We present a new probabilistic model checker Storm. Using state-of-the-art
libraries, we aim for both high performance and versatility. This extended
abstract gives a brief overview of the features of Storm.
"
830,"Performance evaluation of explicit finite difference algorithms with
  varying amounts of computational and memory intensity","  Future architectures designed to deliver exascale performance motivate the
need for novel algorithmic changes in order to fully exploit their
capabilities. In this paper, the performance of several numerical algorithms,
characterised by varying degrees of memory and computational intensity, are
evaluated in the context of finite difference methods for fluid dynamics
problems. It is shown that, by storing some of the evaluated derivatives as
single thread- or process-local variables in memory, or recomputing the
derivatives on-the-fly, a speed-up of ~2 can be obtained compared to
traditional algorithms that store all derivatives in global arrays.
"
831,Anisotropic mesh adaptation in Firedrake with PETSc DMPlex,"  Despite decades of research in this area, mesh adaptation capabilities are
still rarely found in numerical simulation software. We postulate that the
primary reason for this is lack of usability. Integrating mesh adaptation into
existing software is difficult as non-trivial operators, such as error metrics
and interpolation operators, are required, and integrating available adaptive
remeshers is not straightforward. Our approach presented here is to first
integrate Pragmatic, an anisotropic mesh adaptation library, into DMPlex, a
PETSc object that manages unstructured meshes and their interactions with
PETSc's solvers and I/O routines. As PETSc is already widely used, this will
make anisotropic mesh adaptation available to a much larger community. As a
demonstration of this we describe the integration of anisotropic mesh
adaptation into Firedrake, an automated Finite Element based system for the
portable solution of partial differential equations which already uses PETSc
solvers and I/O via DMPlex. We present a proof of concept of this integration
with a three-dimensional advection test case.
"
832,emgr - The Empirical Gramian Framework,"  System Gramian matrices are a well-known encoding for properties of
input-output systems such as controllability, observability or minimality.
These so-called system Gramians were developed in linear system theory for
applications such as model order reduction of control systems. Empirical
Gramian are an extension to the system Gramians for parametric and nonlinear
systems as well as a data-driven method of computation. The empirical Gramian
framework - emgr - implements the empirical Gramians in a uniform and
configurable manner, with applications such as Gramian-based (nonlinear) model
reduction, decentralized control, sensitivity analysis, parameter
identification and combined state and parameter reduction.
"
833,Generating Families of Practical Fast Matrix Multiplication Algorithms,"  Matrix multiplication (GEMM) is a core operation to numerous scientific
applications. Traditional implementations of Strassen-like fast matrix
multiplication (FMM) algorithms often do not perform well except for very large
matrix sizes, due to the increased cost of memory movement, which is
particularly noticeable for non-square matrices. Such implementations also
require considerable workspace and modifications to the standard BLAS
interface. We propose a code generator framework to automatically implement a
large family of FMM algorithms suitable for multiplications of arbitrary matrix
sizes and shapes. By representing FMM with a triple of matrices [U,V,W] that
capture the linear combinations of submatrices that are formed, we can use the
Kronecker product to define a multi-level representation of Strassen-like
algorithms. Incorporating the matrix additions that must be performed for
Strassen-like algorithms into the inherent packing and micro-kernel operations
inside GEMM avoids extra workspace and reduces the cost of memory movement.
Adopting the same loop structures as high-performance GEMM implementations
allows parallelization of all FMM algorithms with simple but efficient data
parallelism without the overhead of task parallelism. We present a simple
performance model for general FMM algorithms and compare actual performance of
20+ FMM algorithms to modeled predictions. Our implementations demonstrate a
performance benefit over conventional GEMM on single core and multi-core
systems. This study shows that Strassen-like fast matrix multiplication can be
incorporated into libraries for practical use.
"
834,"GFA: Exploratory Analysis of Multiple Data Sources with Group Factor
  Analysis","  The R package GFA provides a full pipeline for factor analysis of multiple
data sources that are represented as matrices with co-occurring samples. It
allows learning dependencies between subsets of the data sources, decomposed
into latent factors. The package also implements sparse priors for the
factorization, providing interpretable biclusters of the multi-source data
"
835,"GPU-Based Parallel Integration of Large Numbers of Independent ODE
  Systems","  The task of integrating a large number of independent ODE systems arises in
various scientific and engineering areas. For nonstiff systems, common explicit
integration algorithms can be used on GPUs, where individual GPU threads
concurrently integrate independent ODEs with different initial conditions or
parameters. One example is the fifth-order adaptive Runge-Kutta-Cash-Karp
(RKCK) algorithm. In the case of stiff ODEs, standard explicit algorithms
require impractically small time-step sizes for stability reasons, and implicit
algorithms are therefore commonly used instead to allow larger time steps and
reduce the computational expense. However, typical high-order implicit
algorithms based on backwards differentiation formulae (e.g., VODE, LSODE)
involve complex logical flow that causes severe thread divergence when
implemented on GPUs, limiting the performance. Therefore, alternate algorithms
are needed. A GPU-based Runge-Kutta-Chebyshev (RKC) algorithm can handle
moderate levels of stiffness and performs significantly faster than not only an
equivalent CPU version but also a CPU-based implicit algorithm (VODE) based on
results shown in the literature. In this chapter, we present the mathematical
background, implementation details, and source code for the RKCK and RKC
algorithms for use integrating large numbers of independent systems of ODEs on
GPUs. In addition, brief performance comparisons are shown for each algorithm,
demonstrating the potential benefit of moving to GPU-based ODE integrators.
"
836,Arb: Efficient Arbitrary-Precision Midpoint-Radius Interval Arithmetic,"  Arb is a C library for arbitrary-precision interval arithmetic using the
midpoint-radius representation, also known as ball arithmetic. It supports real
and complex numbers, polynomials, power series, matrices, and evaluation of
many special functions. The core number types are designed for versatility and
speed in a range of scenarios, allowing performance that is competitive with
non-interval arbitrary-precision types such as MPFR and MPC floating-point
numbers. We discuss the low-level number representation, strategies for
precision and error bounds, and the implementation of efficient polynomial
arithmetic with interval coefficients.
"
837,Binomial Checkpointing for Arbitrary Programs with No User Annotation,"  Heretofore, automatic checkpointing at procedure-call boundaries, to reduce
the space complexity of reverse mode, has been provided by systems like
Tapenade. However, binomial checkpointing, or treeverse, has only been provided
in Automatic Differentiation (AD) systems in special cases, e.g., through
user-provided pragmas on DO loops in Tapenade, or as the nested taping
mechanism in adol-c for time integration processes, which requires that user
code be refactored. We present a framework for applying binomial checkpointing
to arbitrary code with no special annotation or refactoring required. This is
accomplished by applying binomial checkpointing directly to a program trace.
This trace is produced by a general-purpose checkpointing mechanism that is
orthogonal to AD.
"
838,Efficient Implementation of a Higher-Order Language with Built-In AD,"  We show that Automatic Differentiation (AD) operators can be provided in a
dynamic language without sacrificing numeric performance. To achieve this,
general forward and reverse AD functions are added to a simple high-level
dynamic language, and support for them is included in an aggressive optimizing
compiler. Novel technical mechanisms are discussed, which have the ability to
migrate the AD transformations from run-time to compile-time. The resulting
system, although only a research prototype, exhibits startlingly good
performance. In fact, despite the potential inefficiencies entailed by support
of a functional-programming language and a first-class AD operator, performance
is competitive with the fastest available preprocessor-based Fortran AD
systems. On benchmarks involving nested use of the AD operators, it can even
dramatically exceed their performance.
"
839,DiffSharp: An AD Library for .NET Languages,"  DiffSharp is an algorithmic differentiation or automatic differentiation (AD)
library for the .NET ecosystem, which is targeted by the C# and F# languages,
among others. The library has been designed with machine learning applications
in mind, allowing very succinct implementations of models and optimization
routines. DiffSharp is implemented in F# and exposes forward and reverse AD
operators as general nestable higher-order functions, usable by any .NET
language. It provides high-performance linear algebra primitives---scalars,
vectors, and matrices, with a generalization to tensors underway---that are
fully supported by all the AD operators, and which use a BLAS/LAPACK backend
via the highly optimized OpenBLAS library. DiffSharp currently uses operator
overloading, but we are developing a transformation-based version of the
library using F#'s ""code quotation"" metaprogramming facility. Work on a
CUDA-based GPU backend is also underway.
"
840,"A Case for Malleable Thread-Level Linear Algebra Libraries: The LU
  Factorization with Partial Pivoting","  We propose two novel techniques for overcoming load-imbalance encountered
when implementing so-called look-ahead mechanisms in relevant dense matrix
factorizations for the solution of linear systems. Both techniques target the
scenario where two thread teams are created/activated during the factorization,
with each team in charge of performing an independent task/branch of execution.
The first technique promotes worker sharing (WS) between the two tasks,
allowing the threads of the task that completes first to be reallocated for use
by the costlier task. The second technique allows a fast task to alert the
slower task of completion, enforcing the early termination (ET) of the second
task, and a smooth transition of the factorization procedure into the next
iteration.
  The two mechanisms are instantiated via a new malleable thread-level
implementation of the Basic Linear Algebra Subprograms (BLAS), and their
benefits are illustrated via an implementation of the LU factorization with
partial pivoting enhanced with look-ahead. Concretely, our experimental results
on a six core Intel-Xeon processor show the benefits of combining WS+ET,
reporting competitive performance in comparison with a task-parallel
runtime-based solution.
"
841,Bidiagonalization with Parallel Tiled Algorithms,"  We consider algorithms for going from a ""full"" matrix to a condensed ""band
bidiagonal"" form using orthogonal transformations. We use the framework of
""algorithms by tiles"". Within this framework, we study: (i) the tiled
bidiagonalization algorithm BiDiag, which is a tiled version of the standard
scalar bidiagonalization algorithm; and (ii) the R-bidiagonalization algorithm
R-BiDiag, which is a tiled version of the algorithm which consists in first
performing the QR factorization of the initial matrix, then performing the
band-bidiagonalization of the R-factor. For both bidiagonalization algorithms
BiDiag and R-BiDiag, we use four main types of reduction trees, namely FlatTS,
FlatTT, Greedy, and a newly introduced auto-adaptive tree, Auto. We provide a
study of critical path lengths for these tiled algorithms, which shows that (i)
R-BiDiag has a shorter critical path length than BiDiag for tall and skinny
matrices, and (ii) Greedy based schemes are much better than earlier proposed
variants with unbounded resources. We provide experiments on a single multicore
node, and on a few multicore nodes of a parallel distributed shared-memory
system, to show the superiority of the new algorithms on a variety of matrix
sizes, matrix shapes and core counts.
"
842,"A Metaprogramming and Autotuning Framework for Deploying Deep Learning
  Applications","  In recent years, deep neural networks (DNNs), have yielded strong results on
a wide range of applications. Graphics Processing Units (GPUs) have been one
key enabling factor leading to the current popularity of DNNs. However, despite
increasing hardware flexibility and software programming toolchain maturity,
high efficiency GPU programming remains difficult: it suffers from high
complexity, low productivity, and low portability. GPU vendors such as NVIDIA
have spent enormous effort to write special-purpose DNN libraries. However, on
other hardware targets, especially mobile GPUs, such vendor libraries are not
generally available. Thus, the development of portable, open, high-performance,
energy-efficient GPU code for DNN operations would enable broader deployment of
DNN-based algorithms. Toward this end, this work presents a framework to enable
productive, high-efficiency GPU programming for DNN computations across
hardware platforms and programming models. In particular, the framework
provides specific support for metaprogramming, autotuning, and DNN-tailored
data types. Using our framework, we explore implementing DNN operations on
three different hardware targets: NVIDIA, AMD, and Qualcomm GPUs. On NVIDIA
GPUs, we show both portability between OpenCL and CUDA as well competitive
performance compared to the vendor library. On Qualcomm GPUs, we show that our
framework enables productive development of target-specific optimizations, and
achieves reasonable absolute performance. Finally, On AMD GPUs, we show initial
results that indicate our framework can yield reasonable performance on a new
platform with minimal effort.
"
843,dMath: Distributed Linear Algebra for DL,"  The paper presents a parallel math library, dMath, that demonstrates leading
scaling when using intranode, internode, and hybrid-parallelism for deep
learning (DL). dMath provides easy-to-use distributed primitives and a variety
of domain-specific algorithms including matrix multiplication, convolutions,
and others allowing for rapid development of scalable applications like deep
neural networks (DNNs). Persistent data stored in GPU memory and advanced
memory management techniques avoid costly transfers between host and device.
dMath delivers performance, portability, and productivity to its specific
domain of support.
"
844,Automating the Last-Mile for High Performance Dense Linear Algebra,"  High performance dense linear algebra (DLA) libraries often rely on a general
matrix multiply (Gemm) kernel that is implemented using assembly or with vector
intrinsics. In particular, the real-valued Gemm kernels provide the
overwhelming fraction of performance for the complex-valued Gemm kernels, along
with the entire level-3 BLAS and many of the real and complex LAPACK routines.
Thus,achieving high performance for the Gemm kernel translates into a high
performance linear algebra stack above this kernel. However, it is a monumental
task for a domain expert to manually implement the kernel for every
library-supported architecture. This leads to the belief that the craft of a
Gemm kernel is more dark art than science. It is this premise that drives the
popularity of autotuning with code generation in the domain of DLA.
  This paper, instead, focuses on an analytical approach to code generation of
the Gemm kernel for different architecture, in order to shed light on the
details or voo-doo required for implementing a high performance Gemm kernel. We
distill the implementation of the kernel into an even smaller kernel, an
outer-product, and analytically determine how available SIMD instructions can
be used to compute the outer-product efficiently. We codify this approach into
a system to automatically generate a high performance SIMD implementation of
the Gemm kernel. Experimental results demonstrate that our approach yields
generated kernels with performance that is competitive with kernels implemented
manually or using empirical search.
"
845,Verifying Integer Programming Results,"  Software for mixed-integer linear programming can return incorrect results
for a number of reasons, one being the use of inexact floating-point
arithmetic. Even solvers that employ exact arithmetic may suffer from
programming or algorithmic errors, motivating the desire for a way to produce
independently verifiable certificates of claimed results. Due to the complex
nature of state-of-the-art MILP solution algorithms, the ideal form of such a
certificate is not entirely clear. This paper proposes such a certificate
format, illustrating its capabilities and structure through examples. The
certificate format is designed with simplicity in mind and is composed of a
list of statements that can be sequentially verified using a limited number of
simple yet powerful inference rules. We present a supplementary verification
tool for compressing and checking these certificates independently of how they
were created. We report computational results on a selection of mixed-integer
linear programming instances from the literature. To this end, we have extended
the exact rational version of the MIP solver SCIP to produce such certificates.
"
846,Moore: Interval Arithmetic in Modern C++,"  We present the library Moore, which implements Interval Arithmetic in modern
C++. This library is based on a new feature in the C++ language called
concepts, which reduces the problems caused by template meta programming, and
leads to a new approach for implementing interval arithmetic libraries in C++.
"
847,"Implementation and evaluation of data-compression algorithms for
  irregular-grid iterative methods on the PEZY-SC processor","  Iterative methods on irregular grids have been used widely in all areas of
comptational science and engineering for solving partial differential equations
with complex geometry. They provide the flexibility to express complex shapes
with relatively low computational cost. However, the direction of the evolution
of high-performance processors in the last two decades have caused serious
degradation of the computational efficiency of iterative methods on irregular
grids, because of relatively low memory bandwidth. Data compression can in
principle reduce the necessary memory memory bandwidth of iterative methods and
thus improve the efficiency. We have implemented several data compression
algorithms on the PEZY-SC processor, using the matrix generated for the HPCG
benchmark as an example. For the SpMV (Sparse Matrix-Vector multiplication)
part of the HPCG benchmark, the best implementation without data compression
achieved 11.6Gflops/chip, close to the theoretical limit due to the memory
bandwidth. Our implementation with data compression has achieved 32.4Gflops.
This is of course rather extreme case, since the grid used in HPCG is
geometrically regular and thus its compression efficiency is very high.
However, in real applications, it is in many cases possible to make a large
part of the grid to have regular geometry, in particular when the resolution is
high. Note that we do not need to change the structure of the program, except
for the addition of the data compression/decompression subroutines. Thus, we
believe the data compression will be very useful way to improve the performance
of many applications which rely on the use of irregular grids.
"
848,"An initial investigation of the performance of GPU-based swept
  time-space decomposition","  Simulations of physical phenomena are essential to the expedient design of
precision components in aerospace and other high-tech industries. These
phenomena are often described by mathematical models involving partial
differential equations (PDEs) without exact solutions. Modern design problems
require simulations with a level of resolution that is difficult to achieve in
a reasonable amount of time even in effectively parallelized solvers. Though
the scale of the problem relative to available computing power is the greatest
impediment to accelerating these applications, significant performance gains
can be achieved through careful attention to the details of memory accesses.
Parallelized PDE solvers are subject to a trade-off in memory management: store
the solution for each timestep in abundant, global memory with high access
costs or in a limited, private memory with low access costs that must be passed
between nodes. The GPU implementation of swept time-space decomposition
presented here mitigates this dilemma by using private (shared) memory,
avoiding internode communication, and overwriting unnecessary values. It shows
significant improvement in the execution time of the PDE solvers in one
dimension achieving speedups of 6-2x for large and small problem sizes
respectively compared to naive GPU versions and 7-300x compared to parallel CPU
versions.
"
849,SimTensor: A synthetic tensor data generator,"  SimTensor is a multi-platform, open-source software for generating artificial
tensor data (either with CP/PARAFAC or Tucker structure) for reproducible
research on tensor factorization algorithms. SimTensor is a stand-alone
application based on MATALB. It provides a wide range of facilities for
generating tensor data with various configurations. It comes with a
user-friendly graphical user interface, which enables the user to generate
tensors with complicated settings in an easy way. It also has this facility to
export generated data to universal formats such as CSV and HDF5, which can be
imported via a wide range of programming languages (C, C++, Java, R, Fortran,
MATLAB, Perl, Python, and many more). The most innovative part of SimTensor is
this that can generate temporal tensors with periodic waves, seasonal effects
and streaming structure. it can apply constraints such as non-negativity and
different kinds of sparsity to the data. SimTensor also provides this facility
to simulate different kinds of change-points and inject various types of
anomalies. The source code and binary versions of SimTensor is available for
download in http://www.simtensor.org.
"
850,"Efficient Realization of Householder Transform through
  Algorithm-Architecture Co-design for Acceleration of QR Factorization","  We present efficient realization of Householder Transform (HT) based QR
factorization through algorithm-architecture co-design where we achieve
performance improvement of 3-90x in-terms of Gflops/watt over state-of-the-art
multicore, General Purpose Graphics Processing Units (GPGPUs), Field
Programmable Gate Arrays (FPGAs), and ClearSpeed CSX700. Theoretical and
experimental analysis of classical HT is performed for opportunities to exhibit
higher degree of parallelism where parallelism is quantified as a number of
parallel operations per level in the Directed Acyclic Graph (DAG) of the
transform. Based on theoretical analysis of classical HT, an opportunity
re-arrange computations in the classical HT is identified that results in
Modified HT (MHT) where it is shown that MHT exhibits 1.33x times higher
parallelism than classical HT. Experiments in off-the-shelf multicore and
General Purpose Graphics Processing Units (GPGPUs) for HT and MHT suggest that
MHT is capable of achieving slightly better or equal performance compared to
classical HT based QR factorization realizations in the optimized software
packages for Dense Linear Algebra (DLA). We implement MHT on a customized
platform for Dense Linear Algebra (DLA) and show that MHT achieves 1.3x better
performance than native implementation of classical HT on the same accelerator.
For custom realization of HT and MHT based QR factorization, we also identify
macro operations in the DAGs of HT and MHT that are realized on a
Reconfigurable Data-path (RDP). We also observe that due to re-arrangement in
the computations in MHT, custom realization of MHT is capable of achieving 12%
better performance improvement over multicore and GPGPUs than the performance
improvement reported by General Matrix Multiplication (GEMM) over highly tuned
DLA software packages for multicore and GPGPUs which is counter-intuitive.
"
851,"The Method of Gauss-Newton to Compute Power Series Solutions of
  Polynomial Homotopies","  We consider the extension of the method of Gauss-Newton from complex
floating-point arithmetic to the field of truncated power series with complex
floating-point coefficients. With linearization we formulate a linear system
where the coefficient matrix is a series with matrix coefficients, and provide
a characterization for when the matrix series is regular based on the algebraic
variety of an augmented system. The structure of the linear system leads to a
block triangular system. In the regular case, solving the linear system is
equivalent to solving a Hermite interpolation problem. We show that this
solution has cost cubic in the problem size. In general, at singular points, we
rely on methods of tropical algebraic geometry to compute Puiseux series. With
a few illustrative examples, we demonstrate the application to polynomial
homotopy continuation.
"
852,Parallel Integer Polynomial Multiplication,"  We propose a new algorithm for multiplying dense polynomials with integer
coefficients in a parallel fashion, targeting multi-core processor
architectures. Complexity estimates and experimental comparisons demonstrate
the advantages of this new approach.
"
853,"An efficient hybrid tridiagonal divide-and-conquer algorithm on
  distributed memory architectures","  In this paper, an efficient divide-and-conquer (DC) algorithm is proposed for
the symmetric tridiagonal matrices based on ScaLAPACK and the hierarchically
semiseparable (HSS) matrices. HSS is an important type of rank-structured
matrices.Most time of the DC algorithm is cost by computing the eigenvectors
via the matrix-matrix multiplications (MMM). In our parallel hybrid DC (PHDC)
algorithm, MMM is accelerated by using the HSS matrix techniques when the
intermediate matrix is large. All the HSS algorithms are done via the package
STRUMPACK. PHDC has been tested by using many different matrices. Compared with
the DC implementation in MKL, PHDC can be faster for some matrices with few
deflations when using hundreds of processes. However, the gains decrease as the
number of processes increases. The comparisons of PHDC with ELPA (the
Eigenvalue soLvers for Petascale Applications library) are similar. PHDC is
usually slower than MKL and ELPA when using 300 or more processes on Tianhe-2
supercomputer.
"
854,BSEPACK User's Guide,"  This is the user manual for the software package BSEPACK (Bethe--Salpeter
Eigenvalue Solver Package).
"
855,Node Aware Sparse Matrix-Vector Multiplication,"  The sparse matrix-vector multiply (SpMV) operation is a key computational
kernel in many simulations and linear solvers. The large communication
requirements associated with a reference implementation of a parallel SpMV
result in poor parallel scalability. The cost of communication depends on the
physical locations of the send and receive processes: messages injected into
the network are more costly than messages sent between processes on the same
node. In this paper, a node aware parallel SpMV (NAPSpMV) is introduced to
exploit knowledge of the system topology, specifically the node-processor
layout, to reduce costs associated with communication. The values of the input
vector are redistributed to minimize both the number and the size of messages
that are injected into the network during a SpMV, leading to a reduction in
communication costs. A variety of computational experiments that highlight the
efficiency of this approach are presented.
"
856,"The Unum Number Format: Mathematical Foundations, Implementation and
  Comparison to IEEE 754 Floating-Point Numbers","  This thesis examines a modern concept for machine numbers based on interval
arithmetic called 'Unums' and compares it to IEEE 754 floating-point
arithmetic, evaluating possible uses of this format where floating-point
numbers are inadequate. In the course of this examination, this thesis builds
theoretical foundations for IEEE 754 floating-point numbers, interval
arithmetic based on the projectively extended real numbers and Unums.
"
857,DyNet: The Dynamic Neural Network Toolkit,"  We describe DyNet, a toolkit for implementing neural network models based on
dynamic declaration of network structure. In the static declaration strategy
that is used in toolkits like Theano, CNTK, and TensorFlow, the user first
defines a computation graph (a symbolic representation of the computation), and
then examples are fed into an engine that executes this computation and
computes its derivatives. In DyNet's dynamic declaration strategy, computation
graph construction is mostly transparent, being implicitly constructed by
executing procedural code that computes the network outputs, and the user is
free to use different network structures for each input. Dynamic declaration
thus facilitates the implementation of more complicated network architectures,
and DyNet is specifically designed to allow users to implement their models in
a way that is idiomatic in their preferred programming language (C++ or
Python). One challenge with dynamic declaration is that because the symbolic
computation graph is defined anew for every training example, its construction
must have low overhead. To achieve this, DyNet has an optimized C++ backend and
lightweight graph representation. Experiments show that DyNet's speeds are
faster than or comparable with static declaration toolkits, and significantly
faster than Chainer, another dynamic declaration toolkit. DyNet is released
open-source under the Apache 2.0 license and available at
http://github.com/clab/dynet.
"
858,"A task-driven implementation of a simple numerical solver for hyperbolic
  conservation laws","  This article describes the implementation of an all-in-one numerical
procedure within the runtime StarPU. In order to limit the complexity of the
method, for the sake of clarity of the presentation of the non-classical
task-driven programming environnement, we have limited the numerics to first
order in space and time. Results show that the task distribution is efficient
if the tasks are numerous and individually large enough so that the task heap
can be saturated by tasks which computational time covers the task management
overhead. Next, we also see that even though they are mostly faster on graphic
cards, not all the tasks are suitable for GPUs, which brings forward the
importance of the task scheduler. Finally, we look at a more realistic system
of conservation laws with an expensive source term, what allows us to conclude
and open on future works involving higher local arithmetic intensity, by
increasing the order of the numerical method or by enriching the model
(increased number of parameters and therefore equations).
"
859,"Scalable linear solvers for sparse linear systems from large-scale
  numerical simulations","  This paper presents our work on designing scalable linear solvers for
large-scale reservoir simulations. The main objective is to support
implementation of parallel reservoir simulators on distributed-memory parallel
systems, where MPI (Message Passing Interface) is employed for communications
among computation nodes. Distributed matrix and vector modules are designed,
which are the base of our parallel linear systems. Commonly-used Krylov
subspace linear solvers are implemented, including the restarted GMRES method,
the LGMRES method, and the BiCGSTAB method. It also has an interface to a
parallel algebraic multigrid solver, BoomerAMG from HYPRE. Parallel
general-purpose preconditioners and special preconditioners for reservoir
simulations are also developed. The numerical experiments show that our linear
solvers have excellent scalability using thousands of CPU cores.
"
860,gearshifft - The FFT Benchmark Suite for Heterogeneous Platforms,"  Fast Fourier Transforms (FFTs) are exploited in a wide variety of fields
ranging from computer science to natural sciences and engineering. With the
rising data production bandwidths of modern FFT applications, judging best
which algorithmic tool to apply, can be vital to any scientific endeavor. As
tailored FFT implementations exist for an ever increasing variety of high
performance computer hardware, choosing the best performing FFT implementation
has strong implications for future hardware purchase decisions, for resources
FFTs consume and for possibly decisive financial and time savings ahead of the
competition. This paper therefor presents gearshifft, which is an open-source
and vendor agnostic benchmark suite to process a wide variety of problem sizes
and types with state-of-the-art FFT implementations (fftw, clfft and cufft).
gearshifft provides a reproducible, unbiased and fair comparison on a wide
variety of hardware to explore which FFT variant is best for a given problem
size.
"
861,"Manyopt: An Extensible Tool for Mixed, Non-Linear Optimization Through
  SMT Solving","  Optimization of Mixed-Integer Non-Linear Programming (MINLP) supports
important decisions in applications such as Chemical Process Engineering. But
current solvers have limited ability for deductive reasoning or the use of
domain-specific theories, and the management of integrality constraints does
not yet exploit automated reasoning tools such as SMT solvers. This seems to
limit both scalability and reach of such tools in practice. We therefore
present a tool, ManyOpt, for MINLP optimization that enables experimentation
with reduction techniques which transform a MINLP problem to feasibility
checking realized by an SMT solver. ManyOpt is similar to the SAT solver
ManySAT in that it runs a specified number of such reduction techniques in
parallel to get the strongest result on a given MINLP problem. The tool is
implemented in layers, which we may see as features and where reduction
techniques are feature vectors. Some of these features are inspired by known
MINLP techniques whereas others are novel and specific to SMT. Our experimental
results on standard benchmarks demonstrate the benefits of this approach. The
tool supports a variety of SMT solvers and is easily extensible with new
features, courtesy of its layered structure. For example, logical formulas for
deductive reasoning are easily added to constrain further the optimization of a
MINLP problem of interest.
"
862,"A scikit-based Python environment for performing multi-label
  classification","  scikit-multilearn is a Python library for performing multi-label
classification. The library is compatible with the scikit/scipy ecosystem and
uses sparse matrices for all internal operations. It provides native Python
implementations of popular multi-label classification methods alongside a novel
framework for label space partitioning and division. It includes modern
algorithm adaptation methods, network-based label space division approaches,
which extracts label dependency information and multi-label embedding
classifiers. It provides python wrapped access to the extensive multi-label
method stack from Java libraries and makes it possible to extend deep learning
single-label methods for multi-label tasks. The library allows multi-label
stratification and data set management. The implementation is more efficient in
problem transformation than other established libraries, has good test coverage
and follows PEP8. Source code and documentation can be downloaded from
http://scikit.ml and also via pip. The library follows BSD licensing scheme.
"
863,Simflowny 2: An upgraded platform for scientific modeling and simulation,"  Simflowny is an open platform which automatically generates parallel code of
scientific dynamical models for different simulation frameworks. Here we
present major upgrades on this software to support an extended set of families
of models, in particular: i) a new generic family for partial differential
equations, which can include spatial derivatives of any order, ii) a new family
for agent based models to study complex phenomena --either on a spatial domain
or on a graph--. Additionally we introduce a flexible graphical user interface
(GUI) to accommodate these and future families of equations. This paper
describes the new GUI architecture and summarizes the formal representation and
implementation of these new families, providing several validation results.
"
864,"Scalar and Tensor Parameters for Importing Tensor Index Notation
  including Einstein Summation Notation","  In this paper, we propose a method for importing tensor index notation,
including Einstein summation notation, into functional programming. This method
involves introducing two types of parameters, i.e, scalar and tensor
parameters, and simplified tensor index rules that do not handle expressions
that are valid only for the Cartesian coordinate system, in which the index can
move up and down freely. An example of such an expression is ""c = A_i B_i"". As
an ordinary function, when a tensor parameter obtains a tensor as an argument,
the function treats the tensor argument as a whole. In contrast, when a scalar
parameter obtains a tensor as an argument, the function is applied to each
component of the tensor. In this paper, we show that introducing these two
types of parameters and our simplified index rules enables us to apply
arbitrary user-defined functions to tensor arguments using index notation
including Einstein summation notation without requiring an additional
description to enable each function to handle tensors.
"
865,"General Semiparametric Shared Frailty Model Estimation and Simulation
  with frailtySurv","  The R package frailtySurv for simulating and fitting semi-parametric shared
frailty models is introduced. Package frailtySurv implements semi-parametric
consistent estimators for a variety of frailty distributions, including gamma,
log-normal, inverse Gaussian and power variance function, and provides
consistent estimators of the standard errors of the parameters' estimators. The
parameters' estimators are asymptotically normally distributed, and therefore
statistical inference based on the results of this package, such as hypothesis
testing and confidence intervals, can be performed using the normal
distribution. Extensive simulations demonstrate the flexibility and correct
implementation of the estimator. Two case studies performed with publicly
available datasets demonstrate applicability of the package. In the Diabetic
Retinopathy Study, the onset of blindness is clustered by patient, and in a
large hard drive failure dataset, failure times are thought to be clustered by
the hard drive manufacturer and model.
"
866,Enhancing speed and scalability of the ParFlow simulation code,"  Regional hydrology studies are often supported by high resolution simulations
of subsurface flow that require expensive and extensive computations. Efficient
usage of the latest high performance parallel computing systems becomes a
necessity. The simulation software ParFlow has been demonstrated to meet this
requirement and shown to have excellent solver scalability for up to 16,384
processes. In the present work we show that the code requires further
enhancements in order to fully take advantage of current petascale machines. We
identify ParFlow's way of parallelization of the computational mesh as a
central bottleneck. We propose to reorganize this subsystem using fast mesh
partition algorithms provided by the parallel adaptive mesh refinement library
p4est. We realize this in a minimally invasive manner by modifying selected
parts of the code to reinterpret the existing mesh data structures. We evaluate
the scaling performance of the modified version of ParFlow, demonstrating good
weak and strong scaling up to 458k cores of the Juqueen supercomputer, and test
an example application at large scale.
"
867,"xSDK Foundations: Toward an Extreme-scale Scientific Software
  Development Kit","  Extreme-scale computational science increasingly demands multiscale and
multiphysics formulations. Combining software developed by independent groups
is imperative: no single team has resources for all predictive science and
decision support capabilities. Scientific libraries provide high-quality,
reusable software components for constructing applications with improved
robustness and portability. However, without coordination, many libraries
cannot be easily composed. Namespace collisions, inconsistent arguments, lack
of third-party software versioning, and additional difficulties make
composition costly.
  The Extreme-scale Scientific Software Development Kit (xSDK) defines
community policies to improve code quality and compatibility across
independently developed packages (hypre, PETSc, SuperLU, Trilinos, and
Alquimia) and provides a foundation for addressing broader issues in software
interoperability, performance portability, and sustainability. The xSDK
provides turnkey installation of member software and seamless combination of
aggregate capabilities, and it marks first steps toward extreme-scale
scientific software ecosystems from which future applications can be composed
rapidly with assured quality and scalability.
"
868,"Landau Collision Integral Solver with Adaptive Mesh Refinement on
  Emerging Architectures","  The Landau collision integral is an accurate model for the small-angle
dominated Coulomb collisions in fusion plasmas. We investigate a high order
accurate, fully conservative, finite element discretization of the nonlinear
multi-species Landau integral with adaptive mesh refinement using the PETSc
library (www.mcs.anl.gov/petsc). We develop algorithms and techniques to
efficiently utilize emerging architectures with an approach that minimizes
memory usage and movement and is suitable for vector processing. The Landau
collision integral is vectorized with Intel AVX-512 intrinsics and the solver
sustains as much as 22% of the theoretical peak flop rate of the Second
Generation Intel Xeon Phi, Knights Landing, processor.
"
869,"Small Superposition Dimension and Active Set Construction for
  Multivariate Integration Under Modest Error Demand","  Constructing active sets is a key part of the Multivariate Decomposition
Method. An algorithm for constructing optimal or quasi-optimal active sets is
proposed in the paper. By numerical experiments, it is shown that the new
method can provide sets that are significantly smaller than the sets
constructed by the already existing method. The experiments also show that the
superposition dimension could surprisingly be very small, at most 3, when the
error demand is not smaller than $10^{-3}$ and the weights decay sufficiently
fast.
"
870,Decoupled Block-Wise ILU(k) Preconditioner on GPU,"  This research investigates the implementation mechanism of block-wise ILU(k)
preconditioner on GPU. The block-wise ILU(k) algorithm requires both the level
k and the block size to be designed as variables. A decoupled ILU(k) algorithm
consists of a symbolic phase and a factorization phase. In the symbolic phase,
a ILU(k) nonzero pattern is established from the point-wise structure extracted
from a block-wise matrix. In the factorization phase, the block-wise matrix
with a variable block size is factorized into a block lower triangular matrix
and a block upper triangular matrix. And a further diagonal factorization is
required to perform on the block upper triangular matrix for adapting a
parallel triangular solver on GPU.We also present the numerical experiments to
study the preconditioner actions on different k levels and block sizes.
"
871,"ForestClaw: A parallel algorithm for patch-based adaptive mesh
  refinement on a forest of quadtrees","  We describe a parallel, adaptive, multi-block algorithm for explicit
integration of time dependent partial differential equations on two-dimensional
Cartesian grids. The grid layout we consider consists of a nested hierarchy of
fixed size, non-overlapping, logically Cartesian grids stored as leaves in a
quadtree. Dynamic grid refinement and parallel partitioning of the grids is
done through the use of the highly scalable quadtree/octree library p4est.
Because our concept is multi-block, we are able to easily solve on a variety of
geometries including the cubed sphere. In this paper, we pay special attention
to providing details of the parallel ghost-filling algorithm needed to ensure
that both corner and edge ghost regions around each grid hold valid values.
  We have implemented this algorithm in the ForestClaw code using single-grid
solvers from ClawPack, a software package for solving hyperbolic PDEs using
finite volumes methods. We show weak and strong scalability results for scalar
advection problems on two-dimensional manifold domains on 1 to 64Ki MPI
processes, demonstrating neglible regridding overhead.
"
872,A Java library to perform S-expansions of Lie algebras,"  The contraction method is a procedure that allows to establish non-trivial
relations between Lie algebras and has had succesful applications in both
mathematics and theoretical physics. This work deals with generalizations of
the contraction procedure with a main focus in the so called S-expansion method
as it includes most of the other generalized contractions. Basically, the
S-exansion combines a Lie algebra $\mathcal{G}$ with a finite abelian semigroup
$S$ in order to define new S-expanded algebras. After giving a description of
the main ingredients used in this paper, we present a Java library that
automatizes the S-expansion procedure. With this computational tool we are able
to represent Lie algebras and semigroups, so we can perform S-expansions of Lie
algebras using arbitrary semigroups. We explain how the library methods has
been constructed and how they work; then we give a set of example programs
aimed to solve different problems. They are presented so that any user can
easily modify them to perform his own calculations, without being necessarily
an expert in Java. Finally, some comments about further developements and
possible new applications are made.
"
873,"Neural Networks for Beginners. A fast implementation in Matlab, Torch,
  TensorFlow","  This report provides an introduction to some Machine Learning tools within
the most common development environments. It mainly focuses on practical
problems, skipping any theoretical introduction. It is oriented to both
students trying to approach Machine Learning and experts looking for new
frameworks.
"
874,"Coupling parallel adaptive mesh refinement with a nonoverlapping domain
  decomposition solver","  We study the effect of adaptive mesh refinement on a parallel domain
decomposition solver of a linear system of algebraic equations. These concepts
need to be combined within a parallel adaptive finite element software. A
prototype implementation is presented for this purpose. It uses adaptive mesh
refinement with one level of hanging nodes. Two and three-level versions of the
Balancing Domain Decomposition based on Constraints (BDDC) method are used to
solve the arising system of algebraic equations. The basic concepts are
recalled and components necessary for the combination are studied in detail. Of
particular interest is the effect of disconnected subdomains, a typical output
of the employed mesh partitioning based on space-filling curves, on the
convergence and solution time of the BDDC method. It is demonstrated using a
large set of experiments that while both refined meshes and disconnected
subdomains have a negative effect on the convergence of BDDC, the number of
iterations remains acceptable. In addition, scalability of the three-level BDDC
solver remains good on up to a few thousands of processor cores. The largest
presented problem using adaptive mesh refinement has over 10^9 unknowns and is
solved on 2048 cores.
"
875,A GPU-based Multi-level Algorithm for Boundary Value Problems,"  A novel and scalable geometric multi-level algorithm is presented for the
numerical solution of elliptic partial differential equations, specially
designed to run with high occupancy of streaming processors inside Graphics
Processing Units(GPUs). The algorithm consists of iterative, superposed
operations on a single grid, and it is composed of two simple full-grid
routines: a restriction and a coarsened interpolation-relaxation. The
restriction is used to collect sources using recursive coarsened averages, and
the interpolation-relaxation simultaneously applies coarsened finite-difference
operators and interpolations. The routines are scheduled in a saw-like refining
cycle. Convergence to machine precision is achieved repeating the full cycle
using accumulated residuals and successively collecting the solution. Its total
number of operations scale linearly with the number of nodes. It provides an
attractive fast solver for Boundary Value Problems (BVPs), specially for
simulations running entirely in the GPU. Applications shown in this work
include the deformation of two-dimensional grids, the computation of
three-dimensional streamlines for a singular trifoil-knot vortex and the
calculation of three-dimensional electric potentials in heterogeneous
dielectric media.
"
876,"A Unified 2D/3D Large Scale Software Environment for Nonlinear Inverse
  Problems","  Large scale parameter estimation problems are among some of the most
computationally demanding problems in numerical analysis. An academic
researcher's domain-specific knowledge often precludes that of software design,
which results in inversion frameworks that are technically correct, but not
scalable to realistically-sized problems. On the other hand, the computational
demands for realistic problems result in industrial codebases that are geared
solely for high performance, rather than comprehensibility or flexibility. We
propose a new software design for inverse problems constrained by partial
differential equations that bridges the gap between these two seemingly
disparate worlds. A hierarchical and modular design allows a user to delve into
as much detail as she desires, while exploiting high performance primitives at
the lower levels. Our code has the added benefit of actually reflecting the
underlying mathematics of the problem, which lowers the cognitive load on user
using it and reduces the initial startup period before a researcher can be
fully productive. We also introduce a new preconditioner for the 3D Helmholtz
equation that is suitable for fault-tolerant distributed systems. Numerical
experiments on a variety of 2D and 3D test problems demonstrate the
effectiveness of this approach on scaling algorithms from small to large scale
problems with minimal code changes.
"
877,A Domain-Specific Language and Editor for Parallel Particle Methods,"  Domain-specific languages (DSLs) are of increasing importance in scientific
high-performance computing to reduce development costs, raise the level of
abstraction and, thus, ease scientific programming. However, designing and
implementing DSLs is not an easy task, as it requires knowledge of the
application domain and experience in language engineering and compilers.
Consequently, many DSLs follow a weak approach using macros or text generators,
which lack many of the features that make a DSL a comfortable for programmers.
Some of these features---e.g., syntax highlighting, type inference, error
reporting, and code completion---are easily provided by language workbenches,
which combine language engineering techniques and tools in a common ecosystem.
In this paper, we present the Parallel Particle-Mesh Environment (PPME), a DSL
and development environment for numerical simulations based on particle methods
and hybrid particle-mesh methods. PPME uses the meta programming system (MPS),
a projectional language workbench. PPME is the successor of the Parallel
Particle-Mesh Language (PPML), a Fortran-based DSL that used conventional
implementation strategies. We analyze and compare both languages and
demonstrate how the programmer's experience can be improved using static
analyses and projectional editing. Furthermore, we present an explicit domain
model for particle abstractions and the first formal type system for particle
methods.
"
878,The Stochastic Processes Generation in OpenModelica,"  Background: Component-based modeling language Modelica (OpenModelica is open
source implementation) is used for the numerical simulation of complex
processes of different nature represented by ODE system. However, in
OpenModelica standard library there is no routines for pseudo-random numbers
generation, which makes it impossible to use for stochastic modeling processes.
Purpose: The goal of this article is a brief overview of a number of algorithms
for generation a sequence of uniformly distributed pseudo random numbers and
quality assessment of the sequence given by them, as well as the ways to
implement some of these algorithms in OpenModelica system. Methods: All the
algorithms are implemented in C language, and the results of their work tested
using open source package DieHarder. For those algorithms that do not use bit
operations, we describe there realisation using OpwnModelica. The other
algorithms can be called in OpenModelica as C functions Results: We have
implemented and tested about nine algorithms. DieHarder testing revealed the
highest quality pseudo-random number generators. Also we have reviewed
libraries Noise and AdvancedNoise, who claim to be adding to the Modelica
Standard Library. Conclusions: In OpenModelica system can be implemented
generators of uniformly distributed pseudo-random numbers, which is the first
step towards to make OpenModelica suitable for simulation of stochastic
processes.
"
879,Faster Base64 Encoding and Decoding Using AVX2 Instructions,"  Web developers use base64 formats to include images, fonts, sounds and other
resources directly inside HTML, JavaScript, JSON and XML files. We estimate
that billions of base64 messages are decoded every day. We are motivated to
improve the efficiency of base64 encoding and decoding. Compared to
state-of-the-art implementations, we multiply the speeds of both the encoding
(~10x) and the decoding (~7x). We achieve these good results by using the
single-instruction-multiple-data (SIMD) instructions available on recent Intel
processors (AVX2). Our accelerated software abides by the specification and
reports errors when encountering characters outside of the base64 set. It is
available online as free software under a liberal license.
"
880,"Conical: an extended module for computing a numerically satisfactory
  pair of solutions of the differential equation for conical functions","  Conical functions appear in a large number of applications in physics and
engineering. In this paper we describe an extension of our module CONICAL for
the computation of conical functions. Specifically, the module includes now a
routine for computing the function ${{\rm R}}^{m}_{-\frac{1}{2}+i\tau}(x)$, a
real-valued numerically satisfactory companion of the function ${\rm
P}^m_{-\tfrac12+i\tau}(x)$ for $x>1$. In this way, a natural basis for solving
Dirichlet problems bounded by conical domains is provided.
"
881,BLASFEO: basic linear algebra subroutines for embedded optimization,"  BLASFEO is a dense linear algebra library providing high-performance
implementations of BLAS- and LAPACK-like routines for use in embedded
optimization. A key difference with respect to existing high-performance
implementations of BLAS is that the computational performance is optimized for
small to medium scale matrices, i.e., for sizes up to a few hundred. BLASFEO
comes with three different implementations: a high-performance implementation
aiming at providing the highest performance for matrices fitting in cache, a
reference implementation providing portability and embeddability and optimized
for very small matrices, and a wrapper to standard BLAS and LAPACK providing
high-performance on large matrices. The three implementations of BLASFEO
together provide high-performance dense linear algebra routines for matrices
ranging from very small to large. Compared to both open-source and proprietary
highly-tuned BLAS libraries, for matrices of size up to about one hundred the
high-performance implementation of BLASFEO is about 20-30% faster than the
corresponding level 3 BLAS routines and 2-3 times faster than the corresponding
LAPACK routines.
"
882,Strassen's Algorithm for Tensor Contraction,"  Tensor contraction (TC) is an important computational kernel widely used in
numerous applications. It is a multi-dimensional generalization of matrix
multiplication (GEMM). While Strassen's algorithm for GEMM is well studied in
theory and practice, extending it to accelerate TC has not been previously
pursued. Thus, we believe this to be the first paper to demonstrate how one can
in practice speed up tensor contraction with Strassen's algorithm. By adopting
a Block-Scatter-Matrix format, a novel matrix-centric tensor layout, we can
conceptually view TC as GEMM for a general stride storage, with an implicit
tensor-to-matrix transformation. This insight enables us to tailor a recent
state-of-the-art implementation of Strassen's algorithm to TC, avoiding
explicit transpositions (permutations) and extra workspace, and reducing the
overhead of memory movement that is incurred. Performance benefits are
demonstrated with a performance model as well as in practice on modern single
core, multicore, and distributed memory parallel architectures, achieving up to
1.3x speedup. The resulting implementations can serve as a drop-in replacement
for various applications with significant speedup.
"
883,Two variants of the Froiduire-Pin Algorithm for finite semigroups,"  In this paper, we present two algorithms based on the Froidure-Pin Algorithm
for computing the structure of a finite semigroup from a generating set. As was
the case with the original algorithm of Froidure and Pin, the algorithms
presented here produce the left and right Cayley graphs, a confluent
terminating rewriting system, and a reduced word of the rewriting system for
every element of the semigroup.
  If $U$ is any semigroup, and $A$ is a subset of $U$, then we denote by
$\langle A\rangle$ the least subsemigroup of $U$ containing $A$. If $B$ is any
other subset of $U$, then, roughly speaking, the first algorithm we present
describes how to use any information about $\langle A\rangle$, that has been
found using the Froidure-Pin Algorithm, to compute the semigroup $\langle A\cup
B\rangle$. More precisely, we describe the data structure for a finite
semigroup $S$ given by Froidure and Pin, and how to obtain such a data
structure for $\langle A\cup B\rangle$ from that for $\langle A\rangle$. The
second algorithm is a lock-free concurrent version of the Froidure-Pin
Algorithm.
"
884,HPTT: A High-Performance Tensor Transposition C++ Library,"  Recently we presented TTC, a domain-specific compiler for tensor
transpositions. Despite the fact that the performance of the generated code is
nearly optimal, due to its offline nature, TTC cannot be utilized in all the
application codes in which the tensor sizes and the necessary tensor
permutations are determined at runtime. To overcome this limitation, we
introduce the open-source C++ library High-Performance Tensor Transposition
(HPTT). Similar to TTC, HPTT incorporates optimizations such as blocking,
multi-threading, and explicit vectorization; furthermore it decomposes any
transposition into multiple loops around a so called micro-kernel. This modular
design---inspired by BLIS---makes HPTT easy to port to different architectures,
by only replacing the hand-vectorized micro-kernel (e.g., a 4x4 transpose).
HPTT also offers an optional autotuning framework---guided by a performance
model---that explores a vast search space of implementations at runtime
(similar to FFTW). Across a wide range of different tensor transpositions and
architectures (e.g., Intel Ivy Bridge, Intel Knights Landing, ARMv7, IBM
Power7), HPTT attains a bandwidth comparable to that of SAXPY, and yields
remarkable speedups over Eigen's tensor transposition implementation. Most
importantly, the integration of HPTT into the Cyclops Tensor Framework (CTF)
improves the overall performance of tensor contractions by up to 3.1x.
"
885,DATeS: A Highly-Extensible Data Assimilation Testing Suite v1.0,"  A flexible and highly-extensible data assimilation testing suite, named
DATeS, is described in this paper. DATeS aims to offer a unified testing
environment that allows researchers to compare different data assimilation
methodologies and understand their performance in various settings. The core of
DATeS is implemented in Python and takes advantage of its object-oriented
capabilities. The main components of the package (the numerical models, the
data assimilation algorithms, the linear algebra solvers, and the time
discretization routines) are independent of each other, which offers great
flexibility to configure data assimilation applications. DATeS can interface
easily with large third-party numerical models written in Fortran or in C, and
with a plethora of external solvers.
"
886,"A Novel Hybrid Quicksort Algorithm Vectorized using AVX-512 on Intel
  Skylake","  The modern CPU's design, which is composed of hierarchical memory and
SIMD/vectorization capability, governs the potential for algorithms to be
transformed into efficient implementations. The release of the AVX-512 changed
things radically, and motivated us to search for an efficient sorting algorithm
that can take advantage of it. In this paper, we describe the best strategy we
have found, which is a novel two parts hybrid sort, based on the well-known
Quicksort algorithm. The central partitioning operation is performed by a new
algorithm, and small partitions/arrays are sorted using a branch-free
Bitonic-based sort. This study is also an illustration of how classical
algorithms can be adapted and enhanced by the AVX-512 extension. We evaluate
the performance of our approach on a modern Intel Xeon Skylake and assess the
different layers of our implementation by sorting/partitioning integers, double
floating-point numbers, and key/value pairs of integers. Our results
demonstrate that our approach is faster than two libraries of reference: the
GNU \emph{C++} sort algorithm by a speedup factor of 4, and the Intel IPP
library by a speedup factor of 1.4.
"
887,Particle-based and Meshless Methods with Aboria,"  Aboria is a powerful and flexible C++ library for the implementation of
particle-based numerical methods. The particles in such methods can represent
actual particles (e.g. Molecular Dynamics) or abstract particles used to
discretise a continuous function over a domain (e.g. Radial Basis Functions).
Aboria provides a particle container, compatible with the Standard Template
Library, spatial search data structures, and a Domain Specific Language to
specify non-linear operators on the particle set. This paper gives an overview
of Aboria's design, an example of use, and a performance benchmark.
"
888,Computing Tropical Prevarieties in Parallel,"  The computation of the tropical prevariety is the first step in the
application of polyhedral methods to compute positive dimensional solution sets
of polynomial systems. In particular, pretropisms are candidate leading
exponents for the power series developments of the solutions. The computation
of the power series may start as soon as one pretropism is available, so our
parallel computation of the tropical prevariety has an application in a
pipelined solver.
  We present a parallel implementation of dynamic enumeration. Our first
distributed memory implementation with forked processes achieved good speedups,
but quite often resulted in large variations in the execution times of the
processes. The shared memory multithreaded version applies work stealing to
reduce the variability of the run time. Our implementation applies the thread
safe Parma Polyhedral Library (PPL), in exact arithmetic with the GNU
Multiprecision Arithmetic Library (GMP), aided by the fast memory allocations
of TCMalloc.
  Our parallel implementation is capable of computing the tropical prevariety
of the cyclic 16-roots problem. We also report on computational experiments on
the $n$-body and $n$-vortex problems; our computational results compare
favorably with Gfan.
"
889,Computing isomorphisms and embeddings of finite fields,"  Let $\mathbb{F}_q$ be a finite field. Given two irreducible polynomials $f,g$
over $\mathbb{F}_q$, with $\mathrm{deg} f$ dividing $\mathrm{deg} g$, the
finite field embedding problem asks to compute an explicit description of a
field embedding of $\mathbb{F}_q[X]/f(X)$ into $\mathbb{F}_q[Y]/g(Y)$. When
$\mathrm{deg} f = \mathrm{deg} g$, this is also known as the isomorphism
problem.
  This problem, a special instance of polynomial factorization, plays a central
role in computer algebra software. We review previous algorithms, due to
Lenstra, Allombert, Rains, and Narayanan, and propose improvements and
generalizations. Our detailed complexity analysis shows that our newly proposed
variants are at least as efficient as previously known algorithms, and in many
cases significantly better.
  We also implement most of the presented algorithms, compare them with the
state of the art computer algebra software, and make the code available as open
source. Our experiments show that our new variants consistently outperform
available software.
"
890,"cuTT: A High-Performance Tensor Transpose Library for CUDA Compatible
  GPUs","  We introduce the CUDA Tensor Transpose (cuTT) library that implements
high-performance tensor transposes for NVIDIA GPUs with Kepler and above
architectures. cuTT achieves high performance by (a) utilizing two
GPU-optimized transpose algorithms that both use a shared memory buffer in
order to reduce global memory access scatter, and by (b) computing memory
positions of tensor elements using a thread-parallel algorithm. We evaluate the
performance of cuTT on a variety of benchmarks with tensor ranks ranging from 2
to 12 and show that cuTT performance is independent of the tensor rank and that
it performs no worse than an approach based on code generation. We develop a
heuristic scheme for choosing the optimal parameters for tensor transpose
algorithms by implementing an analytical GPU performance model that can be used
at runtime without need for performance measurements or profiling. Finally, by
integrating cuTT into the tensor algebra library TAL-SH, we significantly
reduce the tensor transpose overhead in tensor contractions, achieving as low
as just one percent overhead for arithmetically intensive tensor contractions.
"
891,A revision of the subtract-with-borrow random number generators,"  The most popular and widely used subtract-with-borrow generator, also known
as RANLUX, is reimplemented as a linear congruential generator using large
integer arithmetic with the modulus size of 576 bits. Modern computers, as well
as the specific structure of the modulus inferred from RANLUX, allow for the
development of a fast modular multiplication -- the core of the procedure. This
was previously believed to be slow and have too high cost in terms of computing
resources. Our tests show a significant gain in generation speed which is
comparable with other fast, high quality random number generators. An
additional feature is the fast skipping of generator states leading to a
seeding scheme which guarantees the uniqueness of random number sequences.
"
892,"Accelerating solutions of one-dimensional unsteady PDEs with GPU-based
  swept time-space decomposition","  The expedient design of precision components in aerospace and other high-tech
industries requires simulations of physical phenomena often described by
partial differential equations (PDEs) without exact solutions. Modern design
problems require simulations with a level of resolution difficult to achieve in
reasonable amounts of time---even in effectively parallelized solvers. Though
the scale of the problem relative to available computing power is the greatest
impediment to accelerating these applications, significant performance gains
can be achieved through careful attention to the details of memory
communication and access. The swept time-space decomposition rule reduces
communication between sub-domains by exhausting the domain of influence before
communicating boundary values. Here we present a GPU implementation of the
swept rule, which modifies the algorithm for improved performance on this
processing architecture by prioritizing use of private (shared) memory,
avoiding interblock communication, and overwriting unnecessary values. It shows
significant improvement in the execution time of finite-difference solvers for
one-dimensional unsteady PDEs, producing speedups of 2--9$\times$ for a range
of problem sizes, respectively, compared with simple GPU versions and
7--300$\times$ compared with parallel CPU versions. However, for a more
sophisticated one-dimensional system of equations discretized with a
second-order finite-volume scheme, the swept rule performs 1.2--1.9$\times$
worse than a standard implementation for all problem sizes.
"
893,"Computing the Lambert W function in arbitrary-precision complex interval
  arithmetic","  We describe an algorithm to evaluate all the complex branches of the Lambert
W function with rigorous error bounds in interval arithmetic, which has been
implemented in the Arb library. The classic 1996 paper on the Lambert W
function by Corless et al. provides a thorough but partly heuristic numerical
analysis which needs to be complemented with some explicit inequalities and
practical observations about managing precision and branch cuts.
"
894,"A performance spectrum for parallel computational frameworks that solve
  PDEs","  Important computational physics problems are often large-scale in nature, and
it is highly desirable to have robust and high performing computational
frameworks that can quickly address these problems. However, it is no trivial
task to determine whether a computational framework is performing efficiently
or is scalable. The aim of this paper is to present various strategies for
better understanding the performance of any parallel computational frameworks
for solving PDEs. Important performance issues that negatively impact
time-to-solution are discussed, and we propose a performance spectrum analysis
that can enhance one's understanding of critical aforementioned performance
issues. As proof of concept, we examine commonly used finite element simulation
packages and software and apply the performance spectrum to quickly analyze the
performance and scalability across various hardware platforms, software
implementations, and numerical discretizations. It is shown that the proposed
performance spectrum is a versatile performance model that is not only
extendable to more complex PDEs such as hydrostatic ice sheet flow equations,
but also useful for understanding hardware performance in a massively parallel
computing environment. Potential applications and future extensions of this
work are also discussed.
"
895,TSFC: a structure-preserving form compiler,"  A form compiler takes a high-level description of the weak form of partial
differential equations and produces low-level code that carries out the finite
element assembly. In this paper we present the Two-Stage Form Compiler (TSFC),
a new form compiler with the main motivation to maintain the structure of the
input expression as long as possible. This facilitates the application of
optimizations at the highest possible level of abstraction. TSFC features a
novel, structure-preserving method for separating the contributions of a form
to the subblocks of the local tensor in discontinuous Galerkin problems. This
enables us to preserve the tensor structure of expressions longer through the
compilation process than other form compilers. This is also achieved in part by
a two-stage approach that cleanly separates the lowering of finite element
constructs to tensor algebra in the first stage, from the scheduling of those
tensor operations in the second stage. TSFC also efficiently traverses
complicated expressions, and experimental evaluation demonstrates good
compile-time performance even for highly complex forms.
"
896,CLBlast: A Tuned OpenCL BLAS Library,"  This work introduces CLBlast, an open-source BLAS library providing optimized
OpenCL routines to accelerate dense linear algebra for a wide variety of
devices. It is targeted at machine learning and HPC applications and thus
provides a fast matrix-multiplication routine (GEMM) to accelerate the core of
many applications (e.g. deep learning, iterative solvers, astrophysics,
computational fluid dynamics, quantum chemistry). CLBlast has five main
advantages over other OpenCL BLAS libraries: 1) it is optimized for and tested
on a large variety of OpenCL devices including less commonly used devices such
as embedded and low-power GPUs, 2) it can be explicitly tuned for specific
problem-sizes on specific hardware platforms, 3) it can perform operations in
half-precision floating-point FP16 saving bandwidth, time and energy, 4) it has
an optional CUDA back-end, 5) and it can combine multiple operations in a
single batched routine, accelerating smaller problems significantly. This paper
describes the library and demonstrates the advantages of CLBlast experimentally
for different use-cases on a wide variety of OpenCL hardware.
"
897,"Nemo/Hecke: Computer Algebra and Number Theory Packages for the Julia
  Programming Language","  We introduce two new packages, Nemo and Hecke, written in the Julia
programming language for computer algebra and number theory. We demonstrate
that high performance generic algorithms can be implemented in Julia, without
the need to resort to a low-level C implementation. For specialised algorithms,
we use Julia's efficient native C interface to wrap existing C/C++ libraries
such as Flint, Arb, Antic and Singular. We give examples of how to use Hecke
and Nemo and discuss some algorithms that we have implemented to provide high
performance basic arithmetic.
"
898,Spin Summations: A High-Performance Perspective,"  Besides tensor contractions, one of the most pronounced computational
bottlenecks in the non-orthogonally spin-adapted forms of the quantum chemistry
methods CCSDT and CCSDTQ, and their approximate forms---including CCSD(T) and
CCSDT(Q)---are spin summations. At a first sight, spin summations are
operations similar to tensor transpositions; a closer look instead reveals
additional challenges to high-performance calculations, including temporal
locality as well as scattered memory accesses. This publication explores a
sequence of algorithmic solutions for spin summations, each exploiting
individual properties of either the underlying hardware (e.g. caches,
vectorization), or the problem itself (e.g. factorizability). The final
algorithm combines the advantages of all the solutions, while avoiding their
drawbacks; this algorithm, achieves high-performance through parallelization,
vectorization, and by exploiting the temporal locality inherent to spin
summations. Combined, these optimizations result in speedups between 2.4x and
5.5x over the NCC quantum chemistry software package. In addition to such a
performance boost, our algorithm can perform the spin summations in-place, thus
reducing the memory footprint by 2x over an out-of-place variant.
"
899,"Introducing Geometric Algebra to Geometric Computing Software
  Developers: A Computational Thinking Approach","  Designing software systems for Geometric Computing applications can be a
challenging task. Software engineers typically use software abstractions to
hide and manage the high complexity of such systems. Without the presence of a
unifying algebraic system to describe geometric models, the use of software
abstractions alone can result in many design and maintenance problems.
Geometric Algebra (GA) can be a universal abstract algebraic language for
software engineering geometric computing applications. Few sources, however,
provide enough information about GA-based software implementations targeting
the software engineering community. In particular, successfully introducing GA
to software engineers requires quite different approaches from introducing GA
to mathematicians or physicists. This article provides a high-level
introduction to the abstract concepts and algebraic representations behind the
elegant GA mathematical structure. The article focuses on the conceptual and
representational abstraction levels behind GA mathematics with sufficient
references for more details. In addition, the article strongly recommends
applying the methods of Computational Thinking in both introducing GA to
software engineers, and in using GA as a mathematical language for developing
Geometric Computing software systems.
"
900,Sparse Matrix Multiplication On An Associative Processor,"  Sparse matrix multiplication is an important component of linear algebra
computations. Implementing sparse matrix multiplication on an associative
processor (AP) enables high level of parallelism, where a row of one matrix is
multiplied in parallel with the entire second matrix, and where the execution
time of vector dot product does not depend on the vector size. Four sparse
matrix multiplication algorithms are explored in this paper, combining AP and
baseline CPU processing to various levels. They are evaluated by simulation on
a large set of sparse matrices. The computational complexity of sparse matrix
multiplication on AP is shown to be an O(nnz) where nnz is the number of
nonzero elements. The AP is found to be especially efficient in binary sparse
matrix multiplication. AP outperforms conventional solutions in power
efficiency.
"
901,ParMooN - a modernized program package based on mapped finite elements,"  {\sc ParMooN} is a program package for the numerical solution of elliptic and
parabolic partial differential equations. It inherits the distinct features of
its predecessor {\sc MooNMD} \cite{JM04}: strict decoupling of geometry and
finite element spaces, implementation of mapped finite elements as their
definition can be found in textbooks, and a geometric multigrid preconditioner
with the option to use different finite element spaces on different levels of
the multigrid hierarchy. After having presented some thoughts about in-house
research codes, this paper focuses on aspects of the parallelization for a
distributed memory environment, which is the main novelty of {\sc ParMooN}.
Numerical studies, performed on compute servers, assess the efficiency of the
parallelized geometric multigrid preconditioner in comparison with some
parallel solvers that are available in the library {\sc PETSc}. The results of
these studies give a first indication whether the cumbersome implementation of
the parallelized geometric multigrid method was worthwhile or not.
"
902,"Parallel Matrix-Free Implementation of Frequency-Domain Finite
  Difference Methods for Cluster Computing","  Full-wave 3D electromagnetic simulations of complex planar devices,
multilayer interconnects, and chip packages are presented for wide-band
frequency-domain analysis using the finite difference integration technique
developed in the PETSc software package. Initial reordering of the index
assignment to the unknowns makes the resulting system matrix diagonally
dominant. The rearrangement also facilitates the decomposition of large domain
into slices for passing the mesh information to different machines. Matrix-free
methods are then exploited to minimize the number of element-wise
multiplications and memory requirements in the construction of the system of
linear equations. Besides, the recipes provide extreme ease of modifications in
the kernel of the code. The applicability of different Krylov subspace solvers
is investigated. The accuracy is checked through comparisons with CST MICROWAVE
STUDIO transient solver results. The parallel execution of the compiled code on
specific number of processors in multi-core distributed-memory architectures
demonstrate high scalability of the computational algorithm.
"
903,A Unified Optimization Approach for Sparse Tensor Operations on GPUs,"  Sparse tensors appear in many large-scale applications with multidimensional
and sparse data. While multidimensional sparse data often need to be processed
on manycore processors, attempts to develop highly-optimized GPU-based
implementations of sparse tensor operations are rare. The irregular computation
patterns and sparsity structures as well as the large memory footprints of
sparse tensor operations make such implementations challenging. We leverage the
fact that sparse tensor operations share similar computation patterns to
propose a unified tensor representation called F-COO. Combined with
GPU-specific optimizations, F-COO provides highly-optimized implementations of
sparse tensor computations on GPUs. The performance of the proposed unified
approach is demonstrated for tensor-based kernels such as the Sparse Matricized
Tensor- Times-Khatri-Rao Product (SpMTTKRP) and the Sparse Tensor- Times-Matrix
Multiply (SpTTM) and is used in tensor decomposition algorithms. Compared to
state-of-the-art work we improve the performance of SpTTM and SpMTTKRP up to
3.7 and 30.6 times respectively on NVIDIA Titan-X GPUs. We implement a
CANDECOMP/PARAFAC (CP) decomposition and achieve up to 14.9 times speedup using
the unified method over state-of-the-art libraries on NVIDIA Titan-X GPUs.
"
904,"Increasing the Efficiency of Sparse Matrix-Matrix Multiplication with a
  2.5D Algorithm and One-Sided MPI","  Matrix-matrix multiplication is a basic operation in linear algebra and an
essential building block for a wide range of algorithms in various scientific
fields. Theory and implementation for the dense, square matrix case are
well-developed. If matrices are sparse, with application-specific sparsity
patterns, the optimal implementation remains an open question. Here, we explore
the performance of communication reducing 2.5D algorithms and one-sided MPI
communication in the context of linear scaling electronic structure theory. In
particular, we extend the DBCSR sparse matrix library, which is the basic
building block for linear scaling electronic structure theory and low scaling
correlated methods in CP2K. The library is specifically designed to efficiently
perform block-sparse matrix-matrix multiplication of matrices with a relatively
large occupation. Here, we compare the performance of the original
implementation based on Cannon's algorithm and MPI point-to-point
communication, with an implementation based on MPI one-sided communications
(RMA), in both a 2D and a 2.5D approach. The 2.5D approach trades memory and
auxiliary operations for reduced communication, which can lead to a speedup if
communication is dominant. The 2.5D algorithm is somewhat easier to implement
with one-sided communications. A detailed description of the implementation is
provided, also for non ideal processor topologies, since this is important for
actual applications. Given the importance of the precise sparsity pattern, and
even the actual matrix data, which decides the effective fill-in upon
multiplication, the tests are performed within the CP2K package with
application benchmarks. Results show a substantial boost in performance for the
RMA based 2.5D algorithm, up to 1.80x, which is observed to increase with the
number of involved processes in the parallelization.
"
905,Automatic Differentiation using Constraint Handling Rules in Prolog,"  Automatic differentiation is a technique which allows a programmer to define
a numerical computation via compositions of a broad range of numeric and
computational primitives and have the underlying system support the computation
of partial derivatives of the result with respect to any of its inputs, without
making any finite difference approximations, and without manipulating large
symbolic expressions representing the computation. This note describes a novel
approach to reverse mode automatic differentiation using constraint logic
programmming, specifically, the constraint handling rules (CHR) library of SWI
Prolog, resulting in a very small (50 lines of code) implementation. When
applied to a differentiation-based implementation of the inside-outside
algorithm for parameter learning in probabilistic grammars, the CHR based
implementations outperformed two well-known frameworks for optimising
differentiable functions, Theano and TensorFlow, by a large margin.
"
906,Solver composition across the PDE/linear algebra barrier,"  The efficient solution of discretisations of coupled systems of partial
differential equations (PDEs) is at the core of much of numerical simulation.
Significant effort has been expended on scalable algorithms to precondition
Krylov iterations for the linear systems that arise. With few exceptions, the
reported numerical implementation of such solution strategies is specific to a
particular model setup, and intimately ties the solver strategy to the
discretisation and PDE, especially when the preconditioner requires auxiliary
operators. In this paper, we present recent improvements in the Firedrake
finite element library that allow for straightforward development of the
building blocks of extensible, composable preconditioners that decouple the
solver from the model formulation. Our implementation extends the algebraic
composability of linear solvers offered by the PETSc library by augmenting
operators, and hence preconditioners, with the ability to provide any necessary
auxiliary operators. Rather than specifying up front the full solver
configuration, tied to the model, solvers can be developed independently of
model formulation and configured at runtime. We illustrate with examples from
incompressible fluids and temperature-driven convection.
"
907,A randomized Halton algorithm in R,"  Randomized quasi-Monte Carlo (RQMC) sampling can bring orders of magnitude
reduction in variance compared to plain Monte Carlo (MC) sampling. The extent
of the efficiency gain varies from problem to problem and can be hard to
predict. This article presents an R function rhalton that produces scrambled
versions of Halton sequences. On some problems it brings efficiency gains of
several thousand fold. On other problems, the efficiency gain is minor. The
code is designed to make it easy to determine whether a given integrand will
benefit from RQMC sampling. An RQMC sample of n points in $[0,1]^d$ can be
extended later to a larger n and/or d.
"
908,Parareal Algorithm Implementation and Simulation in Julia,"  We present a full implementation of the parareal algorithm---an integration
technique to solve differential equations in parallel---in the Julia
programming language for a fully general, first-order, initial-value problem.
We provide a brief overview of Julia---a concurrent programming language for
scientific computing. Our implementation of the parareal algorithm accepts both
coarse and fine integrators as functional arguments. We use Euler's method and
another Runge-Kutta integration technique as the integrators in our
experiments. We also present a simulation of the algorithm for purposes of
pedagogy and as a tool for investigating the performance of the algorithm.
"
909,Geometry-Oblivious FMM for Compressing Dense SPD Matrices,"  We present GOFMM (geometry-oblivious FMM), a novel method that creates a
hierarchical low-rank approximation, ""compression,"" of an arbitrary dense
symmetric positive definite (SPD) matrix. For many applications, GOFMM enables
an approximate matrix-vector multiplication in $N \log N$ or even $N$ time,
where $N$ is the matrix size. Compression requires $N \log N$ storage and work.
In general, our scheme belongs to the family of hierarchical matrix
approximation methods. In particular, it generalizes the fast multipole method
(FMM) to a purely algebraic setting by only requiring the ability to sample
matrix entries. Neither geometric information (i.e., point coordinates) nor
knowledge of how the matrix entries have been generated is required, thus the
term ""geometry-oblivious."" Also, we introduce a shared-memory parallel scheme
for hierarchical matrix computations that reduces synchronization barriers. We
present results on the Intel Knights Landing and Haswell architectures, and on
the NVIDIA Pascal architecture for a variety of matrices.
"
910,Compiling LATEX to computer algebra-enabled HTML5,"  This document explains how to create or modify an existing LATEX document
with commands enabling computations in the HTML5 output: when the reader opens
the HTML5 output, he can run a computation in his browser, or modify the
command to be executed and run it. This is done by combining different
softwares: hevea for compilation to HTML5, giac.js for the CAS computing kernel
(itself compiled from the C++ Giac library with emscripten), and a modified
version of itex2MML for fast and nice rendering in MathML in browsers that
support MathML.
"
911,Adaptive Modular Exponentiation Methods v.s. Python's Power Function,"  In this paper we use Python to implement two efficient modular exponentiation
methods: the adaptive m-ary method and the adaptive sliding-window method of
window size k, where both m's are adaptively chosen based on the length of
exponent. We also conduct the benchmark for both methods. Evaluation results
show that compared to the industry-standard efficient implementations of
modular power function in CPython and Pypy, our algorithms can reduce 1-5%
computing time for exponents with more than 3072 bits.
"
912,Applying the Polyhedral Model to Tile Time Loops in Devito,"  The run time of many scientific computation applications for numerical
methods is heavily dependent on just a few multi-dimensional loop nests. Since
these applications are often limited by memory bandwidth rather than
computational resources they can benefit greatly from any optimizations which
decrease the run time of their loops by improving data reuse and thus reducing
the total memory traffic. Some of the most effective of these optimizations are
not suitable for development by hand or require advanced software engineering
knowledge which is beyond the level of many researchers who are not specialists
in code optimization. Several tools exist to automate the generation of
high-performance code for numerical methods, such as Devito which produces code
for finite-difference approximations typically used in the seismic imaging
domain. We present a loop-tiling optimization which can be applied to
Devito-generated loops and improves run time by up to 27.5%, and options for
automating this optimization in the Devito framework.
"
913,Optimised finite difference computation from symbolic equations,"  Domain-specific high-productivity environments are playing an increasingly
important role in scientific computing due to the levels of abstraction and
automation they provide. In this paper we introduce Devito, an open-source
domain-specific framework for solving partial differential equations from
symbolic problem definitions by the finite difference method. We highlight the
generation and automated execution of highly optimized stencil code from only a
few lines of high-level symbolic Python for a set of scientific equations,
before exploring the use of Devito operators in seismic inversion problems.
"
914,Language-based Abstractions for Dynamical Systems,"  Ordinary differential equations (ODEs) are the primary means to modelling
dynamical systems in many natural and engineering sciences. The number of
equations required to describe a system with high heterogeneity limits our
capability of effectively performing analyses. This has motivated a large body
of research, across many disciplines, into abstraction techniques that provide
smaller ODE systems while preserving the original dynamics in some appropriate
sense. In this paper we give an overview of a recently proposed
computer-science perspective to this problem, where ODE reduction is recast to
finding an appropriate equivalence relation over ODE variables, akin to
classical models of computation based on labelled transition systems.
"
915,"Batched QR and SVD Algorithms on GPUs with Applications in Hierarchical
  Matrix Compression","  We present high performance implementations of the QR and the singular value
decomposition of a batch of small matrices hosted on the GPU with applications
in the compression of hierarchical matrices. The one-sided Jacobi algorithm is
used for its simplicity and inherent parallelism as a building block for the
SVD of low rank blocks using randomized methods. We implement multiple kernels
based on the level of the GPU memory hierarchy in which the matrices can reside
and show substantial speedups against streamed cuSOLVER SVDs. The resulting
batched routine is a key component of hierarchical matrix compression, opening
up opportunities to perform H-matrix arithmetic efficiently on GPUs.
"
916,FDTD: solving 1+1D delay PDE in parallel,"  We present a proof of concept for solving a 1+1D complex-valued, delay
partial differential equation (PDE) that emerges in the study of waveguide
quantum electrodynamics (QED) by adapting the finite-difference time-domain
(FDTD) method. The delay term is spatially non-local, rendering conventional
approaches such as the method of lines inapplicable. We show that by properly
designing the grid and by supplying the (partial) exact solution as the
boundary condition, the delay PDE can be numerically solved. In addition, we
demonstrate that while the delay imposes strong data dependency, multi-thread
parallelization can nevertheless be applied to such a problem. Our code
provides a numerically exact solution to the time-dependent multi-photon
scattering problem in waveguide QED.
"
917,"Dragon: A Computation Graph Virtual Machine Based Deep Learning
  Framework","  Deep Learning has made a great progress for these years. However, it is still
difficult to master the implement of various models because different
researchers may release their code based on different frameworks or interfaces.
In this paper, we proposed a computation graph based framework which only aims
to introduce well-known interfaces. It will help a lot when reproducing a newly
model or transplanting models that were implemented by other frameworks.
Additionally, we implement numerous recent models covering both Computer Vision
and Nature Language Processing. We demonstrate that our framework will not
suffer from model-starving because it is much easier to make full use of the
works that are already done.
"
918,"Example Setups of Navier-Stokes Equations with Control and Observation:
  Spatial Discretization and Representation via Linear-quadratic Matrix
  Coefficients","  We provide spatial discretizations of nonlinear incompressible Navier-Stokes
equations with inputs and outputs in the form of matrices ready to use in any
numerical linear algebra package. We discuss the assembling of the system
operators and the realization of boundary conditions and inputs and outputs. We
describe the two benchmark problems - the driven cavity and the cylinder wake -
and provide the corresponding data. The use of the data is illustrated by
numerous example setups. The test cases are provided as plain PYTHON or
OCTAVE/MATLAB script files for immediate replication.
"
919,"An Open Source C++ Implementation of Multi-Threaded Gaussian Mixture
  Models, k-Means and Expectation Maximisation","  Modelling of multivariate densities is a core component in many signal
processing, pattern recognition and machine learning applications. The
modelling is often done via Gaussian mixture models (GMMs), which use
computationally expensive and potentially unstable training algorithms. We
provide an overview of a fast and robust implementation of GMMs in the C++
language, employing multi-threaded versions of the Expectation Maximisation
(EM) and k-means training algorithms. Multi-threading is achieved through
reformulation of the EM and k-means algorithms into a MapReduce-like framework.
Furthermore, the implementation uses several techniques to improve numerical
stability and modelling accuracy. We demonstrate that the multi-threaded
implementation achieves a speedup of an order of magnitude on a recent 16 core
machine, and that it can achieve higher modelling accuracy than a previously
well-established publically accessible implementation. The multi-threaded
implementation is included as a user-friendly class in recent releases of the
open source Armadillo C++ linear algebra library. The library is provided under
the permissive Apache~2.0 license, allowing unencumbered use in commercial
products.
"
920,Owl: A General-Purpose Numerical Library in OCaml,"  Owl is a new numerical library developed in the OCaml language. It focuses on
providing a comprehensive set of high-level numerical functions so that
developers can quickly build up data analytical applications. In this abstract,
we will present Owl's design, core components, and its key functionality.
"
921,ELFI: Engine for Likelihood-Free Inference,"  Engine for Likelihood-Free Inference (ELFI) is a Python software library for
performing likelihood-free inference (LFI). ELFI provides a convenient syntax
for arranging components in LFI, such as priors, simulators, summaries or
distances, to a network called ELFI graph. The components can be implemented in
a wide variety of languages. The stand-alone ELFI graph can be used with any of
the available inference methods without modifications. A central method
implemented in ELFI is Bayesian Optimization for Likelihood-Free Inference
(BOLFI), which has recently been shown to accelerate likelihood-free inference
up to several orders of magnitude by surrogate-modelling the distance. ELFI
also has an inbuilt support for output data storing for reuse and analysis, and
supports parallelization of computation from multiple cores up to a cluster
environment. ELFI is designed to be extensible and provides interfaces for
widening its functionality. This makes the adding of new inference methods to
ELFI straightforward and automatically compatible with the inbuilt features.
"
922,FEMPAR: An object-oriented parallel finite element framework,"  FEMPAR is an open source object oriented Fortran200X scientific software
library for the high-performance scalable simulation of complex multiphysics
problems governed by partial differential equations at large scales, by
exploiting state-of-the-art supercomputing resources. It is a highly
modularized, flexible, and extensible library, that provides a set of modules
that can be combined to carry out the different steps of the simulation
pipeline. FEMPAR includes a rich set of algorithms for the discretization step,
namely (arbitrary-order) grad, div, and curl-conforming finite element methods,
discontinuous Galerkin methods, B-splines, and unfitted finite element
techniques on cut cells, combined with $h$-adaptivity. The linear solver module
relies on state-of-the-art bulk-asynchronous implementations of multilevel
domain decomposition solvers for the different discretization alternatives and
block-preconditioning techniques for multiphysics problems. FEMPAR is a
framework that provides users with out-of-the-box state-of-the-art
discretization techniques and highly scalable solvers for the simulation of
complex applications, hiding the dramatic complexity of the underlying
algorithms. But it is also a framework for researchers that want to experience
with new algorithms and solvers, by providing a highly extensible framework. In
this work, the first one in a series of articles about FEMPAR, we provide a
detailed introduction to the software abstractions used in the discretization
module and the related geometrical module. We also provide some ingredients
about the assembly of linear systems arising from finite element
discretizations, but the software design of complex scalable multilevel solvers
is postponed to a subsequent work.
"
923,"Practically efficient methods for performing bit-reversed permutation in
  C++11 on the x86-64 architecture","  The bit-reversed permutation is a famous task in signal processing and is key
to efficient implementation of the fast Fourier transform. This paper presents
optimized C++11 implementations of five extant methods for computing the
bit-reversed permutation: Stockham auto-sort, naive bitwise swapping, swapping
via a table of reversed bytes, local pairwise swapping of bits, and swapping
via a cache-localized matrix buffer. Three new strategies for performing the
bit-reversed permutation in C++11 are proposed: an inductive method using the
bitwise XOR operation, a template-recursive closed form, and a cache-oblivious
template-recursive approach, which reduces the bit-reversed permutation to
smaller bit-reversed permutations and a square matrix transposition. These new
methods are compared to the extant approaches in terms of theoretical runtime,
empirical compile time, and empirical runtime. The template-recursive
cache-oblivious method is shown to be competitive with the fastest known
method; however, we demonstrate that the cache-oblivious method can more
readily benefit from parallelization on multiple cores and on the GPU.
"
924,"Veamy: an extensible object-oriented C++ library for the virtual element
  method","  This paper summarizes the development of Veamy, an object-oriented C++
library for the virtual element method (VEM) on general polygonal meshes, whose
modular design is focused on its extensibility. The linear elastostatic and
Poisson problems in two dimensions have been chosen as the starting stage for
the development of this library. The theory of the VEM, upon which Veamy is
built, is presented using a notation and a terminology that resemble the
language of the finite element method (FEM) in engineering analysis. Several
examples are provided to demonstrate the usage of Veamy, and in particular, one
of them features the interaction between Veamy and the polygonal mesh generator
PolyMesher. A computational performance comparison between VEM and FEM is also
conducted. Veamy is free and open source software.
"
925,"The basic principles and the structure and algorithmically software of
  computing by hypercomplex number","  In article the basic principles put in a basis of algorithmicallysoftware of
hypercomplex number calculations, structure of a software, structure of
functional subsystems are considered. The most important procedures included in
subsystems are considered, program listings and examples of their application
are given.
"
926,"An OpenGL and C++ based function library for curve and surface modeling
  in a large class of extended Chebyshev spaces","  We propose a platform-independent multi-threaded function library that
provides data structures to generate, differentiate and render both the
ordinary basis and the normalized B-basis of a user-specified extended
Chebyshev (EC) space that comprises the constants and can be identified with
the solution space of a constant-coefficient homogeneous linear differential
equation defined on a sufficiently small interval. Using the obtained
normalized B-bases, our library can also generate, (partially) differentiate,
modify and visualize a large family of so-called B-curves and tensor product
B-surfaces. Moreover, the library also implements methods that can be used to
perform dimension elevation, to subdivide B-curves and B-surfaces by means of
de Casteljau-like B-algorithms, and to generate basis transformations for the
B-representation of arbitrary integral curves and surfaces that are described
in traditional parametric form by means of the ordinary bases of the underlying
EC spaces. Independently of the algebraic, exponential, trigonometric or mixed
type of the applied EC space, the proposed library is numerically stable and
efficient up to a reasonable dimension number and may be useful for academics
and engineers in the fields of Approximation Theory, Computer Aided Geometric
Design, Computer Graphics, Isogeometric and Numerical Analysis.
"
927,"PSelInv - A Distributed Memory Parallel Algorithm for Selected
  Inversion: the non-symmetric Case","  This paper generalizes the parallel selected inversion algorithm called
PSelInv to sparse non- symmetric matrices. We assume a general sparse matrix A
has been decomposed as PAQ = LU on a distributed memory parallel machine, where
L, U are lower and upper triangular matrices, and P, Q are permutation
matrices, respectively. The PSelInv method computes selected elements of A-1.
The selection is confined by the sparsity pattern of the matrix AT . Our
algorithm does not assume any symmetry properties of A, and our parallel
implementation is memory efficient, in the sense that the computed elements of
A-T overwrites the sparse matrix L+U in situ. PSelInv involves a large number
of collective data communication activities within different processor groups
of various sizes. In order to minimize idle time and improve load balancing,
tree-based asynchronous communication is used to coordinate all such collective
communication. Numerical results demonstrate that PSelInv can scale efficiently
to 6,400 cores for a variety of matrices.
"
928,Designing and building the mlpack open-source machine learning library,"  mlpack is an open-source C++ machine learning library with an emphasis on
speed and flexibility. Since its original inception in 2007, it has grown to be
a large project implementing a wide variety of machine learning algorithms,
from standard techniques such as decision trees and logistic regression to
modern techniques such as deep neural networks as well as other
recently-published cutting-edge techniques not found in any other library.
mlpack is quite fast, with benchmarks showing mlpack outperforming other
libraries' implementations of the same methods. mlpack has an active community,
with contributors from around the world---including some from PUST. This short
paper describes the goals and design of mlpack, discusses how the open-source
community functions, and shows an example usage of mlpack for a simple data
science problem.
"
929,Computer Algebra for Microhydrodynamics,"  I describe a method for computer algebra that helps with laborious
calculations typically encountered in theoretical microhydrodynamics. The
program mimics how humans calculate by matching patterns and making
replacements according to the rules of algebra and calculus. This note gives an
overview and walks through an example, while the accompanying code repository
contains the implementation details, a tutorial, and more examples. The code
repository is attached as supplementary material to this note, and maintained
at https://github.com/jeinarsson/matte
"
930,Parallel solver for shifted systems in a hybrid CPU-GPU framework,"  This paper proposes a combination of a hybrid CPU--GPU and a pure GPU
software implementation of a direct algorithm for solving shifted linear
systems $(A - \sigma I)X = B$ with large number of complex shifts $\sigma$ and
multiple right-hand sides. Such problems often appear e.g. in control theory
when evaluating the transfer function, or as a part of an algorithm performing
interpolatory model reduction, as well as when computing pseudospectra and
structured pseudospectra, or solving large linear systems of ordinary
differential equations. The proposed algorithm first jointly reduces the
general full $n\times n$ matrix $A$ and the $n\times m$ full right-hand side
matrix $B$ to the controller Hessenberg canonical form that facilitates
efficient solution: $A$ is transformed to a so-called $m$-Hessenberg form and
$B$ is made upper-triangular. This is implemented as blocked highly parallel
CPU--GPU hybrid algorithm; individual blocks are reduced by the CPU, and the
necessary updates of the rest of the matrix are split among the cores of the
CPU and the GPU. To enhance parallelization, the reduction and the updates are
overlapped. In the next phase, the reduced $m$-Hessenberg--triangular systems
are solved entirely on the GPU, with shifts divided into batches. The benefits
of such load distribution are demonstrated by numerical experiments. In
particular, we show that our proposed implementation provides an excellent
basis for efficient implementations of computational methods in systems and
control theory, from evaluation of transfer function to the interpolatory model
reduction.
"
931,"Preconditioned Spectral Clustering for Stochastic Block Partition
  Streaming Graph Challenge","  Locally Optimal Block Preconditioned Conjugate Gradient (LOBPCG) is
demonstrated to efficiently solve eigenvalue problems for graph Laplacians that
appear in spectral clustering. For static graph partitioning, 10-20 iterations
of LOBPCG without preconditioning result in ~10x error reduction, enough to
achieve 100% correctness for all Challenge datasets with known truth
partitions, e.g., for graphs with 5K/.1M (50K/1M) Vertices/Edges in 2 (7)
seconds, compared to over 5,000 (30,000) seconds needed by the baseline Python
code. Our Python code 100% correctly determines 98 (160) clusters from the
Challenge static graphs with 0.5M (2M) vertices in 270 (1,700) seconds using
10GB (50GB) of memory. Our single-precision MATLAB code calculates the same
clusters at half time and memory. For streaming graph partitioning, LOBPCG is
initiated with approximate eigenvectors of the graph Laplacian already computed
for the previous graph, in many cases reducing 2-3 times the number of required
LOBPCG iterations, compared to the static case. Our spectral clustering is
generic, i.e. assuming nothing specific of the block model or streaming, used
to generate the graphs for the Challenge, in contrast to the base code.
Nevertheless, in 10-stage streaming comparison with the base code for the 5K
graph, the quality of our clusters is similar or better starting at stage 4 (7)
for emerging edging (snowballing) streaming, while the computations are over
100-1000 faster.
"
932,Algorithmic patterns for $\mathcal{H}$-matrices on many-core processors,"  In this work, we consider the reformulation of hierarchical ($\mathcal{H}$)
matrix algorithms for many-core processors with a model implementation on
graphics processing units (GPUs). $\mathcal{H}$ matrices approximate specific
dense matrices, e.g., from discretized integral equations or kernel ridge
regression, leading to log-linear time complexity in dense matrix-vector
products. The parallelization of $\mathcal{H}$ matrix operations on many-core
processors is difficult due to the complex nature of the underlying algorithms.
While previous algorithmic advances for many-core hardware focused on
accelerating existing $\mathcal{H}$ matrix CPU implementations by many-core
processors, we here aim at totally relying on that processor type. As main
contribution, we introduce the necessary parallel algorithmic patterns allowing
to map the full $\mathcal{H}$ matrix construction and the fast matrix-vector
product to many-core hardware. Here, crucial ingredients are space filling
curves, parallel tree traversal and batching of linear algebra operations. The
resulting model GPU implementation hmglib is the, to the best of the authors
knowledge, first entirely GPU-based Open Source $\mathcal{H}$ matrix library of
this kind. We conclude this work by an in-depth performance analysis and a
comparative performance study against a standard $\mathcal{H}$ matrix library,
highlighting profound speedups of our many-core parallel approach.
"
933,"Look-Ahead in the Two-Sided Reduction to Compact Band Forms for
  Symmetric Eigenvalue Problems and the SVD","  We address the reduction to compact band forms, via unitary similarity
transformations, for the solution of symmetric eigenvalue problems and the
computation of the singular value decomposition (SVD). Concretely, in the first
case we revisit the reduction to symmetric band form while, for the second
case, we propose a similar alternative, which transforms the original matrix to
(unsymmetric) band form, replacing the conventional reduction method that
produces a triangular--band output. In both cases, we describe algorithmic
variants of the standard Level-3 BLAS-based procedures, enhanced with
look-ahead, to overcome the performance bottleneck imposed by the panel
factorization. Furthermore, our solutions employ an algorithmic block size that
differs from the target bandwidth, illustrating the important performance
benefits of this decision. Finally, we show that our alternative compact band
form for the SVD is key to introduce an effective look-ahead strategy into the
corresponding reduction procedure.
"
934,Distributed Triangle Counting in the Graphulo Matrix Math Library,"  Triangle counting is a key algorithm for large graph analysis. The Graphulo
library provides a framework for implementing graph algorithms on the Apache
Accumulo distributed database. In this work we adapt two algorithms for
counting triangles, one that uses the adjacency matrix and another that also
uses the incidence matrix, to the Graphulo library for server-side processing
inside Accumulo. Cloud-based experiments show a similar performance profile for
these different approaches on the family of power law Graph500 graphs, for
which data skew increasingly bottlenecks. These results motivate the design of
skew-aware hybrid algorithms that we propose for future work.
"
935,"From MPI to MPI+OpenACC: Conversion of a legacy FORTRAN PCG solver for
  the spherical Laplace equation","  A real-world example of adding OpenACC to a legacy MPI FORTRAN Preconditioned
Conjugate Gradient code is described, and timing results for multi-node
multi-GPU runs are shown. The code is used to obtain three-dimensional
spherical solutions to the Laplace equation. Its application is finding
potential field solutions of the solar corona, a useful tool in space weather
modeling. We highlight key tips, strategies, and challenges faced when adding
OpenACC. Performance results are shown for running the code with MPI-only on
multiple CPUs, and with MPI+OpenACC on multiple GPUs and CPUs.
"
936,qTorch: The Quantum Tensor Contraction Handler,"  Classical simulation of quantum computation is necessary for studying the
numerical behavior of quantum algorithms, as there does not yet exist a large
viable quantum computer on which to perform numerical tests. Tensor network
(TN) contraction is an algorithmic method that can efficiently simulate some
quantum circuits, often greatly reducing the computational cost over methods
that simulate the full Hilbert space. In this study we implement a tensor
network contraction program for simulating quantum circuits using multi-core
compute nodes. We show simulation results for the Max-Cut problem on 3- through
7-regular graphs using the quantum approximate optimization algorithm (QAOA),
successfully simulating up to 100 qubits. We test two different methods for
generating the ordering of tensor index contractions: one is based on the tree
decomposition of the line graph, while the other generates ordering using a
straight-forward stochastic scheme. Through studying instances of QAOA
circuits, we show the expected result that as the treewidth of the quantum
circuit's line graph decreases, TN contraction becomes significantly more
efficient than simulating the whole Hilbert space. The results in this work
suggest that tensor contraction methods are superior only when simulating
Max-Cut/QAOA with graphs of regularities approximately five and below. Insight
into this point of equal computational cost helps one determine which
simulation method will be more efficient for a given quantum circuit. The
stochastic contraction method outperforms the line graph based method only when
the time to calculate a reasonable tree decomposition is prohibitively
expensive. Finally, we release our software package, qTorch (Quantum TensOR
Contraction Handler), intended for general quantum circuit simulation.
"
937,"OpenMP GNU and Intel Fortran programs for solving the time-dependent
  Gross-Pitaevskii equation","  We present Open Multi-Processing (OpenMP) version of Fortran 90 programs for
solving the Gross-Pitaevskii (GP) equation for a Bose-Einstein condensate in
one, two, and three spatial dimensions, optimized for use with GNU and Intel
compilers. We use the split-step Crank-Nicolson algorithm for imaginary- and
real-time propagation, which enables efficient calculation of stationary and
non-stationary solutions, respectively. The present OpenMP programs are
designed for computers with multi-core processors and optimized for compiling
with both commercially-licensed Intel Fortran and popular free open-source GNU
Fortran compiler. The programs are easy to use and are elaborated with helpful
comments for the users. All input parameters are listed at the beginning of
each program. Different output files provide physical quantities such as
energy, chemical potential, root-mean-square sizes, densities, etc. We also
present speedup test results for new versions of the programs.
"
938,A Rewriting System for Convex Optimization Problems,"  We describe a modular rewriting system for translating optimization problems
written in a domain-specific language to forms compatible with low-level solver
interfaces. Translation is facilitated by reductions, which accept a category
of problems and transform instances of that category to equivalent instances of
another category. Our system proceeds in two key phases: analysis, in which we
attempt to find a suitable solver for a supplied problem, and canonicalization,
in which we rewrite the problem in the selected solver's standard form. We
implement the described system in version 1.0 of CVXPY, a domain-specific
language for mathematical and especially convex optimization. By treating
reductions as first-class objects, our method makes it easy to match problems
to solvers well-suited for them and to support solvers with a wide variety of
standard forms.
"
939,Magnus integrators on multicore CPUs and GPUs,"  In the present paper we consider numerical methods to solve the discrete
Schr\""odinger equation with a time dependent Hamiltonian (motivated by problems
encountered in the study of spin systems). We will consider both short-range
interactions, which lead to evolution equations involving sparse matrices, and
long-range interactions, which lead to dense matrices. Both of these settings
show very different computational characteristics. We use Magnus integrators
for time integration and employ a framework based on Leja interpolation to
compute the resulting action of the matrix exponential. We consider both
traditional Magnus integrators (which are extensively used for these types of
problems in the literature) as well as the recently developed commutator-free
Magnus integrators and implement them on modern CPU and GPU (graphics
processing unit) based systems.
  We find that GPUs can yield a significant speed-up (up to a factor of $10$ in
the dense case) for these types of problems. In the sparse case GPUs are only
advantageous for large problem sizes and the achieved speed-ups are more
modest. In most cases the commutator-free variant is superior but especially on
the GPU this advantage is rather small. In fact, none of the advantage of
commutator-free methods on GPUs (and on multi-core CPUs) is due to the
elimination of commutators. This has important consequences for the design of
more efficient numerical methods.
"
940,High-Performance Derivative Computations using CoDiPack,"  There are several AD tools available, which all implement different
strategies for the reverse mode of AD. The major strategies are primal value
taping (implemented e.g. by ADOL-c) and Jacobi taping (implemented e.g. by
adept and dco/c++). Especially for Jacobi taping, recent advances by using
expression templates make this approach very attractive for large scale
software. The current implementations are either closed source or miss
essential features and flexibility. Therefore, we present the new AD tool
CoDiPack (Code Differentiation Package) in this paper. It is specifically
designed for a minimal memory consumption and optimal runtime, such that it can
be used for the differentiation of large scale software. An essential part of
the design of CoDiPack is the modular layout and the recursive data structures,
which do not only allow the efficient implementation of the Jacobi taping
approach, but will also enable other approaches like the primal value taping or
new research ideas. We will also present the performance value of CoDiPack on a
generic PDE example and on the SU2 code.
"
941,A new indexed approach to render the attractors of Kleinian groups,"  One widespread procedure to render the attractor of Kleinian groups,
published in the renown book ""Indra's Pearls"" and based upon a combinatorial
tree model, wants huge memory resources to compute and store all the words
required. We will present here a new faster and lighter version which drops the
original words array and pulls out words from integer numbers.
"
942,Tensors Come of Age: Why the AI Revolution will help HPC,"  This article discusses how the automation of tensor algorithms, based on A
Mathematics of Arrays and Psi Calculus, and a new way to represent numbers,
Unum Arithmetic, enables mechanically provable, scalable, portable, and more
numerically accurate software.
"
943,"Energy efficiency of finite difference algorithms on multicore CPUs,
  GPUs, and Intel Xeon Phi processors","  In addition to hardware wall-time restrictions commonly seen in
high-performance computing systems, it is likely that future systems will also
be constrained by energy budgets. In the present work, finite difference
algorithms of varying computational and memory intensity are evaluated with
respect to both energy efficiency and runtime on an Intel Ivy Bridge CPU node,
an Intel Xeon Phi Knights Landing processor, and an NVIDIA Tesla K40c GPU. The
conventional way of storing the discretised derivatives to global arrays for
solution advancement is found to be inefficient in terms of energy consumption
and runtime. In contrast, a class of algorithms in which the discretised
derivatives are evaluated on-the-fly or stored as thread-/process-local
variables (yielding high compute intensity) is optimal both with respect to
energy consumption and runtime. On all three hardware architectures considered,
a speed-up of ~2 and an energy saving of ~2 are observed for the high compute
intensive algorithms compared to the memory intensive algorithm. The energy
consumption is found to be proportional to runtime, irrespective of the power
consumed and the GPU has an energy saving of ~5 compared to the same algorithm
on a CPU node.
"
944,"HPC optimal parallel communication algorithm for the simulation of
  fractional-order systems","  A parallel numerical simulation algorithm is presented for fractional-order
systems involving Caputo-type derivatives, based on the Adams-Bashforth-Moulton
(ABM) predictor-corrector scheme. The parallel algorithm is implemented using
several different approaches: a pure MPI version, a combination of MPI with
OpenMP optimization and a memory saving speedup approach. All tests run on a
BlueGene/P cluster, and comparative improvement results for the running time
are provided. As an applied experiment, the solutions of a fractional-order
version of a system describing a forced series LCR circuit are numerically
computed, depicting cascades of period-doubling bifurcations which lead to the
onset of chaotic behavior.
"
945,"Tuning Technique for Multiple Precision Dense Matrix Multiplication
  using Prediction of Computational Time","  Although reliable long precision floating-point arithmetic libraries such as
QD and MPFR/GMP are necessary to solve ill-conditioned problems in numerical
simulation, long precision BLAS-level computation such as matrix multiplication
has not been fully optimized because tuning costs are very high compared to
IEEE float and double precision arithmetic. In this study, we develop a
technique to shorten this tuning time by using prediction of computational
times in several block sizes for the blocking algorithm, and then selecting the
fastest matrix multiplication method for tuning multiple precision dense real
matrix multiplication in various precisions, matrix sizes, and degrees of
parallelization.
"
946,"SoAx: A generic C++ Structure of Arrays for handling Particles in HPC
  Codes","  The numerical study of physical problems often require integrating the
dynamics of a large number of particles evolving according to a given set of
equations. Particles are characterized by the information they are carrying
such as an identity, a position other. There are generally speaking two
different possibilities for handling particles in high performance computing
(HPC) codes. The concept of an Array of Structures (AoS) is in the spirit of
the object-oriented programming (OOP) paradigm in that the particle information
is implemented as a structure. Here, an object (realization of the structure)
represents one particle and a set of many particles is stored in an array. In
contrast, using the concept of a Structure of Arrays (SoA), a single structure
holds several arrays each representing one property (such as the identity) of
the whole set of particles.
  The AoS approach is often implemented in HPC codes due to its handiness and
flexibility. For a class of problems, however, it is know that the performance
of SoA is much better than that of AoS. We confirm this observation for our
particle problem. Using a benchmark we show that on modern Intel Xeon
processors the SoA implementation is typically several times faster than the
AoS one. On Intel's MIC co-processors the performance gap even attains a factor
of ten. The same is true for GPU computing, using both computational and
multi-purpose GPUs.
  Combining performance and handiness, we present the library SoAx that has
optimal performance (on CPUs, MICs, and GPUs) while providing the same
handiness as AoS. For this, SoAx uses modern C++ design techniques such
template meta programming that allows to automatically generate code for user
defined heterogeneous data structures.
"
947,"Subdomain Deflation Combined with Local AMG: a Case Study Using AMGCL
  Library","  The paper proposes a combination of the subdomain deflation method and local
algebraic multigrid as a scalable distributed memory preconditioner that is
able to solve large linear systems of equations. The implementation of the
algorithm is made available for the community as part of an open source AMGCL
library. The solution targets both homogeneous (CPU-only) and heterogeneous
(CPU/GPU) systems, employing hybrid MPI/OpenMP approach in the former and a
combination of MPI, OpenMP, and CUDA in the latter cases. The use of OpenMP
minimizes the number of MPI processes, thus reducing the communication overhead
of the deflation method and improving both weak and strong scalability of the
preconditioner. The examples of scalar, Poisson-like, systems as well as
non-scalar problems, stemming out of the discretization of the Navier-Stokes
equations, are considered in order to estimate performance of the implemented
algorithm. A comparison with a traditional global AMG preconditioner based on a
well-established Trilinos ML package is provided.
"
948,Deriving Correct High-Performance Algorithms,"  Dijkstra observed that verifying correctness of a program is difficult and
conjectured that derivation of a program hand-in-hand with its proof of
correctness was the answer. We illustrate this goal-oriented approach by
applying it to the domain of dense linear algebra libraries for distributed
memory parallel computers. We show that algorithms that underlie the
implementation of most functionality for this domain can be systematically
derived to be correct. The benefit is that an entire family of algorithms for
an operation is discovered so that the best algorithm for a given architecture
can be chosen. This approach is very practical: Ideas inspired by it have been
used to rewrite the dense linear algebra software stack starting below the
Basic Linear Algebra Subprograms (BLAS) and reaching up through the Elemental
distributed memory library, and every level in between. The paper demonstrates
how formal methods and rigorous mathematical techniques for correctness impact
HPC.
"
949,On Parallel Solution of Sparse Triangular Linear Systems in CUDA,"  The acceleration of sparse matrix computations on modern many-core
processors, such as the graphics processing units (GPUs), has been recognized
and studied over a decade. Significant performance enhancements have been
achieved for many sparse matrix computational kernels such as sparse
matrix-vector products and sparse matrix-matrix products. Solving linear
systems with sparse triangular structured matrices is another important sparse
kernel as demanded by a variety of scientific and engineering applications such
as sparse linear solvers. However, the development of efficient parallel
algorithms in CUDA for solving sparse triangular linear systems remains a
challenging task due to the inherently sequential nature of the computation. In
this paper, we will revisit this problem by reviewing the existing
level-scheduling methods and proposing algorithms with self-scheduling
techniques. Numerical results have indicated that the CUDA implementations of
the proposed algorithms can outperform the state-of-the-art solvers in cuSPARSE
by a factor of up to $2.6$ for structured model problems and general sparse
matrices.
"
950,Wilson and Domainwall Kernels on Oakforest-PACS,"  We report the performance of Wilson and Domainwall Kernels on a new Intel
Xeon Phi Knights Landing based machine named Oakforest-PACS, which is co-hosted
by University of Tokyo and Tsukuba University and is currently fastest in
Japan. This machine uses Intel Omni-Path for the internode network. We compare
performance with several types of implementation including that makes use of
the Grid library. The code is incorporated with the code set Bridge++.
"
951,"Geometric Computing with Chain Complexes: Design and Features of a Julia
  Package","  Geometric computing with chain complexes allows for the computation of the
whole chain of linear spaces and (co)boundary operators generated by a space
decomposition into a cell complex. The space decomposition is stored and
handled with LAR (Linear Algebraic Representation), i.e. with sparse integer
arrays, and allows for using cells of a very general type, even non convex and
with internal holes. In this paper we discuss the features and the merits of
this approach, and describe the goals and the implementation of a software
package aiming at providing for simple and efficient computational support of
geometric computing with any kind of meshes, using linear algebra tools with
sparse matrices. The library is being written in Julia, the novel efficient and
parallel language for scientific computing. This software, that is being ported
on hybrid architectures (CPU+GPU) of last generation, is yet under development.
"
952,Nauticle: a general-purpose particle-based simulation tool,"  Nauticle is a general-purpose simulation tool for the flexible and highly
configurable application of particle-based methods of either discrete or
continuum phenomena. It is presented that Nauticle has three distinct layers
for users and developers, then the top two layers are discussed in detail. The
paper introduces the Symbolic Form Language (SFL) of Nauticle, which
facilitates the formulation of user-defined numerical models at the top level
in text-based configuration files and provides simple application examples of
use. On the other hand, at the intermediate level, it is shown that the SFL can
be intuitively extended with new particle methods without tedious recoding or
even the knowledge of the bottom level. Finally, the efficiency of the code is
also tested through a performance benchmark.
"
953,Communication-avoiding Cholesky-QR2 for rectangular matrices,"  Scalable QR factorization algorithms for solving least squares and eigenvalue
problems are critical given the increasing parallelism within modern machines.
We introduce a more general parallelization of the CholeskyQR2 algorithm and
show its effectiveness for a wide range of matrix sizes. Our algorithm executes
over a 3D processor grid, the dimensions of which can be tuned to trade-off
costs in synchronization, interprocessor communication, computational work, and
memory footprint. We implement this algorithm, yielding a code that can achieve
a factor of $\Theta(P^{1/6})$ less interprocessor communication on $P$
processors than any previous parallel QR implementation. Our performance study
on Intel Knights-Landing and Cray XE supercomputers demonstrates the
effectiveness of this CholeskyQR2 parallelization on a large number of nodes.
Specifically, relative to ScaLAPACK's QR, on 1024 nodes of Stampede2, our
CholeskyQR2 implementation is faster by 2.6x-3.3x in strong scaling tests and
by 1.1x-1.9x in weak scaling tests.
"
954,"Implicit Low-Order Unstructured Finite-Element Multiple Simulation
  Enhanced by Dense Computation using OpenACC","  In this paper, we develop a low-order three-dimensional finite-element solver
for fast multiple-case crust deformation analysis on GPU-based systems. Based
on a high-performance solver designed for massively parallel CPU based systems,
we modify the algorithm to reduce random data access, and then insert OpenACC
directives. The developed solver on ten Reedbush-H nodes (20 P100 GPUs)
attained speedup of 14.2 times from 20 K computer nodes, which is high
considering the peak memory bandwidth ratio of 11.4 between the two systems. On
the newest Volta generation V100 GPUs, the solver attained a further 2.45 times
speedup from P100 GPUs. As a demonstrative example, we computed 368 cases of
crustal deformation analyses of northeast Japan with 400 million degrees of
freedom. The total procedure of algorithm modification and porting
implementation took only two weeks; we can see that high performance
improvement was achieved with low development cost. With the developed solver,
we can expect improvement in reliability of crust-deformation analyses by
many-case analyses on a wide range of GPU-based systems.
"
955,Auto-Differentiating Linear Algebra,"  Development systems for deep learning (DL), such as Theano, Torch,
TensorFlow, or MXNet, are easy-to-use tools for creating complex neural network
models. Since gradient computations are automatically baked in, and execution
is mapped to high performance hardware, these models can be trained end-to-end
on large amounts of data. However, it is currently not easy to implement many
basic machine learning primitives in these systems (such as Gaussian processes,
least squares estimation, principal components analysis, Kalman smoothing),
mainly because they lack efficient support of linear algebra primitives as
differentiable operators. We detail how a number of matrix decompositions
(Cholesky, LQ, symmetric eigen) can be implemented as differentiable operators.
We have implemented these primitives in MXNet, running on CPU and GPU in single
and double precision. We sketch use cases of these new operators, learning
Gaussian process and Bayesian linear regression models, where we demonstrate
very substantial reductions in implementation complexity and running time
compared to previous codes. Our MXNet extension allows end-to-end learning of
hybrid models, which combine deep neural networks (DNNs) with Bayesian
concepts, with applications in advanced Gaussian process models, scalable
Bayesian optimization, and Bayesian active learning.
"
956,GooFit 2.0,"  The GooFit package provides physicists a simple, familiar syntax for
manipulating probability density functions and performing fits, and is highly
optimized for data analysis on NVIDIA GPUs and multithreaded CPU backends.
GooFit was updated to version 2.0, bringing a host of new features. A
completely revamped and redesigned build system makes GooFit easier to install,
develop with, and run on virtually any system. Unit testing, continuous
integration, and advanced logging options are improving the stability and
reliability of the system. Developing new PDFs now uses standard CUDA
terminology and provides a lower barrier for new users. The system now has
built-in support for multiple graphics cards or nodes using MPI, and is being
tested on a wide range of different systems. GooFit also has significant
improvements in performance on some GPU architectures due to optimized memory
access. Support for time-dependent four-body amplitude analyses has also been
added.
"
957,Performance Portability Strategies for Grid C++ Expression Templates,"  One of the key requirements for the Lattice QCD Application Development as
part of the US Exascale Computing Project is performance portability across
multiple architectures. Using the Grid C++ expression template as a starting
point, we report on the progress made with regards to the Grid GPU offloading
strategies. We present both the successes and issues encountered in using CUDA,
OpenACC and Just-In-Time compilation. Experimentation and performance on GPUs
with a SU(3)$\times$SU(3) streaming test will be reported. We will also report
on the challenges of using current OpenMP 4.x for GPU offloading in the same
code.
"
958,Fast Linear Transformations in Python,"  This paper introduces a new free library for the Python programming language,
which provides a collection of structured linear transforms, that are not
represented as explicit two dimensional arrays but in a more efficient way by
exploiting the structural knowledge.
  This allows fast and memory savy forward and backward transformations while
also provding a clean but still flexible interface to these effcient
algorithms, thus making code more readable, scable and adaptable.
  We first outline the goals of this library, then how they were achieved and
lastly we demonstrate the performance compared to current state of the art
packages available for Python.
  This library is released and distributed under a free license.
"
959,"A Massively Parallel Algorithm for the Approximate Calculation of
  Inverse p-th Roots of Large Sparse Matrices","  We present the submatrix method, a highly parallelizable method for the
approximate calculation of inverse p-th roots of large sparse symmetric
matrices which are required in different scientific applications. We follow the
idea of Approximate Computing, allowing imprecision in the final result in
order to be able to utilize the sparsity of the input matrix and to allow
massively parallel execution. For an n x n matrix, the proposed algorithm
allows to distribute the calculations over n nodes with only little
communication overhead. The approximate result matrix exhibits the same
sparsity pattern as the input matrix, allowing for efficient reuse of allocated
data structures.
  We evaluate the algorithm with respect to the error that it introduces into
calculated results, as well as its performance and scalability. We demonstrate
that the error is relatively limited for well-conditioned matrices and that
results are still valuable for error-resilient applications like
preconditioning even for ill-conditioned matrices. We discuss the execution
time and scaling of the algorithm on a theoretical level and present a
distributed implementation of the algorithm using MPI and OpenMP. We
demonstrate the scalability of this implementation by running it on a
high-performance compute cluster comprised of 1024 CPU cores, showing a speedup
of 665x compared to single-threaded execution.
"
960,SGDLibrary: A MATLAB library for stochastic gradient descent algorithms,"  We consider the problem of finding the minimizer of a function $f:
\mathbb{R}^d \rightarrow \mathbb{R}$ of the finite-sum form $\min f(w) =
1/n\sum_{i}^n f_i(w)$. This problem has been studied intensively in recent
years in the field of machine learning (ML). One promising approach for
large-scale data is to use a stochastic optimization algorithm to solve the
problem. SGDLibrary is a readable, flexible and extensible pure-MATLAB library
of a collection of stochastic optimization algorithms. The purpose of the
library is to provide researchers and implementers a comprehensive evaluation
environment for the use of these algorithms on various ML problems.
"
961,"Performance Optimization and Parallelization of a Parabolic Equation
  Solver in Computational Ocean Acoustics on Modern Many-core Computer","  As one of open-source codes widely used in computational ocean acoustics,
FOR3D can provide a very good estimate for underwater acoustic propagation. In
this paper, we propose a performance optimization and parallelization to speed
up the running of FOR3D. We utilized a variety of methods to enhance the entire
performance, such as using a multi-threaded programming model to exploit the
potential capability of the many-core node of high-performance computing (HPC)
system, tuning compile options, using efficient tuned mathematical library and
utilizing vectorization optimization instruction. In addition, we extended the
application from single-frequency calculation to multi-frequency calculation
successfully by using OpenMP+MPI hybrid programming techniques on the
mainstream HPC platform. A detailed performance evaluation was performed and
the results showed that the proposed parallelization obtained good accelerated
effect of 25.77X when testing a typical three-dimensional medium-sized case on
Tianhe-2 supercomputer. It also showed that the tuned parallel version has a
weak-scalability. The speed of calculation of underwater sound field can be
greatly improved by the strategy mentioned in this paper. The method used in
this paper is not only applicable to other similar computing models in
computational ocean acoustics but also a guideline of performance enhancement
for scientific and engineering application running on modern
many-core-computing platform.
"
962,"Acceleration of tensor-product operations for high-order finite element
  methods","  This paper is devoted to GPU kernel optimization and performance analysis of
three tensor-product operators arising in finite element methods. We provide a
mathematical background to these operations and implementation details.
Achieving close-to-the-peak performance for these operators requires extensive
optimization because of the operators' properties: low arithmetic intensity,
tiered structure, and the need to store intermediate results inside the kernel.
We give a guided overview of optimization strategies and we present a
performance model that allows us to compare the efficacy of these optimizations
against an empirically calibrated roofline.
"
963,"Exposing and exploiting structure: optimal code generation for
  high-order finite element methods","  Code generation based software platforms, such as Firedrake, have become
popular tools for developing complicated finite element discretisations of
partial differential equations. We extended the code generation infrastructure
in Firedrake with optimisations that can exploit the structure inherent to some
finite elements. This includes sum factorisation on cuboid cells for
continuous, discontinuous, H(div) and H(curl) conforming elements. Our
experiments confirm optimal algorithmic complexity for high-order finite
element assembly. This is achieved through several novel contributions: the
introduction of a more powerful interface between the form compiler and the
library providing the finite elements; a more abstract, smarter library of
finite elements called FInAT that explicitly communicates the structure of
elements; and form compiler algorithms to automatically exploit this exposed
structure.
"
964,CGAlgebra: a Mathematica package for conformal geometric algebra,"  A tutorial of the Mathematica package CGAlgebra, for conformal geometric
algebra calculations is presented. Using rule-based programming, the
5-dimensional conformal geometric algebra is implemented and defined functions
simplify the calculations of geometric, outer and inner products, as well as
many other calculations related with geometric transformations. CGAlgebra is
available from https://github.com/jlaragonvera/Geometric-Algebra
"
965,"Tangent: Automatic Differentiation Using Source Code Transformation in
  Python","  Automatic differentiation (AD) is an essential primitive for machine learning
programming systems. Tangent is a new library that performs AD using source
code transformation (SCT) in Python. It takes numeric functions written in a
syntactic subset of Python and NumPy as input, and generates new Python
functions which calculate a derivative. This approach to automatic
differentiation is different from existing packages popular in machine
learning, such as TensorFlow and Autograd. Advantages are that Tangent
generates gradient code in Python which is readable by the user, easy to
understand and debug, and has no runtime overhead. Tangent also introduces
abstractions for easily injecting logic into the generated gradient code,
further improving usability.
"
966,DLVM: A modern compiler infrastructure for deep learning systems,"  Deep learning software demands reliability and performance. However, many of
the existing deep learning frameworks are software libraries that act as an
unsafe DSL in Python and a computation graph interpreter. We present DLVM, a
design and implementation of a compiler infrastructure with a linear algebra
intermediate representation, algorithmic differentiation by adjoint code
generation, domain-specific optimizations and a code generator targeting GPU
via LLVM. Designed as a modern compiler infrastructure inspired by LLVM, DLVM
is more modular and more generic than existing deep learning compiler
frameworks, and supports tensor DSLs with high expressivity. With our
prototypical staged DSL embedded in Swift, we argue that the DLVM system
enables a form of modular, safe and performant frameworks for deep learning.
"
967,"Fast matrix-free evaluation of discontinuous Galerkin finite element
  operators","  We present an algorithmic framework for matrix-free evaluation of
discontinuous Galerkin finite element operators based on sum factorization on
quadrilateral and hexahedral meshes. We identify a set of kernels for fast
quadrature on cells and faces targeting a wide class of weak forms originating
from linear and nonlinear partial differential equations. Different algorithms
and data structures for the implementation of operator evaluation are compared
in an in-depth performance analysis. The sum factorization kernels are
optimized by vectorization over several cells and faces and an even-odd
decomposition of the one-dimensional compute kernels. In isolation our
implementation then reaches up to 60\% of arithmetic peak on Intel Haswell and
Broadwell processors and up to 50\% of arithmetic peak on Intel Knights
Landing. The full operator evaluation reaches only about half that throughput
due to memory bandwidth limitations from loading the input and output vectors,
MPI ghost exchange, as well as handling variable coefficients and the geometry.
Our performance analysis shows that the results are often within 10\% of the
available memory bandwidth for the proposed implementation, with the exception
of the Cartesian mesh case where the cost of gather operations and MPI
communication are more substantial.
"
968,"Domain-Specific Acceleration and Auto-Parallelization of Legacy
  Scientific Code in FORTRAN 77 using Source-to-Source Compilation","  Massively parallel accelerators such as GPGPUs, manycores and FPGAs represent
a powerful and affordable tool for scientists who look to speed up simulations
of complex systems. However, porting code to such devices requires a detailed
understanding of heterogeneous programming tools and effective strategies for
parallelization. In this paper we present a source to source compilation
approach with whole-program analysis to automatically transform single-threaded
FORTRAN 77 legacy code into OpenCL-accelerated programs with parallelized
kernels.
  The main contributions of our work are: (1) whole-source refactoring to allow
any subroutine in the code to be offloaded to an accelerator. (2) Minimization
of the data transfer between the host and the accelerator by eliminating
redundant transfers. (3) Pragmatic auto-parallelization of the code to be
offloaded to the accelerator by identification of parallelizable maps and
reductions.
  We have validated the code transformation performance of the compiler on the
NIST FORTRAN 78 test suite and several real-world codes: the Large Eddy
Simulator for Urban Flows, a high-resolution turbulent flow model; the shallow
water component of the ocean model Gmodel; the Linear Baroclinic Model, an
atmospheric climate model and Flexpart-WRF, a particle dispersion simulator.
  The automatic parallelization component has been tested on as 2-D Shallow
Water model (2DSW) and on the Large Eddy Simulator for Urban Flows (UFLES) and
produces a complete OpenCL-enabled code base. The fully OpenCL-accelerated
versions of the 2DSW and the UFLES are resp. 9x and 20x faster on GPU than the
original code on CPU, in both cases this is the same performance as manually
ported code.
"
969,"Performance Analysis and Optimization of Sparse Matrix-Vector
  Multiplication on Modern Multi- and Many-Core Processors","  This paper presents a low-overhead optimizer for the ubiquitous sparse
matrix-vector multiplication (SpMV) kernel. Architectural diversity among
different processors together with structural diversity among different sparse
matrices lead to bottleneck diversity. This justifies an SpMV optimizer that is
both matrix- and architecture-adaptive through runtime specialization. To this
direction, we present an approach that first identifies the performance
bottlenecks of SpMV for a given sparse matrix on the target platform either
through profiling or by matrix property inspection, and then selects suitable
optimizations to tackle those bottlenecks. Our optimization pool is based on
the widely used Compressed Sparse Row (CSR) sparse matrix storage format and
has low preprocessing overheads, making our overall approach practical even in
cases where fast decision making and optimization setup is required. We
evaluate our optimizer on three x86-based computing platforms and demonstrate
that it is able to distinguish and appropriately optimize SpMV for the majority
of matrices in a representative test suite, leading to significant speedups
over the CSR and Inspector-Executor CSR SpMV kernels available in the latest
release of the Intel MKL library.
"
970,PQSER: A Matlab package for spectral seriation,"  The seriation problem is an important ordering issue which consists of
finding the best ordering of a set of units whose interrelationship is defined
by a bipartite graph. It has important applications in, e.g., archaeology,
anthropology, psychology, and biology. This paper presents a Matlab
implementation of an algorithm for spectral seriation by Atkins et al., based
on the use of the Fiedler vector of the Laplacian matrix associated to the
problem, which encodes the set of admissible solutions into a PQ-tree. We
introduce some numerical technicalities in the original algorithm to improve
its performance, and point out that the presence of a multiple Fiedler value
may have a substantial influence on the computation of an approximated
solution, in the presence of inconsistent data sets. Practical examples and
numerical experiments show how to use the toolbox to process data sets deriving
from real-world applications.
"
971,"Hydra: a C++11 framework for data analysis in massively parallel
  platforms","  Hydra is a header-only, templated and C++11-compliant framework designed to
perform the typical bottleneck calculations found in common HEP data analyses
on massively parallel platforms. The framework is implemented on top of the
C++11 Standard Library and a variadic version of the Thrust library and is
designed to run on Linux systems, using OpenMP, CUDA and TBB enabled devices.
This contribution summarizes the main features of Hydra. A basic description of
the overall design, functionality and user interface is provided, along with
some code examples and measurements of performance.
"
972,Python Implementation and Construction of Finite Abelian Groups,"  Here we present a working framework to establish finite abelian groups in
python. The primary aim is to allow new A-level students to work with examples
of finite abelian groups using open source software. We include the code used
in the implementation of the framework. We also prove some useful results
regarding finite abelian groups which are used to establish the functions and
help show how number theoretic results can blend with computational power when
studying algebra. The groups established are based modular multiplication and
addition. We include direct products of cyclic groups meaning the user has
access to all finite abelian groups.
"
973,A generic and fast C++ optimization framework,"  The development of the mlpack C++ machine learning library
(http://www.mlpack.org/) has required the design and implementation of a
flexible, robust optimization system that is able to solve the types of
arbitrary optimization problems that may arise all throughout machine learning
problems. In this paper, we present the generic optimization framework that we
have designed for mlpack. A key priority in the design was ease of
implementation of both new optimizers and new objective functions to be
optimized; therefore, implementation of a new optimizer requires only one
method and implementation of a new objective function requires at most four
functions. This leads to simple and intuitive code, which, for fast prototyping
and experimentation, is of paramount importance. When compared to optimization
frameworks of other libraries, we find that mlpack's supports more types of
objective functions, is able to make optimizations that other frameworks do
not, and seamlessly supports user-defined objective functions and optimizers.
"
974,Solving Poisson's Equation on the Microsoft HoloLens,"  We present a mixed reality application (HoloFEM) for the Microsoft HoloLens.
The application lets a user define and solve a physical problem governed by
Poisson's equation with the surrounding real world geometry as input data.
Holograms are used to visualise both the problem and the solution. The finite
element method is used to solve Poisson's equation. Solving and visualising
partial differential equations in mixed reality could have potential usage in
areas such as building planning and safety engineering.
"
975,PhasePack User Guide,"  ""Phase retrieval"" refers to the recovery of signals from the magnitudes (and
not the phases) of linear measurements. While there has been a recent explosion
in development of phase retrieval methods, the lack of a common interface has
made it difficult to compare new methods against the current state-of-the-art.
PhasePack is a software library that creates a common interface for a wide
range of phase retrieval schemes. PhasePack also provides a test bed for phase
retrieval methods using both synthetic data and publicly available empirical
datasets.
"
976,"Efficiently and easily integrating differential equations with JiTCODE,
  JiTCDDE, and JiTCSDE","  We present a family of Python modules for the numerical integration of
ordinary, delay, or stochastic differential equations. The key features are
that the user enters the derivative symbolically and it is
just-in-time-compiled, allowing the user to efficiently integrate differential
equations from a higher-level interpreted language. The presented modules are
particularly suited for large systems of differential equations such as used to
describe dynamics on complex networks. Through the selected method of input,
the presented modules also allow to almost completely automatize the process of
estimating regular as well as transversal Lyapunov exponents for ordinary and
delay differential equations. We conceptually discuss the modules' design,
analyze their performance, and demonstrate their capabilities by application to
timely problems.
"
977,"TRPL+K: Thick-Restart Preconditioned Lanczos+K Method for Large
  Symmetric Eigenvalue Problems","  The Lanczos method is one of the standard approaches for computing a few
eigenpairs of a large, sparse, symmetric matrix. It is typically used with
restarting to avoid unbounded growth of memory and computational requirements.
Thick-restart Lanczos is a popular restarted variant because of its simplicity
and numerically robustness. However, convergence can be slow for highly
clustered eigenvalues so more effective restarting techniques and the use of
preconditioning is needed. In this paper, we present a thick-restart
preconditioned Lanczos method, TRPL+K, that combines the power of locally
optimal restarting (+K) and preconditioning techniques with the efficiency of
the thick-restart Lanczos method. TRPL+K employs an inner-outer scheme where
the inner loop applies Lanczos on a preconditioned operator while the outer
loop augments the resulting Lanczos subspace with certain vectors from the
previous restart cycle to obtain eigenvector approximations with which it thick
restarts the outer subspace. We first identify the differences from various
relevant methods in the literature. Then, based on an optimization perspective,
we show an asymptotic global quasi-optimality of a simplified TRPL+K method
compared to an unrestarted global optimal method. Finally, we present extensive
experiments showing that TRPL+K either outperforms or matches other
state-of-the-art eigenmethods in both matrix-vector multiplications and
computational time.
"
978,Abaqus2Matlab: A suitable tool for finite element post-processing,"  A suitable piece of software is presented to connect Abaqus, a sophisticated
finite element package, with Matlab, the most comprehensive program for
mathematical analysis. This interface between these well-known codes not only
benefits from the image processing and the integrated graph-plotting features
of Matlab but also opens up new opportunities in results post-processing,
statistical analysis and mathematical optimization, among many other
possibilities. The software architecture and usage are appropriately described
and two problems of particular engineering significance are addressed to
demonstrate its capabilities. Firstly, the software is employed to assess
cleavage fracture through a novel 3-parameter Weibull probabilistic framework.
Then, its potential to create and train neural networks is used to identify
damage parameters through a hybrid experimental-numerical scheme, and model
crack propagation in structural materials by means of a cohesive zone approach.
The source code, detailed documentation and a large number of tutorials can be
freely downloaded from www.abaqus2matlab.com.
"
979,HomotopyContinuation.jl: A package for homotopy continuation in Julia,"  We present the Julia package HomotopyContinuation.jl, which provides an
algorithmic framework for solving polynomial systems by numerical homotopy
continuation. We introduce the basic capabilities of the package and
demonstrate the software on an illustrative example. We motivate our choice of
Julia and how its features allow us to improve upon existing software packages
with respect to usability, modularity and performance. Furthermore, we compare
the performance of HomotopyContinuation.jl to the existing packages Bertini and
PHCpack.
"
980,TLib: A Flexible C++ Tensor Framework for Numerical Tensor Calculus,"  Numerical tensor calculus comprise basic tensor operations such as the
entrywise addition and contraction of higher-order tensors. We present, TLib,
flexible tensor framework with generic tensor functions and tensor classes that
assists users to implement generic and flexible tensor algorithms in C++. The
number of dimensions, the extents of the dimensions of the tensors and the
contraction modes of the tensor operations can be runtime variable. Our
framework provides tensor classes that simplify the management of
multidimensional data and utilization of tensor operations using
object-oriented and generic programming techniques. Additional stream classes
help the user to verify and compare of numerical results with MATLAB. Tensor
operations are implemented with generic tensor functions and in terms of
multidimensional iterator types only, decoupling data storage representation
and computation. The user can combine tensor functions with different tensor
types and extend the framework without further modification of the classes or
functions. We discuss the design and implementation of the framework and
demonstrate its usage with examples that have been discussed in the literature.
"
981,Constructive Arithmetics in Ore Localizations of Domains,"  For a non-commutative domain $R$ and a multiplicatively closed set $S$ the
(left) Ore localization of $R$ at $S$ exists if and only if $S$ satisfies the
(left) Ore property. Since the concept has been introduced by Ore back in the
1930's, Ore localizations have been widely used in theory and in applications.
We investigate the arithmetics of the localized ring $S^{-1}R$ from both
theoretical and practical points of view. We show that the key component of the
arithmetics is the computation of the intersection of a left ideal with a
submonoid $S$ of $R$. It is not known yet, whether there exists an algorithmic
solution of this problem in general. Still, we provide such solutions for cases
where $S$ is equipped with additional structure by distilling three most
frequently occurring types of Ore sets. We introduce the notion of the (left)
saturation closure and prove that it is a canonical form for (left) Ore sets in
$R$. We provide an implementation of arithmetics over the ubiquitous
$G$-algebras in \textsc{Singular:Plural} and discuss questions arising in this
context. Numerous examples illustrate the effectiveness of the proposed
approach.
"
982,Rings: an efficient Java/Scala library for polynomial rings,"  In this paper we briefly discuss \Rings --- an efficient lightweight library
for commutative algebra. Polynomial arithmetic, GCDs, polynomial factorization
and Gr\""obner bases are implemented with the use of modern asymptotically fast
algorithms. \Rings can be easily interacted or embedded in applications in
high-energy physics and other research areas via a simple API with fully typed
hierarchy of algebraic structures and algorithms for commutative algebra. The
use of the Scala language brings a quite novel powerful, strongly typed
functional programming model allowing to write short, expressive, and fast code
for applications. At the same time Rings shows one of the best performances
among existing software for algebraic calculations. \Rings is available from
http://github.com/PoslavskySV/rings
"
983,In a Nutshell: Sequential Parameter Optimization,"  The performance of optimization algorithms relies crucially on their
parameterizations. Finding good parameter settings is called algorithm tuning.
Using a simple simulated annealing algorithm, we will demonstrate how
optimization algorithms can be tuned using the sequential parameter
optimization toolbox (SPOT). SPOT provides several tools for automated and
interactive tuning. The underling concepts of the SPOT approach are explained.
This includes key techniques such as exploratory fitness landscape analysis and
response surface methodology. Many examples illustrate how SPOT can be used for
understanding the performance of algorithms and gaining insight into
algorithm's behavior. Furthermore, we demonstrate how SPOT can be used as an
optimizer and how a sophisticated ensemble approach is able to combine several
meta models via stacking.
"
984,"Accelerating the computation of FLAPW methods on heterogeneous
  architectures","  Legacy codes in computational science and engineering have been very
successful in providing essential functionality to researchers. However, they
are not capable of exploiting the massive parallelism provided by emerging
heterogeneous architectures. The lack of portable performance and scalability
puts them at high risk: either they evolve or they are doomed to disappear. One
example of legacy code which would heavily benefit from a modern design is
FLEUR, a software for electronic structure calculations. In previous work, the
computational bottleneck of FLEUR was partially re-engineered to have a modular
design that relies on standard building blocks, namely BLAS and LAPACK. In this
paper, we demonstrate how the initial redesign enables the portability to
heterogeneous architectures. More specifically, we study different approaches
to port the code to architectures consisting of multi-core CPUs equipped with
one or more coprocessors such as Nvidia GPUs and Intel Xeon Phis. Our final
code attains over 70\% of the architectures' peak performance, and outperforms
Nvidia's and Intel's libraries. Finally, on JURECA, the supercomputer where
FLEUR is often executed, the code takes advantage of the full power of the
computing nodes, attaining $5\times$ speedup over the sole use of the CPUs.
"
985,"A distributed-memory hierarchical solver for general sparse linear
  systems","  We present a parallel hierarchical solver for general sparse linear systems
on distributed-memory machines. For large-scale problems, this fully algebraic
algorithm is faster and more memory-efficient than sparse direct solvers
because it exploits the low-rank structure of fill-in blocks. Depending on the
accuracy of low-rank approximations, the hierarchical solver can be used either
as a direct solver or as a preconditioner. The parallel algorithm is based on
data decomposition and requires only local communication for updating boundary
data on every processor. Moreover, the computation-to-communication ratio of
the parallel algorithm is approximately the volume-to-surface-area ratio of the
subdomain owned by every processor. We present various numerical results to
demonstrate the versatility and scalability of the parallel algorithm.
"
986,"CameraTransform: a Scientific Python Package for Perspective Camera
  Corrections","  Scientific applications often require an exact reconstruction of object
positions and distances from digital images. Therefore, the images need to be
corrected for perspective distortions. We present \textit{CameraTransform}, a
python package that performs a perspective image correction whereby the height,
tilt/roll angle and heading of the camera can be automatically obtained from
the images if additional information such as GPS coordinates or object sizes
are provided. We present examples of images of penguin colonies that are
recorded with stationary cameras and from a helicopter.
"
987,A C++ interface to QCDNUM,"  In this document we report on the recent development of a C++ interface to
the FORTRAN-based evolution program QCDNUM. A short description of the
interface is given with a few basic examples of its usage.
"
988,"On quality of implementation of Fortran 2008 complex intrinsic functions
  on branch cuts","  Branch cuts in complex functions in combination with signed zero and signed
infinity have important uses in fracture mechanics, jet flow and aerofoil
analysis. We present benchmarks for validating Fortran 2008 complex functions -
LOG, SQRT, ASIN, ACOS, ATAN, ASINH, ACOSH and ATANH - on branch cuts with
arguments of all 3 IEEE floating point binary formats: binary32, binary64 and
binary128. Results are reported with 8 Fortran 2008 compilers: GCC, Flang,
Cray, Oracle, PGI, Intel, NAG and IBM. Multiple test failures were revealed,
e.g. wrong signs of results or unexpected overflow, underflow, or NaN. We
conclude that the quality of implementation of these Fortran 2008 intrinsics in
many compilers is not yet sufficient to remove the need for special code for
branch cuts. The test results are complemented by conformal maps of the branch
cuts and detailed derivations of the values of these functions on branch cuts,
to be used as a reference. The benchmarks are freely available from
cmplx.sf.net. This work will be of interest to engineers who use complex
functions, as well as to compiler and maths library developers.
"
989,ruptures: change point detection in Python,"  ruptures is a Python library for offline change point detection. This package
provides methods for the analysis and segmentation of non-stationary signals.
Implemented algorithms include exact and approximate detection for various
parametric and non-parametric models. ruptures focuses on ease of use by
providing a well-documented and consistent interface. In addition, thanks to
its modular structure, different algorithms and models can be connected and
extended within this package.
"
990,"Computing the sparse matrix vector product using block-based kernels
  without zero padding on processors with AVX-512 instructions","  The sparse matrix-vector product (SpMV) is a fundamental operation in many
scientific applications from various fields. The High Performance Computing
(HPC) community has therefore continuously invested a lot of effort to provide
an efficient SpMV kernel on modern CPU architectures. Although it has been
shown that block-based kernels help to achieve high performance, they are
difficult to use in practice because of the zero padding they require. In the
current paper, we propose new kernels using the AVX-512 instruction set, which
makes it possible to use a blocking scheme without any zero padding in the
matrix memory storage. We describe mask-based sparse matrix formats and their
corresponding SpMV kernels highly optimized in assembly language. Considering
that the optimal blocking size depends on the matrix, we also provide a method
to predict the best kernel to be used utilizing a simple interpolation of
results from previous executions. We compare the performance of our approach to
that of the Intel MKL CSR kernel and the CSR5 open-source package on a set of
standard benchmark matrices. We show that we can achieve significant
improvements in many cases, both for sequential and for parallel executions.
Finally, we provide the corresponding code in an open source library, called
SPC5.
"
991,Tensor Train decomposition on TensorFlow (T3F),"  Tensor Train decomposition is used across many branches of machine learning.
We present T3F -- a library for Tensor Train decomposition based on TensorFlow.
T3F supports GPU execution, batch processing, automatic differentiation, and
versatile functionality for the Riemannian optimization framework, which takes
into account the underlying manifold structure to construct efficient
optimization methods. The library makes it easier to implement machine learning
papers that rely on the Tensor Train decomposition. T3F includes documentation,
examples and 94% test coverage.
"
992,"Review of theory and implementation of hyper-dual numbers for first and
  second order automatic differentiation","  In this review we present hyper-dual numbers as a tool for the automatic
differentiation of computer programs via operator overloading.
  We start with a motivational introduction into the ideas of algorithmic
differentiation. Then we illuminate the concepts behind operator overloading
and dual numbers.
  Afterwards, we present hyper-dual numbers (and vectors) as an extension of
dual numbers for the computation of the Jacobian and the Hessian matrices of a
computer program. We review a mathematical theorem that proves the correctness
of the derivative information that is obtained from hyper-dual numbers.
  Finally, we refer to a freely available implementation of a hyper-dual number
class in Matlab. We explain an interface that can be called with a function as
argument such that the Jacobian and Hessian of this function are returned.
"
993,Distributed dynamic load balancing for task parallel programming,"  In this paper, we derive and investigate approaches to dynamically load
balance a distributed task parallel application software. The load balancing
strategy is based on task migration. Busy processes export parts of their ready
task queue to idle processes. Idle--busy pairs of processes find each other
through a random search process that succeeds within a few steps with high
probability. We evaluate the load balancing approach for a block Cholesky
factorization implementation and observe a reduction in execution time on the
order of 5\% in the selected test cases.
"
994,rlsm: R package for least squares Monte Carlo,"  This short paper briefly describes the implementation of the least squares
Monte Carlo method in the rlsm package. This package provides users with an
easy manner to experiment with the large amount of R regression tools on any
regression basis and reward functions. This package also computes lower and
upper bounds for the true value function via duality methods.
"
995,rcss: Subgradient and duality approach for dynamic programming,"  This short paper gives an introduction to the \emph{rcss} package. The R
package \emph{rcss} provides users with a tool to approximate the value
functions in the Bellman recursion using convex piecewise linear functions
formed using operations on tangents. A pathwise method is then used to gauge
the quality of the numerical results.
"
996,CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs,"  Deep Neural Networks are becoming increasingly popular in always-on IoT edge
devices performing data analytics right at the source, reducing latency as well
as energy consumption for data communication. This paper presents CMSIS-NN,
efficient kernels developed to maximize the performance and minimize the memory
footprint of neural network (NN) applications on Arm Cortex-M processors
targeted for intelligent IoT edge devices. Neural network inference based on
CMSIS-NN kernels achieves 4.6X improvement in runtime/throughput and 4.9X
improvement in energy efficiency.
"
997,Stop talking to me -- a communication-avoiding ADER-DG realisation,"  We present a communication- and data-sensitive formulation of ADER-DG for
hyperbolic differential equation systems. Sensitive here has multiple flavours:
First, the formulation reduces the persistent memory footprint. This reduces
pressure on the memory subsystem. Second, the formulation realises the
underlying predictor-corrector scheme with single-touch semantics, i.e., each
degree of freedom is read on average only once per time step from the main
memory. This reduces communication through the memory controllers. Third, the
formulation breaks up the tight coupling of the explicit time stepping's
algorithmic steps to mesh traversals. This averages out data access peaks.
Different operations and algorithmic steps are ran on different grid entities.
Finally, the formulation hides distributed memory data transfer behind the
computation aligned with the mesh traversal. This reduces pressure on the
machine interconnects. All techniques applied by our formulation are elaborated
by means of a rigorous task formalism. They break up ADER-DG's tight causal
coupling of compute steps and can be generalised to other predictor-corrector
schemes.
"
998,"GraphCombEx: A Software Tool for Exploration of Combinatorial
  Optimisation Properties of Large Graphs","  We present a prototype of a software tool for exploration of multiple
combinatorial optimisation problems in large real-world and synthetic complex
networks. Our tool, called GraphCombEx (an acronym of Graph Combinatorial
Explorer), provides a unified framework for scalable computation and
presentation of high-quality suboptimal solutions and bounds for a number of
widely studied combinatorial optimisation problems. Efficient representation
and applicability to large-scale graphs and complex networks are particularly
considered in its design. The problems currently supported include maximum
clique, graph colouring, maximum independent set, minimum vertex clique
covering, minimum dominating set, as well as the longest simple cycle problem.
Suboptimal solutions and intervals for optimal objective values are estimated
using scalable heuristics. The tool is designed with extensibility in mind,
with the view of further problems and both new fast and high-performance
heuristics to be added in the future. GraphCombEx has already been successfully
used as a support tool in a number of recent research studies using
combinatorial optimisation to analyse complex networks, indicating its promise
as a research software tool.
"
999,"Slate: extending Firedrake's domain-specific abstraction to hybridized
  solvers for geoscience and beyond","  Within the finite element community, discontinuous Galerkin (DG) and mixed
finite element methods have become increasingly popular in simulating
geophysical flows. However, robust and efficient solvers for the resulting
saddle-point and elliptic systems arising from these discretizations continue
to be an on-going challenge. One possible approach for addressing this issue is
to employ a method known as hybridization, where the discrete equations are
transformed such that classic static condensation and local post-processing
methods can be employed. However, it is challenging to implement hybridization
as performant parallel code within complex models, whilst maintaining
separation of concerns between applications scientists and software experts. In
this paper, we introduce a domain-specific abstraction within the Firedrake
finite element library that permits the rapid execution of these hybridization
techniques within a code-generating framework. The resulting framework composes
naturally with Firedrake's solver environment, allowing for the implementation
of hybridization and static condensation as runtime-configurable
preconditioners via the Python interface to PETSc, petsc4py. We provide
examples derived from second order elliptic problems and geophysical fluid
dynamics. In addition, we demonstrate that hybridization shows great promise
for improving the performance of solvers for mixed finite element
discretizations of equations related to large-scale geophysical flows.
"
1000,HOL Light QE,"  We are interested in algorithms that manipulate mathematical expressions in
mathematically meaningful ways. Expressions are syntactic, but most logics do
not allow one to discuss syntax. ${\rm CTT}_{\rm qe}$ is a version of Church's
type theory that includes quotation and evaluation operators, akin to quote and
eval in the Lisp programming language. Since the HOL logic is also a version of
Church's type theory, we decided to add quotation and evaluation to HOL Light
to demonstrate the implementability of ${\rm CTT}_{\rm qe}$ and the benefits of
having quotation and evaluation in a proof assistant. The resulting system is
called HOL Light QE. Here we document the design of HOL Light QE and the
challenges that needed to be overcome. The resulting implementation is freely
available.
"
1001,Automatic differentiation of ODE integration,"  We discuss the calculation of the derivatives of ODE systems with the
automatic differentiation tool ADiMat. Using the well-known Lotka-Volterra
equations and the ode23 ODE solver as examples we show the analytic derivatives
and detail how to differentiate a top-level function that calls ode23 somewhere
with ADiMat. This involves the manual construction of substitution function to
propagate the derivatives in forward and reverse mode. We also show how to use
the reverse mode code to evaluate the Hessian in forward-over-reverse mode.
"
1002,"High-level python abstractions for optimal checkpointing in inversion
  problems","  Inversion and PDE-constrained optimization problems often rely on solving the
adjoint problem to calculate the gradient of the objec- tive function. This
requires storing large amounts of intermediate data, setting a limit to the
largest problem that might be solved with a given amount of memory available.
Checkpointing is an approach that can reduce the amount of memory required by
redoing parts of the computation instead of storing intermediate results. The
Revolve checkpointing algorithm o ers an optimal schedule that trades
computational cost for smaller memory footprints. Integrat- ing Revolve into a
modern python HPC code and combining it with code generation is not
straightforward. We present an API that makes checkpointing accessible from a
DSL-based code generation environment along with some initial performance gures
with a focus on seismic applications.
"
1003,"High Performance Rearrangement and Multiplication Routines for Sparse
  Tensor Arithmetic","  Researchers are increasingly incorporating numeric high-order data, i.e.,
numeric tensors, within their practice. Just like the matrix/vector (MV)
paradigm, the development of multi-purpose, but high-performance, sparse data
structures and algorithms for arithmetic calculations, e.g., those found in
Einstein-like notation, is crucial for the continued adoption of tensors. We
use the example of high-order differential operators to illustrate this need.
As sparse tensor arithmetic is an emerging research topic, with challenges
distinct from the MV paradigm, many aspects require further articulation. We
focus on three core facets. First, aligning with prominent voices in the field,
we emphasise the importance of data structures able to accommodate the
operational complexity of tensor arithmetic. However, we describe a linearised
coordinate (LCO) data structure that provides faster and more memory-efficient
sorting performance. Second, flexible data structures, like the LCO, rely
heavily on sorts and permutations. We introduce an innovative permutation
algorithm, based on radix sort, that is tailored to rearrange already-sorted
sparse data, producing significant performance gains. Third, we introduce a
novel poly-algorithm for sparse tensor products, where hyper-sparsity is a
possibility. Different manifestations of hyper-sparsity demand their own
approach, which our poly-algorithm is the first to provide. These developments
are incorporated within our LibNT and NTToolbox software libraries. Benchmarks,
frequently drawn from the high-order differential operators example,
demonstrate the practical impact of our routines, with speed-ups of 40% or
higher compared to alternative high-performance implementations. Comparisons
against the MATLAB Tensor Toolbox show over 10 times speed improvements. Thus,
these advancements produce significant practical improvements for sparse tensor
arithmetic.
"
1004,GPU Accelerated Finite Element Assembly with Runtime Compilation,"  In recent years, high performance scientific computing on graphics processing
units (GPUs) have gained widespread acceptance. These devices are designed to
offer massively parallel threads for running code with general purpose. There
are many researches focus on finite element method with GPUs. However, most of
the works are specific to certain problems and applications. Some works propose
methods for finite element assembly that is general for a wide range of finite
element models. But the development of finite element code is dependent on the
hardware architectures. It is usually complicated and error prone using the
libraries provided by the hardware vendors. In this paper, we present
architecture and implementation of finite element assembly for partial
differential equations (PDEs) based on symbolic computation and runtime
compilation technique on GPU. User friendly programming interface with symbolic
computation is provided. At the same time, high computational efficiency is
achieved by using runtime compilation technique. As far as we know, it is the
first work using this technique to accelerate finite element assembly for
solving PDEs. Experiments show that a one to two orders of speedup is achieved
for the problems studied in the paper.
"
1005,"Achieving Efficient Realization of Kalman Filter on CGRA through
  Algorithm-Architecture Co-design","  In this paper, we present efficient realization of Kalman Filter (KF) that
can achieve up to 65% of the theoretical peak performance of underlying
architecture platform. KF is realized using Modified Faddeeva Algorithm (MFA)
as a basic building block due to its versatility and REDEFINE Coarse Grained
Reconfigurable Architecture (CGRA) is used as a platform for experiments since
REDEFINE is capable of supporting realization of a set algorithmic compute
structures at run-time on a Reconfigurable Data-path (RDP). We perform several
hardware and software based optimizations in the realization of KF to achieve
116% improvement in terms of Gflops over the first realization of KF. Overall,
with the presented approach for KF, 4-105x performance improvement in terms of
Gflops/watt over several academically and commercially available realizations
of KF is attained. In REDEFINE, we show that our implementation is scalable and
the performance attained is commensurate with the underlying hardware resources
"
1006,Locality Optimized Unstructured Mesh Algorithms on GPUs,"  Unstructured-mesh based numerical algorithms such as finite volume and finite
element algorithms form an important class of applications for many scientific
and engineering domains. The key difficulty in achieving higher performance
from these applications is the indirect accesses that lead to data-races when
parallelized. Current methods for handling such data-races lead to reduced
parallelism and suboptimal performance. Particularly on modern many-core
architectures, such as GPUs, that has increasing core/thread counts, reducing
data movement and exploiting memory locality is vital for gaining good
performance.
  In this work we present novel locality-exploiting optimizations for the
efficient execution of unstructured-mesh algorithms on GPUs. Building on a
two-layered coloring strategy for handling data races, we introduce novel
reordering and partitioning techniques to further improve efficient execution.
The new optimizations are then applied to several well established
unstructured-mesh applications, investigating their performance on NVIDIA's
latest P100 and V100 GPUs. We demonstrate significant speedups
($1.1\text{--}1.75\times$) compared to the state-of-the-art. A range of
performance metrics are benchmarked including runtime, memory transactions,
achieved bandwidth performance, GPU occupancy and data reuse factors and are
used to understand and explain the key factors impacting performance. The
optimized algorithms are implemented as an open-source software library and we
illustrate its use for improving performance of existing or new
unstructured-mesh applications.
"
1007,"QRkit: Sparse, Composable QR Decompositions for Efficient and Stable
  Solutions to Problems in Computer Vision","  Embedded computer vision applications increasingly require the speed and
power benefits of single-precision (32 bit) floating point. However,
applications which make use of Levenberg-like optimization can lose significant
accuracy when reducing to single precision, sometimes unrecoverably so. This
accuracy can be regained using solvers based on QR rather than Cholesky
decomposition, but the absence of sparse QR solvers for common sparsity
patterns found in computer vision means that many applications cannot benefit.
We introduce an open-source suite of solvers for Eigen, which efficiently
compute the QR decomposition for matrices with some common sparsity patterns
(block diagonal, horizontal and vertical concatenation, and banded). For
problems with very particular sparsity structures, these elements can be
composed together in 'kit' form, hence the name QRkit. We apply our methods to
several computer vision problems, showing competitive performance and
suitability especially in single precision arithmetic.
"
1008,"Fast and rigorous arbitrary-precision computation of Gauss-Legendre
  quadrature nodes and weights","  We describe a strategy for rigorous arbitrary-precision evaluation of
Legendre polynomials on the unit interval and its application in the generation
of Gauss-Legendre quadrature rules. Our focus is on making the evaluation
practical for a wide range of realistic parameters, corresponding to the
requirements of numerical integration to an accuracy of about 100 to 100 000
bits. Our algorithm combines the summation by rectangular splitting of several
types of expansions in terms of hypergeometric series with a fixed-point
implementation of Bonnet's three-term recurrence relation. We then compute
rigorous enclosures of the Gauss-Legendre nodes and weights using the interval
Newton method. We provide rigorous error bounds for all steps of the algorithm.
The approach is validated by an implementation in the Arb library, which
achieves order-of-magnitude speedups over previous code for computing
Gauss-Legendre rules with simultaneous high degree and precision.
"
1009,"GPU implementation of algorithm SIMPLE-TS for calculation of unsteady,
  viscous, compressible and heat-conductive gas flows","  The recent trend of using Graphics Processing Units (GPU's) for high
performance computations is driven by the high ratio of price performance for
these units, complemented by their cost effectiveness. At first glance,
computational fluid dynamics (CFD) solvers match perfectly to GPU resources
because these solvers make intensive calculations and use relatively little
memory. Nevertheless, there are scarce results about the practical use of this
serious advantage of GPU over CPU, especially for calculations of viscous,
compressible, heat-conductive gas flows with double precision accuracy. In this
paper, two GPU algorithms according to time approximation of convective terms
were presented: explicit and implicit scheme. To decrease data transfers
between device memories and increase the arithmetic intensity of a GPU code we
minimize the number of kernels. The GPU algorithm was implemented in one kernel
for the implicit scheme and two kernels for the explicit scheme. The numerical
equations were put together using macros and optimization, data copy from
global to private memory, and data reuse were left to the compiler. Thus keeps
the code simpler with excellent maintenance. As a test case, we model the flow
past squares in a microchannel at supersonic speed. The tests show that overall
speedup of AMD Radeon R9 280X is up to 102x compared to Intel Core i5-4690 core
and up to 184x compared to Intel Core i7-920 core, while speedup of NVIDIA
Tesla M2090 is up to 11x compared to Intel Core i5-4690 core and up to 20x
compared to Intel Core i7-920 core. Memory requirements of GPU code are
improved compared to CPU one. It requires 1[GB] global memory for 5.9 million
finite volumes that are two times less compared to C++ CPU code. After all the
code is simple, portable (written in OpenCL), memory efficient and easily
modifiable moreover demonstrates excellent performance.
"
1010,"Certified Roundoff Error Bounds using Bernstein Expansions and Sparse
  Krivine-Stengle Representations","  Floating point error is a drawback of embedded systems implementation that is
difficult to avoid. Computing rigorous upper bounds of roundoff errors is
absolutely necessary for the validation of critical software. This problem of
computing rigorous upper bounds is even more challenging when addressing
non-linear programs. In this paper, we propose and compare two new algorithms
based on Bernstein expansions and sparse Krivine-Stengle representations,
adapted from the field of the global optimization, to compute upper bounds of
roundoff errors for programs implementing polynomial and rational functions. We
also provide the convergence rate of these two algorithms. We release two
related software package FPBern and FPKriSten, and compare them with the
state-of-the-art tools. We show that these two methods achieve competitive
performance, while providing accurate upper bounds by comparison with the other
tools.
"
1011,"A High Performance Implementation of Spectral Clustering on CPU-GPU
  Platforms","  Spectral clustering is one of the most popular graph clustering algorithms,
which achieves the best performance for many scientific and engineering
applications. However, existing implementations in commonly used software
platforms such as Matlab and Python do not scale well for many of the emerging
Big Data applications. In this paper, we present a fast implementation of the
spectral clustering algorithm on a CPU-GPU heterogeneous platform. Our
implementation takes advantage of the computational power of the multi-core CPU
and the massive multithreading and SIMD capabilities of GPUs. Given the input
as data points in high dimensional space, we propose a parallel scheme to build
a sparse similarity graph represented in a standard sparse representation
format. Then we compute the smallest $k$ eigenvectors of the Laplacian matrix
by utilizing the reverse communication interfaces of ARPACK software and
cuSPARSE library, where $k$ is typically very large. Moreover, we implement a
very fast parallelized $k$-means algorithm on GPUs. Our implementation is shown
to be significantly faster compared to the best known Matlab and Python
implementations for each step. In addition, our algorithm scales to problems
with a very large number of clusters.
"
1012,Compiling Diderot: From Tensor Calculus to C,"  Diderot is a parallel domain-specific language for analysis and visualization
of multidimensional scientific images, such as those produced by CT and MRI
scanners. In particular, it supports algorithms where tensor fields (i.e.,
functions from 3D points to tensor values) are used to represent the underlying
physical objects that were scanned by the imaging device. Diderot supports
higher-order programming where tensor fields are first-class values and where
differential operators and lifted linear-algebra operators can be used to
express mathematical reasoning directly in the language. While such lifted
field operations are central to the definition and computation of many
scientific visualization algorithms, to date they have required extensive
manual derivations and laborious implementation.
  The challenge for the Diderot compiler is to effectively translate the
high-level mathematical concepts that are expressible in the surface language
to a low-level and efficient implementation in C. This paper describes our
approach to this challenge, which is based around the careful design of an
intermediate representation (IR), called EIN, and a number of compiler
transformations that lower the program from tensor calculus to C while avoiding
combinatorial explosion in the size of the IR. We describe the challenges in
compiling a language like Diderot, the design of EIN, and the transformation
used by the compiler. We also present an evaluation of EIN with respect to both
compiler efficiency and quality of generated code.
"
1013,"Comparative study of finite element methods using the Time-Accuracy-Size
  (TAS) spectrum analysis","  We present a performance analysis appropriate for comparing algorithms using
different numerical discretizations. By taking into account the total
time-to-solution, numerical accuracy with respect to an error norm, and the
computation rate, a cost-benefit analysis can be performed to determine which
algorithm and discretization are particularly suited for an application. This
work extends the performance spectrum model in Chang et. al. 2017 for
interpretation of hardware and algorithmic tradeoffs in numerical PDE
simulation. As a proof-of-concept, popular finite element software packages are
used to illustrate this analysis for Poisson's equation.
"
1014,Numerical integration in arbitrary-precision ball arithmetic,"  We present an implementation of arbitrary-precision numerical integration
with rigorous error bounds in the Arb library. Rapid convergence is ensured for
piecewise complex analytic integrals by use of the Petras algorithm, which
combines adaptive bisection with adaptive Gaussian quadrature where error
bounds are determined via complex magnitudes without evaluating derivatives.
The code is general, easy to use, and efficient, often outperforming existing
non-rigorous software.
"
1015,"The iisignature library: efficient calculation of iterated-integral
  signatures and log signatures","  Iterated-integral signatures and log signatures are vectors calculated from a
path that characterise its shape. They come from the theory of differential
equations driven by rough paths, and also have applications in statistics and
machine learning. We present algorithms for efficiently calculating these
signatures, and benchmark their performance. We release the methods as a Python
package.
"
1016,Moore: Interval Arithmetic in C++20,"  This article presents the Moore library for interval arithmetic in C++20. It
gives examples of how the library can be used, and explains the basic
principles underlying its design.
"
1017,Sparse Tensor Algebra Optimizations with Workspaces,"  This paper shows how to optimize sparse tensor algebraic expressions by
introducing temporary tensors, called workspaces, into the resulting loop
nests. We develop a new intermediate language for tensor operations called
concrete index notation that extends tensor index notation. Concrete index
notation expresses when and where sub-computations occur and what tensor they
are stored into. We then describe the workspace optimization in this language,
and how to compile it to sparse code by building on prior work in the
literature.
  We demonstrate the importance of the optimization on several important sparse
tensor kernels, including sparse matrix-matrix multiplication (SpMM), sparse
tensor addition (SpAdd), and the matricized tensor times Khatri-Rao product
(MTTKRP) used to factorize tensors. Our results show improvements over prior
work on tensor algebra compilation and brings the performance of these kernels
on par with state-of-the-art hand-optimized implementations. For example, SpMM
was not supported by prior tensor algebra compilers, the performance of MTTKRP
on the nell-2 data set improves by 35%, and MTTKRP can for the first time have
sparse results.
"
1018,OpenMath and SMT-LIB,"  OpenMath and SMT-LIB are languages with very different origins, but both
""represent mathematics"". We describe SMT-LIB for the OpenMath community and
consider adaptations for both languages to support the growing SC-Square
initiative.
"
1019,"Chebyshev Filter Diagonalization on Modern Manycore Processors and
  GPGPUs","  Chebyshev filter diagonalization is well established in quantum chemistry and
quantum physics to compute bulks of eigenvalues of large sparse matrices.
Choosing a block vector implementation, we investigate optimization
opportunities on the new class of high-performance compute devices featuring
both high-bandwidth and low-bandwidth memory. We focus on the transparent
access to the full address space supported by both architectures under
consideration: Intel Xeon Phi ""Knights Landing"" and Nvidia ""Pascal.""
  We propose two optimizations: (1) Subspace blocking is applied for improved
performance and data access efficiency. We also show that it allows
transparently handling problems much larger than the high-bandwidth memory
without significant performance penalties. (2) Pipelining of communication and
computation phases of successive subspaces is implemented to hide communication
costs without extra memory traffic.
  As an application scenario we use filter diagonalization studies on
topological insulator materials. Performance numbers on up to 512 nodes of the
OakForest-PACS and Piz Daint supercomputers are presented, achieving beyond 100
Tflop/s for computing 100 inner eigenvalues of sparse matrices of dimension one
billion.
"
1020,"Scaling Structured Multigrid to 500K+ Cores through Coarse-Grid
  Redistribution","  The efficient solution of sparse, linear systems resulting from the
discretization of partial differential equations is crucial to the performance
of many physics-based simulations. The algorithmic optimality of multilevel
approaches for common discretizations makes them a good candidate for an
efficient parallel solver. Yet, modern architectures for high-performance
computing systems continue to challenge the parallel scalability of multilevel
solvers. While algebraic multigrid methods are robust for solving a variety of
problems, the increasing importance of data locality and cost of data movement
in modern architectures motivates the need to carefully exploit structure in
the problem.
  Robust logically structured variational multigrid methods, such as Black Box
Multigrid (BoxMG), maintain structure throughout the multigrid hierarchy. This
avoids indirection and increased coarse-grid communication costs typical in
parallel algebraic multigrid. Nevertheless, the parallel scalability of
structured multigrid is challenged by coarse-grid problems where the overhead
in communication dominates computation. In this paper, an algorithm is
introduced for redistributing coarse-grid problems through incremental
agglomeration. Guided by a predictive performance model, this algorithm
provides robust redistribution decisions for structured multilevel solvers.
  A two-dimensional diffusion problem is used to demonstrate the significant
gain in performance of this algorithm over the previous approach that used
agglomeration to one processor. In addition, the parallel scalability of this
approach is demonstrated on two large-scale computing systems, with solves on
up to 500K+ cores.
"
1021,Algorithmic Differentiation for Domain Specific Languages,"  Algorithmic Differentiation (AD) can be used to automate the generation of
derivatives in arbitrary software projects. This will generate maintainable
derivatives, that are always consistent with the computation of the software.
If a domain specific language (DSL) is used in a software the state of the art
approach is to differentiate the DSL library with the same AD tool. The
drawback of this solution is the reduced performance since the compiler is no
longer able to optimize the e.g. SIMD operations. The new approach in this
paper integrates the types and operations of the DSL into the AD tool. It will
be an operator overloading tool that is generated from an abstract definition
of a DSL. This approach enables the compiler to optimize again e.g. for SIMD
operation since all calculations are still performed with the original data
types. This will also reduce the required memory for AD since the statements
inside the DLS implementation are no longer seen by the AD tool. The
implementation is presented in the paper and first results for the performance
of the solution are presented.
"
1022,"Efficient Realization of Givens Rotation through Algorithm-Architecture
  Co-design for Acceleration of QR Factorization","  We present efficient realization of Generalized Givens Rotation (GGR) based
QR factorization that achieves 3-100x better performance in terms of
Gflops/watt over state-of-the-art realizations on multicore, and General
Purpose Graphics Processing Units (GPGPUs). GGR is an improvement over
classical Givens Rotation (GR) operation that can annihilate multiple elements
of rows and columns of an input matrix simultaneously. GGR takes 33% lesser
multiplications compared to GR. For custom implementation of GGR, we identify
macro operations in GGR and realize them on a Reconfigurable Data-path (RDP)
tightly coupled to pipeline of a Processing Element (PE). In PE, GGR attains
speed-up of 1.1x over Modified Householder Transform (MHT) presented in the
literature. For parallel realization of GGR, we use REDEFINE, a scalable
massively parallel Coarse-grained Reconfigurable Architecture, and show that
the speed-up attained is commensurate with the hardware resources in REDEFINE.
GGR also outperforms General Matrix Multiplication (gemm) by 10% in-terms of
Gflops/watt which is counter-intuitive.
"
1023,Glyph: Symbolic Regression Tools,"  We present Glyph - a Python package for genetic programming based symbolic
regression. Glyph is designed for usage let by numerical simulations let by
real world experiments. For experimentalists, glyph-remote provides a
separation of tasks: a ZeroMQ interface splits the genetic programming
optimization task from the evaluation of an experimental (or numerical) run.
Glyph can be accessed at http://github.com/ambrosys/glyph . Domain experts are
be able to employ symbolic regression in their experiments with ease, even if
they are not expert programmers. The reuse potential is kept high by a generic
interface design. Glyph is available on PyPI and Github.
"
1024,"PyGOM - A Python Package for Simplifying Modelling with Systems of
  Ordinary Differential Equations","  Ordinary Differential Equations (ODE) are used throughout science where the
capture of rates of change in states is sought. While both pieces of commercial
and open software exist to study such systems, their efficient and accurate
usage frequently requires deep understanding of mathematics and programming.
The package we present here, PyGOM, seeks to remove these obstacles for models
based on ODE systems. We provide a simple interface for the construction of
such systems backed by a comprehensive and easy to use tool--box. This
tool--box implements functions to easily perform common operations for ODE
systems such as solving, parameter estimation, and stochastic simulation. The
package source is freely available and organized in a way that permits easy
extension. With both the algebraic and numeric calculations performed
automatically (but still accessible), the end user is freed to focus on model
development.
"
1025,"Extreme Scale FMM-Accelerated Boundary Integral Equation Solver for Wave
  Scattering","  Algorithmic and architecture-oriented optimizations are essential for
achieving performance worthy of anticipated energy-austere exascale systems. In
this paper, we present an extreme scale FMM-accelerated boundary integral
equation solver for wave scattering, which uses FMM as a matrix-vector
multiplication inside the GMRES iterative method. Our FMM Helmholtz kernels
treat nontrivial singular and near-field integration points. We implement
highly optimized kernels for both shared and distributed memory, targeting
emerging Intel extreme performance HPC architectures. We extract the potential
thread- and data-level parallelism of the key Helmholtz kernels of FMM. Our
application code is well optimized to exploit the AVX-512 SIMD units of Intel
Skylake and Knights Landing architectures. We provide different performance
models for tuning the task-based tree traversal implementation of FMM, and
develop optimal architecture-specific and algorithm aware partitioning, load
balancing, and communication reducing mechanisms to scale up to 6,144 compute
nodes of a Cray XC40 with 196,608 hardware cores. With shared memory
optimizations, we achieve roughly 77% of peak single precision floating point
performance of a 56-core Skylake processor, and on average 60% of peak single
precision floating point performance of a 72-core KNL. These numbers represent
nearly 5.4x and 10x speedup on Skylake and KNL, respectively, compared to the
baseline scalar code. With distributed memory optimizations, on the other hand,
we report near-optimal efficiency in the weak scalability study with respect to
both the logarithmic communication complexity as well as the theoretical
scaling complexity of FMM. In addition, we exhibit up to 85% efficiency in
strong scaling. We compute in excess of 2 billion DoF on the full-scale of the
Cray XC40 supercomputer.
"
1026,"Automatic symbolic computation for discontinuous Galerkin finite element
  methods","  The implementation of discontinuous Galerkin finite element methods (DGFEMs)
represents a very challenging computational task, particularly for systems of
coupled nonlinear PDEs, including multiphysics problems, whose parameters may
consist of power series or functionals of the solution variables. Thereby, the
exploitation of symbolic algebra to express a given DGFEM approximation of a
PDE problem within a high level language, whose syntax closely resembles the
mathematical definition, is an invaluable tool. Indeed, this then facilitates
the automatic assembly of the resulting system of (nonlinear) equations, as
well as the computation of Fr\'echet derivative(s) of the DGFEM scheme, needed,
for example, within a Newton-type solver. However, even exploiting symbolic
algebra, the discretisation of coupled systems of PDEs can still be extremely
verbose and hard to debug. Thereby, in this article we develop a further layer
of abstraction by designing a class structure for the automatic computation of
DGFEM formulations. This work has been implemented within the FEniCS package,
based on exploiting the Unified Form Language. Numerical examples are presented
which highlight the simplicity of implementation of DGFEMs for the numerical
approximation of a range of PDE problems.
"
1027,A Blackbox Polynomial System Solver on Parallel Shared Memory Computers,"  A numerical irreducible decomposition for a polynomial system provides
representations for the irreducible factors of all positive dimensional
solution sets of the system, separated from its isolated solutions. Homotopy
continuation methods are applied to compute a numerical irreducible
decomposition. Load balancing and pipelining are techniques in a parallel
implementation on a computer with multicore processors. The application of the
parallel algorithms is illustrated on solving the cyclic $n$-roots problems, in
particular for $n = 8, 9$, and~12.
"
1028,The Generalized Matrix Chain Algorithm,"  In this paper, we present a generalized version of the matrix chain algorithm
to generate efficient code for linear algebra problems, a task for which human
experts often invest days or even weeks of works. The standard matrix chain
problem consists in finding the parenthesization of a matrix product $M := A_1
A_2 \cdots A_n$ that minimizes the number of scalar operations. In practical
applications, however, one frequently encounters more complicated expressions,
involving transposition, inversion, and matrix properties. Indeed, the
computation of such expressions relies on a set of computational kernels that
offer functionality well beyond the simple matrix product. The challenge then
shifts from finding an optimal parenthesization to finding an optimal mapping
of the input expression to the available kernels. Furthermore, it is often the
case that a solution based on the minimization of scalar operations does not
result in the optimal solution in terms of execution time. In our experiments,
the generated code outperforms other libraries and languages on average by a
factor of about 9. The motivation for this work comes from the fact
that---despite great advances in the development of compilers---the task of
mapping linear algebra problems to optimized kernels is still to be done
manually. In order to relieve the user from this complex task, new techniques
for the compilation of linear algebra expressions have to be developed.
"
1029,"A Scalable Shared-Memory Parallel Simplex for Large-Scale Linear
  Programming","  The Simplex tableau has been broadly used and investigated in the industry
and academia. With the advent of the big data era, ever larger problems are
posed to be solved in ever larger machines whose architecture type did not
exist in the conception of this algorithm. In this paper, we present a
shared-memory parallel implementation of the Simplex tableau algorithm for
dense large-scale Linear Programming (LP) problems for use in modern multi-core
architectures. We present the general scheme and explain the strategies taken
to parallelize each step of the standard simplex algorithm, emphasizing the
solutions found to solve performance bottlenecks. We analyzed the speedup and
the parallel efficiency for the proposed implementation relative to the
standard Simplex algorithm using a shared-memory system with 64 processing
cores. The experiments were performed for several different problems, with up
to 8192 variables and constraints, in their primal and dual formulations. The
results show that the performance is mostly much better when we use the
formulation with more variables than inequality constraints. Also, they show
that the parallelization strategies applied to avoid bottlenecks lead the
implementation to scale well with the problem size and the core count up to a
certain limit of problem size. Further analysis showed that this scaling limit
was an effect of resource limitation. Even though, our implementation was able
to reach speedups in the order of 19x.
"
1030,{\mu}-cuDNN: Accelerating Deep Learning Frameworks with Micro-Batching,"  NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used
in deep learning. Specifically, cuDNN implements several equivalent convolution
algorithms, whose performance and memory footprint may vary considerably,
depending on the layer dimensions. When an algorithm is automatically selected
by cuDNN, the decision is performed on a per-layer basis, and thus it often
resorts to slower algorithms that fit the workspace size constraints. We
present {\mu}-cuDNN, a transparent wrapper library for cuDNN, which divides
layers' mini-batch computation into several micro-batches. Based on Dynamic
Programming and Integer Linear Programming, {\mu}-cuDNN enables faster
algorithms by decreasing the workspace requirements. At the same time,
{\mu}-cuDNN keeps the computational semantics unchanged, so that it decouples
statistical efficiency from the hardware efficiency safely. We demonstrate the
effectiveness of {\mu}-cuDNN over two frameworks, Caffe and TensorFlow,
achieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2
GPU. These results indicate that using micro-batches can seamlessly increase
the performance of deep learning, while maintaining the same memory footprint.
"
1031,Adaptive control in rollforward recovery for extreme scale multigrid,"  With the increasing number of compute components, failures in future
exa-scale computer systems are expected to become more frequent. This motivates
the study of novel resilience techniques. Here, we extend a recently proposed
algorithm-based recovery method for multigrid iterations by introducing an
adaptive control. After a fault, the healthy part of the system continues the
iterative solution process, while the solution in the faulty domain is
re-constructed by an asynchronous on-line recovery. The computations in both
the faulty and healthy subdomains must be coordinated in a sensitive way, in
particular, both under and over-solving must be avoided. Both of these waste
computational resources and will therefore increase the overall
time-to-solution. To control the local recovery and guarantee an optimal
re-coupling, we introduce a stopping criterion based on a mathematical error
estimator. It involves hierarchical weighted sums of residuals within the
context of uniformly refined meshes and is well-suited in the context of
parallel high-performance computing. The re-coupling process is steered by
local contributions of the error estimator. We propose and compare two criteria
which differ in their weights. Failure scenarios when solving up to
$6.9\cdot10^{11}$ unknowns on more than 245\,766 parallel processes will be
reported on a state-of-the-art peta-scale supercomputer demonstrating the
robustness of the method.
"
1032,"Programming Parallel Dense Matrix Factorizations with Look-Ahead and
  OpenMP","  We investigate a parallelization strategy for dense matrix factorization
(DMF) algorithms, using OpenMP, that departs from the legacy (or conventional)
solution, which simply extracts concurrency from a multithreaded version of
BLAS. This approach is also different from the more sophisticated
runtime-assisted implementations, which decompose the operation into tasks and
identify dependencies via directives and runtime support. Instead, our strategy
attains high performance by explicitly embedding a static look-ahead technique
into the DMF code, in order to overcome the performance bottleneck of the panel
factorization, and realizing the trailing update via a cache-aware
multi-threaded implementation of the BLAS. Although the parallel algorithms are
specified with a highlevel of abstraction, the actual implementation can be
easily derived from them, paving the road to deriving a high performance
implementation of a considerable fraction of LAPACK functionality on any
multicore platform with an OpenMP-like runtime.
"
1033,"Multiprecision Arithmetic for Cryptology in C++ - Compile-Time
  Computations and Beating the Performance of Hand-Optimized Assembly at
  Run-Time","  We describe a new C++ library for multiprecision arithmetic for numbers in
the order of 100--500 bits, i.e., representable with just a few limbs. The
library is written in ""optimizing-compiler-friendly"" C++, with an emphasis on
the use of fixed-size arrays and particular function-argument-passing styles
(including the avoidance of naked pointers) to allow the limbs to be allocated
on the stack or even in registers. Depending on the particular functionality,
we get close to, or significantly beat the performance of existing libraries
for multiprecision arithmetic that employ hand-optimized assembly code.
  Most functions in the library are constant-time, which is a necessity for
secure implementations of cryptographic protocols.
  Beyond the favorable runtime performance, our library is, to the best of the
author's knowledge, the first library that offers big-integer computations
during compile-time. For example, when implementing finite-field arithmetic
with a fixed modulus, this feature enables the automatic precomputation (at
compile time) of the special modulus-dependent constants required for Barrett
and Montgomery reduction. Another application is to parse (at compile-time) a
base-10-encoded big-integer literal.
"
1034,"OpenFPM: A scalable open framework for particle and particle-mesh codes
  on parallel computers","  Scalable and efficient numerical simulations continue to gain importance, as
computation is firmly established as the third pillar of discovery, alongside
theory and experiment. Meanwhile, the performance of computing hardware grows
through increasing heterogeneous parallelism, enabling simulations of ever more
complex models. However, efficiently implementing scalable codes on
heterogeneous, distributed hardware systems becomes the bottleneck. This
bottleneck can be alleviated by intermediate software layers that provide
higher-level abstractions closer to the problem domain, hence allowing the
computational scientist to focus on the simulation. Here, we present OpenFPM,
an open and scalable framework that provides an abstraction layer for numerical
simulations using particles and/or meshes. OpenFPM provides transparent and
scalable infrastructure for shared-memory and distributed-memory
implementations of particles-only and hybrid particle-mesh simulations of both
discrete and continuous models, as well as non-simulation codes. This
infrastructure is complemented with portable implementations of frequently used
numerical routines, as well as interfaces to third-party libraries. We present
the architecture and design of OpenFPM, detail the underlying abstractions, and
benchmark the framework in applications ranging from Smoothed-Particle
Hydrodynamics (SPH) to Molecular Dynamics (MD), Discrete Element Methods (DEM),
Vortex Methods, stencil codes, high-dimensional Monte Carlo sampling (CMA-ES),
and Reaction-Diffusion solvers, comparing it to the current state of the art
and existing software frameworks.
"
1035,Fast parallel multidimensional FFT using advanced MPI,"  We present a new method for performing global redistributions of
multidimensional arrays essential to parallel fast Fourier (or similar)
transforms. Traditional methods use standard all-to-all collective
communication of contiguous memory buffers, thus necessary requiring local data
realignment steps intermixed in-between redistribution and transform steps.
Instead, our method takes advantage of subarray datatypes and generalized
all-to-all scatter/gather from the MPI-2 standard to communicate discontiguous
memory buffers, effectively eliminating the need for local data realignments.
Despite generalized all-to-all communication of discontiguous data being
generally slower, our proposal economizes in local work. For a range of strong
and weak scaling tests, we found the overall performance of our method to be on
par and often better than well-established libraries like MPI-FFTW, P3DFFT, and
2DECOMP&FFT. We provide compact routines implemented at the highest possible
level using the MPI bindings for the C programming language. These routines
apply to any global redistribution, over any two directions of a
multidimensional array, decomposed on arbitrary Cartesian processor grids (1D
slabs, 2D pencils, or even higher-dimensional decompositions). The high level
implementation makes the code easy to read, maintain, and eventually extend.
Our approach enables for future speedups from optimizations in the internal
datatype handling engines within MPI implementations.
"
1036,Format Abstraction for Sparse Tensor Algebra Compilers,"  This paper shows how to build a sparse tensor algebra compiler that is
agnostic to tensor formats (data layouts). We develop an interface that
describes formats in terms of their capabilities and properties, and show how
to build a modular code generator where new formats can be added as plugins. We
then describe six implementations of the interface that compose to form the
dense, CSR/CSF, COO, DIA, ELL, and HASH tensor formats and countless variants
thereof. With these implementations at hand, our code generator can generate
code to compute any tensor algebra expression on any combination of the
aforementioned formats.
  To demonstrate our technique, we have implemented it in the taco tensor
algebra compiler. Our modular code generator design makes it simple to add
support for new tensor formats, and the performance of the generated code is
competitive with hand-optimized implementations. Furthermore, by extending taco
to support a wider range of formats specialized for different application and
data characteristics, we can improve end-user application performance. For
example, if input data is provided in the COO format, our technique allows
computing a single matrix-vector multiplication directly with the data in COO,
which is up to 3.6$\times$ faster than by first converting the data to CSR.
"
1037,"Automatic generation of CUDA code performing tensor manipulations using
  C++ expression templates","  We present a C++ library, TLoops, which uses a hierarchy of expression
templates to represent operations upon tensorial quantities in single lines of
C++ code that resemble analytic equations. These expressions may be run as-is,
but may also be used to emit equivalent low-level C or CUDA code, which either
performs the operations more quickly on the CPU, or allows them to be rapidly
ported to run on NVIDIA GPUs. We detail the expression template and C++-class
hierarchy that represents the expressions and which makes automatic
code-generation possible. We then present benchmarks of the expression-template
code, the automatically generated C code, and the automatically generated CUDA
code running on several generations of NVIDIA GPU.
"
1038,Tiramisu: A Polyhedral Compiler for Expressing Fast and Portable Code,"  This paper introduces Tiramisu, a polyhedral framework designed to generate
high performance code for multiple platforms including multicores, GPUs, and
distributed machines. Tiramisu introduces a scheduling language with novel
extensions to explicitly manage the complexities that arise when targeting
these systems. The framework is designed for the areas of image processing,
stencils, linear algebra and deep learning. Tiramisu has two main features: it
relies on a flexible representation based on the polyhedral model and it has a
rich scheduling language allowing fine-grained control of optimizations.
Tiramisu uses a four-level intermediate representation that allows full
separation between the algorithms, loop transformations, data layouts, and
communication. This separation simplifies targeting multiple hardware
architectures with the same algorithm. We evaluate Tiramisu by writing a set of
image processing, deep learning, and linear algebra benchmarks and compare them
with state-of-the-art compilers and hand-tuned libraries. We show that Tiramisu
matches or outperforms existing compilers and libraries on different hardware
architectures, including multicore CPUs, GPUs, and distributed machines.
"
1039,Scrambled Linear Pseudorandom Number Generators,"  Linear pseudorandom number generators are very popular due to their high
speed, to the ease with which generators with a sizable state space can be
created, and to their provable theoretical properties. However, they suffer
from linear artifacts which show as failures in linearity-related statistical
tests such as the binary-rank and the linear-complexity test. In this paper, we
give three new contributions. First, we introduce two new linear
transformations that have been handcrafted to have good statistical properties
and at the same time to be programmable very efficiently on superscalar
processors, or even directly in hardware. Then, we describe a new test for
Hamming-weight dependencies that is able to discover subtle, previously unknown
biases in existing generators (in particular, in linear ones). Finally, we
describe a number of scramblers, that is, nonlinear functions applied to the
state array that reduce or delete the linear artifacts, and propose
combinations of linear transformations and scramblers that give extremely fast
pseudorandom generators of high quality. A novelty in our approach is that we
use ideas from the theory of filtered linear-feedback shift register to prove
some properties of our scramblers, rather than relying purely on heuristics. In
the end, we provide simple, extremely fast generators that use a few hundred
bits of memory, have provable properties and pass very strong statistical
tests.
"
1040,RealCertify: a Maple package for certifying non-negativity,"  Let $\mathbb{Q}$ (resp. $\mathbb{R}$) be the field of rational (resp. real)
numbers and $X = (X_1, \ldots, X_n)$ be variables. Deciding the non-negativity
of polynomials in $\mathbb{Q}[X]$ over $\mathbb{R}^n$ or over semi-algebraic
domains defined by polynomial constraints in $\mathbb{Q}[X]$ is a classical
algorithmic problem for symbolic computation.
  The Maple package \textsc{RealCertify} tackles this decision problem by
computing sum of squares certificates of non-negativity for inputs where such
certificates hold over the rational numbers. It can be applied to numerous
problems coming from engineering sciences, program verification and
cyber-physical systems. It is based on hybrid symbolic-numeric algorithms based
on semi-definite programming.
"
1041,A User-Friendly Hybrid Sparse Matrix Class in C++,"  When implementing functionality which requires sparse matrices, there are
numerous storage formats to choose from, each with advantages and
disadvantages. To achieve good performance, several formats may need to be used
in one program, requiring explicit selection and conversion between the
formats. This can be both tedious and error-prone, especially for non-expert
users. Motivated by this issue, we present a user-friendly sparse matrix class
for the C++ language, with a high-level application programming interface
deliberately similar to the widely used MATLAB language. The class internally
uses two main approaches to achieve efficient execution: (i) a hybrid storage
framework, which automatically and seamlessly switches between three underlying
storage formats (compressed sparse column, coordinate list, Red-Black tree)
depending on which format is best suited for specific operations, and (ii)
template-based meta-programming to automatically detect and optimise execution
of common expression patterns. To facilitate relatively quick conversion of
research code into production environments, the class and its associated
functions provide a suite of essential sparse linear algebra functionality
(eg., arithmetic operations, submatrix manipulation) as well as high-level
functions for sparse eigendecompositions and linear equation solvers. The
latter are achieved by providing easy-to-use abstractions of the low-level
ARPACK and SuperLU libraries. The source code is open and provided under the
permissive Apache 2.0 license, allowing unencumbered use in commercial
products.
"
1042,"MPI+X: task-based parallelization and dynamic load balance of finite
  element assembly","  The main computing tasks of a finite element code(FE) for solving partial
differential equations (PDE's) are the algebraic system assembly and the
iterative solver. This work focuses on the first task, in the context of a
hybrid MPI+X paradigm. Although we will describe algorithms in the FE context,
a similar strategy can be straightforwardly applied to other discretization
methods, like the finite volume method. The matrix assembly consists of a loop
over the elements of the MPI partition to compute element matrices and
right-hand sides and their assemblies in the local system to each MPI
partition. In a MPI+X hybrid parallelism context, X has consisted traditionally
of loop parallelism using OpenMP. Several strategies have been proposed in the
literature to implement this loop parallelism, like coloring or substructuring
techniques to circumvent the race condition that appears when assembling the
element system into the local system. The main drawback of the first technique
is the decrease of the IPC due to bad spatial locality. The second technique
avoids this issue but requires extensive changes in the implementation, which
can be cumbersome when several element loops should be treated. We propose an
alternative, based on the task parallelism of the element loop using some
extensions to the OpenMP programming model. The taskification of the assembly
solves both aforementioned problems. In addition, dynamic load balance will be
applied using the DLB library, especially efficient in the presence of hybrid
meshes, where the relative costs of the different elements is impossible to
estimate a priori. This paper presents the proposed methodology, its
implementation and its validation through the solution of large computational
mechanics problems up to 16k cores.
"
1043,Program Generation for Small-Scale Linear Algebra Applications,"  We present SLinGen, a program generation system for linear algebra. The input
to SLinGen is an application expressed mathematically in a
linear-algebra-inspired language (LA) that we define. LA provides basic
scalar/vector/matrix additions/multiplications and higher level operations
including linear systems solvers, Cholesky and LU factorizations. The output of
SLinGen is performance-optimized single-source C code, optionally vectorized
with intrinsics. The target of SLinGen are small-scale computations on
fixed-size operands, for which a straightforward implementation using optimized
libraries (e.g., BLAS or LAPACK) is known to yield suboptimal performance
(besides increasing code size and introducing dependencies), but which are
crucial in control, signal processing, computer vision, and other domains.
Internally, SLinGen uses synthesis and DSL-based techniques to optimize at a
high level of abstraction. We benchmark our program generator on three
prototypical applications: the Kalman filter, Gaussian process regression, and
an L1-analysis convex solver, as well as basic routines including Cholesky
factorization and solvers for the continuous-time Lyapunov and Sylvester
equations. The results show significant speed-ups compared to straightforward C
with Intel icc and clang with a polyhedral optimizer, as well as library-based
and template-based implementations.
"
1044,The EPFL Logic Synthesis Libraries,"  We present a collection of modular open source C++ libraries for the
development of logic synthesis applications. These libraries can be used to
develop applications for the design of classical and emerging technologies, as
well as for the implementation of quantum compilers. All libraries are well
documented and well tested. Furthermore, being header-only, the libraries can
be readily used as core components in complex logic synthesis systems.
"
1045,geomstats: a Python Package for Riemannian Geometry in Machine Learning,"  We introduce geomstats, a python package that performs computations on
manifolds such as hyperspheres, hyperbolic spaces, spaces of symmetric positive
definite matrices and Lie groups of transformations. We provide efficient and
extensively unit-tested implementations of these manifolds, together with
useful Riemannian metrics and associated Exponential and Logarithm maps. The
corresponding geodesic distances provide a range of intuitive choices of
Machine Learning loss functions. We also give the corresponding Riemannian
gradients. The operations implemented in geomstats are available with different
computing backends such as numpy, tensorflow and keras. We have enabled GPU
implementation and integrated geomstats manifold computations into keras deep
learning framework. This paper also presents a review of manifolds in machine
learning and an overview of the geomstats package with examples demonstrating
its use for efficient and user-friendly Riemannian geometry.
"
1046,"CUDACLAW: A high-performance programmable GPU framework for the solution
  of hyperbolic PDEs","  We present cudaclaw, a CUDA-based high performance data-parallel framework
for the solution of multidimensional hyperbolic partial differential equation
(PDE) systems, equations describing wave motion. cudaclaw allows computational
scientists to solve such systems on GPUs without being burdened by the need to
write CUDA code, worry about thread and block details, data layout, and data
movement between the different levels of the memory hierarchy. The user defines
the set of PDEs to be solved via a CUDA- independent serial Riemann solver and
the framework takes care of orchestrating the computations and data transfers
to maximize arithmetic throughput. cudaclaw treats the different spatial
dimensions separately to allow suitable block sizes and dimensions to be used
in the different directions, and includes a number of optimizations to minimize
access to global memory.
"
1047,"ChASE: Chebyshev Accelerated Subspace iteration Eigensolver for
  sequences of Hermitian eigenvalue problems","  Solving dense Hermitian eigenproblems arranged in a sequence with direct
solvers fails to take advantage of those spectral properties which are
pertinent to the entire sequence, and not just to the single problem. When such
features take the form of correlations between the eigenvectors of consecutive
problems, as is the case in many real-world applications, the potential benefit
of exploiting them can be substantial. We present ChASE, a modern algorithm and
library based on subspace iteration with polynomial acceleration. Novel to
ChASE is the computation of the spectral estimates that enter in the filter and
an optimization of the polynomial degree which further reduces the necessary
FLOPs. ChASE is written in C++ using the modern software engineering concepts
which favor a simple integration in application codes and a straightforward
portability over heterogeneous platforms. When solving sequences of Hermitian
eigenproblems for a portion of their extremal spectrum, ChASE greatly benefits
from the sequence's spectral properties and outperforms direct solvers in many
scenarios. The library ships with two distinct parallelization schemes,
supports execution over distributed GPUs, and it is easily extensible to other
parallel computing architectures.
"
1048,"A Scalable and Modular Software Architecture for Finite Elements on
  Hierarchical Hybrid Grids","  In this article, a new generic higher-order finite-element framework for
massively parallel simulations is presented. The modular software architecture
is carefully designed to exploit the resources of modern and future
supercomputers. Combining an unstructured topology with structured grid
refinement facilitates high geometric adaptability and matrix-free multigrid
implementations with excellent performance. Different abstraction levels and
fully distributed data structures additionally ensure high flexibility,
extensibility, and scalability. The software concepts support sophisticated
load balancing and flexibly combining finite element spaces. Example scenarios
with coupled systems of PDEs show the applicability of the concepts to
performing geophysical simulations.
"
1049,"COREclust: a new package for a robust and scalable analysis of complex
  data","  In this paper, we present a new R package COREclust dedicated to the
detection of representative variables in high dimensional spaces with a
potentially limited number of observations. Variable sets detection is based on
an original graph clustering strategy denoted CORE-clustering algorithm that
detects CORE-clusters, i.e. variable sets having a user defined size range and
in which each variable is very similar to at least another variable.
Representative variables are then robustely estimate as the CORE-cluster
centers. This strategy is entirely coded in C++ and wrapped by R using the Rcpp
package. A particular effort has been dedicated to keep its algorithmic cost
reasonable so that it can be used on large datasets. After motivating our work,
we will explain the CORE-clustering algorithm as well as a greedy extension of
this algorithm. We will then present how to use it and results obtained on
synthetic and real data.
"
1050,Particle-based simulations of reaction-diffusion processes with Aboria,"  Mathematical models of transport and reactions in biological systems have
been traditionally written in terms of partial differential equations (PDEs)
that describe the time evolution of population-level variables. In recent
years, the use of stochastic particle-based models, which keep track of the
evolution of each organism in the system, has become widespread. These models
provide a lot more detail than the population-based PDE models, for example by
explicitly modelling particle-particle interactions, but bring with them many
computational challenges. In this paper we overview Aboria, a powerful and
flexible C++ library for the implementation of numerical methods for
particle-based models. We demonstrate the use of Aboria with a commonly used
model in mathematical biology, namely cell chemotaxis. Cells interact with each
other and diffuse, biased by extracellular chemicals, that can be altered by
the cells themselves. We use a hybrid approach where particle-based models of
cells are coupled with a PDE for the concentration of the extracellular
chemical.
"
1051,"Optimizing Sparse Matrix-Vector Multiplication on Emerging Many-Core
  Architectures","  Sparse matrix vector multiplication (SpMV) is one of the most common
operations in scientific and high-performance applications, and is often
responsible for the application performance bottleneck. While the sparse matrix
representation has a significant impact on the resulting application
performance, choosing the right representation typically relies on expert
knowledge and trial and error. This paper provides the first comprehensive
study on the impact of sparse matrix representations on two emerging many-core
architectures: the Intel's Knights Landing (KNL) XeonPhi and the ARM-based
FT-2000Plus (FTP). Our large-scale experiments involved over 9,500 distinct
profiling runs performed on 956 sparse datasets and five mainstream SpMV
representations. We show that the best sparse matrix representation depends on
the underlying architecture and the program input. To help developers to choose
the optimal matrix representation, we employ machine learning to develop a
predictive model. Our model is first trained offline using a set of training
examples. The learned model can be used to predict the best matrix
representation for any unseen input for a given architecture. We show that our
model delivers on average 95% and 91% of the best available performance on KNL
and FTP respectively, and it achieves this with no runtime profiling overhead.
"
1052,"Efficient Multi-Accuracy Computations of Complex Functions with Complex
  Arguments","  We present an efficient multi-accuracy algorithm for the computations of a
set of special functions of a complex argument, z=x+iy. These functions include
the complex probability function w(z), and closely related functions such as
the error function erf(z), complementary error function erfc(z), imaginary
error function erfi(z), scaled complementary error function, erfcx(z), the
plasma dispersion function Z(z), Dawson s function Daw(z), and Fresnel
integrals S(z) and C(z). Computational results from the present algorithm are
compared with results from competitive algorithms and widely used software
packages showing superior accuracy and efficiency of the present algorithm. In
particular, the present results highlight concerns about the accuracy of
evaluating such special functions using commercial packages like Mathematica
and free/open source packages like the MIT-C++ package.
"
1053,"Efficient Differentiable Programming in a Functional Array-Processing
  Language","  We present a system for the automatic differentiation of a higher-order
functional array-processing language. The core functional language underlying
this system simultaneously supports both source-to-source automatic
differentiation and global optimizations such as loop transformations. Thanks
to this feature, we demonstrate how for some real-world machine learning and
computer vision benchmarks, the system outperforms the state-of-the-art
automatic differentiation tools.
"
1054,Generalized Polylogarithms in Maple,"  This paper describes generalized polylogarithms, multiple polylogarithms, and
multiple zeta values, along with their implementation in Maple 2018. This set
of related functions is of interest in high energy physics as well as in number
theory. Algorithms for the analytical manipulation and numerical evaluation of
these functions are described, along with the way these features are
implemented in Maple.
"
1055,"Far-HO: A Bilevel Programming Package for Hyperparameter Optimization
  and Meta-Learning","  In (Franceschi et al., 2018) we proposed a unified mathematical framework,
grounded on bilevel programming, that encompasses gradient-based hyperparameter
optimization and meta-learning. We formulated an approximate version of the
problem where the inner objective is solved iteratively, and gave sufficient
conditions ensuring convergence to the exact problem. In this work we show how
to optimize learning rates, automatically weight the loss of single examples
and learn hyper-representations with Far-HO, a software package based on the
popular deep learning framework TensorFlow that allows to seamlessly tackle
both HO and ML problems.
"
1056,"SIMD Vectorization for the Lennard-Jones Potential with AVX2 and AVX-512
  instructions","  This work describes the SIMD vectorization of the force calculation of the
Lennard-Jones potential with Intel AVX2 and AVX-512 instruction sets. Since the
force-calculation kernel of the molecular dynamics method involves indirect
access to memory, the data layout is one of the most important factors in
vectorization. We find that the Array of Structures (AoS) with padding exhibits
better performance than Structure of Arrays (SoA) with appropriate
vectorization and optimizations. In particular, AoS with 512-bit width exhibits
the best performance among the architectures. While the difference in
performance between AoS and SoA is significant for the vectorization with AVX2,
that with AVX-512 is minor. The effect of other optimization techniques, such
as software pipelining together with vectorization, is also discussed. We
present results for benchmarks on three CPU architectures: Intel Haswell (HSW),
Knights Landing (KNL), and Skylake (SKL). The performance gains by
vectorization are about 42\% on HSW compared with the code optimized without
vectorization. On KNL, the hand-vectorized codes exhibit 34\% better
performance than the codes vectorized automatically by the Intel compiler. On
SKL, the code vectorized with AVX2 exhibits slightly better performance than
that with vectorized AVX-512.
"
1057,"Numerical Evaluation of Elliptic Functions, Elliptic Integrals and
  Modular Forms","  We describe algorithms to compute elliptic functions and their relatives
(Jacobi theta functions, modular forms, elliptic integrals, and the
arithmetic-geometric mean) numerically to arbitrary precision with rigorous
error bounds for arbitrary complex variables. Implementations in ball
arithmetic are available in the open source Arb library. We discuss the
algorithms from a concrete implementation point of view, with focus on
performance at tens to thousands of digits of precision.
"
1058,A model-driven approach for a new generation of adaptive libraries,"  Efficient high-performance libraries often expose multiple tunable parameters
to provide highly optimized routines. These can range from simple loop unroll
factors or vector sizes all the way to algorithmic changes, given that some
implementations can be more suitable for certain devices by exploiting hardware
characteristics such as local memories and vector units. Traditionally, such
parameters and algorithmic choices are tuned and then hard-coded for a specific
architecture and for certain characteristics of the inputs. However, emerging
applications are often data-driven, thus traditional approaches are not
effective across the wide range of inputs and architectures used in practice.
In this paper, we present a new adaptive framework for data-driven applications
which uses a predictive model to select the optimal algorithmic parameters by
training with synthetic and real datasets. We demonstrate the effectiveness of
a BLAS library and specifically on its matrix multiplication routine. We
present experimental results for two GPU architectures and show significant
performance gains of up to 3x (on a high-end NVIDIA Pascal GPU) and 2.5x (on an
embedded ARM Mali GPU) when compared to a traditionally optimized library.
"
1059,Tensor-Tensor Product Toolbox,"  The tensor-tensor product (t-product) [M. E. Kilmer and C. D. Martin, 2011]
is a natural generalization of matrix multiplication. Based on t-product, many
operations on matrix can be extended to tensor cases, including tensor SVD,
tensor spectral norm, tensor nuclear norm [C. Lu, et al., 2018] and many
others. The linear algebraic structure of tensors are similar to the matrix
cases. We develop a Matlab toolbox to implement several basic operations on
tensors based on t-product. The toolbox is available at
https://github.com/canyilu/tproduct.
"
1060,"Enclave Tasking for Discontinuous Galerkin Methods on Dynamically
  Adaptive Meshes","  High-order Discontinuous Galerkin (DG) methods promise to be an excellent
discretisation paradigm for partial differential equation solvers by combining
high arithmetic intensity with localised data access. They also facilitate
dynamic adaptivity without the need for conformal meshes. A parallel evaluation
of DG's weak formulation within a mesh traversal is non-trivial, as dependency
graphs over dynamically adaptive meshes change, as causal constraints along
resolution transitions have to be preserved, and as data sends along MPI domain
boundaries have to be triggered in the correct order. We propose to process
mesh elements subject to constraints with high priority or, where needed,
serially throughout a traversal. The remaining cells form enclaves and are
spawned into a task system. This introduces concurrency, mixes memory-intensive
DG integrations with compute-bound Riemann solves, and overlaps computation and
communication. We discuss implications on MPI and show that MPI parallelisation
improves by a factor of three through enclave tasking, while we obtain an
additional factor of two from shared memory if grids are dynamically adaptive.
"
1061,Parallel Nonnegative CP Decomposition of Dense Tensors,"  The CP tensor decomposition is a low-rank approximation of a tensor. We
present a distributed-memory parallel algorithm and implementation of an
alternating optimization method for computing a CP decomposition of dense
tensor data that can enforce nonnegativity of the computed low-rank factors.
The principal task is to parallelize the matricized-tensor times Khatri-Rao
product (MTTKRP) bottleneck subcomputation. The algorithm is computation
efficient, using dimension trees to avoid redundant computation across MTTKRPs
within the alternating method. Our approach is also communication efficient,
using a data distribution and parallel algorithm across a multidimensional
processor grid that can be tuned to minimize communication. We benchmark our
software on synthetic as well as hyperspectral image and neuroscience dynamic
functional connectivity data, demonstrating that our algorithm scales well to
100s of nodes (up to 4096 cores) and is faster and more general than the
currently available parallel software.
"
1062,"Optimising finite-difference methods for PDEs through parameterised
  time-tiling in Devito","  Finite-difference methods are widely used in solving partial differential
equations. In a large problem set, approximations can take days or weeks to
evaluate, yet the bulk of computation may occur within a single loop nest. The
modelling process for researchers is not straightforward either, requiring
models with differential equations to be translated into stencil kernels, then
optimised separately. One tool that seeks to speed up and eliminate mistakes
from this tedious procedure is Devito, used to efficiently employ
finite-difference methods.
  In this work, we implement time-tiling, a loop nest optimisation, in Devito
yielding a decrease in runtime of up to 45%, and at least 20% across stencils
from the acoustic wave equation family, widely used in Devito's target domain
of seismic imaging. We present an estimator for arithmetic intensity under
time-tiling and a model to predict runtime improvements in stencil
computations. We also consider generalisation of time-tiling to imperfect loop
nests, a less widely studied problem.
"
1063,Function space bases in the dune-functions module,"  The dune-functions Dune module provides interfaces for functions and function
space bases. It forms one abstraction level above grids, shape functions, and
linear algebra, and provides infrastructure for full discretization frameworks
like dune-pdelab and dune-fem. This document describes the function space bases
provided by dune-functions. These are based on an abstract description of bases
for product spaces as trees of simpler bases. From this description, many
different numberings of degrees of freedom by multi-indices can be derived in a
natural way. We describe the abstract concepts, document the programmer
interface, and give a complete example program that solves the stationary
Stokes equation using Taylor-Hood elements.
"
1064,Probabilistic Inference Using Generators - The Statues Algorithm,"  We present here a new probabilistic inference algorithm that gives exact
results in the domain of discrete probability distributions. This algorithm,
named the Statues algorithm, calculates the marginal probability distribution
on probabilistic models defined as direct acyclic graphs. These models are made
up of well-defined primitives that allow to express, in particular, joint
probability distributions, Bayesian networks, discrete Markov chains,
conditioning and probabilistic arithmetic. The Statues algorithm relies on a
variable binding mechanism based on the generator construct, a special form of
coroutine; being related to the enumeration algorithm, this new algorithm
brings important improvements in terms of efficiency, which makes it valuable
in regard to other exact marginalization algorithms. After introduction of
several definitions, primitives and compositional rules, we present in details
the Statues algorithm. Then, we briefly discuss the interest of this algorithm
compared to others and we present possible extensions. Finally, we introduce
Lea and MicroLea, two Python libraries implementing the Statues algorithm,
along with several use cases. A proof of the correctness of the algorithm is
provided in appendix.
"
1065,Clustering Complex Zeros of Triangular Systems of Polynomials,"  This paper gives the first algorithm for finding a set of natural
$\epsilon$-clusters of complex zeros of a triangular system of polynomials
within a given polybox in $\mathbb{C}^n$, for any given $\epsilon>0$. Our
algorithm is based on a recent near-optimal algorithm of Becker et al (2016)
for clustering the complex roots of a univariate polynomial where the
coefficients are represented by number oracles.
  Our algorithm is numeric, certified and based on subdivision. We implemented
it and compared it with two well-known homotopy solvers on various triangular
systems. Our solver always gives correct answers, is often faster than the
homotopy solver that often gives correct answers, and sometimes faster than the
one that gives sometimes correct results.
"
1066,"Elfun18 A collection of Matlab functions for the computation of
  Elliptical Integrals and Jacobian elliptic functions of real arguments","  In the article we outline the set of Matlab functions that enable the
computation of elliptic Integrals and Jacobian elliptic functions for real
arguments. Correctness, robustness, efficiency and accuracy of the functions
are discussed in some details. An example from the elasticity theory
illustrates use of the collection.
"
1067,Implementation of a Near-Optimal Complex Root Clustering Algorithm,"  We describe Ccluster, a software for computing natural $\epsilon$-clusters of
complex roots in a given box of the complex plane. This algorithm from Becker
et al.~(2016) is near-optimal when applied to the benchmark problem of
isolating all complex roots of an integer polynomial. It is one of the first
implementations of a near-optimal algorithm for complex roots. We describe some
low level techniques for speeding up the algorithm. Its performance is compared
with the well-known MPSolve library and Maple.
"
1068,"A scalable H-matrix approach for the solution of boundary integral
  equations on multi-GPU clusters","  In this work, we consider the solution of boundary integral equations by
means of a scalable hierarchical matrix approach on clusters equipped with
graphics hardware, i.e. graphics processing units (GPUs). To this end, we
extend our existing single-GPU hierarchical matrix library hmglib such that it
is able to scale on many GPUs and such that it can be coupled to arbitrary
application codes. Using a model GPU implementation of a boundary element
method (BEM) solver, we are able to achieve more than 67 percent relative
parallel speed-up going from 128 to 1024 GPUs for a model geometry test case
with 1.5 million unknowns and a real-world geometry test case with almost 1.2
million unknowns. On 1024 GPUs of the cluster Titan, it takes less than 6
minutes to solve the 1.5 million unknowns problem, with 5.7 minutes for the
setup phase and 20 seconds for the iterative solver. To the best of the
authors' knowledge, we here discuss the first fully GPU-based
distributed-memory parallel hierarchical matrix Open Source library using the
traditional H-matrix format and adaptive cross approximation with an
application to BEM problems.
"
1069,A GPU-enabled finite volume solver for large shallow water simulations,"  This paper presents the implementation of a HLLC finite volume solver using
GPU technology for the solution of shallow water problems in two dimensions. It
compares both CPU and GPU approaches for implementing all the solver's steps.
The technology of graphics and central processors is highlighted with a
particular emphasis on the CUDA architecture of NVIDIA. The simple and
well-documented Application Programming Interface (CUDA API) facilitates the
use of the display card workstation as an additional computer unit to the
central processor. Four professional solutions of the NVIDIA Quadro line are
tested. Comparison tests between CPU and GPU are carried out on unstructured
grids of small sizes (up to 10,000 elements), medium and large sizes (up to
10,000,000 elements). For all test cases, the accuracy of results is of the
same order of magnitude for both approaches. Furthermore, the obtained speed
gains with the GPU strongly depend on the model of the graphics card, the size
of the problem and the simulation time.
"
1070,"The Implementation of the Colored Abstract Simplicial Complex and its
  Application to Mesh Generation","  We introduce CASC: a new, modern, and header-only C++ library which provides
a data structure to represent arbitrary dimension abstract simplicial complexes
(ASC) with user-defined classes stored directly on the simplices at each
dimension. This is accomplished by using the latest C++ language features
including variadic template parameters introduced in C++11 and automatic
function return type deduction from C++14. Effectively CASC decouples the
representation of the topology from the interactions of user data. We present
the innovations and design principles of the data structure and related
algorithms. This includes a metadata aware decimation algorithm which is
general for collapsing simplices of any dimension. We also present an example
application of this library to represent an orientable surface mesh.
"
1071,"FluidFFT: common API (C++ and Python) for Fast Fourier Transform HPC
  libraries","  The Python package fluidfft provides a common Python API for performing Fast
Fourier Transforms (FFT) in sequential, in parallel and on GPU with different
FFT libraries (FFTW, P3DFFT, PFFT, cuFFT). fluidfft is a comprehensive FFT
framework which allows Python users to easily and efficiently perform FFT and
the associated tasks, such as as computing linear operators and energy spectra.
We describe the architecture of the package composed of C++ and Cython FFT
classes, Python ""operator"" classes and Pythran functions. The package supplies
utilities to easily test itself and benchmark the different FFT solutions for a
particular case and on a particular machine. We present a performance scaling
analysis on three different computing clusters and a microbenchmark showing
that fluidfft is an interesting solution to write efficient Python applications
using FFT.
"
1072,"Architecture and performance of Devito, a system for automated stencil
  computation","  Stencil computations are a key part of many high-performance computing
applications, such as image processing, convolutional neural networks, and
finite-difference solvers for partial differential equations. Devito is a
framework capable of generating highly-optimized code given symbolic equations
expressed in Python, specialized in, but not limited to, affine (stencil)
codes. The lowering process---from mathematical equations down to C++ code---is
performed by the Devito compiler through a series of intermediate
representations. Several performance optimizations are introduced, including
advanced common sub-expressions elimination, tiling and parallelization. Some
of these are obtained through well-established stencil optimizers, integrated
in the back-end of the Devito compiler. The architecture of the Devito
compiler, as well as the performance optimizations that are applied when
generating code, are presented. The effectiveness of such performance
optimizations is demonstrated using operators drawn from seismic imaging
applications.
"
1073,The Dune Python Module,"  In this paper we present the new Dune-Python module which provides Python
bindings for the Dune core, which is a C++ environment for solving partial
differential equations. The aim of this new module is to firstly provide the
general infrastructure for exporting realizations of statically polymorphic
interfaces based on just-in-time compilation and secondly to provide bindings
for the central interfaces of the dune core modules. In the first release we
focus on the grid interface. Our aim is to only introduce a thin layer when
passing objects into Python which can be removed when the object is passed back
into a C++ algorithm. Thus no efficiency is lost and little additional code
maintenance cost is incurred. To make the transition for Dune users to the
Python environment straightforward the Python classes provide a very similar
interface to their C++ counterparts. In addition, vectorized versions of many
interfaces allow for more efficient code on the Python side. The infrastructure
for exporting these interfaces and the resulting bindings for a Dune grid are
explained in detail in this paper for both experienced Dune users and others
interested in a flexible Python environment for implementing grid based schemes
for solving partial differential equations.
"
1074,"Confederated Modular Differential Equation APIs for Accelerated
  Algorithm Development and Benchmarking","  Performant numerical solving of differential equations is required for
large-scale scientific modeling. In this manuscript we focus on two questions:
(1) how can researchers empirically verify theoretical advances and
consistently compare methods in production software settings and (2) how can
users (scientific domain experts) keep up with the state-of-the-art methods to
select those which are most appropriate? Here we describe how the confederated
modular API of DifferentialEquations.jl addresses these concerns. We detail the
package-free API which allows numerical methods researchers to readily utilize
and benchmark any compatible method directly in full-scale scientific
applications. In addition, we describe how the complexity of the method choices
is abstracted via a polyalgorithm. We show how scientific tooling built on top
of DifferentialEquations.jl, such as packages for dynamical systems
quantification and quantum optics simulation, both benefit from this structure
and provide themselves as convenient benchmarking tools.
"
1075,Physical-type correctness in scientific Python,"  The representation of units and dimensions in informatics systems is barely
codified and often ignored. For instance, the major languages used in
scientific computing (Fortran, C and Python), have no type for dimension or
unit, and so physical quantities are represented in a program by variables of
type real, resulting in the possibility of unit or dimensional errors. In view
of this danger, many authors have proposed language schemes for unit-checking
and conversion. However, since many physical quantities have the same units, it
is possible for a block of code to be unit-compatible, but still physically
meaningless. We demonstrate the limitations of three Python unit-libraries and
present a justification and method for checking kind-of-quantity.
"
1076,"Computational and applied topology, tutorial","  This is a tutorial in applied and computational topology and topological data
analysis. It is illustrated with numerous computational examples that utilize
Gudhi library. It is under constant development, so please do not consider this
version as final.
"
1077,"A Benchmark of Selected Algorithmic Differentiation Tools on Some
  Problems in Computer Vision and Machine Learning","  Algorithmic differentiation (AD) allows exact computation of derivatives
given only an implementation of an objective function. Although many AD tools
are available, a proper and efficient implementation of AD methods is not
straightforward. The existing tools are often too different to allow for a
general test suite. In this paper, we compare fifteen ways of computing
derivatives including eleven automatic differentiation tools implementing
various methods and written in various languages (C++, F#, MATLAB, Julia and
Python), two symbolic differentiation tools, finite differences, and
hand-derived computation.
  We look at three objective functions from computer vision and machine
learning. These objectives are for the most part simple, in the sense that no
iterative loops are involved, and conditional statements are encapsulated in
functions such as {\tt abs} or {\tt logsumexp}. However, it is important for
the success of algorithmic differentiation that such `simple' objective
functions are handled efficiently, as so many problems in computer vision and
machine learning are of this form.
  Of course, our results depend on programmer skill, and familiarity with the
tools. However, we contend that this paper presents an important datapoint: a
skilled programmer devoting roughly a week to each tool produced the timings we
present. We have made our implementations available as open source to allow the
community to replicate and update these benchmarks.
"
1078,GuiTeNet: A graphical user interface for tensor networks,"  We introduce a graphical user interface for constructing arbitrary tensor
networks and specifying common operations like contractions or splitting,
denoted GuiTeNet. Tensors are represented as nodes with attached legs,
corresponding to the ordered dimensions of the tensor. GuiTeNet visualizes the
current network, and instantly generates Python/NumPy source code for the
hitherto sequence of user actions. Support for additional programming languages
is planned for the future. We discuss the elementary operations on tensor
networks used by GuiTeNet, together with high-level optimization strategies.
The software runs directly in web browsers and is available online at
http://guitenet.org.
"
1079,"Accelerating wave-propagation algorithms with adaptive mesh refinement
  using the Graphics Processing Unit (GPU)","  Clawpack is a library for solving nonlinear hyperbolic partial differential
equations using high-resolution finite volume methods based on Riemann solvers
and limiters. It supports Adaptive Mesh Refinement (AMR), which is essential in
solving multi-scale problems. Recently, we added capabilities to accelerate the
code by using the Graphics Process Unit (GPU). Routines that manage CPU and GPU
AMR data and facilitate the execution of GPU kernels are added. Customized and
CPU thread-safe memory managers are designed to manage GPU and CPU memory
pools, which is essential in eliminating the overhead of memory allocation and
de-allocation. A global reduction is conducted every time step for dynamically
adjusting the time step based on Courant number restrictions. Some small GPU
kernels are merged into bigger kernels, which greatly reduces kernel launching
overhead. A speed-up between $2$ and $3$ for the total running time is observed
in an acoustics benchmark problem.
"
1080,pySDC - Prototyping spectral deferred corrections,"  In this paper we present the Python framework pySDC for solving collocation
problems with spectral deferred correction methods (SDC) and their
time-parallel variant PFASST, the parallel full approximation scheme in space
and time. pySDC features many implementations of SDC and PFASST, from simple
implicit time-stepping to high-order implicit-explicit or multi-implicit
splitting and multi-level spectral deferred corrections. It comes with many
different, pre-implemented examples and has seven tutorials to help new users
with their first steps. Time-parallelism is implemented either in an emulated
way for debugging and prototyping as well as using MPI for benchmarking. The
code is fully documented and tested using continuous integration, including
most results of previous publications. Here, we describe the structure of the
code by taking two different perspectives: the user's and the developer's
perspective. While the first sheds light on the front-end, the examples and the
tutorials, the second is used to describe the underlying implementation and the
data structures. We show three different examples to highlight various aspects
of the implementation, the capabilities and the usage of pySDC. Also, couplings
to the FEniCS framework and PETSc, the latter including spatial parallelism
with MPI, are described.
"
1081,Fast Flexible Function Dispatch in Julia,"  Technical computing is a challenging application area for programming
languages to address. This is evinced by the unusually large number of
specialized languages in the area (e.g. MATLAB, R), and the complexity of
common software stacks, often involving multiple languages and custom code
generators. We believe this is ultimately due to key characteristics of the
domain: highly complex operators, a need for extensive code specialization for
performance, and a desire for permissive high-level programming styles allowing
productive experimentation. The Julia language attempts to provide a more
effective structure for this kind of programming by allowing programmers to
express complex polymorphic behaviors using dynamic multiple dispatch over
parametric types. The forms of extension and reuse permitted by this paradigm
have proven valuable for technical computing. We report on how this approach
has allowed domain experts to express useful abstractions while simultaneously
providing a natural path to better performance for high-level technical code.
"
1082,Linguistic Relativity and Programming Languages,"  The use of programming languages can wax and wane across the decades. We
examine the split-apply- combine pattern that is common in statistical
computing, and consider how its invocation or implementation in languages like
MATLAB and APL differ from R/dplyr. The differences in spelling illustrate how
the concept of linguistic relativity applies to programming languages in ways
that are analogous to human languages. Finally, we discuss how Julia, by being
a high performance yet general purpose dynamic language, allows its users to
express different abstractions to suit individual preferences.
"
1083,"Bringing Together Dynamic Geometry Software and the Graphics Processing
  Unit","  We equip dynamic geometry software (DGS) with a user-friendly method that
enables massively parallel calculations on the graphics processing unit (GPU).
This interplay of DGS and GPU opens up various applications in education and
mathematical research. The GPU-aided discovery of mathematical properties,
interactive visualizations of algebraic surfaces (raycasting), the mathematical
deformation of images and footage in real-time, and computationally demanding
numerical simulations of PDEs are examples from the long and versatile list of
new domains that our approach makes accessible within a DGS. We ease the
development of complex (mathematical) visualizations and provide a
rapid-prototyping scheme for general-purpose computations (GPGPU).
  The possibility to program both CPU and GPU with the use of only one
high-level (scripting) programming language is a crucial aspect of our concept.
We embed shader programming seamlessly within a high-level (scripting)
programming environment. The aforementioned requires the symbolic process of
the transcompilation of a high-level programming language into shader
programming language for GPU and, in this article, we address the challenge of
the automatic translation of a high-level programming language to a shader
language of the GPU. To maintain platform independence and the possibility to
use our technology on modern devices, we focus on a realization through WebGL.
"
1084,Code generation for generally mapped finite elements,"  Many classical finite elements such as the Argyris and Bell elements have
long been absent from high-level PDE software. Building on recent theoretical
work, we describe how to implement very general finite element transformations
in FInAT and hence into the Firedrake finite element system. Numerical results
evaluate the new elements, comparing them to existing methods for classical
problems. For a second order model problem, we find that new elements give
smooth solutions at a mild increase in cost over standard Lagrange elements.
For fourth-order problems, however, the newly-enabled methods significantly
outperform interior penalty formulations. We also give some advanced use cases,
solving the nonlinear Cahn-Hilliard equation and some biharmonic eigenvalue
problems (including Chladni plates) using $C^1$ discretizations.
"
1085,"A parallel non-uniform fast Fourier transform library based on an
  ""exponential of semicircle"" kernel","  The nonuniform fast Fourier transform (NUFFT) generalizes the FFT to off-grid
data. Its many applications include image reconstruction, data analysis, and
the numerical solution of differential equations. We present FINUFFT, an
efficient parallel library for type 1 (nonuiform to uniform), type 2 (uniform
to nonuniform), or type 3 (nonuniform to nonuniform) transforms, in dimensions
1, 2, or 3. It uses minimal RAM, requires no precomputation or plan steps, and
has a simple interface to several languages. We perform the expensive
spreading/interpolation between nonuniform points and the fine grid via a
simple new kernel---the `exponential of semicircle' $e^{\beta \sqrt{1-x^2}}$ in
$x\in[-1,1]$---in a cache-aware load-balanced multithreaded implementation. The
deconvolution step requires the Fourier transform of the kernel, for which we
propose efficient numerical quadrature. For types 1 and 2, rigorous error
bounds asymptotic in the kernel width approach the fastest known exponential
rate, namely that of the Kaiser--Bessel kernel. We benchmark against several
popular CPU-based libraries, showing favorable speed and memory footprint,
especially in three dimensions when high accuracy and/or clustered point
distributions are desired.
"
1086,A Simple Methodology for Computing Families of Algorithms,"  Discovering ""good"" algorithms for an operation is often considered an art
best left to experts. What if there is a simple methodology, an algorithm, for
systematically deriving a family of algorithms as well as their cost analyses,
so that the best algorithm can be chosen? We discuss such an approach for
deriving loop-based algorithms. The example used to illustrate this
methodology, evaluation of a polynomial, is itself simple yet the best
algorithm that results is surprising to a non-expert: Horner's rule. We finish
by discussing recent advances that make this approach highly practical for the
domain of high-performance linear algebra software libraries.
"
1087,Implementing Strassen's Algorithm with CUTLASS on NVIDIA Volta GPUs,"  Conventional GPU implementations of Strassen's algorithm (Strassen) typically
rely on the existing high-performance matrix multiplication (GEMM), trading
space for time. As a result, such approaches can only achieve practical speedup
for relatively large, ""squarish"" matrices due to the extra memory overhead, and
their usages are limited due to the considerable workspace. We present novel
Strassen primitives for GPUs that can be composed to generate a family of
Strassen algorithms. Our algorithms utilize both the memory and thread
hierarchies on GPUs, reusing shared memory and register files inherited from
GEMM, fusing additional operations, and avoiding extra workspace. We further
exploit intra- and inter-kernel parallelism by batching, streaming, and
employing atomic operations. We also develop a performance model for NVIDIA
Volta GPUs to select the appropriate blocking parameters and predict the
performance for GEMM and Strassen. Overall, our 1-level Strassen can achieve up
to 1.11x speedup with a crossover point as small as 1,536 compared to
cublasSgemm on a NVIDIA Tesla V100 GPU. With additional workspace, our 2-level
Strassen can achieve 1.19x speedup with a crossover point at 7,680.
"
1088,"An Experimental Comparison of SONC and SOS Certificates for
  Unconstrained Optimization","  Finding the minimum of a multivariate real polynomial is a well-known hard
problem with various applications. We present a polynomial time algorithm to
approximate such lower bounds via sums of nonnegative circuit polynomials
(SONC). As a main result, we carry out the first large-scale comparison of
SONC, using this algorithm and different geometric programming (GP) solvers,
with the classical sums of squares (SOS) approach, using several of the most
common semidefinite programming (SDP) solvers. SONC yields bounds competitive
to SOS in several cases, but using significantly less time and memory. In
particular, SONC/GP can handle much larger problem instances than SOS/SDP.
"
1089,"A general-purpose hierarchical mesh partitioning method with node
  balancing strategies for large-scale numerical simulations","  Large-scale parallel numerical simulations are essential for a wide range of
engineering problems that involve complex, coupled physical processes
interacting across a broad range of spatial and temporal scales. The data
structures involved in such simulations (meshes, sparse matrices, etc.) are
frequently represented as graphs, and these graphs must be optimally
partitioned across the available computational resources in order for the
underlying calculations to scale efficiently. Partitions which minimize the
number of graph edges that are cut (edge-cuts) while simultaneously maintaining
a balance in the amount of work (i.e. graph nodes) assigned to each processor
core are desirable, and the performance of most existing partitioning software
begins to degrade in this metric for partitions with more than than $O(10^3)$
processor cores. In this work, we consider a general-purpose hierarchical
partitioner which takes into account the existence of multiple processor cores
and shared memory in a compute node while partitioning a graph into an
arbitrary number of subgraphs. We demonstrate that our algorithms significantly
improve the preconditioning efficiency and overall performance of realistic
numerical simulations running on up to 32,768 processor cores with nearly
$10^9$ unknowns.
"
1090,Tuning the Performance of a Computational Persistent Homology Package,"  In recent years, persistent homology has become an attractive method for data
analysis. It captures topological features, such as connected components,
holes, and voids from point cloud data and summarizes the way in which these
features appear and disappear in a filtration sequence. In this project, we
focus on improving the performance of Eirene, a computational package for
persistent homology. Eirene is a 5000-line open-source software library
implemented in the dynamic programming language Julia. We use the Julia
profiling tools to identify performance bottlenecks and develop novel methods
to manage them, including the parallelization of some time-consuming functions
on multicore/manycore hardware. Empirical results show that performance can be
greatly improved.
"
1091,When Lift-and-Project Cuts are Different,"  In this paper, we present a method to determine if a lift-and-project cut for
a mixed-integer linear program is irregular, in which case the cut is not
equivalent to any intersection cut from the bases of the linear relaxation.
This is an important question due to the intense research activity for the past
decade on cuts from multiple rows of simplex tableau as well as on
lift-and-project cuts from non-split disjunctions. While it is known since
Balas and Perregaard (2003) that lift-and-project cuts from split disjunctions
are always equivalent to intersection cuts and consequently to such multi-row
cuts, Balas and Kis (2016) have recently shown that there is a necessary and
sufficient condition in the case of arbitrary disjunctions: a lift-and-project
cut is regular if, and only if, it corresponds to a regular basic solution of
the Cut Generating Linear Program (CGLP). This paper has four contributions.
First, we state a result that simplifies the verification of regularity for
basic CGLP solutions from Balas and Kis (2016). Second, we provide a
mixed-integer formulation that checks whether there is a regular CGLP solution
for a given cut that is regular in a broader sense, which also encompasses
irregular cuts that are implied by the regular cut closure. Third, we describe
a numerical procedure based on such formulation that identifies irregular
lift-and-project cuts. Finally, we use this method to evaluate how often
lift-and-project cuts from simple $t$-branch split disjunctions are irregular,
and thus not equivalent to multi-row cuts, on 74 instances of the MIPLIB
benchmarks.
"
1092,Random problems with R,"  R (Version 3.5.1 patched) has an issue with its random sampling
functionality. R generates random integers between $1$ and $m$ by multiplying
random floats by $m$, taking the floor, and adding $1$ to the result.
Well-known quantization effects in this approach result in a non-uniform
distribution on $\{ 1, \ldots, m\}$. The difference, which depends on $m$, can
be substantial. Because the sample function in R relies on generating random
integers, random sampling in R is biased. There is an easy fix: construct
random integers directly from random bits, rather than multiplying a random
float by $m$. That is the strategy taken in Python's numpy.random.randint()
function, among others. Example source code in Python is available at
https://github.com/statlab/cryptorandom/blob/master/cryptorandom/cryptorandom.py
(see functions getrandbits() and randbelow_from_randbits()).
"
1093,"auditor: an R Package for Model-Agnostic Visual Validation and
  Diagnostics","  Machine learning models have spread to almost every area of life. They are
successfully applied in biology, medicine, finance, physics, and other fields.
With modern software it is easy to train even a~complex model that fits the
training data and results in high accuracy on the test set. The problem arises
when models fail confronted with real-world data.
  This paper describes methodology and tools for model-agnostic audit.
Introduced techniques facilitate assessing and comparing the goodness of fit
and performance of models. In~addition, they may be used for the analysis of
the similarity of residuals and for identification of~outliers and influential
observations. The examination is carried out by diagnostic scores and visual
verification.
  Presented methods were implemented in the auditor package for R. Due to
flexible and~consistent grammar, it is simple to validate models of any
classes.
"
1094,"Software for Sparse Tensor Decomposition on Emerging Computing
  Architectures","  In this paper, we develop software for decomposing sparse tensors that is
portable to and performant on a variety of multicore, manycore, and GPU
computing architectures. The result is a single code whose performance matches
optimized architecture-specific implementations. The key to a portable approach
is to determine multiple levels of parallelism that can be mapped in different
ways to different architectures, and we explain how to do this for the
matricized tensor times Khatri-Rao product (MTTKRP) which is the key kernel in
canonical polyadic tensor decomposition. Our implementation leverages the
Kokkos framework, which enables a single code to achieve high performance
across multiple architectures that differ in how they approach fine-grained
parallelism. We also introduce a new construct for portable thread-local
arrays, which we call compile-time polymorphic arrays. Not only are the
specifics of our approaches and implementation interesting for tuning tensor
computations, but they also provide a roadmap for developing other portable
high-performance codes. As a last step in optimizing performance, we modify the
MTTKRP algorithm itself to do a permuted traversal of tensor nonzeros to reduce
atomic-write contention. We test the performance of our implementation on 16-
and 68-core Intel CPUs and the K80 and P100 NVIDIA GPUs, showing that we are
competitive with state-of-the-art architecture-specific codes while having the
advantage of being able to run on a variety of architectures.
"
1095,FDBB: Fluid Dynamics Building Blocks,"  High-performance computing platforms are becoming more and more
heterogeneous, which makes it very difficult for researchers and scientific
software developers to keep up with the rapid changes on the hardware market.
In this paper, the open-source project FDBB (Fluid Dynamics Building Blocks) is
presented, which eases the development of fluid dynamics applications for
heterogeneous systems. It consists of a low-level API that provides a unified
interface to many different linear algebra back-ends and a lightweight and
extendible high-level expression template library, which provides largely
customizable fluid dynamics building blocks, like transformations between
primary and secondary variables as well as expressions for Riemann invariants,
equations of state, inviscid fluxes and their flux-Jacobians. The performance
of the developed approach is assessed both for synthetic micro-benchmarks and
within mini-applications.
"
1096,"Scalar Arithmetic Multiple Data: Customizable Precision for Deep Neural
  Networks","  Quantization of weights and activations in Deep Neural Networks (DNNs) is a
powerful technique for network compression, and has enjoyed significant
attention and success. However, much of the inference-time benefit of
quantization is accessible only through the use of customized hardware
accelerators or by providing an FPGA implementation of quantized arithmetic.
  Building on prior work, we show how to construct arbitrary bit-precise signed
and unsigned integer operations using a software technique which logically
\emph{embeds} a vector architecture with custom bit-width lanes in universally
available fixed-width scalar arithmetic.
  We evaluate our approach on a high-end Intel Haswell processor, and an
embedded ARM processor. Our approach yields very fast implementations of
bit-precise custom DNN operations, which often match or exceed the performance
of operations quantized to the sizes supported in native arithmetic. At the
strongest level of quantization, our approach yields a maximum speedup of
$\thicksim6\times$ on the Intel platform, and $\thicksim10\times$ on the ARM
platform versus quantization to native 8-bit integers.
"
1097,Multiscale finite element calculations in Python using SfePy,"  SfePy (Simple finite elements in Python) is a software for solving various
kinds of problems described by partial differential equations in one, two or
three spatial dimensions by the finite element method. Its source code is
mostly (85\%) Python and relies on fast vectorized operations provided by the
NumPy package. For a particular problem two interfaces can be used: a
declarative application programming interface (API), where problem
description/definition files (Python modules) are used to define a calculation,
and an imperative API, that can be used for interactive commands, or in scripts
and libraries. After outlining the SfePy package development, the paper
introduces its implementation, structure and general features. The components
for defining a partial differential equation are described using an example of
a simple heat conduction problem. Specifically, the declarative API of SfePy is
presented in the example. To illustrate one of SfePy's main assets, the
framework for implementing complex multiscale models based on the theory of
homogenization, an example of a two-scale piezoelastic model is presented,
showing both the mathematical description of the problem and the corresponding
code.
"
1098,"Validation of a PETSc based software implementing a 4DVAR Data
  Assimilation algorithm: a case study related with an Oceanic Model based on
  Shallow Water equation","  In this work are presented and discussed some results related to the
validation process of a software module based on PETSc which implements a Data
Assimilation algorithm.
"
1099,"GPdoemd: a Python package for design of experiments for model
  discrimination","  Model discrimination identifies a mathematical model that usefully explains
and predicts a given system's behaviour. Researchers will often have several
models, i.e. hypotheses, about an underlying system mechanism, but insufficient
experimental data to discriminate between the models, i.e. discard inaccurate
models. Given rival mathematical models and an initial experimental data set,
optimal design of experiments suggests maximally informative experimental
observations that maximise a design criterion weighted by prediction
uncertainty. The model uncertainty requires gradients, which may not be readily
available for black-box models. This paper (i) proposes a new design criterion
using the Jensen-R\'enyi divergence, and (ii) develops a novel method replacing
black-box models with Gaussian process surrogates. Using the surrogates, we
marginalise out the model parameters with approximate inference. Results show
these contributions working well for both classical and new test instances. We
also (iii) introduce and discuss GPdoemd, the open-source implementation of the
Gaussian process surrogate method.
"
1100,"Studies on the energy and deep memory behaviour of a cache-oblivious,
  task-based hyperbolic PDE solver","  We study the performance behaviour of a seismic simulation using the ExaHyPE
engine with a specific focus on memory characteristics and energy needs.
ExaHyPE combines dynamically adaptive mesh refinement (AMR) with ADER-DG. It is
parallelized using tasks, and it is cache efficient. AMR plus ADER-DG yields a
task graph which is highly dynamic in nature and comprises both arithmetically
expensive tasks and tasks which challenge the memory's latency. The expensive
tasks and thus the whole code benefit from AVX vectorization, though we suffer
from memory access bursts. A frequency reduction of the chip improves the
code's energy-to-solution. Yet, it does not mitigate burst effects. The bursts'
latency penalty becomes worse once we add Intel Optane technology, increase the
core count significantly, or make individual, computationally heavy tasks fall
out of close caches. Thread overbooking to hide away these latency penalties
contra-productive with non-inclusive caches as it destroys the cache and
vectorization character. In cases where memory-intense and computationally
expensive tasks overlap, ExaHyPE's cache-oblivious implementation can exploit
deep, non-inclusive, heterogeneous memory effectively, as main memory misses
arise infrequently and slow down only few cores. We thus propose that upcoming
supercomputing simulation codes with dynamic, inhomogeneous task graphs are
actively supported by thread runtimes in intermixing tasks of different compute
character, and we propose that future hardware actively allows codes to
downclock the cores running particular task types.
"
1101,Coloured and task-based stencil codes,"  Simple stencil codes are and remain an important building block in scientific
computing. On shared memory nodes, they are traditionally parallelised through
colouring or (recursive) tiling. New OpenMP versions alternatively allow users
to specify data dependencies explicitly and to outsource the decision how to
distribute the work to the runtime system. We evaluate traditional
multithreading strategies on both Broadwell and KNL, study the arising
assignment of tasks to threads and, from there, derive two efficient ways to
parallelise stencil codes on regular Cartesian grids that fuse colouring and
task-based approaches.
"
1102,"Matrix-free construction of HSS representation using adaptive randomized
  sampling","  We present new algorithms for the randomized construction of hierarchically
semi-separable matrices, addressing several practical issues. The HSS
construction algorithms use a partially matrix-free, adaptive randomized
projection scheme to determine the maximum off-diagonal block rank. We develop
both relative and absolute stopping criteria to determine the minimum dimension
of the random projection matrix that is sufficient for the desired accuracy.
Two strategies are discussed to adaptively enlarge the random sample matrix:
repeated doubling of the number of random vectors, and iteratively incrementing
the number of random vectors by a fixed number. The relative and absolute
stopping criteria are based on probabilistic bounds for the Frobenius norm of
the random projection of the Hankel blocks of the input matrix. We discuss
parallel implementation and computation and communication cost of both
variants. Parallel numerical results for a range of applications, including
boundary element method matrices and quantum chemistry Toeplitz matrices, show
the effectiveness, scalability and numerical robustness of the proposed
algorithms.
"
1103,"Optimizing AIREBO: Navigating the Journey from Complex Legacy Code to
  High Performance","  Despite initiatives to improve the quality of scientific codes, there still
is a large presence of legacy code. Such code often needs to implement a lot of
functionality under time constrains, sacrificing quality. Additionally, quality
is rarely improved by optimizations for new architectures. This development
model leads to code that is increasingly difficult to work with. Our suggested
solution includes complexity-reducing refactoring and hardware abstraction. We
focus on the AIREBO potential from LAMMPS, where the challenge is that any
potential kernel is rather large and complex, hindering systematic
optimization. This issue is common to codes that model multiple physical
phenomena. We present our journey from the C++ port of a previous Fortran code
to performance-portable, KNC-hybrid, vectorized, scalable, optimized code
supporting full and reduced precision. The journey includes extensive testing
that fixed bugs in the original code. Large-scale, full-precision runs sustain
speedups of more than 4x (KNL) and 3x (Skylake).
"
1104,"Expressing Sparse Matrix Computations for Productive Performance on
  Spatial Architectures","  This paper addresses spatial programming of sparse matrix computations for
productive performance. The challenge is how to express an irregular
computation and its optimizations in a regular way.
  A sparse matrix has (non-zero) values and a structure. In this paper, we
propose to classify the implementations of a computation on a sparse matrix
into two categories: (1) structure-driven, or top-down, approach, which
traverses the structure with given row and column indices and locates the
corresponding values, and (2) values-driven, or bottom-up, approach, which
loads and processes the values in parallel streams, and decodes the structure
for the values' corresponding row and column indices.
  On a spatial architecture like FPGAs, the values-driven approach is the norm.
We show how to express a sparse matrix computation and its optimizations for a
values-driven implementation. A compiler automatically synthesizes a code to
decode the structure. In this way, programmers focus on optimizing the
processing of the values, using familiar optimizations for dense matrices,
while leaving the complex, irregular structure traversal to an automatic
compiler. We also attempt to regularize the optimizations of the reduction for
a dynamic number of values, which is common in a sparse matrix computation.
"
1105,Dynamic Automatic Differentiation of GPU Broadcast Kernels,"  We show how forward-mode automatic differentiation (AD) can be employed
within larger reverse-mode computations to dynamically differentiate broadcast
operations in a GPU-friendly manner. Our technique fully exploits the broadcast
Jacobian's inherent sparsity structure, and unlike a pure reverse-mode
approach, this ""mixed-mode"" approach does not require a backwards pass over the
broadcasted operation's subgraph, obviating the need for several
reverse-mode-specific programmability restrictions on user-authored broadcast
operations. Most notably, this approach allows broadcast fusion in primal code
despite the presence of data-dependent control flow. We discuss an experiment
in which a Julia implementation of our technique outperformed pure reverse-mode
TensorFlow and Julia implementations for differentiating through broadcast
operations within an HM-LSTM cell update calculation.
"
1106,The Ocean Tensor Package,"  Matrix and tensor operations form the basis of a wide range of fields and
applications, and in many cases constitute a substantial part of the overall
computational complexity. The ability of general-purpose GPUs to speed up many
of these operations and enable others has resulted in a widespread adaptation
of these devices. In order for tensor operations to take full advantage of the
computational power, specialized software is required, and currently there
exist several packages (predominantly in the area of deep learning) that
incorporate tensor operations on both CPU and GPU. Nevertheless, a stand-alone
framework that supports general tensor operations is still missing. In this
paper we fill this gap and propose the Ocean Tensor Library: a modular
tensor-support package that is designed to serve as a foundational layer for
applications that require dense tensor operations on a variety of device types.
The API is carefully designed to be powerful, extensible, and at the same time
easy to use. The package is available as open source.
"
1107,ensmallen: a flexible C++ library for efficient function optimization,"  We present ensmallen, a fast and flexible C++ library for mathematical
optimization of arbitrary user-supplied functions, which can be applied to many
machine learning problems. Several types of optimizations are supported,
including differentiable, separable, constrained, and categorical objective
functions. The library provides many pre-built optimizers (including numerous
variants of SGD and Quasi-Newton optimizers) as well as a flexible framework
for implementing new optimizers and objective functions. Implementation of a
new optimizer requires only one method and a new objective function requires
typically one or two C++ functions. This can aid in the quick implementation
and prototyping of new machine learning algorithms. Due to the use of C++
template metaprogramming, ensmallen is able to support compiler optimizations
that provide fast runtimes. Empirical comparisons show that ensmallen is able
to outperform other optimization frameworks (like Julia and SciPy), sometimes
by large margins. The library is distributed under the BSD license and is ready
for use in production environments.
"
1108,Nonequispaced Fast Fourier Transform (NFFT) Interface for Julia,"  This report describes the newly added Julia interface to the NFFT3 library.
We explain the multidimensional NFFT algorithm and basics of the interface.
Furthermore, we go into detail about the different parameters and how to adjust
them properly.
"
1109,CatBoost: gradient boosting with categorical features support,"  In this paper we present CatBoost, a new open-sourced gradient boosting
library that successfully handles categorical features and outperforms existing
publicly available implementations of gradient boosting in terms of quality on
a set of popular publicly available datasets. The library has a GPU
implementation of learning algorithm and a CPU implementation of scoring
algorithm, which are significantly faster than other gradient boosting
libraries on ensembles of similar sizes.
"
1110,Optimizations of the Eigensolvers in the ELPA Library,"  The solution of (generalized) eigenvalue problems for symmetric or Hermitian
matrices is a common subtask of many numerical calculations in electronic
structure theory or materials science. Solving the eigenvalue problem can
easily amount to a sizeable fraction of the whole numerical calculation. For
researchers in the field of computational materials science, an efficient and
scalable solution of the eigenvalue problem is thus of major importance. The
ELPA-library is a well-established dense direct eigenvalue solver library,
which has proven to be very efficient and scalable up to very large core
counts. In this paper, we describe the latest optimizations of the ELPA-library
for new HPC architectures of the Intel Skylake processor family with an AVX-512
SIMD instruction set, or for HPC systems accelerated with recent GPUs. We also
describe a complete redesign of the API in a modern modular way, which, apart
from a much simpler and more flexible usability, leads to a new path to access
system-specific performance optimizations. In order to ensure optimal
performance for a particular scientific setting or a specific HPC system, the
new API allows the user to influence in straightforward way the internal
details of the algorithms and of performance-critical parameters used in the
ELPA-library. On top of that, we introduced an autotuning functionality, which
allows for finding the best settings in a self-contained automated way. In
situations where many eigenvalue problems with similar settings have to be
solved consecutively, the autotuning process of the ELPA-library can be done
""on-the-fly"". Practical applications from materials science which rely on
so-called self-consistency iterations can profit from the autotuning. On some
examples of scientific interest, simulated with the FHI-aims application, the
advantages of the latest optimizations of the ELPA-library are demonstrated.
"
1111,"Issues in the software implementation of stochastic numerical
  Runge-Kutta","  This paper discusses stochastic numerical methods of Runge-Kutta type with
weak and strong convergences for systems of stochastic differential equations
in It\^o form. At the beginning we give a brief overview of the stochastic
numerical methods and information from the theory of stochastic differential
equations. Then we motivate the approach to the implementation of these methods
using source code generation. We discuss the implementation details and the
used programming languages and libraries
"
1112,Gravitational octree code performance evaluation on Volta GPU,"  In this study, the gravitational octree code originally optimized for the
Fermi, Kepler, and Maxwell GPU architectures is adapted to the Volta
architecture. The Volta architecture introduces independent thread scheduling
requiring either the insertion of the explicit synchronizations at appropriate
locations or the enforcement of the same implicit synchronizations as do the
Pascal or earlier architectures by specifying \texttt{-gencode
arch=compute\_60,code=sm\_70}. The performance measurements on Tesla V100, the
current flagship GPU by NVIDIA, revealed that the $N$-body simulations of the
Andromeda galaxy model with $2^{23} = 8388608$ particles took $3.8 \times
10^{-2}$~s or $3.3 \times 10^{-2}$~s per step for each case. Tesla V100
achieves a 1.4 to 2.2-fold acceleration in comparison with Tesla P100, the
flagship GPU in the previous generation. The observed speed-up of 2.2 is
greater than 1.5, which is the ratio of the theoretical peak performance of the
two GPUs. The independence of the units for integer operations from those for
floating-point number operations enables the overlapped execution of integer
and floating-point number operations. It hides the execution time of the
integer operations leading to the speed-up rate above the theoretical peak
performance ratio. Tesla V100 can execute $N$-body simulation with up to $25
\times 2^{20} = 26214400$ particles, and it took $2.0 \times 10^{-1}$~s per
step. It corresponds to $3.5$~TFlop/s, which is 22\% of the single-precision
theoretical peak performance.
"
1113,A Feature Complete SPIKE Banded Algorithm and Solver,"  New features and enhancements for the SPIKE banded solver are presented.
Among all the SPIKE algorithm versions, we focus our attention on the recursive
SPIKE technique which provides the best trade-off between generality and
parallel efficiency, but was known for its lack of flexibility. Its application
was essentially limited to power of two number of cores/processors. This
limitation is successfully addressed in this paper. In addition, we present a
new transpose solve option, a standard feature of most numerical solver
libraries which has never been addressed by the SPIKE algorithm so far. A
pivoting recursive SPIKE strategy is finally presented as an alternative to
non-pivoting scheme for systems with large condition numbers. All these new
enhancements participate to create a feature complete SPIKE algorithm and a new
black-box SPIKE-OpenMP package that significantly outperforms the performance
and scalability obtained with other state-of-the-art banded solvers.
"
1114,"A Search for Good Pseudo-random Number Generators : Survey and Empirical
  Studies","  In today's world, several applications demand numbers which appear random but
are generated by a background algorithm; that is, pseudo-random numbers. Since
late $19^{th}$ century, researchers have been working on pseudo-random number
generators (PRNGs). Several PRNGs continue to develop, each one demanding to be
better than the previous ones. In this scenario, this paper targets to verify
the claim of so-called good generators and rank the existing generators based
on strong empirical tests in same platforms. To do this, the genre of PRNGs
developed so far has been explored and classified into three groups -- linear
congruential generator based, linear feedback shift register based and cellular
automata based. From each group, well-known generators have been chosen for
empirical testing. Two types of empirical testing has been done on each PRNG --
blind statistical tests with Diehard battery of tests, TestU01 library and NIST
statistical test-suite and graphical tests (lattice test and space-time diagram
test). Finally, the selected $29$ PRNGs are divided into $24$ groups and are
ranked according to their overall performance in all empirical tests.
"
1115,A Review of automatic differentiation and its efficient implementation,"  Derivatives play a critical role in computational statistics, examples being
Bayesian inference using Hamiltonian Monte Carlo sampling and the training of
neural networks. Automatic differentiation is a powerful tool to automate the
calculation of derivatives and is preferable to more traditional methods,
especially when differentiating complex algorithms and mathematical functions.
The implementation of automatic differentiation however requires some care to
insure efficiency. Modern differentiation packages deploy a broad range of
computational techniques to improve applicability, run time, and memory
management. Among these techniques are operation overloading, region based
memory, and expression templates. There also exist several mathematical
techniques which can yield high performance gains when applied to complex
algorithms. For example, semi-analytical derivatives can reduce by orders of
magnitude the runtime required to numerically solve and differentiate an
algebraic equation. Open problems include the extension of current packages to
provide more specialized routines, and efficient methods to perform
higher-order differentiation.
"
1116,"FusionStitching: Deep Fusion and Code Generation for Tensorflow
  Computations on GPUs","  In recent years, there is a surge on machine learning applications in
industry. Many of them are based on popular AI frameworks like Tensorflow,
Torch, Caffe, or MxNet, etc, and are enpowered by accelerator platforms such as
GPUs. One important challenge of running Tensorflow computations on GPUs is the
fine granularity problem, namely, FLOPS of individual ops are far from enough
to fully exploit the computing power of underlying accelerators. The XLA
framework provides a solid foundation to explore this problem further. In this
paper, we propose FusionStitching, a novel, comprehensive Op fusion and code
generation system to stitch computations into large GPU kernels. Experimental
results on four public models and two of our large inhouse applications show
another 55% (geometric mean) reduction of GPU kernel launches, compared to the
XLA fusion baseline. This increases the E2E performance of both of our latency
critical inhouse applications up to 20%.
"
1117,"AMGCL: an Efficient, Flexible, and Extensible Algebraic Multigrid
  Implementation","  The paper presents AMGCL -- an opensource C++ library implementing the
algebraic multigrid method (AMG) for solution of large sparse linear systems of
equations, usually arising from discretization of partial differential
equations on an unstructured grid. The library supports both shared and
distributed memory computation, allows to utilize modern massively parallel
processors via OpenMP, OpenCL, or CUDA technologies, has minimal dependencies,
and is easily extensible. The design principles behind AMGCL are discussed and
it is shown that the code performance is on par with alternative
implementations.
"
1118,"Zeffiro user interface for electromagnetic brain imaging: a GPU
  accelerated FEM tool for forward and inverse computations in Matlab","  This article introduces the Zeffiro interface (ZI) version 2.2 for brain
imaging. ZI aims to provide a simple, accessible and multimodal open source
platform for finite element method (FEM) based and graphics processing unit
(GPU) accelerated forward and inverse computations in the Matlab environment.
It allows one to (1) generate a given multi-compartment head model, (2) to
evaluate a lead field matrix as well as (3) to invert and analyze a given set
of measurements. GPU acceleration is applied in each of the processing stages
(1)-(3). In its current configuration, ZI includes forward solvers for
electro-/magnetoencephalography (EEG) and linearized electrical impedance
tomography (EIT) as well as a set of inverse solvers based on the hierarchical
Bayesian model (HBM). We report the results of EEG and EIT inversion tests
performed with real and synthetic data, respectively, and demonstrate
numerically how the inversion parameters affect the EEG inversion outcome in
HBM. The GPU acceleration was found to be essential in the generation of the FE
mesh and the LF matrix in order to achieve a reasonable computing time. The
code package can be extended in the future based on the directions given in
this article.
"
1119,"Applying the swept rule for solving explicit partial differential
  equations on heterogeneous computing systems","  Applications that exploit the architectural details of high-performance
computing (HPC) systems have become increasingly invaluable in academia and
industry over the past two decades. The most important hardware development of
the last decade in HPC has been the General Purpose Graphics Processing Unit
(GPGPU), a class of massively parallel devices that now contributes the
majority of computational power in the top 500 supercomputers. As these systems
grow, small costs such as latency---due to the fixed cost of memory accesses
and communication---accumulate in a large simulation and become a significant
barrier to performance. The swept time-space decomposition rule is a
communication-avoiding technique for time-stepping stencil update formulas that
attempts to reduce latency costs. This work extends the swept rule by targeting
heterogeneous, CPU/GPU architectures representing current and future HPC
systems. We compare our approach to a naive decomposition scheme with two test
equations using an MPI+CUDA pattern on 40 processes over two nodes containing
one GPU. The swept rule produces a factor of 1.9 to 23 speedup for the heat
equation and a factor of 1.1 to 2.0 speedup for the Euler equations, using the
same processors and work distribution, and with the best possible
configurations. These results show the potential effectiveness of the swept
rule for different equations and numerical schemes on massively parallel
computing systems that incur substantial latency costs.
"
1120,Modeling Deep Learning Accelerator Enabled GPUs,"  The efficacy of deep learning has resulted in its use in a growing number of
applications. The Volta graphics processor unit (GPU) architecture from NVIDIA
introduced a specialized functional unit, the ""tensor core"", that helps meet
the growing demand for higher performance for deep learning. In this paper we
study the design of the tensor cores in NVIDIA's Volta and Turing
architectures. We further propose an architectural model for the tensor cores
in Volta. When implemented a GPU simulator, GPGPU-Sim, our tensor core model
achieves 99.6\% correlation versus an NVIDIA Titan~V GPU in terms of average
instructions per cycle when running tensor core enabled GEMM workloads. We also
describe support added to enable GPGPU-Sim to run CUTLASS, an open-source CUDA
C++ template library providing customizable GEMM templates that utilize tensor
cores.
"
1121,"Practical Sparse Matrices in C++ with Hybrid Storage and Template-Based
  Expression Optimisation","  Despite the importance of sparse matrices in numerous fields of science,
software implementations remain difficult to use for non-expert users,
generally requiring the understanding of underlying details of the chosen
sparse matrix storage format. In addition, to achieve good performance, several
formats may need to be used in one program, requiring explicit selection and
conversion between the formats. This can be both tedious and error-prone,
especially for non-expert users. Motivated by these issues, we present a
user-friendly and open-source sparse matrix class for the C++ language, with a
high-level application programming interface deliberately similar to the widely
used MATLAB language. This facilitates prototyping directly in C++ and aids the
conversion of research code into production environments. The class internally
uses two main approaches to achieve efficient execution: (i) a hybrid storage
framework, which automatically and seamlessly switches between three underlying
storage formats (compressed sparse column, Red-Black tree, coordinate list)
depending on which format is best suited and/or available for specific
operations, and (ii) a template-based meta-programming framework to
automatically detect and optimise execution of common expression patterns.
Empirical evaluations on large sparse matrices with various densities of
non-zero elements demonstrate the advantages of the hybrid storage framework
and the expression optimisation mechanism.
"
1122,Sound Approximation of Programs with Elementary Functions,"  Elementary function calls are a common feature in numerical programs. While
their implementions in library functions are highly optimized, their
computation is nonetheless very expensive compared to plain arithmetic. Full
accuracy is, however, not always needed. Unlike arithmetic, where the
performance difference between for example single and double precision
floating-point arithmetic is relatively small, elementary function calls
provide a much richer tradeoff space between accuracy and efficiency.
Navigating this space is challenging. First, generating approximations of
elementary function calls which are guaranteed to satisfy accuracy error bounds
is highly nontrivial. Second, the performance of such approximations generally
depends on several parameters which are unintuitive to choose manually,
especially for non-experts.
  We present a fully automated approach and tool which approximates elementary
function calls inside small programs while guaranteeing overall user provided
error bounds. Our tool leverages existing techniques for roundoff error
computation and approximation of individual elementary function calls, and
provides automated selection of many parameters. Our experiments show that
significant efficiency improvements are possible in exchange for reduced, but
guaranteed, accuracy.
"
1123,"Efficient Distributed-Memory Parallel Matrix-Vector Multiplication with
  Wide or Tall Unstructured Sparse Matrices","  This paper presents an efficient technique for matrix-vector and
vector-transpose-matrix multiplication in distributed-memory parallel computing
environments, where the matrices are unstructured, sparse, and have a
substantially larger number of columns than rows or vice versa. Our method
allows for parallel I/O, does not require extensive preprocessing, and has the
same communication complexity as matrix-vector multiplies with column or row
partitioning. Our implementation of the method uses MPI. We partition the
matrix by individual nonzero elements, rather than by row or column, and use an
""overlapped"" vector representation that is matched to the matrix. The transpose
multiplies use matrix-specific MPI communicators and reductions that we show
can be set up in an efficient manner. The proposed technique achieves a good
work per processor balance even if some of the columns are dense, while keeping
communication costs relatively low.
"
1124,Towards new solutions for scientific computing: the case of Julia,"  This year marks the consolidation of Julia (https://julialang.org/), a
programming language designed for scientific computing, as the first stable
version (1.0) has been released, in August 2018. Among its main features,
expressiveness and high execution speeds are the most prominent: the
performance of Julia code is similar to statically compiled languages, yet
Julia provides a nice interactive shell and fully supports Jupyter; moreover,
it can transparently call external codes written in C, Fortran, and even Python
and R without the need of wrappers. The usage of Julia in the astronomical
community is growing, and a GitHub organization named JuliaAstro takes care of
coordinating the development of packages. In this paper, we present the
features and shortcomings of this language and discuss its application in
astronomy and astrophysics.
"
1125,A note on solving nonlinear optimization problems in variable precision,"  This short note considers an efficient variant of the trust-region algorithm
with dynamic accuracy proposed Carter (1993) and Conn, Gould and Toint (2000)
as a tool for very high-performance computing, an area where it is critical to
allow multi-precision computations for keeping the energy dissipation under
control. Numerical experiments are presented indicating that the use of the
considered method can bring substantial savings in objective function's and
gradient's evaluation ""energy costs"" by efficiently exploiting multi-precision
computations.
"
1126,Functional Design of Computation Graph,"  Representing the control flow of a computer program as a computation graph
can bring many benefits in a broad variety of domains where performance is
critical. This technique is a core component of most major numerical libraries
(TensorFlow, PyTorch, Theano, MXNet,...) and is successfully used to speed up
and optimise many computationally-intensive tasks. However, different design
choices in each of these libraries lead to noticeable differences in efficiency
and in the way an end user writes efficient code. In this report, we detail the
implementation and features of the computation graph support in OCaml's
numerical library Owl, a recent entry in the world of scientific computing.
"
1127,Disciplined Geometric Programming,"  We introduce log-log convex programs, which are optimization problems with
positive variables that become convex when the variables, objective functions,
and constraint functions are replaced with their logs, which we refer to as a
log-log transformation. This class of problems generalizes traditional
geometric programming and generalized geometric programming, and it includes
interesting problems involving nonnegative matrices. We give examples of
log-log convex functions, some well-known and some less so, and we develop an
analog of disciplined convex programming, which we call disciplined geometric
programming. Disciplined geometric programming is a subclass of log-log convex
programming generated by a composition rule and a set of functions with known
curvature under the log-log transformation. Finally, we describe an
implementation of disciplined geometric programming as a reduction in CVXPY
1.0.
"
1128,"Javelin: A Scalable Implementation for Sparse Incomplete LU
  Factorization","  In this work, we present a new scalable incomplete LU factorization framework
called Javelin to be used as a preconditioner for solving sparse linear systems
with iterative methods. Javelin allows for improved parallel factorization on
shared-memory many-core systems by packaging the coefficient matrix into a
format that allows for high performance sparse matrix-vector multiplication and
sparse triangular solves with minimal overheads. The framework achieves these
goals by using a collection of traditional permutations, point-to-point thread
synchronizations, tasking, and segmented prefix scans in a conventional
compressed sparse row format. Moreover, this framework stresses the importance
of co-designing dependent tasks, such as sparse factorization and triangular
solves, on highly-threaded architectures. Using these changes, traditional
fill-in and drop tolerance methods can be used, while still being able to have
observed speedups of up to ~42x on 68 Intel Knights Landing cores and ~12x on
14 Intel Haswell cores.
"
1129,Probabilistic Inference on Noisy Time Series (PINTS),"  Time series models are ubiquitous in science, arising in any situation where
researchers seek to understand how a system's behaviour changes over time. A
key problem in time series modelling is \emph{inference}; determining
properties of the underlying system based on observed time series. For both
statistical and mechanistic models, inference involves finding parameter
values, or distributions of parameters values, for which model outputs are
consistent with observations. A wide variety of inference techniques are
available and different approaches are suitable for different classes of
problems. This variety presents a challenge for researchers, who may not have
the resources or expertise to implement and experiment with these methods.
PINTS (Probabilistic Inference on Noisy Time Series -
https://github.com/pints-team/pints is an open-source (BSD 3-clause license)
Python library that provides researchers with a broad suite of non-linear
optimisation and sampling methods. It allows users to wrap a model and data in
a transparent and straightforward interface, which can then be used with custom
or pre-defined error measures for optimisation, or with likelihood functions
for Bayesian inference or maximum-likelihood estimation. Derivative-free
optimisation algorithms - which work without harder-to-obtain gradient
information - are included, as well as inference algorithms such as adaptive
Markov chain Monte Carlo and nested sampling which estimate distributions over
parameter values. By making these statistical techniques available in an open
and easy-to-use framework, PINTS brings the power of modern statistical
techniques to a wider scientific audience.
"
1130,Pocket Guide to Solve Inverse Problems with GlobalBioIm,"  GlobalBioIm is an open-source MATLAB library for solving inverse problems.
The library capitalizes on the strong commonalities between forward models to
standardize the resolution of a wide range of imaging inverse problems. Endowed
with an operator-algebra mechanism, GlobalBioIm allows one to easily solve
inverse problems by combining elementary modules in a lego-like fashion. This
user-friendly toolbox gives access to cutting-edge reconstruction algorithms,
while its high modularity makes it easily extensible to new modalities and
novel reconstruction methods. We expect GlobalBioIm to respond to the needs of
imaging scientists looking for reliable and easy-to-use computational tools for
solving their inverse problems. In this paper, we present in detail the
structure and main features of the library. We also illustrate its flexibility
with examples from multichannel deconvolution microscopy.
"
1131,"Efficient and scalable data structures and algorithms for goal-oriented
  adaptivity of space-time FEM codes","  The cost- and memory-efficient numerical simulation of coupled volume-based
multi-physics problems like flow, transport, wave propagation and others
remains a challenging task with finite element method (FEM) approaches.
Goal-oriented space and time adaptive methods derived from the dual weighted
residual (DWR) method appear to be a shiny key technology to generate optimal
space-time meshes to minimise costs. Current implementations for challenging
problems of numerical screening tools including the DWR technology broadly
suffer in their extensibility to other problems, in high memory consumption or
in missing system solver technologies. This work contributes to the efficient
embedding of DWR space-time adaptive methods into numerical screening tools for
challenging problems of physically relevance with a new approach of flexible
data structures and algorithms on them, a modularised and complete
implementation as well as illustrative examples to show the performance and
efficiency.
"
1132,Open source software in quantum computing,"  Open source software is becoming crucial in the design and testing of quantum
algorithms. Many of the tools are backed by major commercial vendors with the
goal to make it easier to develop quantum software: this mirrors how
well-funded open machine learning frameworks enabled the development of complex
models and their execution on equally complex hardware. We review a wide range
of open source software for quantum computing, covering all stages of the
quantum toolchain from quantum hardware interfaces through quantum compilers to
implementations of quantum algorithms, as well as all quantum computing
paradigms, including quantum annealing, and discrete and continuous-variable
gate-model quantum computing. The evaluation of each project covers
characteristics such as documentation, licence, the choice of programming
language, compliance with norms of software engineering, and the culture of the
project. We find that while the diversity of projects is mesmerizing, only a
few attract external developers and even many commercially backed frameworks
have shortcomings in software engineering. Based on these observations, we
highlight the best practices that could foster a more active community around
quantum computing software that welcomes newcomers to the field, but also
ensures high-quality, well-documented code.
"
1133,Sundials/ML: Connecting OCaml to the Sundials Numeric Solvers,"  This paper describes the design and implementation of a comprehensive OCaml
interface to the Sundials library of numeric solvers for ordinary differential
equations, differential algebraic equations, and non-linear equations. The
interface provides a convenient and memory-safe alternative to using Sundials
directly from C and facilitates application development by integrating with
higher-level language features, like garbage-collected memory management,
algebraic data types, and exceptions. Our benchmark results suggest that the
interface overhead is acceptable: the standard examples are rarely twice as
slow in OCaml than in C, and often less than 50% slower. The challenges in
interfacing with Sundials are to efficiently and safely share data structures
between OCaml and C, to support multiple implementations of vector operations
and linear solvers through a common interface, and to manage calls and error
signalling to and from OCaml. We explain how we overcame these difficulties
using a combination of standard techniques such as phantom types and
polymorphic variants, and carefully crafted data representations.
"
1134,duneuro - A software toolbox for forward modeling in neuroscience,"  This paper describes duneuro, a software toolbox for forward modeling in
neuroscience. Its purpose is to provide extendible and easy-to-use interfaces
and enable a closer integration into existing analysis pipelines. It provides
implementations of fitted and unfitted finite element methods and makes use of
the Dune framework. The forward problems consist of the electroencephalography
(EEG) and magnetoencephalography (MEG) forward problems. For the incorporation
into existing analysis pipelines, Python and Matlab interfaces are provided.
The practical use is demonstrated on a source analysis example of evoked
potentials.
"
1135,ODE Test Problems: a MATLAB suite of initial value problems,"  ODE Test Problems (OTP) is an object-oriented MATLAB package offering a broad
range of initial value problems which can be used to test numerical methods
such as time integration methods and data assimilation (DA) methods. It
includes problems that are linear and nonlinear, homogeneous and
nonhomogeneous, autonomous and nonautonomous, scalar and high-dimensional,
stiff and nonstiff, and chaotic and nonchaotic. Many are real-world problems
from fields such as chemistry, astrophysics, meteorology, and electrical
engineering. OTP also supports partitioned ODEs for testing IMEX methods,
multirate methods, and other multimethods. Functions for plotting solutions and
creating movies are available for all problems, and exact solutions are
provided when available. OTP is desgined for ease of use-meaning that working
with and modifying problems is simple and intuitive.
"
1136,Faster arbitrary-precision dot product and matrix multiplication,"  We present algorithms for real and complex dot product and matrix
multiplication in arbitrary-precision floating-point and ball arithmetic. A
low-overhead dot product is implemented on the level of GMP limb arrays; it is
about twice as fast as previous code in MPFR and Arb at precision up to several
hundred bits. Up to 128 bits, it is 3-4 times as fast, costing 20-30 cycles per
term for floating-point evaluation and 40-50 cycles per term for balls. We
handle large matrix multiplications even more efficiently via blocks of scaled
integer matrices. The new methods are implemented in Arb and significantly
speed up polynomial operations and linear algebra.
"
1137,"Supporting mixed-datatype matrix multiplication within the BLIS
  framework","  We approach the problem of implementing mixed-datatype support within the
general matrix multiplication (GEMM) operation of the BLIS framework, whereby
each matrix operand A, B, and C may be stored as single- or double-precision
real or complex values. Another factor of complexity, whereby the computation
is allowed to take place in a precision different from the storage precisions
of either A or B, is also included in the discussion. We first break the
problem into mostly orthogonal dimensions, considering the mixing of domains
separately from mixing precisions. Support for all combinations of matrix
operands stored in either the real or complex domain is mapped out by
enumerating the cases and describing an implementation approach for each.
Supporting all combinations of storage and computation precisions is handled by
typecasting the matrices at key stages of the computation---during packing
and/or accumulation, as needed. Several optional optimizations are also
documented. Performance results gathered on a 56-core Marvell ThunderX2 and a
52-core Intel Xeon Platinum demonstrate that high performance is mostly
preserved, with modest slowdowns incurred from unavoidable typecast
instructions. The mixed-datatype implementation confirms that combinatoric
intractability is avoided, with the framework relying on only two assembly
microkernels to implement 128 datatype combinations.
"
1138,"TuckerMPI: A Parallel C++/MPI Software Package for Large-scale Data
  Compression via the Tucker Tensor Decomposition","  Our goal is compression of massive-scale grid-structured data, such as the
multi-terabyte output of a high-fidelity computational simulation. For such
data sets, we have developed a new software package called TuckerMPI, a
parallel C++/MPI software package for compressing distributed data. The
approach is based on treating the data as a tensor, i.e., a multidimensional
array, and computing its truncated Tucker decomposition, a higher-order
analogue to the truncated singular value decomposition of a matrix. The result
is a low-rank approximation of the original tensor-structured data. Compression
efficiency is achieved by detecting latent global structure within the data,
which we contrast to most compression methods that are focused on local
structure. In this work, we describe TuckerMPI, our implementation of the
truncated Tucker decomposition, including details of the data distribution and
in-memory layouts, the parallel and serial implementations of the key kernels,
and analysis of the storage, communication, and computational costs. We test
the software on 4.5 terabyte and 6.7 terabyte data sets distributed across 100s
of nodes (1000s of MPI processes), achieving compression rates between
100-200,000$\times$ which equates to 99-99.999% compression (depending on the
desired accuracy) in substantially less time than it would take to even read
the same dataset from a parallel filesystem. Moreover, we show that our method
also allows for reconstruction of partial or down-sampled data on a single
node, without a parallel computer so long as the reconstructed portion is small
enough to fit on a single machine, e.g., in the instance of
reconstructing/visualizing a single down-sampled time step or computing summary
statistics.
"
1139,"Distributed-memory parallelization of the aggregated unfitted finite
  element method","  The aggregated unfitted finite element method (AgFEM) is a methodology
recently introduced in order to address conditioning and stability problems
associated with embedded, unfitted, or extended finite element methods. The
method is based on removal of basis functions associated with badly cut cells
by introducing carefully designed constraints, which results in well-posed
systems of linear algebraic equations, while preserving the optimal
approximation order of the underlying finite element spaces. The specific goal
of this work is to present the implementation and performance of the method on
distributed-memory platforms aiming at the efficient solution of large-scale
problems. In particular, we show that, by considering AgFEM, the resulting
systems of linear algebraic equations can be effectively solved using standard
algebraic multigrid preconditioners. This is in contrast with previous works
that consider highly customized preconditioners in order to allow one the usage
of iterative solvers in combination with unfitted techniques. Another novelty
with respect to the methods available in the literature is the problem sizes
that can be handled with the proposed approach. While most of previous
references discussing linear solvers for unfitted methods are based on serial
non-scalable algorithms, we propose a parallel distributed-memory method able
to efficiently solve problems at large scales. This is demonstrated by means of
a weak scaling test defined on complex 3D domains up to 300M degrees of freedom
and one billion cells on 16K CPU cores in the Marenostrum-IV platform. The
parallel implementation of the AgFEM method is available in the large-scale
finite element package FEMPAR.
"
1140,"Hierarchical Matrix Operations on GPUs: Matrix-Vector Multiplication and
  Compression","  Hierarchical matrices are space and time efficient representations of dense
matrices that exploit the low rank structure of matrix blocks at different
levels of granularity. The hierarchically low rank block partitioning produces
representations that can be stored and operated on in near-linear complexity
instead of the usual polynomial complexity of dense matrices. In this paper, we
present high performance implementations of matrix vector multiplication and
compression operations for the $\mathcal{H}^2$ variant of hierarchical matrices
on GPUs. This variant exploits, in addition to the hierarchical block
partitioning, hierarchical bases for the block representations and results in a
scheme that requires only $O(n)$ storage and $O(n)$ complexity for the mat-vec
and compression kernels. These two operations are at the core of algebraic
operations for hierarchical matrices, the mat-vec being a ubiquitous operation
in numerical algorithms while compression/recompression represents a key
building block for other algebraic operations, which require periodic
recompression during execution. The difficulties in developing efficient GPU
algorithms come primarily from the irregular tree data structures that underlie
the hierarchical representations, and the key to performance is to recast the
computations on flattened trees in ways that allow batched linear algebra
operations to be performed. This requires marshaling the irregularly laid out
data in a way that allows them to be used by the batched routines. Marshaling
operations only involve pointer arithmetic with no data movement and as a
result have minimal overhead. Our numerical results on covariance matrices from
2D and 3D problems from spatial statistics show the high efficiency our
routines achieve---over 550GB/s for the bandwidth-limited mat-vec and over
850GFLOPS/s in sustained performance for the compression on the P100 Pascal
GPU.
"
1141,"Faster Remainder by Direct Computation: Applications to Compilers and
  Software Libraries","  On common processors, integer multiplication is many times faster than
integer division. Dividing a numerator n by a divisor d is mathematically
equivalent to multiplication by the inverse of the divisor (n / d = n x 1/d).
If the divisor is known in advance---or if repeated integer divisions will be
performed with the same divisor---it can be beneficial to substitute a less
costly multiplication for an expensive division.
  Currently, the remainder of the division by a constant is computed from the
quotient by a multiplication and a subtraction. But if just the remainder is
desired and the quotient is unneeded, this may be suboptimal. We present a
generally applicable algorithm to compute the remainder more directly.
Specifically, we use the fractional portion of the product of the numerator and
the inverse of the divisor. On this basis, we also present a new, simpler
divisibility algorithm to detect nonzero remainders.
  We also derive new tight bounds on the precision required when representing
the inverse of the divisor. Furthermore, we present simple C implementations
that beat the optimized code produced by state-of-art C compilers on recent x64
processors (e.g., Intel Skylake and AMD Ryzen), sometimes by more than 25%. On
all tested platforms including 64-bit ARM and POWER8, our divisibility-test
functions are faster than state-of-the-art Granlund-Montgomery
divisibility-test functions, sometimes by more than 50%.
"
1142,Fast Strassen-based $A^t A$ Parallel Multiplication,"  Matrix multiplication $A^t A$ appears as intermediate operation during the
solution of a wide set of problems. In this paper, we propose a new
cache-oblivious algorithm for the $A^t A$ multiplication. Our algorithm,
A$\scriptstyle \mathsf{T}$A, calls classical Strassen's algorithm as
sub-routine, decreasing the computational cost %(expressed in number of
performed products) of the conventional $A^t A$ multiplication to
$\frac{2}{7}n^{\log_2 7}$. It works for generic rectangular matrices and
exploits the peculiar symmetry of the resulting product matrix for sparing
memory. We used the MPI paradigm to implement A$\scriptstyle \mathsf{T}$A in
parallel, and we tested its performances on a small subset of nodes of the
Galileo cluster. Experiments highlight good scalability and speed-up, also
thanks to minimal number of exchanged messages in the designed communication
system. Parallel overhead and inherently sequential time fraction are
negligible in the tested configurations.
"
1143,The BLAS API of BLASFEO: optimizing performance for small matrices,"  BLASFEO is a dense linear algebra library providing high-performance
implementations of BLAS- and LAPACK-like routines for use in embedded
optimization and other applications targeting relatively small matrices.
BLASFEO defines an API which uses a packed matrix format as its native format.
This format is analogous to the internal memory buffers of optimized BLAS, but
it is exposed to the user and it removes the packing cost from the routine
call. For matrices fitting in cache, BLASFEO outperforms optimized BLAS
implementations, both open-source and proprietary. This paper investigates the
addition of a standard BLAS API to the BLASFEO framework, and proposes an
implementation switching between two or more algorithms optimized for different
matrix sizes. Thanks to the modular assembly framework in BLASFEO, tailored
linear algebra kernels with mixed column- and panel-major arguments are easily
developed. This BLAS API has lower performance than the BLASFEO API, but it
nonetheless outperforms optimized BLAS and especially LAPACK libraries for
matrices fitting in cache. Therefore, it can boost a wide range of
applications, where standard BLAS and LAPACK libraries are employed and the
matrix size is moderate. In particular, this paper investigates the benefits in
scientific programming languages such as Octave, SciPy and Julia.
"
1144,"Acceleration of expensive computations in Bayesian statistics using
  vector operations","  Many applications in Bayesian statistics are extremely computationally
intensive. However, they are also often inherently parallel, making them prime
targets for modern massively parallel central processing unit (CPU)
architectures. While the use of multi-core and distributed computing is widely
applied in the Bayesian community, very little attention has been given to
fine-grain parallelisation using single instruction multiple data (SIMD)
operations that are available on most modern commodity CPUs. Rather, most
fine-grain tuning in the literature has centred around general purpose graphics
processing units (GPGPUs). Since the effective utilisation of GPGPUs typically
requires specialised programming languages, such technologies are not ideal for
the wider Bayesian community. In this work, we practically demonstrate, using
standard programming libraries, the utility of the SIMD approach for several
topical Bayesian applications. In particular, we consider sampling of the prior
predictive distribution for approximate Bayesian computation (ABC), the
computation of Bayesian $p$-values for testing prior weak informativeness, and
inference on a computationally challenging econometrics model. Through minor
code alterations, we show that SIMD operations can improve the floating point
arithmetic performance resulting in up to $6\times$ improvement in the overall
serial algorithm performance. Furthermore $4$-way parallel versions can lead to
almost $19\times$ improvement over a na\""{i}ve serial implementation. We
illustrate the potential of SIMD operations for accelerating Bayesian
computations and provide the reader with essential implementation techniques
required to exploit modern massively parallel processing environments using
standard software development tools.
"
1145,"Algorithms and software for projections onto intersections of convex and
  non-convex sets with applications to inverse problems","  We propose algorithms and software for computing projections onto the
intersection of multiple convex and non-convex constraint sets. The software
package, called SetIntersectionProjection, is intended for the regularization
of inverse problems in physical parameter estimation and image processing. The
primary design criterion is working with multiple sets, which allows us to
solve inverse problems with multiple pieces of prior knowledge. Our algorithms
outperform the well known Dykstra's algorithm when individual sets are not easy
to project onto because we exploit similarities between constraint sets. Other
design choices that make the software fast and practical to use, include
recently developed automatic selection methods for auxiliary algorithm
parameters, fine and coarse grained parallelism, and a multilevel acceleration
scheme. We provide implementation details and examples that show how the
software can be used to regularize inverse problems. Results show that we
benefit from working with all available prior information and are not limited
to one or two regularizers because of algorithmic, computational, or
hyper-parameter selection issues.
"
1146,"PBBFMM3D: a parallel black-box algorithm for kernel matrix-vector
  multiplication","  We introduce \texttt{PBBFMM3D}, a parallel black-box method for computing
kernel matrix-vector multiplication, where the underlying kernel is a
non-oscillatory function in three dimensions. While a naive method requires
$\O(N^2)$ computation, \texttt{PBBFMM3D} reduces the cost to $\O(N)$ work. In
particular, our algorithm requires only the ability to evaluate the kernel
function, and is thus a black-box method. To further accelerate the computation
on shared-memory machines, a parallel algorithm is presented and implemented
using \verb|OpenMP|, which achieved at most $19\times$ speedup on 32 cores in
our numerical experiments. A real-world application in geostatistics is also
presented, where \texttt{PBBFMM3D} is used in computing the truncated
eigen-decomposition (a.k.a., principle component analysis) of a covariance
matrix (a.k.a., graph Laplacian).
"
1147,"Performance Analysis of Effective Symbolic Methods for Solving Band
  Matrix SLAEs","  This paper presents an experimental performance study of implementations of
three symbolic algorithms for solving band matrix systems of linear algebraic
equations with heptadiagonal, pentadiagonal, and tridiagonal coefficient
matrices. The only assumption on the coefficient matrix in order for the
algorithms to be stable is nonsingularity. These algorithms are implemented
using the GiNaC library of C++ and the SymPy library of Python, considering
five different data storing classes. Performance analysis of the
implementations is done using the high-performance computing (HPC) platforms
""HybriLIT"" and ""Avitohol"". The experimental setup and the results from the
conducted computations on the individual computer systems are presented and
discussed. An analysis of the three algorithms is performed.
"
1148,"Takin: An open-source software for experiment planning, visualisation,
  and data analysis","  Due to the instrument's non-trivial resolution function, measurements on
triple-axis spectrometers require extra care from the experimenter in order to
obtain optimal results and to avoid unwanted spurious artefacts. We present a
free and open-source software system that aims to ease many of the tasks
encountered during the planning phase, in the execution and in data treatment
of experiments performed on neutron triple-axis spectrometers. The software is
currently in use and has been successfully tested at the MLZ, but can be
configured to work with other triple-axis instruments and instrument control
systems.
"
1149,"Auto-Vectorizing TensorFlow Graphs: Jacobians, Auto-Batching And Beyond","  We propose a static loop vectorization optimization on top of high level
dataflow IR used by frameworks like TensorFlow. A new statically vectorized
parallel-for abstraction is provided on top of TensorFlow, and used for
applications ranging from auto-batching and per-example gradients, to jacobian
computation, optimized map functions and input pipeline optimization. We report
huge speedups compared to both loop based implementations, as well as run-time
batching adopted by the DyNet framework.
"
1150,GNA: new framework for statistical data analysis,"  We report on the status of GNA --- a new framework for fitting large-scale
physical models. GNA utilizes the data flow concept within which a model is
represented by a directed acyclic graph. Each node is an operation on an array
(matrix multiplication, derivative or cross section calculation, etc). The
framework enables the user to create flexible and efficient large-scale lazily
evaluated models, handle large numbers of parameters, propagate parameters'
uncertainties while taking into account possible correlations between them, fit
models, and perform statistical analysis. The main goal of the paper is to give
an overview of the main concepts and methods as well as reasons behind their
design. Detailed technical information is to be published in further works.
"
1151,"On the Efficacy and High-Performance Implementation of Quaternion Matrix
  Multiplication","  Quaternion symmetry is ubiquitous in the physical sciences. As such, much
work has been afforded over the years to the development of efficient schemes
to exploit this symmetry using real and complex linear algebra. Recent years
have also seen many advances in the formal theoretical development of
explicitly quaternion linear algebra with promising applications in image
processing and machine learning. Despite these advances, there do not currently
exist optimized software implementations of quaternion linear algebra. The
leverage of optimized linear algebra software is crucial in the achievement of
high levels of performance on modern computing architectures, and thus provides
a central tool in the development of high-performance scientific software. In
this work, a case will be made for the efficacy of high-performance quaternion
linear algebra software for appropriate problems. In this pursuit, an optimized
software implementation of quaternion matrix multiplication will be presented
and will be shown to outperform a vendor tuned implementation for the analogous
complex matrix operation. The results of this work pave the path for further
development of high-performance quaternion linear algebra software which will
improve the performance of the next generation of applicable scientific
applications.
"
1152,A study of vectorization for matrix-free finite element methods,"  Vectorization is increasingly important to achieve high performance on modern
hardware with SIMD instructions. Assembly of matrices and vectors in the finite
element method, which is characterized by iterating a local assembly kernel
over unstructured meshes, poses difficulties to effective vectorization.
Maintaining a user-friendly high-level interface with a suitable degree of
abstraction while generating efficient, vectorized code for the finite element
method is a challenge for numerical software systems and libraries. In this
work, we study cross-element vectorization in the finite element framework
Firedrake via code transformation and demonstrate the efficacy of such an
approach by evaluating a wide range of matrix-free operators spanning different
polynomial degrees and discretizations on two recent CPUs using three
mainstream compilers. Our experiments show that our approaches for
cross-element vectorization achieve 30\% of theoretical peak performance for
many examples of practical significance, and exceed 50\% for cases with high
arithmetic intensities, with consistent speed-up over (intra-element)
vectorization restricted to the local assembly kernels.
"
1153,pyLLE: a Fast and User Friendly Lugiato-Lefever Equation Solver,"  We present the development of pyLLE, a freely accessible and cross-platform
Lugiato-Lefever equation solver programmed in Python and Julia and optimized
for the simulation of microresonator frequency combs. Examples illustrating its
operation, the simplicity of use, and performance against other programming
language are presented. The documentation of the software can be found at
https://gregmoille.github.io/pyLLE/
"
1154,"Yet Another Tensor Toolbox for discontinuous Galerkin methods and other
  applications","  The numerical solution of partial differential equations is at the heart of
many grand challenges in supercomputing. Solvers based on high-order
discontinuous Galerkin (DG) discretisation have been shown to scale on large
supercomputers with excellent performance and efficiency, if the implementation
exploits all levels of parallelism and is tailored to the specific
architecture. However, every year new supercomputers emerge and the list of
hardware-specific considerations grows, simultaneously with the list of desired
features in a DG code. Thus we believe that a sustainable DG code needs an
abstraction layer to implement the numerical scheme in a suitable language. We
explore the possibility to abstract the numerical scheme as small tensor
operations, describe them in a domain-specific language (DSL) resembling the
Einstein notation, and to map them to existing code generators which generate
small matrix matrix multiplication routines. The compiler for our DSL
implements classic optimisations that are used for large tensor contractions,
and we present novel optimisation techniques such as equivalent sparsity
patterns and optimal index permutations for temporary tensors. Our application
examples, which include the earthquake simulation software SeisSol, show that
the generated kernels achieve over 50 % peak performance while the DSL
considerably simplifies the implementation.
"
1155,Computing huge Groebner basis like cyclic10 over $\Q$ with Giac,"  We present a short description on how to fine-tune the modular algorithm
implemented in the Giac computer algebra system to reconstruct huge Groebner
basis over $\Q$.The classical cyclic10 benchmark will serve as example.
"
1156,"COFFEE -- An MPI-parallelized Python package for the numerical evolution
  of differential equations","  COFFEE (ConFormal Field Equation Evolver) is a Python package primarily
developed to numerically evolve systems of partial differential equations over
time using the method of lines. It includes a variety of time integrators and
finite differencing stencils with the summation-by-parts property, as well as
pseudo-spectral functionality for angular derivatives of spin-weighted
functions. Some additional capabilities include being MPI-parallelisable on a
variety of different geometries, HDF data output and post processing scripts to
visualize data, and an actions class that allows users to create code for
analysis after each timestep.
"
1157,"A Flexible, Parallel, Adaptive Geometric Multigrid method for FEM","  We present data structures and implementation details of a geometric
multigrid method on adaptively refined meshes for massively parallel
computations. The method uses local smoothing on the refined part of the mesh.
Partitioning is achieved by using a space filling curve for the leaf mesh and
distributing ancestors in the hierarchy based on the leaves. We present a model
of the efficiency of mesh hierarchy distribution and compare its predictions to
runtime measurements. The algorithm is implemented as part of the deal.II
finite element library and as such available to the public.
"
1158,"Cross-Platform Performance Portability Using Highly Parametrized SYCL
  Kernels","  Over recent years heterogeneous systems have become more prevalent across HPC
systems, with over 100 supercomputers in the TOP500 incorporating GPUs or other
accelerators. These hardware platforms have different performance
characteristics and optimization requirements. In order to make the most of
multiple accelerators a developer has to provide implementations of their
algorithms tuned for each device. Hardware vendors provide libraries targeting
their devices specifically, which provide good performance but frequently have
different API designs, hampering portability.
  The SYCL programming model allows users to write heterogeneous programs using
completely standard C++, and so developers have access to the power of C++
templates when developing compute kernels. In this paper we show that by
writing highly parameterized kernels for matrix multiplies and convolutions we
achieve performance competitive with vendor implementations across different
architectures. Furthermore, tuning for new devices amounts to choosing the
combinations of kernel parameters that perform best on the hardware.
"
1159,"Tea: A High-level Language and Runtime System for Automating Statistical
  Analysis","  Though statistical analyses are centered on research questions and
hypotheses, current statistical analysis tools are not. Users must first
translate their hypotheses into specific statistical tests and then perform API
calls with functions and parameters. To do so accurately requires that users
have statistical expertise. To lower this barrier to valid, replicable
statistical analysis, we introduce Tea, a high-level declarative language and
runtime system. In Tea, users express their study design, any parametric
assumptions, and their hypotheses. Tea compiles these high-level specifications
into a constraint satisfaction problem that determines the set of valid
statistical tests, and then executes them to test the hypothesis. We evaluate
Tea using a suite of statistical analyses drawn from popular tutorials. We show
that Tea generally matches the choices of experts while automatically switching
to non-parametric tests when parametric assumptions are not met. We simulate
the effect of mistakes made by non-expert users and show that Tea automatically
avoids both false negatives and false positives that could be produced by the
application of incorrect statistical tests.
"
1160,The MOMMS Family of Matrix Multiplication Algorithms,"  As the ratio between the rate of computation and rate with which data can be
retrieved from various layers of memory continues to deteriorate, a question
arises: Will the current best algorithms for computing matrix-matrix
multiplication on future CPUs continue to be (near) optimal? This paper
provides compelling analytical and empirical evidence that the answer is ""no"".
The analytical results guide us to a new family of algorithms of which the
current state-of-the-art ""Goto's algorithm"" is but one member. The empirical
results, on architectures that were custom built to reduce the amount of
bandwidth to main memory, show that under different circumstances, different
and particular members of the family become more superior. Thus, this family
will likely start playing a prominent role going forward.
"
1161,"Reducing Communication in Algebraic Multigrid with Multi-step Node Aware
  Communication","  Algebraic multigrid (AMG) is often viewed as a scalable $\mathcal{O}(n)$
solver for sparse linear systems. Yet, parallel AMG lacks scalability due to
increasingly large costs associated with communication, both in the initial
construction of a multigrid hierarchy as well as the iterative solve phase.
This work introduces a parallel implementation of AMG to reduce the cost of
communication, yielding an increase in scalability. Standard inter-process
communication consists of sending data regardless of the send and receive
process locations. Performance tests show notable differences in the cost of
intra- and inter-node communication, motivating a restructuring of
communication. In this case, the communication schedule takes advantage of the
less costly intra-node communication, reducing both the number and size of
inter-node messages. Node-centric communication extends to the range of
components in both the setup and solve phase of AMG, yielding an increase in
the weak and strong scalability of the entire method.
"
1162,"Leveraging the bfloat16 Artificial Intelligence Datatype For
  Higher-Precision Computations","  In recent years fused-multiply-add (FMA) units with lower-precision
multiplications and higher-precision accumulation have proven useful in machine
learning/artificial intelligence applications, most notably in training deep
neural networks due to their extreme computational intensity. Compared to
classical IEEE-754 32 bit (FP32) and 64 bit (FP64) arithmetic, these reduced
precision arithmetic can naturally be sped up disproportional to their
shortened width. The common strategy of all major hardware vendors is to
aggressively further enhance their performance disproportionately. One
particular FMA operation that multiplies two BF16 numbers while accumulating in
FP32 has been found useful in deep learning, where BF16 is the 16-bit floating
point datatype with IEEE FP32 numerical range but 8 significant bits of
precision. In this paper, we examine the use this FMA unit to implement
higher-precision matrix routines in terms of potential performance gain and
implications on accuracy. We demonstrate how a decomposition into multiple
smaller datatypes can be used to assemble a high-precision result, leveraging
the higher precision accumulation of the FMA unit. We first demonstrate that
computations of vector inner products and by natural extension, matrix-matrix
products can be achieved by decomposing FP32 numbers in several BF16 numbers
followed by appropriate computations that can accommodate the dynamic range and
preserve accuracy compared to standard FP32 computations, while projecting up
to 5.2x speed-up. Furthermore, we examine solution of linear equations
formulated in the residual form that allows for iterative refinement. We
demonstrate that the solution obtained to be comparable to those offered by
FP64 under a large range of linear system condition numbers.
"
1163,"Towards whole program generation of quadrature-free discontinuous
  Galerkin methods for the shallow water equations","  The shallow water equations (SWE) are a commonly used model to study
tsunamis, tides, and coastal ocean circulation. However, there exist various
approaches to discretize and solve them efficiently. Which of them is best for
a certain scenario is often not known and, in addition, depends heavily on the
used HPC platform. From a simulation software perspective, this places a
premium on the ability to adapt easily to different numerical methods and
hardware architectures. One solution to this problem is to apply code
generation techniques and to express methods and specific hardware-dependent
implementations on different levels of abstraction. This allows for a
separation of concerns and makes it possible, e.g., to exchange the
discretization scheme without having to rewrite all low-level optimized
routines manually. In this paper, we show how code for an advanced
quadrature-free discontinuous Galerkin (DG) discretized shallow water equation
solver can be generated. Here, we follow the multi-layered approach from the
ExaStencils project that starts from the continuous problem formulation, moves
to the discrete scheme, spells out the numerical algorithms, and, finally, maps
to a representation that can be transformed to a distributed memory parallel
implementation by our in-house Scala-based source-to-source compiler. Our
contributions include: A new quadrature-free discontinuous Galerkin
formulation, an extension of the class of supported computational grids, and an
extension of our toolchain allowing to evaluate discrete integrals stemming
from the DG discretization implemented in Python. As first results we present
the whole toolchain and also demonstrate the convergence of our method for
higher order DG discretizations.
"
1164,A Flexible Framework for Parallel Multi-Dimensional DFTs,"  Multi-dimensional discrete Fourier transforms (DFT) are typically decomposed
into multiple 1D transforms. Hence, parallel implementations of any
multi-dimensional DFT focus on parallelizing within or across the 1D DFT.
Existing DFT packages exploit the inherent parallelism across the 1D DFTs and
offer rigid frameworks, that cannot be extended to incorporate both forms of
parallelism and various data layouts to enable some of the parallelism.
However, in the era of exascale, where systems have thousand of nodes and
intricate network topologies, flexibility and parallel efficiency are key
aspects all multi-dimensional DFT frameworks need to have in order to map and
scale the computation appropriately. In this work, we present a flexible
framework, built on the Redistribution Operations and Tensor Expressions (ROTE)
framework, that facilitates the development of a family of parallel
multi-dimensional DFT algorithms by 1) unifying the two parallelization schemes
within a single framework, 2) exploiting the two different parallelization
schemes to different degrees and 3) using different data layouts to distribute
the data across the compute nodes. We demonstrate the need of a versatile
framework and thus a need for a family of parallel multi-dimensional DFT
algorithms on the K-Computer, where we show almost linear strong scaling
results for problem sizes of 1024^3 on 32k compute nodes.
"
1165,"Big Math and the One-Brain Barrier A Position Paper and Architecture
  Proposal","  Over the last decades, a class of important mathematical results have
required an ever increasing amount of human effort to carry out. For some, the
help of computers is now indispensable. We analyze the implications of this
trend towards ""big mathematics"", its relation to human cognition, and how
machine support for big math can be organized. The central contribution of this
position paper is an information model for ""doing mathematics"", which posits
that humans very efficiently integrate four aspects: inference, computation,
tabulation, and narration around a well-organized core of mathematical
knowledge. The challenge for mathematical software systems is that these four
aspects need to be integrated as well. We briefly survey the state of the art.
"
1166,"$\mathtt{bimEX}$: A Mathematica package for exact computations in $3+1$
  bimetric relativity","  We present $\mathtt{bimEX}$, a Mathematica package for exact computations in
3$+$1 bimetric relativity. It is based on the $\mathtt{xAct}$ bundle, which can
handle computations involving both abstract tensors and their components. In
this communication, we refer to the latter case as concrete computations. The
package consists of two main parts. The first part involves the abstract
tensors, and focuses on how to deal with multiple metrics in $\mathtt{xAct}$.
The second part takes an ansatz for the primary variables in a chart as the
input, and returns the covariant BSSN bimetric equations in components in that
chart. Several functions are implemented to make this process as fast and
user-friendly as possible. The package has been used and tested extensively in
spherical symmetry and was the workhorse in obtaining the bimetric covariant
BSSN equations and reproducing the bimetric 3$+$1 equations in the spherical
polar chart.
"
1167,"Stochastic rounding and reduced-precision fixed-point arithmetic for
  solving neural ordinary differential equations","  Although double-precision floating-point arithmetic currently dominates
high-performance computing, there is increasing interest in smaller and simpler
arithmetic types. The main reasons are potential improvements in energy
efficiency and memory footprint and bandwidth. However, simply switching to
lower-precision types typically results in increased numerical errors. We
investigate approaches to improving the accuracy of reduced-precision
fixed-point arithmetic types, using examples in an important domain for
numerical computation in neuroscience: the solution of Ordinary Differential
Equations (ODEs). The Izhikevich neuron model is used to demonstrate that
rounding has an important role in producing accurate spike timings from
explicit ODE solution algorithms. In particular, fixed-point arithmetic with
stochastic rounding consistently results in smaller errors compared to single
precision floating-point and fixed-point arithmetic with round-to-nearest
across a range of neuron behaviours and ODE solvers. A computationally much
cheaper alternative is also investigated, inspired by the concept of dither
that is a widely understood mechanism for providing resolution below the least
significant bit (LSB) in digital signal processing. These results will have
implications for the solution of ODEs in other subject areas, and should also
be directly relevant to the huge range of practical problems that are
represented by Partial Differential Equations (PDEs).
"
1168,Softmax Optimizations for Intel Xeon Processor-based Platforms,"  Softmax is popular normalization method used in machine learning. Deep
learning solutions like Transformer or BERT use the softmax function
intensively, so it is worthwhile to optimize its performance. This article
presents our methodology of optimization and its results applied to softmax. By
presenting this methodology, we hope to increase an interest in deep learning
optimizations for CPUs. We believe that the optimization process presented here
could be transferred to other deep learning frameworks such as TensorFlow or
PyTorch.
"
1169,"A new object-oriented framework for solving multiphysics problems via
  combination of different numerical methods","  Many interesting phenomena are characterized by the complex interaction of
different physical processes, each often best modeled numerically via a
specific approach. In this paper, we present the design and implementation of
an object-oriented framework for performing multiphysics simulations that
allows for the monolithic coupling of different numerical schemes. In contrast,
most of the currently available simulation tools are tailored towards a
specific numerical model, so that one must resort to coupling different codes
externally based on operator splitting. The current framework has been
developed following the C++11 standard, and its main aim is to provide an
environment that affords enough flexibility for developers to implement complex
models while at the same time giving end users a maximum amount of control over
finer details of the simulation without having to write additional code. The
main challenges towards realizing these objectives are discussed in the paper,
together with the manner in which they are addressed. Along with core objects
representing the framework skeleton, we present the various polymorphic classes
that may be utilized by developers to implement new formulations, material
models and solution algorithms. The code architecture is designed to allow
achievement of the aforementioned functionalities with a minimum level of
inheritance in order to improve the learning curve for programmers who are not
acquainted with the software. Key capabilities of the framework are
demonstrated via the solution of numerical examples dealing on composite
torsion, Biot poroelasticity (featuring a combined finite element-finite volume
formulation), and brittle crack propagation using a phase-field approach.
"
1170,Disciplined Quasiconvex Programming,"  We present a composition rule involving quasiconvex functions that
generalizes the classical composition rule for convex functions. This rule
complements well-known rules for the curvature of quasiconvex functions under
increasing functions and pointwise maximums. We refer to the class of
optimization problems generated by these rules, along with a base set of
quasiconvex and quasiconcave functions, as disciplined quasiconvex programs.
Disciplined quasiconvex programming generalizes disciplined convex programming,
the class of optimization problems targeted by most modern domain-specific
languages for convex optimization. We describe an implementation of disciplined
quasiconvex programming that makes it possible to specify and solve quasiconvex
programs in CVXPY 1.0.
"
1171,"Matlab vs. OpenCV: A Comparative Study of Different Machine Learning
  Algorithms","  Scientific Computing relies on executing computer algorithms coded in some
programming languages. Given a particular available hardware, algorithms speed
is a crucial factor. There are many scientific computing environments used to
code such algorithms. Matlab is one of the most tremendously successful and
widespread scientific computing environments that is rich of toolboxes,
libraries, and data visualization tools. OpenCV is a (C++)-based library
written primarily for Computer Vision and its related areas. This paper
presents a comparative study using 20 different real datasets to compare the
speed of Matlab and OpenCV for some Machine Learning algorithms. Although
Matlab is more convenient in developing and data presentation, OpenCV is much
faster in execution, where the speed ratio reaches more than 80 in some cases.
The best of two worlds can be achieved by exploring using Matlab or similar
environments to select the most successful algorithm; then, implementing the
selected algorithm using OpenCV or similar environments to gain a speed factor.
"
1172,"An optimizing multi-platform source-to-source compiler framework for the
  NEURON MODeling Language","  Domain-specific languages (DSLs) play an increasingly important role in the
generation of high performing software. They allow the user to exploit specific
knowledge encoded in the constructs for the generation of code adapted to a
particular hardware architecture; at the same time, they make it easier to
generate optimized code for a multitude of platforms as the transformation has
to be encoded only once. Here, we describe a new code generation framework
(NMODL) for an existing DSL in the NEURON framework, a widely used software for
massively parallel simulation of biophysically detailed brain tissue models.
Existing NMODL DSL transpilers lack either essential features to generate
optimized code or capability to parse the diversity of existing models in the
user community. Our NMODL framework has been tested against a large number of
previously published user models and offers high-level domain-specific
optimizations and symbolic algebraic simplifications before target code
generation. Furthermore, rich analysis tools are provided allowing the
scientist to introspect models. NMODL implements multiple SIMD and SPMD targets
optimized for modern hardware. Benchmarks were performed on Intel Skylake,
Intel KNL and AMD Naples platforms. When comparing NMODL-generated kernels with
NEURON we observe a speedup of up to 20x, resulting into overall speedups of
two different production simulations by $\sim$10x. When compared to a
previously published SIMD optimized version that heavily relied on
auto-vectorization by the compiler still a speedup of up to $\sim$2x is
observed.
"
1173,"P3DFFT: a framework for parallel computations of Fourier transforms in
  three dimensions","  Fourier and related transforms is a family of algorithms widely employed in
diverse areas of computational science, notoriously difficult to scale on
high-performance parallel computers with large number of processing elements
(cores). This paper introduces a popular software package called P3DFFT
implementing Fast Fourier Transforms (FFT) in three dimensions (3D) in a highly
efficient and scalable way. It overcomes a well-known scalability bottleneck of
3D FFT implementations by using two-dimensional domain decomposition. Designed
for portable performance, P3DFFT achieves excellent timings for a number of
systems and problem sizes. On Cray XT5 system P3DFFT attains 45% efficiency in
weak scaling from 128 to 65,536 computational cores. Library features include
Fourier and Chebyshev transforms, Fortran and C interfaces, in- and
out-of-place transforms, uneven data grids, single and double precision. P3DFFT
is available as open source at http://code.google.com/p/p3dfft/. This paper
discusses P3DFFT implementation and performance in a way that helps guide the
user in making optimal choices for parameters of their runs.
"
1174,"Performance Engineering for Real and Complex Tall & Skinny Matrix
  Multiplication Kernels on GPUs","  General matrix-matrix multiplications with double-precision real and complex
entries (DGEMM and ZGEMM) in vendor-supplied BLAS libraries are best optimized
for square matrices but often show bad performance for tall & skinny matrices,
which are much taller than wide. NVIDIA's current CUBLAS implementation
delivers only a fraction of the potential performance as indicated by the
roofline model in this case. We describe the challenges and key characteristics
of an implementation that can achieve close to optimal performance. We further
evaluate different strategies of parallelization and thread distribution, and
devise a flexible, configurable mapping scheme. To ensure flexibility and allow
for highly tailored implementations we use code generation combined with
autotuning. For a large range of matrix sizes in the domain of interest we
achieve at least 2/3 of the roofline performance and often substantially
outperform state-of-the art CUBLAS results on an NVIDIA Volta GPGPU.
"
1175,Non-Conforming Mesh Refinement for High-Order Finite Elements,"  We propose a general algorithm for non-conforming adaptive mesh refinement
(AMR) of unstructured meshes in high-order finite element codes. Our focus is
on h-refinement with a fixed polynomial order. The algorithm handles
triangular, quadrilateral, hexahedral and prismatic meshes of arbitrarily high
order curvature, for any order finite element space in the de Rham sequence. We
present a flexible data structure for meshes with hanging nodes and a general
procedure to construct the conforming interpolation operator, both in serial
and in parallel. The algorithm and data structure allow anisotropic refinement
of tensor product elements in 2D and 3D, and support unlimited refinement
ratios of adjacent elements. We report numerical experiments verifying the
correctness of the algorithms, and perform a parallel scaling study to show
that we can adapt meshes containing billions of elements and run efficiently on
393,000 parallel tasks. Finally, we illustrate the integration of dynamic AMR
into a high-order Lagrangian hydrodynamics solver.
"
1176,Software System Design based on Patterns for Newton-Type Methods,"  A wide range of engineering applications uses optimisation techniques as part
of their solution process. The researcher uses specialized software that
implements well-known optimisation techniques to solve his problem. However,
when it comes to develop original optimisation techniques that fit a particular
problem the researcher has no option but to implement his own new method from
scratch. This leads to large development times and error prone code that, in
general, will not be reused for any other application. In this work, we present
a novel methodology that simplifies, fasten and improves the development
process of scientific software. This methodology guide us on the identification
of design patterns. The application of this methodology generates reusable,
flexible and high quality scientific software. Furthermore, the produced
software becomes a documented tool to transfer the knowledge on the development
process of scientific software. We apply this methodology for the design of an
optimisation framework implementing Newton's type methods which can be used as
a fast prototyping tool of new optimisation techniques based on Newton's type
methods. The abstraction, reusability and flexibility of the developed
framework is measured by means of Martin's metric. The results indicate that
the developed software is highly reusable.
"
1177,"Introduction to StarNEig -- A Task-based Library for Solving
  Nonsymmetric Eigenvalue Problems","  In this paper, we present the StarNEig library for solving dense
non-symmetric (generalized) eigenvalue problems. The library is built on top of
the StarPU runtime system and targets both shared and distributed memory
machines. Some components of the library support GPUs. The library is currently
in an early beta state and only real arithmetic is supported. Support for
complex data types is planned for a future release. This paper is aimed for
potential users of the library. We describe the design choices and capabilities
of the library, and contrast them to existing software such as ScaLAPACK.
StarNEig implements a ScaLAPACK compatibility layer that should make it easy
for a new user to transition to StarNEig. We demonstrate the performance of the
library with a small set of computational experiments.
"
1178,"Analysis of heterogeneous computing approaches to simulating heat
  transfer in heterogeneous material","  The simulation of heat flow through heterogeneous material is important for
the design of structural and electronic components. Classical analytical
solutions to the heat equation PDE are not known for many such domains, even
those having simple geometries. The finite element method can provide
approximations to a weak form continuum solution, with increasing accuracy as
the number of degrees of freedom in the model increases. This comes at a cost
of increased memory usage and computation time; even when taking advantage of
sparse matrix techniques for the finite element system matrix. We summarize
recent approaches in solving problems in structural mechanics and steady state
heat conduction which do not require the explicit assembly of any system
matrices, and adapt them to a method for solving the time-depended flow of
heat. These approaches are highly parallelizable, and can be performed on
graphical processing units (GPUs). Furthermore, they lend themselves to the
simulation of heterogeneous material, with a minimum of added complexity. We
present the mathematical framework of assembly-free FEM approaches, through
which we summarize the benefits of GPU computation. We discuss our
implementation using the OpenCL computing framework, and show how it is further
adapted for use on multiple GPUs. We compare the performance of single and dual
GPUs implementations of our method with previous GPU computing strategies from
the literature and a CPU sparse matrix approach. The utility of the novel
method is demonstrated through the solution of a real-world coefficient inverse
problem that requires thousands of transient heat flow simulations, each of
which involves solving a 1 million degree of freedom linear system over
hundreds of time steps.
"
1179,"ExaHyPE: An Engine for Parallel Dynamically Adaptive Simulations of Wave
  Problems","  ExaHyPE (""An Exascale Hyperbolic PDE Engine"") is a software engine for
solving systems of first-order hyperbolic partial differential equations
(PDEs). Hyperbolic PDEs are typically derived from the conservation laws of
physics and are useful in a wide range of application areas. Applications
powered by ExaHyPE can be run on a student's laptop, but are also able to
exploit thousands of processor cores on state-of-the-art supercomputers. The
engine is able to dynamically increase the accuracy of the simulation using
adaptive mesh refinement where required. Due to the robustness and shock
capturing abilities of ExaHyPE's numerical methods, users of the engine can
simulate linear and non-linear hyperbolic PDEs with very high accuracy. Users
can tailor the engine to their particular PDE by specifying evolved quantities,
fluxes, and source terms. A complete simulation code for a new hyperbolic PDE
can often be realised within a few hours - a task that, traditionally, can take
weeks, months, often years for researchers starting from scratch. In this
paper, we showcase ExaHyPE's workflow and capabilities through real-world
scenarios from our two main application areas: seismology and astrophysics.
"
1180,"Parallel memory-efficient all-at-once algorithms for the sparse matrix
  triple products in multigrid methods","  Multilevel/multigrid methods is one of the most popular approaches for
solving a large sparse linear system of equations, typically, arising from the
discretization of partial differential equations. One critical step in the
multilevel/multigrid methods is to form coarse matrices through a sequence of
sparse matrix triple products. A commonly used approach for the triple products
explicitly involves two steps, and during each step a sparse matrix-matrix
multiplication is employed. This approach works well for many applications with
a good computational efficiency, but it has a high memory overhead since some
auxiliary matrices need to be temporarily stored for accomplishing the
calculations. In this work, we propose two new algorithms that construct a
coarse matrix with taking one pass through the input matrices without involving
any auxiliary matrices for saving memory. The new approaches are referred to as
""all-at-once"" and ""merged all-at-once"", and the traditional method is denoted
as ""two-step"". The all-at-once and the merged all-at-once algorithms are
implemented based on hash tables in PETSc as part of this work with a careful
consideration on the performance in terms of the compute time and the memory
usage. We numerically show that the proposed algorithms and their
implementations are perfectly scalable in both the compute time and the memory
usage with up to 32,768 processor cores for a model problem with 27 billions of
unknowns. The scalability is also demonstrated for a realistic neutron
transport problem with over 2 billion unknowns on a supercomputer with 10,000
processor cores. Compared with the traditional two-step method, the all-at-once
and the merged all-at-once algorithms consume much less memory for both the
model problem and the realistic neutron transport problem meanwhile they are
able to maintain the computational efficiency.
"
1181,"Recursive blocked algorithms for linear systems with Kronecker product
  structure","  Recursive blocked algorithms have proven to be highly efficient at the
numerical solution of the Sylvester matrix equation and its generalizations. In
this work, we show that these algorithms extend in a seamless fashion to
higher-dimensional variants of generalized Sylvester matrix equations, as they
arise from the discretization of PDEs with separable coefficients or the
approximation of certain models in macroeconomics. By combining recursions with
a mechanism for merging dimensions, an efficient algorithm is derived that
outperforms existing approaches based on Sylvester solvers.
"
1182,Landau: language for dynamical systems with automatic differentiation,"  Most numerical solvers used to determine free variables of dynamical systems
rely on first-order derivatives of the state of the system w.r.t. the free
variables. The number of the free variables can be fairly large. One of the
approaches of obtaining those derivatives is the integration of the derivatives
simultaneously with the dynamical equations, which is best done with the
automatic differentiation technique. Even though there exist many automatic
differentiation tools, none have been found to be scalable and usable for
practical purposes of dynamic systems modeling. Landau is a Turing incomplete
statically typed domain-specific language aimed to fill this gap. The Turing
incompleteness provides the ability of sophisticated source code analysis and,
as a result, a highly optimized compiled code. Among other things, the language
syntax supports functions, compile-time ranged for loops, if/else branching
constructions, real variables and arrays, and the ability to manually discard
calculation where the automatic derivatives values are expected to be
negligibly small. In spite of reasonable restrictions, the language is rich
enough to express and differentiate any cumbersome paper-equation with
practically no effort.
"
1183,Robust Task-Parallel Solution of the Triangular Sylvester Equation,"  The Bartels-Stewart algorithm is a standard approach to solving the dense
Sylvester equation. It reduces the problem to the solution of the triangular
Sylvester equation. The triangular Sylvester equation is solved with a variant
of backward substitution. Backward substitution is prone to overflow. Overflow
can be avoided by dynamic scaling of the solution matrix. An algorithm which
prevents overflow is said to be robust. The standard library LAPACK contains
the robust scalar sequential solver dtrsyl. This paper derives a robust,
level-3 BLAS-based task-parallel solver. By adding overflow protection, our
robust solver closes the gap between problems solvable by LAPACK and problems
solvable by existing non-robust task-parallel solvers. We demonstrate that our
robust solver achieves a similar performance as non-robust solvers.
"
1184,On the Parallelization of Triangular Decomposition of Polynomial Systems,"  We discuss the parallelization of algorithms for solving polynomial systems
symbolically by way of triangular decomposition. Algorithms for solving
polynomial systems combine low-level routines for performing arithmetic
operations on polynomials and high-level procedures which produce the different
components (points, curves, surfaces) of the solution set. The latter
""component-level"" parallelization of triangular decompositions, our focus here,
belongs to the class of dynamic irregular parallel applications. Possible
speedup factors depend on geometrical properties of the solution set (number of
components, their dimensions and degrees); these algorithms do not scale with
the number of processors. In this paper we combine two different concurrency
schemes, the fork-join model and producer-consumer patterns, to better capture
opportunities for component-level parallelization. We report on our
implementation with the publicly available BPAS library. Our experimentation
with 340 systems yields promising results.
"
1185,"Bembel: The Fast Isogeometric Boundary Element C++ Library for Laplace,
  Helmholtz, and Electric Wave Equation","  In this article, we present Bembel, the C++ library featuring higher order
isogeometric Galerkin boundary element methods for Laplace, Helmholtz, and
Maxwell problems. Bembel is compatible with geometries from the Octave NURBS
package and provides an interface to the Eigen template library for linear
algebra operations. For computational efficiency, it applies an embedded fast
multipole method tailored to the isogeometric analysis framework and a parallel
matrix assembly based on OpenMP.
"
1186,Exploiting nested task-parallelism in the $\mathcal{H}-LU$ factorization,"  We address the parallelization of the LU factorization of hierarchical
matrices ($\mathcal{H}$-matrices) arising from boundary element methods. Our
approach exploits task-parallelism via the OmpSs programming model and runtime,
which discovers the data-flow parallelism intrinsic to the operation at
execution time, via the analysis of data dependencies based on the memory
addresses of the tasks' operands. This is especially challenging for
$\mathcal{H}$-matrices, as the structures containing the data vary in dimension
during the execution. We tackle this issue by decoupling the data structure
from that used to detect dependencies. Furthermore, we leverage the support for
weak operands and early release of dependencies, recently introduced in
OmpSs-2, to accelerate the execution of parallel codes with nested
task-parallelism and fine-grain tasks.
"
1187,"Raising the Performance of the Tinker-HP Molecular Modeling Package
  [Article v1.0]","  This living paper reviews the present High Performance Computing (HPC)
capabilities of the Tinker-HP molecular modeling package. We focus here on the
reference, double precision, massively parallel molecular dynamics engine
present in Tinker-HP and dedicated to perform large scale simulations. We show
how it can be adapted to recent Intel Central Processing Unit (CPU) petascale
architectures. First, we discuss the new set of Intel Advanced Vector
Extensions 512 (Intel AVX-512) instructions present in recent Intel processors
(e.g., the Intel Xeon Scalable and Intel Xeon Phi 2nd generation processors)
allowing for larger vectorization enhancements. These instructions constitute
the central source of potential computational gains when using the latest
processors, justifying important vectorization efforts for developers. We then
briefly review the organization of the Tinker-HP code and identify the
computational hotspots which require Intel AVX-512 optimization and we propose
a general and optimal strategy to vectorize those particular parts of the code.
We intended to present our optimization strategy in a pedagogical way so it
could benefit to other researchers and students interested in gaining
performances in their own software. Finally we present the performance
enhancements obtained compared to the unoptimized code both sequentially and at
the scaling limit in parallel for classical non-polarizable (CHARMM) and
polarizable force fields (AMOEBA). This paper never ceases to be updated as we
accumulate new data on the associated Github repository between new versions of
this living paper.
"
1188,"Nektar++: enhancing the capability and application of high-fidelity
  spectral/$hp$ element methods","  Nektar++ is an open-source framework that provides a flexible,
high-performance and scalable platform for the development of solvers for
partial differential equations using the high-order spectral/$hp$ element
method. In particular, Nektar++ aims to overcome the complex implementation
challenges that are often associated with high-order methods, thereby allowing
them to be more readily used in a wide range of application areas. In this
paper, we present the algorithmic, implementation and application developments
associated with our Nektar++ version 5.0 release. We describe some of the key
software and performance developments, including our strategies on parallel
I/O, on in situ processing, the use of collective operations for exploiting
current and emerging hardware, and interfaces to enable multi-solver coupling.
Furthermore, we provide details on a newly developed Python interface that
enables a more rapid introduction for new users unfamiliar with spectral/$hp$
element methods, C++ and/or Nektar++. This release also incorporates a number
of numerical method developments - in particular: the method of moving frames,
which provides an additional approach for the simulation of equations on
embedded curvilinear manifolds and domains; a means of handling spatially
variable polynomial order; and a novel technique for quasi-3D simulations to
permit spatially-varying perturbations to the geometry in the homogeneous
direction. Finally, we demonstrate the new application-level features provided
in this release, namely: a facility for generating high-order curvilinear
meshes called NekMesh; a novel new AcousticSolver for aeroacoustic problems;
our development of a 'thick' strip model for the modelling of fluid-structure
interaction problems in the context of vortex-induced vibrations. We conclude
by commenting some directions for future code development and expansion.
"
1189,Computing Theta Functions with Julia,"  We present a new package Theta.jl for computing with the Riemann theta
function. It is implemented in Julia and offers accurate numerical evaluation
of theta functions with characteristics and their derivatives of arbitrary
order. Our package is optimized for multiple evaluations of theta functions for
the same Riemann matrix, in small dimensions. As an application, we report on
experimental approaches to the Schottky problem in genus five.
"
1190,Bspline solids manipulation with Mathematica,"  Bspline solids are used for solid objects modeling in R3. Mathematica
incorporates a several commands to manipulate symbolic and graphically Bspline
basis functions and to graphically manipulate Bsplines curves and surfaces;
however, it does not incorporate any command to the graphical manipulation of
Bspline solids. In this paper, we describe a new Mathematica program to compute
and plotting the Bspline solids. The output obtained is consistent with
Mathematica's notation. The performance of the commands are discussed by using
some illustrative examples.
"
1191,Program Generation for Linear Algebra Using Multiple Layers of DSLs,"  Numerical software in computational science and engineering often relies on
highly-optimized building blocks from libraries such as BLAS and LAPACK, and
while such libraries provide portable performance for a wide range of computing
architectures, they still present limitations in terms of flexibility. We
advocate a domain-specific program generator capable of producing library
routines tailored to the specific needs of the application in terms of sizes,
interface, and target architecture.
"
1192,"SPSMAT: GNU Octave software package for spectral and pseudospectral
  methods","  SPSMAT (Spectral/Pseudospectral matrix method) is an add-on for Octave, that
helps you solve nonfractional-/fractional ordinary/partial
differential/integral equations. In this version, as the first version, the
well-defined spectral or pseudospectral algorithms are considered to solve
differential and integral equations. The motivation is that there are few
software packages available that make such methods easy to use for
practitioners in the field of scientific computing. Additionally, one of the
most practical platforms in computation, MATLAB, is currently not supporting
beneficial and free numerical method for the solution of differential
equations--to the best author's knowledge. To remedy this situation, this paper
provides a description of its relevant uploaded open source software package
and is a broad guidance to describe how to work with this toolbox.
"
1193,"Parallel Performance of Algebraic Multigrid Domain Decomposition
  (AMG-DD)","  Algebraic multigrid (AMG) is a widely used scalable solver and preconditioner
for large-scale linear systems resulting from the discretization of a wide
class of elliptic PDEs. While AMG has optimal computational complexity, the
cost of communication has become a significant bottleneck that limits its
scalability as processor counts continue to grow on modern machines. This paper
examines the design, implementation, and parallel performance of a novel
algorithm, Algebraic Multigrid Domain Decomposition (AMG-DD), designed
specifically to limit communication. The goal of AMG-DD is to provide a
low-communication alternative to standard AMG V-cycles by trading some
additional computational overhead for a significant reduction in communication
cost. Numerical results show that AMG-DD achieves superior accuracy per
communication cost compared to AMG, and speedup over AMG is demonstrated on a
large GPU cluster.
"
1194,"Investigating the OPS intermediate representation to target GPUs in the
  Devito DSL","  The Devito DSL is a code generation tool for the solution of partial
differential equations using the finite difference method specifically aimed at
seismic inversion problems.
  In this work we investigate the integration of OPS, an API to generate highly
optimized code for applications running on structured meshes targeting various
platforms, within Devito as a mean of bringing it to the GPU realm by providing
an implementation of a OPS backend in Devito, obtaining considerable speed ups
compared to the core Devito backend.
"
1195,"A High-Performance Implementation of a Robust Preconditioner for
  Heterogeneous Problems","  We present an efficient implementation of the highly robust and scalable
GenEO preconditioner in the high-performance PDE framework DUNE. The GenEO
coarse space is constructed by combining low energy solutions of a local
generalised eigenproblem using a partition of unity. In this paper we
demonstrate both weak and strong scaling for the GenEO solver on over 15,000
cores by solving an industrially motivated problem with over 200 million
degrees of freedom. Further, we show that for highly complex parameter
distributions arising in certain real-world applications, established methods
become intractable while GenEO remains fully effective. The purpose of this
paper is two-fold: to demonstrate the robustness and high parallel efficiency
of the solver and to document the technical details that are crucial to the
efficiency of the code.
"
1196,A Modular and Extensible Software Architecture for Particle Dynamics,"  Creating a highly parallel and flexible discrete element software requires an
interdisciplinary approach, where expertise from different disciplines is
combined. On the one hand domain specialists provide interaction models between
particles. On the other hand high-performance computing specialists optimize
the code to achieve good performance on different hardware architectures. In
particular, the software must be carefully crafted to achieve good scaling on
massively parallel supercomputers. Combining all this in a flexible and
extensible, widely usable software is a challenging task. In this article we
outline the design decisions and concepts of a newly developed particle
dynamics code MESA-PD that is implemented as part of the waLBerla multi-physics
framework. Extensibility, flexibility, but also performance and scalability are
primary design goals for the new software framework. In particular, the new
modular architecture is designed such that physical models can be modified and
extended by domain scientists without understanding all details of the parallel
computing functionality and the underlying distributed data structures that are
needed to achieve good performance on current supercomputer architectures. This
goal is achieved by combining the high performance simulation framework
waLBerla with code generation techniques. All code and the code generator are
released as open source under GPLv3 within the publicly available waLBerla
framework (www.walberla.net).
"
1197,"Remark on Algorithm 680: evaluation of the complex error function: Cause
  and Remedy for the Loss of Accuracy Near the Real Axis","  In this remark we identify the cause of the loss of accuracy in the
computation of the Faddeyeva function, w(z), near the real axis when using
Algorithm 680. We provide a simple correction to this problem which allows us
to restore this code as one of the important reference routines for accuracy
comparisons.
"
1198,Solving Polynomial Systems with phcpy,"  The solutions of a system of polynomials in several variables are often
needed, e.g.: in the design of mechanical systems, and in phase-space analyses
of nonlinear biological dynamics. Reliable, accurate, and comprehensive
numerical solutions are available through PHCpack, a FOSS package for solving
polynomial systems with homotopy continuation. This paper explores new
developments in phcpy, a scripting interface for PHCpack, over the past five
years. For instance, phcpy is now available online through a JupyterHub server
featuring Python2, Python3, and SageMath kernels. As small systems are solved
in real-time by phcpy, they are suitable for interactive exploration through
the notebook interface. Meanwhile, phcpy supports GPU parallelization,
improving the speed and quality of solutions to much larger polynomial systems.
From various model design and analysis problems in STEM, certain classes of
polynomial system frequently arise, to which phcpy is well-suited.
"
1199,"Algorithms and data structures for matrix-free finite element operators
  with MPI-parallel sparse multi-vectors","  Traditional solution approaches for problems in quantum mechanics scale as
$\mathcal O(M^3)$, where $M$ is the number of electrons. Various methods have
been proposed to address this issue and obtain linear scaling $\mathcal O(M)$.
One promising formulation is the direct minimization of energy. Such methods
take advantage of physical localization of the solution, namely that the
solution can be sought in terms of non-orthogonal orbitals with local support.
In this work a numerically efficient implementation of sparse parallel vectors
within the open-source finite element library deal.II is proposed. The main
algorithmic ingredient is the matrix-free evaluation of the Hamiltonian
operator by cell-wise quadrature. Based on an a-priori chosen support for each
vector we develop algorithms and data structures to perform (i) matrix-free
sparse matrix multivector products (SpMM), (ii) the projection of an operator
onto a sparse sub-space (inner products), and (iii) post-multiplication of a
sparse multivector with a square matrix. The node-level performance is analyzed
using a roofline model. Our matrix-free implementation of finite element
operators with sparse multivectors achieves the performance of 157 GFlop/s on
Intel Cascade Lake architecture. Strong and weak scaling results are reported
for a typical benchmark problem using quadratic and quartic finite element
bases.
"
1200,GPU-based Parallel Computation Support for Stan,"  This paper details an extensible OpenCL framework that allows Stan to utilize
heterogeneous compute devices. It includes GPU-optimized routines for the
Cholesky decomposition, its derivative, other matrix algebra primitives and
some commonly used likelihoods, with more additions planned for the near
future. Stan users can now benefit from large speedups offered by GPUs with
little effort and without changes to their existing Stan code. We demonstrate
the practical utility of our work with two examples - logistic regression and
Gaussian Process regression.
"
1201,"bayes4psy -- an Open Source R Package for Bayesian Statistics in
  Psychology","  Research in psychology generates interesting data sets and unique statistical
modelling tasks. However, these tasks, while important, are often very
specific, so appropriate statistical models and methods cannot be found in
accessible Bayesian tools. As a result, the use of Bayesian methods is limited
to those that have the technical and statistical fundamentals that are required
for probabilistic programming. Such knowledge is not part of the typical
psychology curriculum and is a difficult obstacle for psychology students and
researchers to overcome. The goal of the bayes4psy package is to bridge this
gap and offer a collection of models and methods to be used for data analysis
that arises from psychology experiments and as a teaching tool for Bayesian
statistics in psychology. The package contains Bayesian t-test and
bootstrapping and models for analyzing reaction times, success rates, and
colors. It also provides all the diagnostic, analytic and visualization tools
for the modern Bayesian data analysis workflow.
"
1202,hyppo: A Comprehensive Multivariate Hypothesis Testing Python Package,"  We introduce hyppo, a unified library for performing multivariate hypothesis
testing, including independence, two-sample, and k-sample testing. While many
multivariate independence tests have R packages available, the interfaces are
inconsistent and most are not available in Python. hyppo includes many state of
the art multivariate testing procedures. The package is easy-to-use and is
flexible enough to enable future extensions. The documentation and all releases
are available at https://hyppo.neurodata.io.
"
1203,Multi-dimensional interpolations in C++,"  A C++ software design is presented that can be used to interpolate data in
any number of dimensions. The design is based on a combination of templates of
functional collections of elements and so-called type lists. The design allows
for different search methodologies and interpolation techniques in each
dimension. It is also possible to expand and reduce the number of dimensions,
to interpolate composite data types and to produce on-the-fly additional values
such as derivatives of the interpolating function.
"
1204,Automatic Generation of Efficient Linear Algebra Programs,"  The level of abstraction at which application experts reason about linear
algebra computations and the level of abstraction used by developers of
high-performance numerical linear algebra libraries do not match. The former is
conveniently captured by high-level languages and libraries such as Matlab and
Eigen, while the latter expresses the kernels included in the BLAS and LAPACK
libraries. Unfortunately, the translation from a high-level computation to an
efficient sequence of kernels is a task, far from trivial, that requires
extensive knowledge of both linear algebra and high-performance computing.
Internally, almost all high-level languages and libraries use efficient
kernels; however, the translation algorithms are too simplistic and thus lead
to a suboptimal use of said kernels, with significant performance losses. In
order to both achieve the productivity that comes with high-level languages,
and make use of the efficiency of low level kernels, we are developing Linnea,
a code generator for linear algebra problems. As input, Linnea takes a
high-level description of a linear algebra problem and produces as output an
efficient sequence of calls to high-performance kernels. In 25 application
problems, the code generated by Linnea always outperforms Matlab, Julia, Eigen
and Armadillo, with speedups up to and exceeding 10x.
"
1205,Optimizing Xeon Phi for Interactive Data Analysis,"  The Intel Xeon Phi manycore processor is designed to provide high performance
matrix computations of the type often performed in data analysis. Common data
analysis environments include Matlab, GNU Octave, Julia, Python, and R.
Achieving optimal performance of matrix operations within data analysis
environments requires tuning the Xeon Phi OpenMP settings, process pinning, and
memory modes. This paper describes matrix multiplication performance results
for Matlab and GNU Octave over a variety of combinations of process counts and
OpenMP threads and Xeon Phi memory modes. These results indicate that using
KMP_AFFINITY=granlarity=fine, taskset pinning, and all2all cache memory mode
allows both Matlab and GNU Octave to achieve 66% of the practical peak
performance for process counts ranging from 1 to 64 and OpenMP threads ranging
from 1 to 64. These settings have resulted in generally improved performance
across a range of applications and has enabled our Xeon Phi system to deliver
significant results in a number of real-world applications.
"
1206,"Pseudo random number generators: attention for a newly proposed
  generator","  Xorshift128+ is a newly proposed pseudo random number generator (PRNG), which
is now the standard PRNG in a number of platforms. We point out that
three-dimensional plots of the random points generated by the generator have
visible structures: they concentrate on particular planes in the cube. We
provide mathematical analysis on this phenomenon. A key-observation is that the
exclusive-or is well-approximated by the arithmetic sum or subtraction with
relatively high probability.
"
1207,"A generic finite element framework on parallel tree-based adaptive
  meshes","  In this work we formally derive and prove the correctness of the algorithms
and data structures in a parallel, distributed-memory, generic finite element
framework that supports h-adaptivity on computational domains represented as
forest-of-trees. The framework is grounded on a rich representation of the
adaptive mesh suitable for generic finite elements that is built on top of a
low-level, light-weight forest-of-trees data structure handled by a
specialized, highly parallel adaptive meshing engine, for which we have
identified the requirements it must fulfill to be coupled into our framework.
Atop this two-layered mesh representation, we build the rest of data structures
required for the numerical integration and assembly of the discrete system of
linear equations. We consider algorithms that are suitable for both
subassembled and fully-assembled distributed data layouts of linear system
matrices. The proposed framework has been implemented within the FEMPAR
scientific software library, using p4est as a practical forest-of-octrees
demonstrator. A strong scaling study of this implementation when applied to
Poisson and Maxwell problems reveals remarkable scalability up to 32.2K CPU
cores and 482.2M degrees of freedom. Besides, a comparative performance study
of FEMPAR and the state-of-the-art deal.ii finite element software shows at
least comparative performance, and at most factor 2-3 improvements in the
h-adaptive approximation of a Poisson problem with first- and second-order
Lagrangian finite elements, respectively.
"
1208,Out-of-core singular value decomposition,"  Singular value decomposition (SVD) is a standard matrix factorization
technique that produces optimal low-rank approximations of matrices. It has
diverse applications, including machine learning, data science and signal
processing. However, many common problems involve very large matrices that
cannot fit in the main memory of commodity computers, making it impractical to
use standard SVD algorithms that assume fast random access or large amounts of
space for intermediate calculations. To address this issue, we have implemented
an out-of-core (external memory) randomized SVD solution that is fully scalable
and efficiently parallelizable. This solution factors both dense and sparse
matrices of arbitrarily large size within arbitrarily small memory limits,
efficiently using out-of-core storage as needed. It uses an innovative
technique for partitioning matrices that lends itself to out-of-core and
parallel processing, as well as memory and I/O use planning, automatic load
balancing, performance tuning, and makes possible a number of other practical
enhancements to the current state-of-the-art. Furthermore, by using persistent
external storage (generally HDDs or SSDs), users can resume interrupted
operations without having to recalculate previously performed steps, solving a
major practical problem in factoring very large matrices.
"
1209,Semi-Lagrangian Vlasov simulation on GPUs,"  In this paper, our goal is to efficiently solve the Vlasov equation on GPUs.
A semi-Lagrangian discontinuous Galerkin scheme is used for the discretization.
Such kinetic computations are extremely expensive due to the high-dimensional
phase space. The SLDG code, which is publicly available under the MIT license
abstracts the number of dimensions and uses a shared codebase for both GPU and
CPU based simulations. We investigate the performance of the implementation on
a range of both Tesla (V100, Titan V, K80) and consumer (GTX 1080 Ti) GPUs. Our
implementation is typically able to achieve a performance of approximately 470
GB/s on a single GPU and 1600 GB/s on four V100 GPUs connected via NVLink. This
results in a speedup of about a factor of ten (comparing a single GPU with a
dual socket Intel Xeon Gold node) and approximately a factor of 35 (comparing a
single node with and without GPUs). In addition, we investigate the effect of
single precision computation on the performance of the SLDG code and
demonstrate that a template based dimension independent implementation can
achieve good performance regardless of the dimensionality of the problem.
"
1210,"A Hermite-like basis for faster matrix-free evaluation of interior
  penalty discontinuous Galerkin operators","  This work proposes a basis for improved throughput of matrix-free evaluation
of discontinuous Galerkin symmetric interior penalty discretizations on
hexahedral elements. The basis relies on ideas of Hermite polynomials. It is
used in a fully discontinuous setting not for higher order continuity but to
minimize the effective stencil width, namely to limit the neighbor access of an
element to one data point for the function value and one for the derivative.
The basis is extended to higher orders with nodal contributions derived from
roots of Jacobi polynomials and extended to multiple dimensions with tensor
products, which enable the use of sum factorization. The beneficial effect of
the reduced data access on modern processors is shown. Furthermore, the
viability of the basis in the context of multigrid solvers is analyzed. While a
plain point-Jacobi approach is less efficient than with the best nodal
polynomials, a basis change via sum-factorization techniques enables the
combination of the fast matrix-vector products with effective multigrid
constituents. The basis change is essentially for free on modern hardware
because these computations can be hidden behind the cost of the data access.
"
1211,"The LAPW method with eigendecomposition based on the Hari--Zimmermann
  generalized hyperbolic SVD","  In this paper we propose an accurate, highly parallel algorithm for the
generalized eigendecomposition of a matrix pair $(H, S)$, given in a factored
form $(F^{\ast} J F, G^{\ast} G)$. Matrices $H$ and $S$ are generally complex
and Hermitian, and $S$ is positive definite. This type of matrices emerges from
the representation of the Hamiltonian of a quantum mechanical system in terms
of an overcomplete set of basis functions. This expansion is part of a class of
models within the broad field of Density Functional Theory, which is considered
the golden standard in condensed matter physics. The overall algorithm consists
of four phases, the second and the fourth being optional, where the two last
phases are computation of the generalized hyperbolic SVD of a complex matrix
pair $(F,G)$, according to a given matrix $J$ defining the hyperbolic scalar
product. If $J = I$, then these two phases compute the GSVD in parallel very
accurately and efficiently.
"
1212,"Distributions.jl: Definition and Modeling of Probability Distributions
  in the JuliaStats Ecosystem","  Random variables and their distributions are a central part in many areas of
statistical methods. The Distributions.jl package provides Julia users and
developers tools for working with probability distributions, leveraging Julia
features for their intuitive and flexible manipulation, while remaining highly
efficient through zero-cost abstractions.
"
1213,SciPy 1.0--Fundamental Algorithms for Scientific Computing in Python,"  SciPy is an open source scientific computing library for the Python
programming language. SciPy 1.0 was released in late 2017, about 16 years after
the original version 0.1 release. SciPy has become a de facto standard for
leveraging scientific algorithms in the Python programming language, with more
than 600 unique code contributors, thousands of dependent packages, over
100,000 dependent repositories, and millions of downloads per year. This
includes usage of SciPy in almost half of all machine learning projects on
GitHub, and usage by high profile projects including LIGO gravitational wave
analysis and creation of the first-ever image of a black hole (M87). The
library includes functionality spanning clustering, Fourier transforms,
integration, interpolation, file I/O, linear algebra, image processing,
orthogonal distance regression, minimization algorithms, signal processing,
sparse matrix handling, computational geometry, and statistics. In this work,
we provide an overview of the capabilities and development practices of the
SciPy library and highlight some recent technical developments.
"
1214,PyLops -- A Linear-Operator Python Library for large scale optimization,"  Linear operators and optimisation are at the core of many algorithms used in
signal and image processing, remote sensing, and inverse problems. For small to
medium-scale problems, existing software packages (e.g., MATLAB, Python numpy
and scipy) allow for explicitly building dense (or sparse) matrices and
performing algebraic operations (e.g., computation of matrix-vector products
and manipulation of matrices) with syntax that closely represents their
corresponding analytical forms. However, many real application, large-scale
operators do not lend themselves to explicit matrix representations, usually
forcing practitioners to forego of the convenient linear-algebra syntax
available for their explicit-matrix counterparts. PyLops is an open-source
Python library providing a flexible and scalable framework for the creation and
combination of so-called linear operators, class-based entities that represent
matrices and inherit their associated syntax convenience, but do not rely on
the creation of explicit matrices. We show that PyLops operators can
dramatically reduce the memory load and CPU computations compared to
explicit-matrix calculations, while still allowing users to seamlessly use
their existing knowledge of compact matrix-based syntax that scales to any
problem size because no explicit matrices are required.
"
1215,"Characteristics-based Simulink implementation of first-order quasilinear
  partial differential equations","  The paper deals with solving first-order quasilinear partial differential
equations in an online simulation environment, such as Simulink, utilizing the
well-known and well-recommended method of characteristics. Compared to the
commonly applied space discretization methods on static grids, the
characteristics-based approach provides better numerical stability. Simulink
subsystem implementing the method of characteristics is developed. It employs
Simulink's built-in solver and its zero-crossing detection algorithm to perform
simultaneous integration of a pool of characteristics as well as to create new
characteristics dynamically and discard the old ones. Numerical accuracy of the
solution thus obtained is established. The subsystem has been tested on a
full-state feedback example and produced better results than the space
discretization-based ""method of lines"". The implementation is available for
download and can be used in a wide range of models.
"
1216,"Testing performance with and without Block Low Rank Compression in MUMPS
  and the new PaStiX 6.0 for JOREK nonlinear MHD simulations","  The interface to the MUMPS solver was updated in the JOREK MHD code to
support Block Low Rank (BLR) compression and an interface to the new PaStiX
solver version 6 has been implemented supporting BLR as well. First tests were
carried out with JOREK, which solves a large sparse matrix system iteratively
in each time step. For the preconditioning, a direct solver is applied in the
code to sub-matrices, and at this point BLR was applied with the results being
summarized in this report. For a simple case with a linearly growing mode,
results with both solvers look promising with a considerable reduction of the
memory consumption by several ten percent was obtained. A direct increase in
performance was seen in particular configurations already.
  The choice of the BLR accuracy parameter $\epsilon$ proves to be critical in
this simple test and also in more realistic simulations, which were carried out
only with MUMPS due to the limited time available. The more realistic test
showed an increase in run time when using BLR, which was mitigated when using
larger values of $\epsilon$. However, the GMRes iterative solver does not reach
convergence anymore when $\epsilon$ is too large, since the preconditioner
becomes too inaccurate in that case. It is thus critical to use an $\epsilon$
as large as possible, while still reaching convergence. More tests regarding
this optimum will be necessary in the future. BLR can also lead to an indirect
speed-up in particular cases, when the simulation can be run on a smaller
number of compute nodes due to the reduced memory consumption.
"
1217,"pySOT and POAP: An event-driven asynchronous framework for surrogate
  optimization","  This paper describes Plumbing for Optimization with Asynchronous Parallelism
(POAP) and the Python Surrogate Optimization Toolbox (pySOT). POAP is an
event-driven framework for building and combining asynchronous optimization
strategies, designed for global optimization of expensive functions where
concurrent function evaluations are useful. POAP consists of three components:
a worker pool capable of function evaluations, strategies to propose
evaluations or other actions, and a controller that mediates the interaction
between the workers and strategies. pySOT is a collection of synchronous and
asynchronous surrogate optimization strategies, implemented in the POAP
framework. We support the stochastic RBF method by Regis and Shoemaker along
with various extensions of this method, and a general surrogate optimization
strategy that covers most Bayesian optimization methods. We have implemented
many different surrogate models, experimental designs, acquisition functions,
and a large set of test problems. We make an extensive comparison between
synchronous and asynchronous parallelism and find that the advantage of
asynchronous computation increases as the variance of the evaluation time or
number of processors increases. We observe a close to linear speed-up with 4,
8, and 16 processors in both the synchronous and asynchronous setting.
"
1218,"A tutorial-driven introduction to the parallel finite element library
  FEMPAR v1.0.0","  This work is a user guide to the FEMPAR scientific software library. FEMPAR
is an open-source object-oriented framework for the simulation of partial
differential equations (PDEs) using finite element methods on
distributed-memory platforms. It provides a rich set of tools for numerical
discretization and built-in scalable solvers for the resulting linear systems
of equations. An application expert that wants to simulate a PDE-governed
problem has to extend the framework with a description of the weak form of the
PDE at hand (and additional perturbation terms for non-conforming
approximations). We show how to use the library by going through three
different tutorials. The first tutorial simulates a linear PDE (Poisson
equation) in a serial environment for a structured mesh using both continuous
and discontinuous Galerkin finite element methods. The second tutorial extends
it with adaptive mesh refinement on octree meshes. The third tutorial is a
distributed-memory version of the previous one that combines a scalable octree
handler and a scalable domain decomposition solver. The exposition is
restricted to linear PDEs and simple geometries to keep it concise. The
interested user can dive into more tutorials available in the FEMPAR public
repository to learn about further capabilities of the library, e.g., nonlinear
PDEs and nonlinear solvers, time integration, multi-field PDEs, block
preconditioning, or unstructured mesh handling.
"
1219,"GraphBLAST: A High-Performance Linear Algebra-based Graph Framework on
  the GPU","  High-performance implementations of graph algorithms are challenging to
implement on new parallel hardware such as GPUs because of three challenges:
(1) the difficulty of coming up with graph building blocks, (2) load imbalance
on parallel hardware, and (3) graph problems having low arithmetic intensity.
To address some of these challenges, GraphBLAS is an innovative, on-going
effort by the graph analytics community to propose building blocks based on
sparse linear algebra, which will allow graph algorithms to be expressed in a
performant, succinct, composable and portable manner. In this paper, we examine
the performance challenges of a linear-algebra-based approach to building graph
frameworks and describe new design principles for overcoming these bottlenecks.
Among the new design principles is exploiting input sparsity, which allows
users to write graph algorithms without specifying push and pull direction.
Exploiting output sparsity allows users to tell the backend which values of the
output in a single vectorized computation they do not want computed.
Load-balancing is an important feature for balancing work amongst parallel
workers. We describe the important load-balancing features for handling graphs
with different characteristics. The design principles described in this paper
have been implemented in ""GraphBLAST"", the first high-performance linear
algebra-based graph framework on NVIDIA GPUs that is open-source. The results
show that on a single GPU, GraphBLAST has on average at least an order of
magnitude speedup over previous GraphBLAS implementations SuiteSparse and GBTL,
comparable performance to the fastest GPU hardwired primitives and
shared-memory graph frameworks Ligra and Gunrock, and better performance than
any other GPU graph framework, while offering a simpler and more concise
programming model.
"
1220,Ripser: efficient computation of Vietoris-Rips persistence barcodes,"  We present an algorithm for the computation of Vietoris-Rips persistence
barcodes and describe its implementation in the software Ripser. The method
relies on implicit representations of the coboundary operator and of the
filtration order of the simplices, avoiding the explicit construction and
storage of the filtration coboundary matrix. Our implementation shows
substantial improvements over previous software both in time and memory usage.
"
1221,"Domain-Driven Solver (DDS) Version 2.0: a MATLAB-based Software Package
  for Convex Optimization Problems in Domain-Driven Form","  Domain-Driven Solver (DDS) is a MATLAB-based software package for convex
optimization problems in Domain-Driven form [Karimi and Tun\c{c}el,
arXiv:1804.06925]. The current version of DDS accepts every combination of the
following function/set constraints: (1) symmetric cones (LP, SOCP, and SDP);
(2) quadratic constraints that are SOCP representable; (3) direct sums of an
arbitrary collection of 2-dimensional convex sets defined as the epigraphs of
univariate convex functions (including as special cases geometric programming
and entropy programming); (4) generalized power cone; (5) epigraphs of matrix
norms (including as a special case minimization of nuclear norm over a linear
subspace); (6) vector relative entropy; (7) epigraphs of quantum entropy and
quantum relative entropy; and (8) constraints involving hyperbolic polynomials.
DDS is a practical implementation of the infeasible-start primal-dual algorithm
designed and analyzed in [Karimi and Tun\c{c}el, arXiv:1804.06925]. This
manuscript contains the users' guide, as well as theoretical results needed for
the implementation of the algorithms. To help the users, we included many
examples. We also discussed some implementation details and techniques we used
to improve the efficiency and further expansion of the software to cover the
emerging classes of convex optimization problems.
"
1222,"SODECL: An Open Source Library for Calculating Multiple Orbits of a
  System of Stochastic Differential Equations in Parallel","  Stochastic differential equations (SDEs) are widely used to model systems
affected by random processes. In general, the analysis of an SDE model requires
numerical solutions to be generated many times over multiple parameter
combinations. However, this process often requires considerable computational
resources to be practicable. Due to the embarrassingly parallel nature of the
task, devices such as multi-core processors and graphics processing units
(GPUs) can be employed for acceleration.
  Here, we present {\bf SODECL} (\url{https://github.com/avramidis/sodecl}), a
software library that utilises such devices to calculate multiple orbits of an
SDE model. To evaluate the acceleration provided by SODECL, we compared the
time required to calculate multiple orbits of an exemplar stochastic model when
one CPU core is used, to the time required when using all CPU cores or a GPU.
In addition, to assess scalability, we investigated how the model size affected
execution time on different parallel compute devices.
  Our results show that when using all 32 CPU cores of a high-end
high-performance computing node, the task is accelerated by a factor of up to
$\simeq$6.7, compared to when using a single CPU core. Executing the task on a
high-end GPU yielded accelerations of up to $\simeq$4.5, compared to a single
CPU core.
"
1223,"Open Traffic Models -- A framework for hybrid simulation of
  transportation networks","  This paper introduces a new approach to hybrid traffic modeling, along with
its implementation in software. The software allows modelers to assign traffic
models to individual links in a network. Each model implements a series of
methods, refered to as the modeling interface. These methods are used by the
program to exchange information between adjacent models. Traffic controllers
are implemented in a similar manner. The paper outlines the important
components of the method: the network description, the description of demands,
and the modeling and control interfaces. We include tests demonstrating the
propagation of congestion between pairs of macroscpoic, mesoscopic, and
microscopic models. Open Traffic Models is an open source implementation of
these concepts, and is available at https://github.com/ggomes/otm-sim.
"
1224,OpenMP parallelization of multiple precision Taylor series method,"  OpenMP parallelization of multiple precision Taylor series method is
proposed. A very good parallel performance scalability and parallel efficiency
inside one computation node of a CPU-cluster is observed. We explain the
details of the parallelization on the classical example of the Lorentz
equations. The same approach can be applied straightforwardly to a large class
of chaotic dynamical systems.
"
1225,High Performance Block Incomplete LU Factorization,"  Many application problems that lead to solving linear systems make use of
preconditioned Krylov subspace solvers to compute their solution. Among the
most popular preconditioning approaches are incomplete factorization methods
either as single-level approaches or within a multilevel framework. We will
present a block incomplete factorization that is based on skillfully blocking
the system initially and throughout the factorization. This approach allows for
the use of cache-optimized dense matrix kernels such as level-3 BLAS or LAPACK.
We will demonstrate how this block approach outperforms the scalar method often
by orders of magnitude on modern architectures, paving the way for its
prospective use inside various multilevel incomplete factorization approaches
or other applications where the core part relies on an incomplete
factorization.
"
1226,ArborX: A Performance Portable Geometric Search Library,"  Searching for geometric objects that are close in space is a fundamental
component of many applications. The performance of search algorithms comes to
the forefront as the size of a problem increases both in terms of total object
count as well as in the total number of search queries performed. Scientific
applications requiring modern leadership-class supercomputers also pose an
additional requirement of performance portability, i.e. being able to
efficiently utilize a variety of hardware architectures. In this paper, we
introduce a new open-source C++ search library, ArborX, which we have designed
for modern supercomputing architectures. We examine scalable search algorithms
with a focus on performance, including a highly efficient parallel bounding
volume hierarchy implementation, and propose a flexible interface making it
easy to integrate with existing applications. We demonstrate the performance
portability of ArborX on multi-core CPUs and GPUs, and compare it to the
state-of-the-art libraries such as Boost.Geometry.Index and nanoflann.
"
1227,Implicit Hari--Zimmermann algorithm for the generalized SVD on the GPUs,"  A parallel, blocked, one-sided Hari--Zimmermann algorithm for the generalized
singular value decomposition (GSVD) of a real or a complex matrix pair $(F,G)$
is here proposed, where $F$ and $G$ have the same number of columns, and are
both of the full column rank. The algorithm targets either a single graphics
processing unit (GPU), or a cluster of those, performs all non-trivial
computation exclusively on the GPUs, requires the minimal amount of memory to
be reasonably expected, scales acceptably with the increase of the number of
GPUs available, and guarantees the reproducible, bitwise identical output of
the runs repeated over the same input and with the same number of GPUs.
"
1228,PLANC: Parallel Low Rank Approximation with Non-negativity Constraints,"  We consider the problem of low-rank approximation of massive dense
non-negative tensor data, for example to discover latent patterns in video and
imaging applications. As the size of data sets grows, single workstations are
hitting bottlenecks in both computation time and available memory. We propose a
distributed-memory parallel computing solution to handle massive data sets,
loading the input data across the memories of multiple nodes and performing
efficient and scalable parallel algorithms to compute the low-rank
approximation. We present a software package called PLANC (Parallel Low Rank
Approximation with Non-negativity Constraints), which implements our solution
and allows for extension in terms of data (dense or sparse, matrices or tensors
of any order), algorithm (e.g., from multiplicative updating techniques to
alternating direction method of multipliers), and architecture (we exploit GPUs
to accelerate the computation in this work).We describe our parallel
distributions and algorithms, which are careful to avoid unnecessary
communication and computation, show how to extend the software to include new
algorithms and/or constraints, and report efficiency and scalability results
for both synthetic and real-world data sets.
"
1229,"A Low-Memory Time-Efficient Implementation of Outermorphisms for
  Higher-Dimensional Geometric Algebras","  From the beginning of David Hestenes rediscovery of geometric algebra in the
1960s, outermorphisms have been a cornerstone in the mathematical development
of GA. Many important mathematical formulations in GA can be expressed as
outermorphisms such as versor products, linear projection operators, and
mapping between related coordinate frames. Over the last two decades, GA-based
mathematical models and software implementations have been developed in many
fields of science and engineering. As such, efficient implementations of
outermorphisms are of significant importance within this context. This work
attempts to shed some light on the problem of optimizing software
implementations of outermorphisms for practical prototyping applications using
geometric algebra. The approach we propose here for implementing outermorphisms
requires orders of magnitude less memory compared to other common approaches,
while being comparable in time performance, especially for high-dimensional
geometric algebras.
"
1230,"Computing Derivatives for PETSc Adjoint Solvers using Algorithmic
  Differentiation","  Most nonlinear partial differential equation (PDE) solvers require the
Jacobian matrix associated to the differential operator. In PETSc, this is
typically achieved by either an analytic derivation or numerical approximation
method such as finite differences. For complex applications, hand-coding the
Jacobian can be time-consuming and error-prone, yet computationally efficient.
Whilst finite difference approximations are straight-forward to implement, they
have high arithmetic complexity and low accuracy. Alternatively, one may
compute Jacobians using algorithmic differentiation (AD), yielding the same
derivatives as an analytic derivation, with the added benefit that the
implementation is problem independent. In this work, the operator overloading
AD tool ADOL-C is applied to generate Jacobians for time-dependent, nonlinear
PDEs and their adjoints. Various strategies are considered, including
compressed and matrix-free approaches. In numerical experiments with a 2D
diffusion-reaction model, the performance of these strategies has been studied
and compared to the hand-derived version.
"
1231,"hIPPYlib: An Extensible Software Framework for Large-Scale Inverse
  Problems Governed by PDEs; Part I: Deterministic Inversion and Linearized
  Bayesian Inference","  We present an extensible software framework, hIPPYlib, for solution of
large-scale deterministic and Bayesian inverse problems governed by partial
differential equations (PDEs) with infinite-dimensional parameter fields (which
are high-dimensional after discretization). hIPPYlib overcomes the prohibitive
nature of Bayesian inversion for this class of problems by implementing
state-of-the-art scalable algorithms for PDE-based inverse problems that
exploit the structure of the underlying operators, notably the Hessian of the
log-posterior. The key property of the algorithms implemented in hIPPYlib is
that the solution of the deterministic and linearized Bayesian inverse problem
is computed at a cost, measured in linearized forward PDE solves, that is
independent of the parameter dimension. The mean of the posterior is
approximated by the MAP point, which is found by minimizing the negative
log-posterior. This deterministic nonlinear least-squares optimization problem
is solved with an inexact matrix-free Newton-CG method. The posterior
covariance is approximated by the inverse of the Hessian of the negative log
posterior evaluated at the MAP point. This Gaussian approximation is exact when
the parameter-to-observable map is linear; otherwise, its logarithm agrees to
two derivatives with the log-posterior at the MAP point, and thus it can serve
as a proposal for Hessian-based MCMC methods. The construction of the posterior
covariance is made tractable by invoking a low-rank approximation of the
Hessian of the log-likelihood. Scalable tools for sample generation are also
implemented. hIPPYlib makes all of these advanced algorithms easily accessible
to domain scientists and provides an environment that expedites the development
of new algorithms. hIPPYlib is also a teaching tool to educate researchers and
practitioners who are new to inverse problems and the Bayesian inference
framework.
"
1232,"The surrogate matrix methodology: A reference implementation for
  low-cost assembly in isogeometric analysis","  A reference implementation of a new method in isogeometric analysis (IGA) is
presented. It delivers low-cost variable-scale approximations (surrogates) of
the matrices which IGA conventionally requires to be computed by element-scale
quadrature. To generate surrogate matrices, quadrature must only be performed
on a fraction of the elements in the computational domain. In this way,
quadrature determines only a subset of the entries in the final matrix. The
remaining matrix entries are computed by a simple B-spline interpolation
procedure. We present the modifications and extensions required for a reference
implementation in the open-source IGA software library GeoPDEs. The exposition
is fashioned to help facilitate similar modifications in other contemporary
software libraries.
"
1233,PySPH: a Python-based framework for smoothed particle hydrodynamics,"  PySPH is a Python-based framework for particle methods in general and
Smoothed Particle Hydrodynamics (SPH) in particular. PySPH allows a user to
define a complete SPH simulation using pure Python. High-performance code is
generated from this high-level Python code and executed on either multiple
cores, or on GPUs, seamlessly. It also supports distributed execution using
MPI. PySPH supports a wide variety of SPH schemes and formulations. These
include incompressible and compressible fluid flow, elastic dynamics, rigid
body dynamics, shallow water equations and other problems. PySPH supports a
variety of boundary conditions including mirror, periodic, solid wall, inlet
and outlet boundary conditions. The package is written to facilitate reuse and
reproducibility. This paper discusses the overall design of PySPH and
demonstrates many of its features. Several example results are shown to
demonstrate the range of features that PySPH provides.
"
1234,"DuMu$^\text{x}$ 3 -- an open-source simulator for solving flow and
  transport problems in porous media with a focus on model coupling","  We present version 3 of the open-source simulator for flow and transport
processes in porous media DuMu$^\text{x}$. DuMu$^\text{x}$ is based on the
modular C++ framework Dune (Distributed and Unified Numerics Environment) and
is developed as a research code with a focus on modularity and reusability. We
describe recent efforts in improving the transparency and efficiency of the
development process and community-building, as well as efforts towards quality
assurance and reproducible research. In addition to a major redesign of many
simulation components in order to facilitate setting up complex simulations in
DuMu$^\text{x}$, version 3 introduces a more consistent abstraction of finite
volume schemes. Finally, the new framework for multi-domain simulations is
described, and three numerical examples demonstrate its flexibility.
"
1235,"PittPack: An Open-Source Poisson's Equation Solver for Extreme-Scale
  Computing with Accelerators","  We present a parallel implementation of a direct solver for the Poisson's
equation on extreme-scale supercomputers with accelerators. We introduce a
chunked-pencil decomposition as the domain-decomposition strategy to distribute
work among processing elements to achieve superior scalability at large number
of accelerators. Chunked-pencil decomposition enables overlapping nodal
communication and data transfer between the central processing units (CPUs) and
the graphics processing units (GPUs). Second, it improves data locality by
keeping neighboring elements in adjacent memory locations. Third, it allows
usage of shared-memory for certain segments of the algorithm when possible, and
last but not least, it enables contiguous message transfer among the nodes. Two
different communication patterns are designed. The fist pattern aims to fully
overlap the communication with data transfer and designed for speedup of
overall turnaround time, whereas the second method concentrates on low memory
usage and is more network friendly for computations at extreme scale. To ensure
software portability, we interleave OpenACC with MPI in the software. The
numerical solution and its formal second order of accuracy is verified using
method of manufactured solutions for various combinations of boundary
conditions. Weak scaling analysis is performed using up to 1.1 trillion
Cartesian mesh points using 16384 GPUs on a petascale leadership class
supercomputer.
"
1236,"Multithreaded Filtering Preconditioner for Diffusion Equation on
  Structured Grid","  A parallel and nested version of a frequency filtering preconditioner is
proposed for linear systems corresponding to diffusion equation on a structured
grid. The proposed preconditioner is found to be robust with respect to jumps
in the diffusion coefficients. The storage requirement for the preconditioner
is O(N),where N is number of rows of matrix, hence, a fairly large problem of
size more than 42 million unknowns has been solved on a quad core machine with
64GB RAM. The parallelism is achieved using twisted factorization and SIMD
operations. The preconditioner achieves a speedup of 3.3 times on a quad core
processor clocked at 4.2 GHz, and compared to a well known algebraic multigrid
method, it is significantly faster in both setup and solve times for diffusion
equations with jumps.
"
1237,PyIT2FLS: A New Python Toolkit for Interval Type 2 Fuzzy Logic Systems,"  Fuzzy logic is an accepted and well-developed approach for constructing
verbal models. Fuzzy based methods are getting more popular, while the
engineers deal with more daily life tasks. This paper presents a new Python
toolkit for Interval Type 2 Fuzzy Logic Systems (IT2FLS). Developing software
tools is an important issue for facilitating the practical use of theoretical
results. There are limited tools for implementing IT2FLSs in Python. The
developed PyIT2FLS is providing a set of tools for fast and easy modeling of
fuzzy systems. This paper includes a brief description of how developed toolkit
can be used. Also, three examples are given showing the usage of the developed
toolkit for simulating IT2FLSs. First, a simple rule-based system is developed
and it's codes are presented in the paper. The second example is the prediction
of the Mackey-Glass chaotic time series using IT2FLS. In this example, the
Particle Swarm Optimization (PSO) algorithm is used for determining system
parameters while minimizing the mean square error. In the last example, an
IT2FPID is designed and used for controlling a linear time-delay system. The
code for the examples are available on toolkit's GitHub page:
\url{https://github.com/Haghrah/PyIT2FLS}. The simulations and their results
confirm the ability of the developed toolkit to be used in a wide range of the
applications.
"
1238,Efficient Stochastic Programming in Julia,"  We present StochasticPrograms.jl, an open-source framework for stochastic
programming written in the Julia language. The framework includes both modeling
tools and structure-exploiting optimization algorithms. We show how stochastic
programming models can be efficiently formulated using expressive syntax.
Defined models can be instantiated, inspected, and analyzed interactively. The
framework was implemented to scale seamlessly to distributed environments. As a
result, stochastic programs are efficiently memory-distributed on
supercomputers or cloud architectures and solved using parallel optimization
algorithms. These structure-exploiting solvers are based on variations of the
classical L-shaped and progressive-hedging algorithms. We provide a concise
mathematical background for the various tools and constructs available in the
framework, along with code listings exemplifying their usage. Both software
innovations related to the implementation of the framework and algorithmic
innovations related to the structured solvers are highlighted. We conclude by
performing numerical benchmarks of the distributed algorithms in a multi-node
setup. We showcase strong scaling properties of the solvers and outline
techniques for further speedups.
"
1239,SUNDIALS Multiphysics+MPIManyVector Performance Testing,"  In this report we document performance test results on a SUNDIALS-based
multiphysics demonstration application. We aim to assess the large-scale
parallel performance of new capabilities that have been added to the SUNDIALS
suite of time integrators and nonlinear solvers in recent years under funding
from both the Exascale Computing Project (ECP) and the Scientific Discovery
through Advanced Scientific (SciDAC) program, specifically: (a) SUNDIALS' new
MPIManyVector module, that allows extreme flexibility in how a solution
""vector"" is staged on computational resources, (b) ARKode's new multirate
integration module, MRIStep, allowing high-order accurate calculations that
subcycle ""fast"" processes within ""slow"" ones, (c) SUNDIALS' new flexible linear
solver interfaces, that allow streamlined specification of problem-specific
linear solvers, and (d) SUNDIALS' new N_Vector additions of ""fused"" vector
operations (to increase arithmetic intensity) and separation of reduction
operations into ""local"" and ""global"" versions (to reduce latency by combining
multiple reductions into a single MPI_Allreduce call). We anticipate that
subsequent reports will extend this work to investigate a variety of other new
features, including SUNDIALS' generic SUNNonlinearSolver interface and
accelerator-enabled N_Vector modules, and upcoming MRIStep extensions to
support custom ""fast"" integrators (that leverage problem structure) and IMEX
integration of the ""slow"" time scale (to add diffusion).
"
1240,The DUNE Framework: Basic Concepts and Recent Developments,"  This paper presents the basic concepts and the module structure of the
Distributed and Unified Numerics Environment and reflects on recent
developments and general changes that happened since the release of the first
Dune version in 2007 and the main papers describing that state [1, 2]. This
discussion is accompanied with a description of various advanced features, such
as coupling of domains and cut cells, grid modifications such as adaptation and
moving domains, high order discretizations and node level performance,
non-smooth multigrid methods, and multiscale methods. A brief discussion on
current and future development directions of the framework concludes the paper.
"
1241,pylustrator: Code generation for reproducible figures for publication,"  One major challenge in science is to make all results potentially
reproducible. Thus, along with the raw data, every step from basic processing
of the data, evaluation, to the generation of the figures, has to be documented
as clearly as possible. While there are many programming libraries that cover
the basic processing and plotting steps (e.g. Matplotlib in Python), no library
yet addresses the reproducible composing of single plots into meaningful
figures for publication. Thus, up to now it is still state-of-the-art to
generate publishable figures using image-processing or vector-drawing software
leading to unwanted alterations of the presented data in the worst case and to
figure quality reduction in the best case. Pylustrator a open source library
based on the Matplotlib aims to fill this gap and provides a tool to easily
generate the code necessary to compose publication figures from single plots.
It provides a graphical user interface where the user can interactively compose
the figures. All changes are tracked and converted to code that is
automatically integrated into the calling script file. Thus, this software
provides the missing link from raw data to the complete plot published in
scientific journals and thus contributes to the transparency of the complete
evaluation procedure.
"
1242,"A user-guide to Gridap -- grid-based approximation of partial
  differential equations in Julia","  We present Gridap, a new scientific software library for the numerical
approximation of partial differential equations (PDEs) using grid-based
approximations. Gridap is an open-source software project exclusively written
in the Julia programming language. The main motivation behind the development
of this library is to provide an easy-to-use framework for the development of
complex PDE solvers in a dynamically typed style without sacrificing the
performance of statically typed languages. This work is a tutorial-driven user
guide to the library. It covers some popular linear and nonlinear PDE systems
for scalar and vector fields, single and multi-field problems, conforming and
nonconforming finite element discretizations, on structured and unstructured
meshes of simplices and hexahedra.
"
1243,GPU Fast Convolution via the Overlap-and-Save Method in Shared Memory,"  We present an implementation of the overlap-and-save method, a method for the
convolution of very long signals with short response functions, which is
tailored to GPUs. We have implemented several FFT algorithms (using the CUDA
programming language) which exploit GPU shared memory, allowing for GPU
accelerated convolution. We compare our implementation with an implementation
of the overlap-and-save algorithm utilizing the NVIDIA FFT library (cuFFT). We
demonstrate that by using a shared memory based FFT we can achieved significant
speed-ups for certain problem sizes and lower the memory requirements of the
overlap-and-save method on GPUs.
"
1244,"Enabling Distributed-Memory Tensor Completion in Python using New Sparse
  Tensor Kernels","  Tensor computations are increasingly prevalent numerical techniques in data
science, but pose unique challenges for high-performance implementation. We
provide novel algorithms and systems infrastructure, together enabling the
first high-level parallel implementations of three algorithms for the tensor
completion problem: alternating least squares (ALS), stochastic gradient
descent (SGD), and coordinate descent (CCD++). We develop these methods using a
new Python interface to the Cyclops tensor algebra library, which fully
automates the management of distributed-memory parallelism and sparsity for
NumPy-style operations on multidimensional arrays. To make possible tensor
completion for very sparse tensors, we introduce a new multi-tensor routine,
TTTP, that is asymptotically more efficient than pairwise tensor contraction
for key components of the tensor completion methods. In particular, we show how
TTTP can be used to perform an ALS via conjugate gradient with implicit
matrix-vector products, a novel tensor completion algorithm. Further, we
provide the first distributed tensor library with hypersparse matrix
representations, via integration of new sequential and parallel routines into
the Cyclops library. We provide microbenchmarking results on the Stampede2
supercomputer to demonstrate the efficiency of this functionality. Finally, we
study the performance of the tensor completion methods for a synthetic tensor
with 10 billion nonzeros and the Netflix dataset.
"
1245,Optimizing Geometric Multigrid Methods with Evolutionary Computation,"  For many linear and nonlinear systems that arise from the discretization of
partial differential equations the construction of an efficient multigrid
solver is a challenging task. Here we present a novel approach for the
optimization of geometric multigrid methods that is based on evolutionary
computation, a generic program optimization technique inspired by the principle
of natural evolution. A multigrid solver is represented as a tree of
mathematical expressions which we generate based on a tailored grammar. The
quality of each solver is evaluated in terms of convergence and compute
performance using automated local Fourier analysis (LFA) and roofline
performance modeling, respectively. Based on these objectives a multi-objective
optimization is performed using strongly typed genetic programming with a
non-dominated sorting based selection. To evaluate the model-based prediction
and to target concrete applications, scalable implementations of an evolved
solver can be automatically generated with the ExaStencils framework. We
demonstrate our approach by constructing multigrid solvers for the steady-state
heat equation with constant and variable coefficients that consistently perform
better than common V- and W-cycles.
"
1246,"DBCSR: A Library for Dense Matrix Multiplications on Distributed
  GPU-Accelerated Systems","  Most, if not all the modern scientific simulation packages utilize matrix
algebra operations. Among the operation of the linear algebra, one of the most
important kernels is the multiplication of matrices, dense and sparse. Examples
of application of such a kernel are in electronic structure calculations,
machine learning, data mining, graph processing, and digital signal processing.
Several optimized libraries exist that can achieve high-performance on
distributed systems. Only a few of them target distributed GPU-accelerated
systems. In most of the cases, these libraries are provided and optimized by
system vendors for their specific computer systems. In this paper, we present
the DBCSR library (Distributed Block Compressed Sparse Row) for the distributed
dense matrix-matrix multiplications. Although the library is specifically
designed for block-sparse matrix-matrix multiplications, we optimized it for
the dense case on GPU-accelerated systems. We show that the DBCSR outperforms
the multiplication of matrices of different sizes and shapes provided by a
vendor optimized GPU version of the ScaLAPACK library up to 2.5x (1.4x on
average).
"
1247,Implementing evaluation strategies for continuous real functions,"  We give a technical overview of our exact-real implementation of various
representations of the space of continuous unary real functions over the unit
domain and a family of associated (partial) operations, including integration,
range computation, as well as pointwise addition, multiplication, division,
sine, cosine, square root and maximisation.
  We use several representations close to the usual theoretical model, based on
an oracle that evaluates the function at a point or over an interval. We also
include several representations based on an oracle that computes a converging
sequence of rigorous (piecewise or one-piece) polynomial and rational
approximations over the whole unit domain. Finally, we describe ""local""
representations that combine both approaches, i.e. oracle-like representations
that return a rigorous symbolic approximation of the function over a requested
interval sub-domain with a requested effort.
  See also our paper ""Representations and evaluation strategies for feasibly
approximable functions"" which compares the efficiency of these representations
and algorithms and also formally describes and analyses one of the key
algorithms, namely a polynomial-time division of functions in a
piecewise-polynomial representation. We do not reproduce this division
algorithm here.
"
1248,"New robust ScaLAPACK routine for computing the QR factorization with
  column pivoting","  In this note we describe two modifications of the ScaLAPACK subroutines
PxGEQPF for computing the QR factorization with the Businger-Golub column
pivoting. First, we resolve a subtle numerical instability in the same way as
we have done it for the LAPACK subroutines xGEQPF, xGEQP3 in 2006. [LAPACK
Working Note 176 (2006); ACM Trans. Math. Softw. 2008]. The problem originates
in the first release of LINPACK in the 1970's: due to severe cancellations in
the down-dating of partial column norms, the pivoting procedure may be in the
dark completely about the true norms of the pivot column candidates. This may
cause miss-pivoting, and as a result loss of the important rank revealing
structure of the computed triangular factor, with severe consequences on other
solvers that rely on the rank revealing pivoting. The instability is so subtle
that, e.g., inserting a WRITE statement or changing the process topology can
drastically change the result. Secondly, we also correct a programming error in
the complex subroutines PCGEQPF, PZGEQPF, which also causes wrong pivoting
because of erroneous use of PSCNRM2, PDZNRM2 for the explicit norm computation.
"
1249,"Some remarks on the performance of Matlab, Python and Octave in
  simulating dynamical systems","  Matlab has been considered as a leader computational platform for many
engineering fields. Well documented and reliable, Matlab presents as a great
advantage its ability to increase the user productivity. However, Python and
Octave are among some of the languages that have challenged Matlab. Octave and
Python are well known examples of high-level scripting languages, with a great
advantage of being open source software. The novelty of this paper is devoted
to offer a comparison among these tree languages in the simulation of dynamical
systems. We have applied the lower bound error to estimate the error of
simulation. The comparison was performed with the chaotic systems Duffing-Ueda
oscillator and the Chua's circuit, both identified with polynomial NARMAX.
Octave presents the best reliable outcome. Nevertheless, Matlab needs the
lowest time to undertake the same activity. Python has presented the worse
result for the stop simulation criterion.
"
1250,"An Optimized, Parallel Computation of the Ghost Layer for Adaptive
  Hybrid Forest Meshes","  We discuss parallel algorithms to gather topological information about
off-process mesh neighbor elements. This information is commonly called the
ghost layer, whose creation is a fundamental, necessary task in executing most
parallel, element-based computer simulations. Approaches differ in that the
ghost layer may either be inherently part of the mesh data structure that is
maintained and modified, or kept separate and constructed/deleted as needed.
  In this work, we present an updated design following the latter approach,
which we favor for its modularity of algorithms and data structures. We target
arbitrary adaptive, non-conforming forest-of-(oc)trees meshes of mixed element
shapes, such as cubes, prisms, and tetrahedra, and restrict ourselves to
face-ghosts. Our algorithm has low complexity and redundancy since we reduce it
to generic codimension-1 subalgorithms that can be flexibly combined. We cover
several existing solutions as special cases and optimize further using
recursive, amortized tree searches and traversals.
"
1251,"NEP: a module for the parallel solution of nonlinear eigenvalue problems
  in SLEPc","  SLEPc is a parallel library for the solution of various types of large-scale
eigenvalue problems. In the last years we have been developing a module within
SLEPc, called NEP, that is intended for solving nonlinear eigenvalue problems.
These problems can be defined by means of a matrix-valued function that depends
nonlinearly on a single scalar parameter. We do not consider the particular
case of polynomial eigenvalue problems (which are implemented in a different
module in SLEPc) and focus here on rational eigenvalue problems and other
general nonlinear eigenproblems involving square roots or any other nonlinear
function. The paper discusses how the NEP module has been designed to fit the
needs of applications and provides a description of the available solvers,
including some implementation details such as parallelization. Several test
problems coming from real applications are used to evaluate the performance and
reliability of the solvers.
"
1252,"The deal.II finite element library: design, features, and insights","  deal.II is a state-of-the-art finite element library focused on generality,
dimension-independent programming, parallelism, and extensibility. Herein, we
outline its primary design considerations and its sophisticated features such
as distributed meshes, $hp$-adaptivity, support for complex geometries, and
matrix-free algorithms. But deal.II is more than just a software library: It is
also a diverse and worldwide community of developers and users, as well as an
educational platform. We therefore also discuss some of the technical and
social challenges and lessons learned in running a large community software
project over the course of two decades.
"
1253,"RationalizeRoots: Software Package for the Rationalization of Square
  Roots","  The computation of Feynman integrals often involves square roots. One way to
obtain a solution in terms of multiple polylogarithms is to rationalize these
square roots by a suitable variable change. We present a program that can be
used to find such transformations. After an introduction to the theoretical
background, we explain in detail how to use the program in practice.
"
1254,"Effect of Mixed Precision Computing on H-Matrix Vector Multiplication in
  BEM Analysis","  Hierarchical Matrix (H-matrix) is an approximation technique which splits a
target dense matrix into multiple submatrices, and where a selected portion of
submatrices are low-rank approximated. The technique substantially reduces both
time and space complexity of dense matrix vector multiplication, and hence has
been applied to numerous practical problems.
  In this paper, we aim to accelerate the H-matrix vector multiplication by
introducing mixed precision computing, where we employ both binary64 (FP64) and
binary32 (FP32) arithmetic operations. We propose three methods to introduce
mixed precision computing to H-matrix vector multiplication, and then evaluate
them in a boundary element method (BEM) analysis. The numerical tests examine
the effects of mixed precision computing, particularly on the required
simulation time and rate of convergence of the iterative (BiCG-STAB) linear
solver. We confirm the effectiveness of the proposed methods.
"
1255,"Abstractions and automated algorithms for mixed domain finite element
  methods","  Mixed dimensional partial differential equations (PDEs) are equations
coupling unknown fields defined over domains of differing topological
dimension. Such equations naturally arise in a wide range of scientific fields
including geology, physiology, biology and fracture mechanics. Mixed
dimensional PDEs are also commonly encountered when imposing non-standard
conditions over a subspace of lower dimension e.g. through a Lagrange
multiplier. In this paper, we present general abstractions and algorithms for
finite element discretizations of mixed domain and mixed dimensional PDEs of
co-dimension up to one (i.e. nD-mD with |n-m| <= 1). We introduce high level
mathematical software abstractions together with lower level algorithms for
expressing and efficiently solving such coupled systems. The concepts
introduced here have also been implemented in the context of the FEniCS finite
element software. We illustrate the new features through a range of examples,
including a constrained Poisson problem, a set of Stokes-type flow models and a
model for ionic electrodiffusion.
"
1256,"Exa-Dune -- Flexible PDE Solvers, Numerical Methods and Applications","  In the Exa-Dune project we have developed, implemented and optimised
numerical algorithms and software for the scalable solution of partial
differential equations (PDEs) on future exascale systems exhibiting a
heterogeneous massively parallel architecture. In order to cope with the
increased probability of hardware failures, one aim of the project was to add
flexible, application-oriented resilience capabilities into the framework.
Continuous improvement of the underlying hardware-oriented numerical methods
have included GPU-based sparse approximate inverses, matrix-free
sum-factorisation for high-order discontinuous Galerkin discretisations as well
as partially matrix-free preconditioners. On top of that, additional
scalability is facilitated by exploiting massive coarse grained parallelism
offered by multiscale and uncertainty quantification methods where we have
focused on the adaptive choice of the coarse/fine scale and the overlap region
as well as the combination of local reduced basis multiscale methods and the
multilevel Monte-Carlo algorithm. Finally, some of the concepts are applied in
a land-surface model including subsurface flow and surface runoff.
"
1257,DISROPT: a Python Framework for Distributed Optimization,"  In this paper we introduce DISROPT, a Python package for distributed
optimization over networks. We focus on cooperative set-ups in which an
optimization problem must be solved by peer-to-peer processors (without central
coordinators) that have access only to partial knowledge of the entire problem.
To reflect this, agents in DISROPT are modeled as entities that are initialized
with their local knowledge of the problem. Agents then run local routines and
communicate with each other to solve the global optimization problem. A simple
syntax has been designed to allow for an easy modeling of the problems. The
package comes with many distributed optimization algorithms that are already
embedded. Moreover, the package provides full-fledged functionalities for
communication and local computation, which can be used to design and implement
new algorithms. DISROPT is available at github.com/disropt/disropt under the
GPL license, with a complete documentation and many examples.
"
1258,TensorTrace: an application to contract tensor networks,"  Tensor network methods are a conceptually elegant framework for encoding
complicated datasets, where high-order tensors are approximated as networks of
low-order tensors. In practice, however, the numeric implementation of tensor
network algorithms is often a labor-intensive and error-prone task, even for
experienced researchers in this area. \emph{TensorTrace} is application
designed to alleviate the burden of contracting tensor networks: it provides a
graphic drawing interface specifically tailored for the construction of tensor
network diagrams, from which the code for their optimal contraction can then be
automatically generated (in the users choice of the MATLAB, Python or Julia
languages). \emph{TensorTrace} is freely available at
\url{https://www.tensortrace.com} with versions for Windows, Mac and Ubuntu.
"
1259,MOOSE: Enabling Massively Parallel Multiphysics Simulation,"  Harnessing modern parallel computing resources to achieve complex
multi-physics simulations is a daunting task. The Multiphysics Object Oriented
Simulation Environment (MOOSE) aims to enable such development by providing
simplified interfaces for specification of partial differential equations,
boundary conditions, material properties, and all aspects of a simulation
without the need to consider the parallel, adaptive, nonlinear, finite-element
solve that is handled internally. Through the use of interfaces and
inheritance, each portion of a simulation becomes reusable and composable in a
manner that allows disparate research groups to share code and create an
ecosystem of growing capability that lowers the barrier for the creation of
multiphysics simulation codes. Included within the framework is a unique
capability for building multiscale, multiphysics simulations through
simultaneous execution of multiple sub-applications with data transfers between
the scales. Other capabilities include automatic differentiation, scaling to a
large number of processors, hybrid parallelism, and mesh adaptivity. To date,
MOOSE-based applications have been created in areas of science and engineering
such as nuclear physics, geothermal science, magneto-hydrodynamics, seismic
events, compressible and incompressible fluid flow, microstructure evolution,
and advanced manufacturing processes.
"
1260,"The RaPID-OMEGA system: Room and Proctor Intelligent Decider for large
  scale tests programming","  We present the mathematical modeling for the problem of choosing rooms and
proctoring crews for massive tests, together with its implementation as the
open-box system RaPID-Omega. The mathematical model is a binary integer
programming problem: a combination of the 0-1 Knapsack problem and the
job-assignment problem. The model makes decisions according the following
criteria in order of priority: minimization of labor-hours, maximization of
equity in the distribution of duties and maximization of the proctoring
quality. The software is a digital solution for the aforementioned problem,
which is a common need in educational institutions offering large, coordinated,
lower-division courses. The system can be downloaded from
\url{https://sites.google.com/a/unal.edu.co/fernando-a-morales-j/home/research/software}
"
1261,"Role-Oriented Code Generation in an Engine for Solving Hyperbolic PDE
  Systems","  The development of a high performance PDE solver requires the combined
expertise of interdisciplinary teams with respect to application domain,
numerical scheme and low-level optimization. In this paper, we present how the
ExaHyPE engine facilitates the collaboration of such teams by isolating three
roles: application, algorithms, and optimization expert. We thus support team
members in letting them focus on their own area of expertise while integrating
their contributions into an HPC production code. Inspired by web application
development practices, ExaHyPE relies on two custom code generation modules,
the Toolkit and the Kernel Generator, which follow a Model-View-Controller
architectural pattern on top of the Jinja2 template engine library. Using
Jinja2's templates to abstract the critical components of the engine and
generated glue code, we isolate the application development from the engine.
The template language also allows us to define and use custom template macros
that isolate low-level optimizations from the numerical scheme described in the
templates. We present three use cases, each focusing on one of our user roles,
showcasing how the design of the code generation modules allows to easily
expand the solver schemes to support novel demands from applications, to add
optimized algorithmic schemes (with reduced memory footprint, e.g.), or provide
improved low-level SIMD vectorization support.
"
1262,"Semi-Automatic Task Graph Construction for $\mathcal{H}$-Matrix
  Arithmetic","  A new method to construct task graphs for \mcH-matrix arithmetic is
introduced, which uses the information associated with all tasks of the
standard recursive \mcH-matrix algorithms, e.g., the block index set of the
matrix blocks involved in the computation. Task refinement, i.e., the
replacement of tasks by sub-computations, is then used to proceed in the
\mcH-matrix hierarchy until the matrix blocks containing the actual matrix data
are reached. This process is a natural extension of the classical, recursive
way in which \mcH-matrix arithmetic is defined and thereby simplifies the
efficient usage of many-core systems. Examples for standard and accumulator
based \mcH-arithmetic are shown for model problems with different block
structures.
"
1263,MFEM: a modular finite element methods library,"  MFEM is an open-source, lightweight, flexible and scalable C++ library for
modular finite element methods that features arbitrary high-order finite
element meshes and spaces, support for a wide variety of discretization
approaches and emphasis on usability, portability, and high-performance
computing efficiency. MFEM's goal is to provide application scientists with
access to cutting-edge algorithms for high-order finite element meshing,
discretizations and linear solvers, while enabling researchers to quickly and
easily develop and test new algorithms in very general, fully unstructured,
high-order, parallel and GPU-accelerated settings. In this paper we describe
the underlying algorithms and finite element abstractions provided by MFEM,
discuss the software implementation, and illustrate various applications of the
library.
"
1264,The Linear Algebra Mapping Problem,"  We observe a disconnect between the developers and the end users of linear
algebra libraries. On the one hand, the numerical linear algebra and the
high-performance communities invest significant effort in the development and
optimization of highly sophisticated numerical kernels and libraries, aiming at
the maximum exploitation of both the properties of the input matrices, and the
architectural features of the target computing platform. On the other hand, end
users are progressively less likely to go through the error-prone and time
consuming process of directly using said libraries by writing their code in C
or Fortran; instead, languages and libraries such as Matlab, Julia, Eigen and
Armadillo, which offer a higher level of abstraction, are becoming more and
more popular. Users are given the opportunity to code matrix computations with
a syntax that closely resembles the mathematical description; it is then a
compiler or an interpreter that internally maps the input program to lower
level kernels, as provided by libraries such as BLAS and LAPACK. Unfortunately,
our experience suggests that in terms of performance, this translation is
typically vastly suboptimal.
  In this paper, we first introduce the Linear Algebra Mapping Problem, and
then investigate how effectively a benchmark of test problems is solved by
popular high-level programming languages. Specifically, we consider Matlab,
Octave, Julia, R, Armadillo (C++), Eigen (C++), and NumPy (Python); the
benchmark is meant to test both standard compiler optimizations such as common
subexpression elimination and loop-invariant code motion, as well as linear
algebra specific optimizations such as optimal parenthesization of a matrix
product and kernel selection for matrices with properties. The aim of this
study is to give concrete guidelines for the development of languages and
libraries that support linear algebra computations.
"
1265,"HILUCSI: Simple, Robust, and Fast Multilevel ILU for Large-Scale
  Saddle-Point Problems from PDEs","  Incomplete factorization is a widely used preconditioning technique for
Krylov subspace methods for solving large-scale sparse linear systems. Its
multilevel variants, such as those in ILUPACK and ARMS, are more robust for
many symmetric or unsymmetric linear systems than the traditional, single-level
incomplete LU (or ILU) techniques. However, multilevel ILU still lacked
robustness and efficiency for some large-scale saddle-point problems, which
often arise from systems of partial differential equations (PDEs). In this
work, we introduce HILUCSI, or Hierarchical Incomplete LU-Crout with
Scalability-oriented and Inverse-based dropping, which is specifically designed
to take advantage of some special features of such systems. HILUCSI differs
from the state-of-the-art ILU techniques in two main aspects. First, HILUCSI
leverages the near or partial symmetry of the underlying problems and the
inherent block structures of multilevel ILU to improve robustness and to
simplify the treatment of indefinite systems. Second, HILUCSI introduces a
scalability-oriented dropping in conjunction with a variant of inverse-based
dropping to improve the efficiency for large-scale problems from PDEs. We
demonstrate the effectiveness of HILUCSI for a number of benchmark problems,
including those from mixed formulation of the Poisson equation, Stokes
equations, and Navier-Stokes equations. We also compare its performance with
ILUPACK, the supernodal ILUTP in SuperLU, and multithreaded direct solvers in
PARDISO and MUMPS.
"
1266,Abstract Compilation for Verification of Numerical Accuracy Properties,"  Verification of numerical accuracy properties in modern software remains an
important and challenging task. This paper describes an original framework
combining different solutions for numerical accuracy. First, we extend an
existing runtime verification tool called E-ACSL with rational numbers to
monitor accuracy properties at runtime. Second, we present an abstract
compiler, FLDCompiler, that performs a source-to-source transformation such
that the execution of the resulting program, called an abstract execution, is
an abstract interpretation of the initial program. Third, we propose an
instrumentation library FLDLib that formally propagates accuracy properties
along an abstract execution. While each of these solutions has its own
interest, we emphasize the benefits of their combination for an industrial
setting. Initial experiments show that the proposed technique can efficiently
and soundly analyze the accuracy of industrial programs by restricting the
analysis on thin numerical scenarios.
"
1267,Eigen-AD: Algorithmic Differentiation of the Eigen Library,"  In this work we present useful techniques and possible enhancements when
applying an Algorithmic Differentiation (AD) tool to the linear algebra library
Eigen using our in-house AD by overloading (AD-O) tool dco/c++ as a case study.
After outlining performance and feasibility issues when calculating derivatives
for the official Eigen release, we propose Eigen-AD, which enables different
optimization options for an AD-O tool by providing add-on modules for Eigen.
The range of features includes a better handling of expression templates for
general performance improvements, as well as implementations of symbolically
derived expressions for calculating derivatives of certain core operations. The
software design allows an AD-O tool to provide specializations to automatically
include symbolic operations and thereby keep the look and feel of plain AD by
overloading. As a showcase, dco/c++ is provided with such a module and its
significant performance improvements are validated by benchmarks.
"
1268,"Using performance analysis tools for parallel-in-time integrators --
  Does my time-parallel code do what I think it does?","  While many ideas and proofs of concept for parallel-in-time integration
methods exists, the number of large-scale, accessible time-parallel codes is
rather small. This is often due to the apparent or subtle complexity of the
algorithms and the many pitfalls awaiting developers of parallel numerical
software. One example of such a time-parallel code is pySDC, which implements,
among others, the parallel full approximation scheme in space and time
(PFASST). Inspired by nonlinear multigrid ideas, PFASST allows to integrate
multiple time-steps simultaneously using a space-time hierarchy of spectral
deferred corrections. In this paper we demonstrate the application of
performance analysis tools to the PFASST implementation pySDC. Tracing the path
we took for this work, we highlight the obstacles encountered, describe
remedies and explain the sometimes surprising findings made possible by the
tools. Although focusing only on a single implementation of a particular
parallel-in-time integrator, we hope that our results and in particular the way
we obtained them are a blueprint for other time-parallel codes.
"
1269,"Replicated Computational Results (RCR) Report for ""Code Generation for
  Generally Mapped Finite Elements""","  ""Code Generation for Generally Mapped Finite Elements"" includes performance
results for the finite element methods discussed in that manuscript. The
authors provided a Zenodo archive with the Firedrake components and
dependencies used, as well as the scripts that generated the results. The
software was installed on two similar platforms; then, new results were
gathered and compared to the original results. After completing this process,
the results have been deemed replicable by the reviewer.
"
1270,"PFASST-ER: Combining the Parallel Full Approximation Scheme in Space and
  Time with parallelization across the method","  To extend prevailing scaling limits when solving time-dependent partial
differential equations, the parallel full approximation scheme in space and
time (PFASST) has been shown to be a promising parallel-in-time integrator.
Similar to a space-time multigrid, PFASST is able to compute multiple
time-steps simultaneously and is therefore in particular suitable for
large-scale applications on high performance computing systems. In this work we
couple PFASST with a parallel spectral deferred correction (SDC) method,
forming an unprecedented doubly time-parallel integrator. While PFASST provides
global, large-scale ""parallelization across the step"", the inner parallel SDC
method allows to integrate each individual time-step ""parallel across the
method"" using a diagonalized local Quasi-Newton solver. This new method, which
we call ""PFASST with Enhanced concuRrency"" (PFASST-ER), therefore exposes even
more temporal parallelism. For two challenging nonlinear reaction-diffusion
problems, we show that PFASST-ER works more efficiently than the classical
variants of PFASST and can be used to run parallel-in-time beyond the number of
time-steps.
"
1271,Recent Developments in Iterative Methods for Reducing Synchronization,"  On modern parallel architectures, the cost of synchronization among
processors can often dominate the cost of floating-point computation. Several
modifications of the existing methods have been proposed in order to keep the
communication cost as low as possible. This paper aims at providing a brief
overview of recent advances in parallel iterative methods for solving
large-scale problems. We refer the reader to the related references for more
details on the derivation, implementation, performance, and analysis of these
techniques.
"
1272,CheasePy,"  CheasePy is code written in Python to run the CHEASE (Cubic Hermite Element
Axisymmetric Static Equilibrium) code, which solves the Grad-Shafranov equation
for toroidal MHD equilibria using pressure and current profiles and fixed
plasma boundaries that is defined by a set of experimental data points (R,Z).
The CheasePy code allows an iterative running of the CHEASE code either to
check the preservation of MHD equilibria or converging to an experimentally
defined total toroidal plasma current by modifying any input quantity.
"
1273,bertha: Project Skeleton for Scientific Software,"  Science depends heavily on reliable and easy-to-use software packages, such
as mathematical libraries or data analysis tools. Developing such packages
requires a lot of effort, which is too often avoided due to the lack of funding
or recognition. In order to reduce the efforts required to create sustainable
software packages, we present a project skeleton that ensures the best software
engineering practices from the start of a project, or serves as reference for
existing projects.
"
1274,"PyTorch: An Imperative Style, High-Performance Deep Learning Library","  Deep learning frameworks have often focused on either usability or speed, but
not both. PyTorch is a machine learning library that shows that these two goals
are in fact compatible: it provides an imperative and Pythonic programming
style that supports code as a model, makes debugging easy and is consistent
with other popular scientific computing libraries, while remaining efficient
and supporting hardware accelerators such as GPUs.
  In this paper, we detail the principles that drove the implementation of
PyTorch and how they are reflected in its architecture. We emphasize that every
aspect of PyTorch is a regular Python program under the full control of its
user. We also explain how the careful and pragmatic implementation of the key
components of its runtime enables them to work together to achieve compelling
performance.
  We demonstrate the efficiency of individual subsystems, as well as the
overall speed of PyTorch on several common benchmarks.
"
1275,"High Performance Solution of Skew-symmetric Eigenvalue Problems with
  Applications in Solving the Bethe-Salpeter Eigenvalue Problem","  We present a high-performance solver for dense skew-symmetric matrix
eigenvalue problems. Our work is motivated by applications in computational
quantum physics, where one solution approach to solve the so-called
Bethe-Salpeter equation involves the solution of a large, dense, skew-symmetric
eigenvalue problem. The computed eigenpairs can be used to compute the optical
absorption spectrum of molecules and crystalline systems. One state-of-the art
high-performance solver package for symmetric matrices is the ELPA (Eigenvalue
SoLvers for Petascale Applications) library. We extend the methods available in
ELPA to skew-symmetric matrices. This way, the presented solution method can
benefit from the optimizations available in ELPA that make it a
well-established, efficient and scalable library, such as GPU support. We
compare performance and scalability of our method to the only available
high-performance approach for skew-symmetric matrices, an indirect route
involving complex arithmetic. In total, we achieve a performance that is up to
3.67 higher than the reference method using Intel's ScaLAPACK implementation.
The runtime to solve the Bethe-Salpeter-Eigenvalue problem can be improved by a
factor of 10. Our method is freely available in the current release of the ELPA
library.
"
1276,differint: A Python Package for Numerical Fractional Calculus,"  Fractional calculus has become widely studied and applied to physical
problems in recent years. As a result, many methods for the numerical
computation of fractional derivatives and integrals have been defined. However,
these algorithms are often programmed in an ad hoc manner, requiring
researchers to implement and debug their own code. This work introduces the
\textit{differint} software package, which offers a single repository for
multiple numerical algorithms for the computation of fractional derivatives and
integrals. This package is coded in the open-source Python programming
language. The Gr\""unwald-Letnikov, improved Gr\""unwald-Letnikov, and
Riemann-Liouville algorithms from the fractional calculus are included in this
package. The algorithms presented are computed from their descriptions found in
[2]. This work concludes with suggestions for the application of the
\textit{differint} software package.
"
1277,"High Accuracy Low Precision QR Factorization and Least Square Solver on
  GPU with TensorCore","  Driven by the insatiable needs to process ever larger amount of data with
more complex models, modern computer processors and accelerators are beginning
to offer half precision floating point arithmetic support, and extremely
optimized special units such as NVIDIA TensorCore on GPU and Google Tensor
Processing Unit (TPU) that does half precision matrix-matrix multiplication
exceptionally efficiently. In this paper we present a large scale mixed
precision linear least square solver that achieves high accuracy using the low
precision TensorCore GPU. The mixed precision system consists of both
innovative algorithms and implementations, and is shown to be up to 14x faster
than single precision cuSOLVER at QR matrix factorization at large scale with
slightly lower accuracy, and up to 10x faster than double precision direct QR
least square solver with comparable accuracy.
"
1278,"Alsvinn: A Fast multi-GPGPU finite volume solver with a strong emphasis
  on reproducibility","  We present the Alsvinn simulator, a fast multi general purpose graphical
processing unit (GPGPU) finite volume solver for hyperbolic conservation laws
in multiple space dimensions. Alsvinn has native support for uncertainty
quantifications, and exhibits excellent scaling on top tier compute clusters.
"
1279,"PETSc TSAdjoint: a discrete adjoint ODE solver for first-order and
  second-order sensitivity analysis","  We present a new software system PETSc TSAdjoint for first-order and
second-order adjoint sensitivity analysis of time-dependent nonlinear
differential equations. The derivative calculation in PETSc TSAdjoint is
essentially a high-level algorithmic differentiation process. The adjoint
models are derived by differentiating the timestepping algorithms and
implemented based on the parallel infrastructure in PETSc. Full differentiation
of the library code including MPI routines thus is avoided, and users do not
need to derive their own adjoint models for their specific applications. PETSc
TSAdjoint can compute the first-order derivative, that is, the gradient of a
scalar functional, and the Hessian-vector product that carries second-order
derivative information, while requiring minimal input (a few callbacks) from
the users. Optimal checkpointing schemes are employed by the adjoint model in a
manner that is transparent to users. Usability, efficiency, and scalability are
demonstrated through examples from a variety of applications.
"
1280,"PCPATCH: software for the topological construction of multigrid
  relaxation methods","  Effective relaxation methods are necessary for good multigrid convergence.
For many equations, standard Jacobi and Gau{\ss}-Seidel are inadequate, and
more sophisticated space decompositions are required; examples include problems
with semidefinite terms or saddle point structure. In this paper we present a
unifying software abstraction, PCPATCH, for the topological construction of
space decompositions for multigrid relaxation methods. Space decompositions are
specified by collecting topological entities in a mesh (such as all vertices or
facets) and applying a construction rule (such as taking all degrees of freedom
in the cells around each entity). The software is implemented in PETSc and
facilitates the elegant expression of a wide range of schemes merely by varying
solver options at runtime. In turn, this allows for the very rapid development
of fast solvers for difficult problems.
"
1281,Assembly of multiscale linear PDE operators,"  In numerous applications the mathematical model consists of different
processes coupled across a lower dimensional manifold. Due to the multiscale
coupling, finite element discretization of such models presents a challenge.
Assuming that only singlescale finite element forms can be assembled we present
here a simple algorithm for representing multiscale models as linear operators
suitable for Krylov methods. Flexibility of the approach is demonstrated by
numerical examples with coupling across dimensionality gap 1 and 2.
Preconditioners for several of the problems are discussed.
"
1282,"AVaN Pack: An Analytical/Numerical Solution for Variance-Based
  Sensitivity Analysis","  Sensitivity analysis is an important concept to analyze the influences of
parameters in a system, an equation or a collection of data. The methods used
for sensitivity analysis are divided into deterministic and statistical
techniques. Generally, deterministic techniques analyze fixed points of a model
whilst stochastic techniques analyze a range of values. Deterministic methods
fail in analyze the entire range of input values and stochastic methods
generate outcomes with random errors. In this manuscript, we are interested in
stochastic methods, mainly in variance-based techniques such as Variance and
Sobol indices, since this class of techniques is largely used on literature.
The objective of this manuscript is to present an analytical solution for
variance based sensitive analysis. As a result of this research, two small
programs were developed in Javascript named as AVaN Pack (Analysis of Variance
through Numerical solution). These programs allow users to find the
contribution of each individual parameter in any function by means of a
mathematical solution, instead of sampling-based ones.
"
1283,Strategies for the vectorized Block Conjugate Gradients method,"  Block Krylov methods have recently gained a lot of attraction. Due to their
increased arithmetic intensity they offer a promising way to improve
performance on modern hardware. Recently Frommer et al. presented a block
Krylov framework that combines the advantages of block Krylov methods and data
parallel methods. We review this framework and apply it on the Block Conjugate
Gradients method,to solve linear systems with multiple right hand sides. In
this course we consider challenges that occur on modern hardware, like a
limited memory bandwidth, the use of SIMD instructions and the communication
overhead. We present a performance model to predict the efficiency of different
Block CG variants and compare these with experimental numerical results.
"
1284,Linnea: Automatic Generation of Efficient Linear Algebra Programs,"  The translation of linear algebra computations into efficient sequences of
library calls is a non-trivial task that requires expertise in both linear
algebra and high-performance computing. Almost all high-level languages and
libraries for matrix computations (e.g., Matlab, Eigen) internally use
optimized kernels such as those provided by BLAS and LAPACK; however, their
translation algorithms are often too simplistic and thus lead to a suboptimal
use of said kernels, resulting in significant performance losses. In order to
combine the productivity offered by high-level languages, and the performance
of low-level kernels, we are developing Linnea, a code generator for linear
algebra problems. As input, Linnea takes a high-level description of a linear
algebra problem; as output, it returns an efficient sequence of calls to
high-performance kernels. Linnea uses a custom best-first search algorithm to
find a first solution in less than a second, and increasingly better solutions
when given more time. In 125 test problems, the code generated by Linnea almost
always outperforms Matlab, Julia, Eigen and Armadillo, with speedups up to and
exceeding 10x.
"
1285,"Medusa: A C++ Library for solving PDEs using Strong Form Mesh-Free
  methods","  Medusa, a novel library for implementation of strong form mesh-free methods,
is described. We identify and present common parts and patterns among many such
methods reported in the literature, such as node positioning, stencil selection
and stencil weight computation. Many different algorithms exist for each part
and the possible combinations offer a plethora of possibilities for
improvements of solution procedures that are far from fully understood. As a
consequence there are still many unanswered questions in mesh-free community
resulting in vivid ongoing research in the field. Medusa implements the core
mesh-free elements as independent blocks, which offers users great flexibility
in experimenting with the method they are developing, as well as easily
comparing it with other existing methods. The paper describes the chosen
abstractions and their usage, illustrates aspects of the philosophy and design,
offers some executions time benchmarks and demonstrates the application of the
library on cases from linear elasticity and fluid flow in irregular 2D and 3D
domains.
"
1286,LEoPart: a particle library for FEniCS,"  This paper introduces LEoPart, an add-on for the open source finite element
software library FEniCS to seamlessly integrate Lagrangian particle
functionality with (Eulerian) mesh-based finite element (FE) approaches.
LEoPart - which is so much as to say: `Lagrangian-Eulerian on Particles' -
contains tools for efficient, accurate and scalable advection of Lagrangian
particles on arbitrary polyhedral meshes. In addition, LEoPart comes with
several projection operators for exchanging information between the scattered
particles and the mesh and \textit{vice versa}. These projection operators are
based on a variational framework, which allows extension to high-order
accuracy. In particular, by implementing a dedicated PDE-constrained
particle-mesh projection operator, LEoPart provides all the tools for
diffusion-free advection, while simultaneously achieving optimal convergence
and ensuring conservation of the projected particle quantities on the
underlying mesh. A range of numerical examples that are prototypical to passive
and active tracer methods highlight the properties and the parallel performance
of the different tools in LEoPart. Finally, future developments are identified.
The source code for LEoPart is actively maintained and available under an open
source license at https://bitbucket.org/jakob_maljaars/leopart.
"
1287,"A Unified Iteration Space Transformation Framework for Sparse and Dense
  Tensor Algebra","  We address the problem of optimizing mixed sparse and dense tensor algebra in
a compiler. We show that standard loop transformations, such as strip-mining,
tiling, collapsing, parallelization and vectorization, can be applied to
irregular loops over sparse iteration spaces. We also show how these
transformations can be applied to the contiguous value arrays of sparse tensor
data structures, which we call their position space, to unlock load-balanced
tiling and parallelism.
  We have prototyped these concepts in the open-source TACO system, where they
are exposed as a scheduling API similar to the Halide domain-specific language
for dense computations. Using this scheduling API, we show how to optimize
mixed sparse/dense tensor algebra expressions, how to generate load-balanced
code by scheduling sparse tensor algebra in position space, and how to generate
sparse tensor algebra GPU code. Our evaluation shows that our transformations
let us generate good code that is competitive with many hand-optimized
implementations from the literature.
"
1288,"Issues with rounding in the GCC implementation of the ISO 18037:2008
  standard fixed-point arithmetic","  We describe various issues caused by the lack of round-to-nearest mode in the
\textit{gcc} compiler implementation of the fixed-point arithmetic data types
and operations. We demonstrate that round-to-nearest is not performed in the
conversion of constants, conversion from one numerical type to a less precise
type and results of multiplications. Furthermore, we show that mixed-precision
operations in fixed-point arithmetic lose precision on arguments, even before
carrying out arithmetic operations. The ISO 18037:2008 standard was created to
standardize C language extensions, including fixed-point arithmetic, for
embedded systems. Embedded systems are usually based on ARM processors, of
which approximately 100 billion have been manufactured by now. Therefore, the
observations about numerical issues that we discuss in this paper can be rather
dangerous and are important to address, given the wide ranging type of
applications that these embedded systems are running.
"
1289,"A Hybrid MPI-CUDA Approach for Nonequispaced Discrete Fourier
  Transformation","  Nonequispaced discrete Fourier transformation (NDFT) is widely applied in all
aspects of computational science and engineering. The computational efficiency
and accuracy of NDFT has always been a critical issue in hindering its
comprehensive applications both in intensive and in extensive aspects of
scientific computing. In our previous work (2018, S.-C. Yang et al., Appl.
Comput. Harmon. Anal. 44, 273), a CUNFFT method was proposed and it shown
outstanding performance in handling NDFT at intermediate scale based on CUDA
(Compute Unified Device Architecture) technology. In the current work, we
further improved the computational efficiency of the CUNTTF method using an
efficient MPI-CUDA hybrid parallelization (HP) scheme of NFFT to achieve a
cutting-edge treatment of NDFT at super extended scale. Within this HP-NFFT
method, the spatial domain of NDFT is decomposed into several parts according
to the accumulative feature of NDFT and the detailed number of CPU and GPU
nodes. These decomposed NDFT subcells are independently calculated on different
CPU nodes using a MPI process-level parallelization mode, and on different GPU
nodes using a CUDA threadlevel parallelization mode and CUNFFT algorithm. A
massive benchmarking of the HP-NFFT method indicates that this method exhibit a
dramatic improvement in computational efficiency for handling NDFT at super
extended scale without loss of computational precision. Furthermore, the
HP-NFFT method is validated via the calculation of Madelung constant of
fluorite crystal structure, and thereafter verified that this method is robust
for the calculation of electrostatic interactions between charged ions in
molecular dynamics simulation systems.
"
1290,"Comparing Python, Go, and C++ on the N-Queens Problem","  Python currently is the dominant language in the field of Machine Learning
but is often criticized for being slow to perform certain tasks. In this
report, we use the well-known $N$-queens puzzle as a benchmark to show that
once compiled using the Numba compiler it becomes competitive with C++ and Go
in terms of execution speed while still allowing for very fast prototyping.
This is true of both sequential and parallel programs. In most cases that arise
in an academic environment, it therefore makes sense to develop in ordinary
Python, identify computational bottlenecks, and use Numba to remove them.
"
1291,"Automatic Generation of Efficient Sparse Tensor Format Conversion
  Routines","  This paper shows how to generate code that efficiently converts sparse
tensors between disparate storage formats (data layouts) such as CSR, DIA, ELL,
and many others. We decompose sparse tensor conversion into three logical
phases: coordinate remapping, analysis, and assembly. We then develop a
language that precisely describes how different formats group together and
order a tensor's nonzeros in memory. This lets a compiler emit code that
performs complex remappings of nonzeros when converting between formats. We
also develop a query language that can extract statistics about sparse tensors,
and we show how to emit efficient analysis code that computes such queries.
Finally, we define an abstract interface that captures how data structures for
storing a tensor can be efficiently assembled given specific statistics about
the tensor. Disparate formats can implement this common interface, thus letting
a compiler emit optimized sparse tensor conversion code for arbitrary
combinations of many formats without hard-coding for any specific combination.
  Our evaluation shows that the technique generates sparse tensor conversion
routines with performance between 1.00 and 2.01$\times$ that of hand-optimized
versions in SPARSKIT and Intel MKL, two popular sparse linear algebra
libraries. And by emitting code that avoids materializing temporaries, which
both libraries need for many combinations of source and target formats, our
technique outperforms those libraries by 1.78 to 4.01$\times$ for CSC/COO to
DIA/ELL conversion.
"
1292,"Awkward Arrays in Python, C++, and Numba","  The Awkward Array library has been an important tool for physics analysis in
Python since September 2018. However, some interface and implementation issues
have been raised in Awkward Array's first year that argue for a
reimplementation in C++ and Numba. We describe those issues, the new
architecture, and present some examples of how the new interface will look to
users. Of particular importance is the separation of kernel functions from data
structure management, which allows a C++ implementation and a Numba
implementation to share kernel functions, and the algorithm that transforms
record-oriented data into columnar Awkward Arrays.
"
1293,"MonteCarloMeasurements.jl: Nonlinear Propagation of Arbitrary
  Multivariate Distributions by means of Method Overloading","  This manuscript outlines a software package that facilitates working with
probability distributions by means of Monte-Carlo methods, in a way that allows
for propagation of multivariate probability distributions through arbitrary
functions. We provide a \emph{type} that represents probability distributions
by an internal vector of unweighted samples, \texttt{Particles}, which is a
subtype of a \texttt{Real} number and behaves just like a regular real number
in calculations by means of method overloading. This makes the software easy to
work with and presents minimal friction for the user. We highlight how this
design facilitates optimal usage of SIMD instructions and showcase the package
for uncertainty propagation through an off-the-shelf ODE solver, as well as for
robust probabilistic optimization with automatic differentiation.
"
1294,Automatically Harnessing Sparse Acceleration,"  Sparse linear algebra is central to many scientific programs, yet compilers
fail to optimize it well. High-performance libraries are available, but
adoption costs are significant. Moreover, libraries tie programs into
vendor-specific software and hardware ecosystems, creating non-portable code.
  In this paper, we develop a new approach based on our specification Language
for implementers of Linear Algebra Computations (LiLAC). Rather than requiring
the application developer to (re)write every program for a given library, the
burden is shifted to a one-off description by the library implementer. The
LiLAC-enabled compiler uses this to insert appropriate library routines without
source code changes.
  LiLAC provides automatic data marshaling, maintaining state between calls and
minimizing data transfers. Appropriate places for library insertion are
detected in compiler intermediate representation, independent of source
languages.
  We evaluated on large-scale scientific applications written in FORTRAN;
standard C/C++ and FORTRAN benchmarks; and C++ graph analytics kernels. Across
heterogeneous platforms, applications and data sets we show speedups of
1.1$\times$ to over 10$\times$ without user intervention.
"
1295,"juSFEM: A Julia-based Open-source Package of Parallel Smoothed Finite
  Element Method (S-FEM) for Elastic Problems","  The Smoothed Finite Element Method (S-FEM) proposed by Liu G.R. can achieve
more accurate results than the conventional FEM. Currently, much commercial
software and many open-source packages have been developed to analyze various
science and engineering problems using the FEM. However, there is little work
focusing on designing and developing software or packages for the S-FEM. In
this paper, we design and implement an open-source package of the parallel
S-FEM for elastic problems by utilizing the Julia language on multi-core CPU.
The Julia language is a fast, easy-to-use, and open-source programming language
that was originally designed for high-performance computing. We term our
package as juSFEM. To the best of the authors knowledge, juSFEM is the first
package of parallel S-FEM developed with the Julia language. To verify the
correctness and evaluate the efficiency of juSFEM, two groups of benchmark
tests are conducted. The benchmark results show that (1) juSFEM can achieve
accurate results when compared to commercial FEM software ABAQUS, and (2)
juSFEM only requires 543 seconds to calculate the displacements of a 3D elastic
cantilever beam model which is composed of approximately 2 million tetrahedral
elements, while in contrast the commercial FEM software needs 930 seconds for
the same calculation model; (3) the parallel juSFEM executed on the 24-core CPU
is approximately 20x faster than the corresponding serial version. Moreover,
the structure and function of juSFEM are easily modularized, and the code in
juSFEM is clear and readable, which is convenient for further development.
"
1296,Fast Cubic Spline Interpolation,"  The Numerical Recipes series of books are a useful resource, but all the
algorithms they contain cannot be used within open-source projects. In this
paper we develop drop-in alternatives to the two algorithms they present for
cubic spline interpolation, showing as much of our work as possible to allow
for replication or criticsm. The output of the new algorithms is compared to
the old, and found to be no different within the limits imposed by
floating-point precision. Benchmarks of all these algorithms, plus variations
which may run faster in certain instances, are performed. In general, all these
algorithms have approximately the same execution time when interpolating curves
with few control points on feature-rich Intel processors; as the number of
control points increases or processor features are removed, the new algorithms
become consistently faster than the old. Exceptions to that generalization are
explored to create implementation guidelines, such as when to expect division
to be faster than multiplication.
"
1297,"SLEEF: A Portable Vectorized Library of C Standard Mathematical
  Functions","  In this paper, we present techniques used to implement our portable
vectorized library of C standard mathematical functions written entirely in C
language. In order to make the library portable while maintaining good
performance, intrinsic functions of vector extensions are abstracted by inline
functions or preprocessor macros. We implemented the functions so that they can
use sub-features of vector extensions such as fused multiply-add, mask
registers and extraction of mantissa. In order to make computation with SIMD
instructions efficient, the library only uses a small number of conditional
branches, and all the computation paths are vectorized. We devised a variation
of the Payne-Hanek argument reduction for trigonometric functions and a
floating point remainder, both of which are suitable for vector computation. We
compare the performance of our library to Intel SVML.
"
1298,"lbmpy: Automatic code generation for efficient parallel lattice
  Boltzmann methods","  Lattice Boltzmann methods are a popular mesoscopic alternative to macroscopic
computational fluid dynamics solvers. Many variants have been developed that
vary in complexity, accuracy, and computational cost. Extensions are available
to simulate multi-phase, multi-component, turbulent, or non-Newtonian flows. In
this work we present lbmpy, a code generation package that supports a wide
variety of different methods and provides a generic development environment for
new schemes as well. A high-level domain-specific language allows the user to
formulate, extend and test various lattice Boltzmann schemes. The method
specification is represented in a symbolic intermediate representation.
Transformations that operate on this intermediate representation optimize and
parallelize the method, yielding highly efficient lattice Boltzmann compute
kernels not only for single- and two-relaxation-time schemes but also for
multi-relaxation-time, cumulant, and entropically stabilized methods. An
integration into the HPC framework waLBerla makes massively parallel,
distributed simulations possible, which is demonstrated through scaling
experiments on the SuperMUC-NG supercomputing system
"
1299,"A toolbox of Equation-Free functions in Matlab\Octave for efficient
  system level simulation","  The `equation-free toolbox' empowers the computer-assisted analysis of
complex, multiscale systems. Its aim is to enable you to immediately use
microscopic simulators to perform macro-scale system level tasks and analysis,
because micro-scale simulations are often the best available description of a
system. The methodology bypasses the derivation of macroscopic evolution
equations by computing the micro-scale simulator only over short bursts in time
on small patches in space, with bursts and patches well-separated in time and
space respectively. We introduce the suite of coded equation-free functions in
an accessible way, link to more detailed descriptions, discuss their
mathematical support, and introduce a novel and efficient algorithm for
Projective Integration. Some facets of toolbox development of equation-free
functions are then detailed. Download the toolbox functions
(https://github.com/uoa1184615/EquationFreeGit) and use to empower efficient
and accurate simulation in a wide range of your science and engineering
problems.
"
1300,Large-Scale Discrete Fourier Transform on TPUs,"  In this work, we present two parallel algorithms for the large-scale discrete
Fourier transform (DFT) on Tensor Processing Unit (TPU) clusters. The two
parallel algorithms are associated with two formulations of DFT: one is based
on the Kronecker product, to be specific, dense matrix multiplications between
the input data and the Vandermonde matrix, denoted as KDFT in this work; the
other is based on the famous Cooley-Tukey algorithm and phase adjustment,
denoted as FFT in this work. Both KDFT and FFT formulations take full advantage
of TPU's strength in matrix multiplications. In the two parallel algorithms,
the same strategy of data decomposition is applied to the input data. Through
the data decomposition, the dense matrix multiplications in KDFT and the
Cooley-Tukey-algorithm-based transform in FFT are kept local within TPU cores
and can be performed completely in parallel. The communication among TPU cores
is achieved through the one-shuffle scheme in both parallel algorithms, with
which sending and receiving data takes place simultaneously between two
neighboring cores and along the same direction on the interconnect network. The
one-shuffle scheme is designed for the interconnect topology of TPU clusters,
minimizing the time required by the communication among TPU cores. Both
parallel algorithms, namely, KDFT and FFT, are implemented in TensorFlow owing
to its rich set of functionalities for scientific computing and simplicity in
realizing parallel computing algorithms. The three-dimensional complex DFT is
performed on an example of dimension $8192 \times 8192 \times 8192$ with a full
TPU Pod: the run time of KDFT is 12.66 seconds and that of FFT is 8.3 seconds.
Strong and weak scaling analyses are provided to demonstrate the high parallel
efficiency of the two DFT implementations on TPUs.
"
1301,Butterfly factorization via randomized matrix-vector multiplications,"  This paper presents an adaptive randomized algorithm for computing the
butterfly factorization of a $m\times n$ matrix with $m\approx n$ provided that
both the matrix and its transpose can be rapidly applied to arbitrary vectors.
The resulting factorization is composed of $O(\log n)$ sparse factors, each
containing $O(n)$ nonzero entries. The factorization can be attained using
$O(n^{3/2}\log n)$ computation and $O(n\log n)$ memory resources. The proposed
algorithm applies to matrices with strong and weak admissibility conditions
arising from surface integral equation solvers with a rigorous error bound, and
is implemented in parallel.
"
1302,pymoo: Multi-objective Optimization in Python,"  Python has become the programming language of choice for research and
industry projects related to data science, machine learning, and deep learning.
Since optimization is an inherent part of these research fields, more
optimization related frameworks have arisen in the past few years. Only a few
of them support optimization of multiple conflicting objectives at a time, but
do not provide comprehensive tools for a complete multi-objective optimization
task. To address this issue, we have developed pymoo, a multi-objective
optimization framework in Python. We provide a guide to getting started with
our framework by demonstrating the implementation of an exemplary constrained
multi-objective optimization scenario. Moreover, we give a high-level overview
of the architecture of pymoo to show its capabilities followed by an
explanation of each module and its corresponding sub-modules. The
implementations in our framework are customizable and algorithms can be
modified/extended by supplying custom operators. Moreover, a variety of single,
multi and many-objective test problems are provided and gradients can be
retrieved by automatic differentiation out of the box. Also, pymoo addresses
practical needs, such as the parallelization of function evaluations, methods
to visualize low and high-dimensional spaces, and tools for multi-criteria
decision making. For more information about pymoo, readers are encouraged to
visit: https://pymoo.org
"
1303,FEAST Eigenvalue Solver v4.0 User Guide,"  The FEAST library package represents an unified framework for solving various
family of eigenvalue problems and achieving accuracy, robustness,
high-performance and scalability on parallel architectures. Its originality
lies with a new transformative numerical approach to the traditional eigenvalue
algorithm design - the FEAST algorithm. The algorithm gathers key elements from
complex analysis, numerical linear algebra and approximation theory, to
construct an optimal subspace iteration technique using approximate spectral
projectors. FEAST can be used for solving both standard and generalized forms
of the Hermitian or non-Hermitian problems (linear or non-linear), and it
belongs to the family of contour integration eigensolvers. FEAST's main
computational task consists of a numerical quadrature computation that involves
solving independent linear systems along a complex contour, each with multiple
right hand sides. In v4.0, FEAST has been reimplemented using an inverse
residual iteration algorithm which enables the linear systems to be solved with
very low accuracy (in single precision) with no impact on the FEAST double
precision convergence rate. As a result, v4.0 is on average 3-4 times faster
than v2.1 and v3.0 using new default optimization parameters (v2.1 has been
featured as Intel-MKL's principal HPC eigensolver since 2013). v4.0 also
implements new important features such as IFEAST (using Inexact Iterative
solver), Non-linear polynomial FEAST, and PFEAST with its 3-MPI levels of
parallelism. FEAST is both a comprehensive library package, and an easy to use
software. It includes flexible reverse communication interfaces and ready to
use driver interfaces for dense, banded and sparse systems.
"
1304,"The Space of Mathematical Software Systems -- A Survey of Paradigmatic
  Systems","  Mathematical software systems are becoming more and more important in pure
and applied mathematics in order to deal with the complexity and scalability
issues inherent in mathematics. In the last decades we have seen a cambric
explosion of increasingly powerful but also diverging systems. To give
researchers a guide to this space of systems, we devise a novel
conceptualization of mathematical software that focuses on five aspects:
inference covers formal logic and reasoning about mathematical statements via
proofs and models, typically with strong emphasis on correctness; computation
covers algorithms and software libraries for representing and manipulating
mathematical objects, typically with strong emphasis on efficiency;
concretization covers generating and maintaining collections of mathematical
objects conforming to a certain pattern, typically with strong emphasis on
complete enumeration; narration covers describing mathematical contexts and
relations, typically with strong emphasis on human readability; finally,
organization covers representing mathematical contexts and objects in
machine-actionable formal languages, typically with strong emphasis on
expressivity and system interoperability. Despite broad agreement that an ideal
system would seamlessly integrate all these aspects, research has diversified
into families of highly specialized systems focusing on a single aspect and
possibly partially integrating others, each with their own communities,
challenges, and successes. In this survey, we focus on the commonalities and
differences of these systems from the perspective of a future multi-aspect
system.
"
1305,"Task-based, GPU-accelerated and Robust Library for Solving Dense
  Nonsymmetric Eigenvalue Problems","  In this paper, we present the StarNEig library for solving dense nonsymmetric
standard and generalized eigenvalue problems. The library is built on top of
the StarPU runtime system and targets both shared and distributed memory
machines. Some components of the library have support for GPU acceleration. The
library is currently in an early beta state and supports only real matrices.
Support for complex matrices is planned for a future release. This paper is
aimed at potential users of the library. We describe the design choices and
capabilities of the library, and contrast them to existing software such as
ScaLAPACK. StarNEig implements a ScaLAPACK compatibility layer which should
assist new users in the transition to StarNEig. We demonstrate the performance
of the library with a sample of computational experiments.
"
1306,Computing rank-revealing factorizations of matrices stored out-of-core,"  This paper describes efficient algorithms for computing rank-revealing
factorizations of matrices that are too large to fit in RAM, and must instead
be stored on slow external memory devices such as solid-state or spinning disk
hard drives (out-of-core or out-of-memory). Traditional algorithms for
computing rank revealing factorizations, such as the column pivoted QR
factorization, or techniques for computing a full singular value decomposition
of a matrix, are very communication intensive. They are naturally expressed as
a sequence of matrix-vector operations, which become prohibitively expensive
when data is not available in main memory. Randomization allows these methods
to be reformulated so that large contiguous blocks of the matrix can be
processed in bulk. The paper describes two distinct methods. The first is a
blocked version of column pivoted Householder QR, organized as a ""left-looking""
method to minimize the number of write operations (which are more expensive
than read operations on a spinning disk drive). The second method results in a
so called UTV factorization which expresses a matrix $A$ as $A = U T V^*$ where
$U$ and $V$ are unitary, and $T$ is triangular. This method is organized as an
algorithm-by-blocks, in which floating point operations overlap read and write
operations. The second method incorporates power iterations, and is
exceptionally good at revealing the numerical rank; it can often be used as a
substitute for a full singular value decomposition. Numerical experiments
demonstrate that the new algorithms are almost as fast when processing data
stored on a hard drive as traditional algorithms are for data stored in main
memory. To be precise, the computational time for fully factorizing an $n\times
n$ matrix scales as $cn^{3}$, with a scaling constant $c$ that is only
marginally larger when the matrix is stored out of core.
"
1307,"hyper.deal: An efficient, matrix-free finite-element library for
  high-dimensional partial differential equations","  This work presents the efficient, matrix-free finite-element library
hyper.deal for solving partial differential equations in two to six dimensions
with high-order discontinuous Galerkin methods. It builds upon the
low-dimensional finite-element library deal.II to create complex
low-dimensional meshes and to operate on them individually. These meshes are
combined via a tensor product on the fly and the library provides new
special-purpose highly optimized matrix-free functions exploiting domain
decomposition as well as shared memory via MPI-3.0 features. Both node-level
performance analyses and strong/weak-scaling studies on up to 147,456 CPU cores
confirm the efficiency of the implementation. Results of the library hyper.deal
are reported for high-dimensional advection problems and for the solution of
the Vlasov--Poisson equation in up to 6D phase space.
"
1308,NeuralSens: Sensitivity Analysis of Neural Networks,"  Neural networks are important tools for data-intensive analysis and are
commonly applied to model non-linear relationships between dependent and
independent variables. However, neural networks are usually seen as ""black
boxes"" that offer minimal information about how the input variables are used to
predict the response in a fitted model. This article describes the
\pkg{NeuralSens} package that can be used to perform sensitivity analysis of
neural networks using the partial derivatives method. Functions in the package
can be used to obtain the sensitivities of the output with respect to the input
variables, evaluate variable importance based on sensitivity measures and
characterize relationships between input and output variables. Methods to
calculate sensitivities are provided for objects from common neural network
packages in \proglang{R}, including \pkg{neuralnet}, \pkg{nnet}, \pkg{RSNNS},
\pkg{h2o}, \pkg{neural}, \pkg{forecast} and \pkg{caret}. The article presents
an overview of the techniques for obtaining information from neural network
models, a theoretical foundation of how are calculated the partial derivatives
of the output with respect to the inputs of a multi-layer perceptron model, a
description of the package structure and functions, and applied examples to
compare \pkg{NeuralSens} functions with analogous functions from other
available \proglang{R} packages.
"
1309,SplineLib: A Modern Multi-Purpose C++ Spline Library,"  This paper provides the description of a novel, multi-purpose spline library.
In accordance with the increasingly diverse modes of usage of splines, it is
multi-purpose in the sense that it supports geometry representation, finite
element analysis, and optimization. The library features reading and writing
for various file formats and a wide range of spline manipulation algorithms.
Further, a new efficient and objective-oriented algorithm for B-spline basis
function evaluation is included. All features are available by a spline-type
independent interface. The library is written in modern C++ with CMake as build
system. This enables it for usage in typical scientific applications. It is
provided as open-source library.
"
1310,MORLAB -- The Model Order Reduction LABoratory,"  For an easy use of model order reduction techniques in applications, software
solutions are needed. In this paper, we describe the MORLAB, Model Order
Reduction LABoratory, toolbox as an efficient implementation of model reduction
techniques for dense, medium-scale linear time-invariant systems. Giving an
introduction to the underlying programming principles of the toolbox, we show
the basic idea of spectral splitting and present an overview about implemented
model reduction techniques. Two numerical examples are used to illustrate
different use cases of the MORLAB toolbox.
"
1311,NLOptControl: A modeling language for solving optimal control problems,"  Current direct-collocation-based optimal control software is either easy to
use or fast, but not both. This is a major limitation for users that are trying
to formulate complex optimal control problems (OCPs) for use in on-line
applications. This paper introduces NLOptControl, an open-source modeling
language that allows users to both easily formulate and quickly solve nonlinear
OCPs using direct-collocation methods. To achieve these attributes,
NLOptControl (1) is written in an efficient, dynamically-typed computing
language called Julia, (2) extends an optimization modeling language called
JuMP to provide a natural algebraic syntax for modeling nonlinear OCPs; and (3)
uses reverse automatic differentiation with the acrylic-coloring method to
exploit sparsity in the Hessian matrix. This work explores the novel design
features of NLOptControl and compares its syntax and speed to those of PROPT.
The syntax comparisons shows that NLOptControl models OCPs more concisely than
PROPT. The speeds of various collocation methods within PROPT and NLOptControl
are benchmarked over a range of collocation points using performance profiles;
overall, NLOptControl's single, two, and four interval pseudospectral methods
are roughly $14$, $26$, and $36$ times faster than PROPT's, respectively.
NLOptControl is well-suited to improve existing off-line and on-line control
systems and to engender new ones.
"
1312,"Matrix Equations, Sparse Solvers: M-M.E.S.S.-2.0.1 -- Philosophy,
  Features and Application for (Parametric) Model","  Matrix equations are omnipresent in (numerical) linear algebra and systems
theory. Especially in model order reduction (MOR) they play a key role in many
balancing based reduction methods for linear dynamical systems. When these
systems arise from spatial discretizations of evolutionary partial differential
equations, their coefficient matrices are typically large and sparse. Moreover,
the numbers of inputs and outputs of these systems are typically far smaller
than the number of spatial degrees of freedom. Then, in many situations the
solutions of the corresponding large-scale matrix equations are observed to
have low (numerical) rank. This feature is exploited by M-M.E.S.S. to find
successively larger low-rank factorizations approximating the solutions. This
contribution describes the basic philosophy behind the implementation and the
features of the package, as well as its application in the model order
reduction of large-scale linear time-invariant (LTI) systems and parametric LTI
systems.
"
1313,"COMPLEX-IT: A Case-Based Modeling and Scenario Simulation Platform for
  Social Inquiry","  COMPLEX-IT is a case-based, mixed-methods platform for social inquiry into
complex data/systems, designed to increase non-expert access to the tools of
computational social science (i.e., cluster analysis, artificial intelligence,
data visualization, data forecasting, and scenario simulation). In particular,
COMPLEX-IT aids social inquiry though a heavy emphasis on learning about the
complex data/system under study, which it does by (a) identifying and
forecasting major and minor clusters/trends; (b) visualizing their complex
causality; and (c) simulating scenarios for potential interventions. COMPLEX-IT
is accessible through the web or can be run locally and is powered by R and the
Shiny web framework.
"
1314,"Airline Crew Pairing Optimization Framework for Large Networks with
  Multiple Crew Bases and Hub-and-Spoke Subnetworks","  Crew Pairing Optimization aims at generating a set of flight sequences (crew
pairings), covering all flights in an airline's flight schedule, at minimum
cost, while satisfying several legality constraints. CPO is critically
important for airlines' business viability, considering that the crew operating
cost is their second-largest expense. It poses an NP-hard combinatorial
optimization problem, to tackle which, the state-of-the-art relies on relaxing
the underlying Integer Programming Problem (IPP) into a Linear Programming
Problem (LPP), solving the latter through Column Generation (CG) technique, and
integerization of the resulting LPP solution. However, with the growing scale
and complexity of the flight networks (those with a large number of flights,
multiple crew bases and/or multiple hub-and-spoke subnetworks), the utility of
the conventional CG-practices has become questionable. This paper proposed an
Airline Crew Pairing Optimization Framework, AirCROP, whose constitutive
modules include the Legal Crew Pairing Generator, Initial Feasible Solution
Generator, and an Optimization Engine built on heuristic-based
CG-implementation. In this paper, besides the design of AirCROP's modules,
insights into important questions related to how these modules interact, which
the literature is otherwise silent on, have been shared. These relate to the
sensitivity of AirCROP's performance towards: sources of variability over
multiple runs for a given problem, initialization method, and termination
parameters for LPP-solutioning and IPP-solutioning. The efficacy of the AirCROP
has been demonstrated on real-world large-scale and complex flight networks
(with over 4200 flights, 15 crew bases, and billion-plus pairings). It is hoped
that with the emergence of such complex flight networks, this paper shall serve
as an important milestone for affiliated research and applications.
"
1315,Flexible numerical optimization with ensmallen,"  This report provides an introduction to the ensmallen numerical optimization
library, as well as a deep dive into the technical details of how it works. The
library provides a fast and flexible C++ framework for mathematical
optimization of arbitrary user-supplied functions. A large set of pre-built
optimizers is provided, including many variants of Stochastic Gradient Descent
and Quasi-Newton optimizers. Several types of objective functions are
supported, including differentiable, separable, constrained, and categorical
objective functions. Implementation of a new optimizer requires only one
method, while a new objective function requires typically only one or two C++
methods. Through internal use of C++ template metaprogramming, ensmallen
provides support for arbitrary user-supplied callbacks and automatic inference
of unsupplied methods without any runtime overhead. Empirical comparisons show
that ensmallen outperforms other optimization frameworks (such as Julia and
SciPy), sometimes by large margins. The library is available at
https://ensmallen.org and is distributed under the permissive BSD license.
"
1316,"Parallel Robust Computation of Generalized Eigenvectors of Matrix
  Pencils","  In this paper we consider the problem of computing generalized eigenvectors
of a matrix pencil in real Schur form. In exact arithmetic, this problem can be
solved using substitution. In practice, substitution is vulnerable to
floating-point overflow. The robust solvers xTGEVC in LAPACK prevent overflow
by dynamically scaling the eigenvectors. These subroutines are sequential
scalar codes which compute the eigenvectors one by one. In this paper we
discuss how to derive robust blocked algorithms. The new StarNEig library
contains a robust task-parallel solver Zazamoukh which runs on top of StarPU.
Our numerical experiments show that Zazamoukh achieves a super-linear speedup
compared with DTGEVC for sufficiently large matrices.
"
1317,Evaluating Abstract Asynchronous Schwarz solvers on GPUs,"  With the commencement of the exascale computing era, we realize that the
majority of the leadership supercomputers are heterogeneous and massively
parallel even on a single node with multiple co-processors such as GPUs and
multiple cores on each node. For example, ORNLs Summit accumulates six NVIDIA
Tesla V100s and 42 core IBM Power9s on each node. Synchronizing across all
these compute resources in a single node or even across multiple nodes is
prohibitively expensive. Hence it is necessary to develop and study
asynchronous algorithms that circumvent this issue of bulk-synchronous
computing for massive parallelism. In this study, we examine the asynchronous
version of the abstract Restricted Additive Schwarz method as a solver where we
do not explicitly synchronize, but allow for communication of the data between
the sub-domains to be completely asynchronous thereby removing the bulk
synchronous nature of the algorithm.
  We accomplish this by using the onesided RMA functions of the MPI standard.
We study the benefits of using such an asynchronous solver over its synchronous
counterpart on both multi-core architectures and on multiple GPUs. We also
study the communication patterns and local solvers and their effect on the
global solver. Finally, we show that this concept can render attractive runtime
benefits over the synchronous counterparts.
"
1318,"Optimization of Generalized Jacobian Chain Products without Memory
  Constraints","  The efficient computation of Jacobians represents a fundamental challenge in
computational science and engineering. Large-scale modular numerical simulation
programs can be regarded as sequences of evaluations of in our case
differentiable modules with corresponding local Jacobians. The latter are
typically not available. Tangent and adjoint versions of the individual modules
are assumed to be given as results of algorithmic differentiation instead. The
classical (Jacobian) matrix chain product formulation is extended with the
optional evaluation of matrix-free Jacobian-matrix and matrix-Jacobian products
as tangents and adjoints. We propose a dynamic programming algorithm for the
minimization of the computational cost of such generalized Jacobian chain
products without considering constraints on the available persistent system
memory. In other words, the naive evaluation of an adjoint of the entire
simulation program is assumed to be a feasible option. No checkpointing is
required. Under the given assumptions we obtain optimal solutions which improve
the best state of the art methods by factors of up to seven on a set of
randomly generated problem instances of growing size.
"
1319,Parametric model order reduction using pyMOR,"  pyMOR is a free software library for model order reduction that includes both
reduced basis and system-theoretic methods. All methods are implemented in
terms of abstract vector and operator interfaces, which allows direct
integration of pyMOR's algorithms with a wide array of external PDE solvers. In
this contribution, we give a brief overview of the available methods and
experimentally compare them for the parametric instationary thermal-block
benchmark defined in arXiv:2003.00846.
"
1320,FunGrim: a symbolic library for special functions,"  We present the Mathematical Functions Grimoire (FunGrim), a website and
database of formulas and theorems for special functions. We also discuss the
symbolic computation library used as the backend and main development tool for
FunGrim, and the Grim formula language used in these projects to represent
mathematical content semantically.
"
1321,"An R Package for generating covariance matrices for maximum-entropy
  sampling from precipitation chemistry data","  We present an open-source R package (MESgenCov v 0.1.0) for temporally
fitting multivariate precipitation chemistry data and extracting a covariance
matrix for use in the MESP (maximum-entropy sampling problem). We provide
multiple functionalities for modeling and model assessment. The package is
tightly coupled with NADP/NTN (National Atmospheric Deposition Program /
National Trends Network) data from their set of 379 monitoring sites,
1978--present. The user specifies the sites, chemicals, and time period
desired, fits an appropriate user-specified univariate model for each site and
chemical selected, and the package produces a covariance matrix for use by MESP
algorithms.
"
1322,A Kogbetliantz-type algorithm for the hyperbolic SVD,"  In this paper a two-sided, parallel Kogbetliantz-type algorithm for the
hyperbolic singular value decomposition (HSVD) of real and complex square
matrices is developed, with a single assumption that the input matrix, of order
$n$, admits such a decomposition into the product of a unitary, a non-negative
diagonal, and a $J$-unitary matrix, where $J$ is a given diagonal matrix of
positive and negative signs. When $J=\pm I$, the proposed algorithm computes
the ordinary SVD. The paper's most important contribution---a derivation of
formulas for the HSVD of $2\times 2$ matrices---is presented first, followed by
the details of their implementation in floating-point arithmetic. Next, the
effects of the hyperbolic transformations on the columns of the iteration
matrix are discussed. These effects then guide a redesign of the dynamic pivot
ordering, being already a well-established pivot strategy for the ordinary
Kogbetliantz algorithm, for the general, $n\times n$ HSVD. A heuristic but
sound convergence criterion is then proposed, which contributes to high
accuracy demonstrated in the numerical testing results. Such a $J$-Kogbetliantz
algorithm as presented here is intrinsically slow, but is nevertheless usable
for matrices of small orders.
"
1323,"Pressio: Enabling projection-based model reduction for large-scale
  nonlinear dynamical systems","  This work introduces Pressio, an open-source project aimed at enabling
leading-edge projection-based reduced order models (ROMs) for large-scale
nonlinear dynamical systems in science and engineering. Pressio provides
model-reduction methods that can reduce both the number of spatial and temporal
degrees of freedom for any dynamical system expressible as a system of
parameterized ordinary differential equations (ODEs). We leverage this simple,
expressive mathematical framework as a pivotal design choice to enable a
minimal application programming interface (API) that is natural to dynamical
systems. The core component of Pressio is a C++11 header-only library that
leverages generic programming to support applications with arbitrary data types
and arbitrarily complex programming models. This is complemented with Python
bindings to expose these C++ functionalities to Python users with negligible
overhead and no user-required binding code. We discuss the distinguishing
characteristics of Pressio relative to existing model-reduction libraries,
outline its key design features, describe how the user interacts with it, and
present two test cases---including one with over 20 million degrees of
freedom---that highlight the performance results of Pressio and illustrate the
breath of problems that can be addressed with it.
"
1324,"Scalable parallel algorithm for solving non-stationary systems of linear
  inequalities","  In this paper, a scalable iterative projection-type algorithm for solving
non-stationary systems of linear inequalities is considered. A non-stationary
system is understood as a large-scale system of inequalities in which
coefficients and constant terms can change during the calculation process. The
proposed parallel algorithm uses the concept of pseudo-projection which
generalizes the notion of orthogonal projection. The parallel pseudo-projection
algorithm is implemented using the parallel BSF-skeleton. An analytical
estimation of the algorithm scalability boundary is obtained on the base of the
BSF cost metric. The large-scale computational experiments were performed on a
cluster computing system. The obtained results confirm the efficiency of the
proposed approach.
"
1325,"Geometric Sparsification of Closeness Relations: Eigenvalue Clustering
  for Computing Matrix Functions","  We show how to efficiently solve a clustering problem that arises in a method
to evaluate functions of matrices. The problem requires finding the connected
components of a graph whose vertices are eigenvalues of a real or complex
matrix and whose edges are pairs of eigenvalues that are at most \delta away
from each other. Davies and Higham proposed solving this problem by enumerating
the edges of the graph, which requires at least $\Omega(n^{2})$ work. We show
that the problem can be solved by computing the Delaunay triangulation of the
eigenvalues, removing from it long edges, and computing the connected
components of the remaining edges in the triangulation. This leads to an
$O(n\log n)$ algorithm. We have implemented both algorithms using CGAL, a
mature and sophisticated computational-geometry software library, and we
demonstrate that the new algorithm is much faster in practice than the naive
algorithm. We also present a tight analysis of the naive algorithm, showing
that it performs $\Theta(n^{2})$ work, and correct a misrepresentation in the
original statement of the problem. To the best of our knowledge, this is the
first application of computational geometry to solve a real-world problem in
numerical linear algebra.
"
1326,FlexRiLoG -- A SageMath Package for Motions of Graphs,"  In this paper we present the SageMath package FlexRiLoG (short for flexible
and rigid labelings of graphs). Based on recent results the software generates
motions of graphs using special edge colorings. The package computes and
illustrates the colorings and the motions. We present the structure and usage
of the package.
"
1327,"Vectorization and Minimization of Memory Footprint for Linear High-Order
  Discontinuous Galerkin Schemes","  We present a sequence of optimizations to the performance-critical compute
kernels of the high-order discontinuous Galerkin solver of the hyperbolic PDE
engine ExaHyPE -- successively tackling bottlenecks due to SIMD operations,
cache hierarchies and restrictions in the software design.
  Starting from a generic scalar implementation of the numerical scheme, our
first optimized variant applies state-of-the-art optimization techniques by
vectorizing loops, improving the data layout and using Loop-over-GEMM to
perform tensor contractions via highly optimized matrix multiplication
functions provided by the LIBXSMM library. We show that memory stalls due to a
memory footprint exceeding our L2 cache size hindered the vectorization gains.
We therefore introduce a new kernel that applies a sum factorization approach
to reduce the kernel's memory footprint and improve its cache locality. With
the L2 cache bottleneck removed, we were able to exploit additional
vectorization opportunities, by introducing a hybrid
Array-of-Structure-of-Array data layout that solves the data layout conflict
between matrix multiplications kernels and the point-wise functions to
implement PDE-specific terms.
  With this last kernel, evaluated in a benchmark simulation at high polynomial
order, only 2\% of the floating point operations are still performed using
scalar instructions and 22.5\% of the available performance is achieved.
"
1328,Making RooFit Ready for Run 3,"  RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used
in most searches and measurements at the Large Hadron Collider. The data to be
collected in Run 3 will enable measurements with higher precision and models
with larger complexity, but also require faster data processing. In this work,
first results on modernising RooFit's collections, restructuring data flow and
vectorising likelihood fits in RooFit will be discussed. These improvements
will enable the LHC experiments to process larger datasets without having to
compromise with respect to model complexity, as fitting times would increase
significantly with the large datasets to be expected in Run 3.
"
1329,"A Faster, More Intuitive RooFit","  RooFit and RooStats, the toolkits for statistical modelling in ROOT, are used
in most searches and measurements at the Large Hadron Collider as well as at
$B$ factories. Larger datasets to be collected at e.g. the High-Luminosity LHC
will enable measurements with higher precision, but will require faster data
processing to keep fitting times stable. In this work, a simplification of
RooFit's interfaces and a redesign of its internal dataflow is presented.
Interfaces are being extended to look and feel more STL-like to be more
accessible both from C++ and Python to improve interoperability and ease of
use, while maintaining compatibility with old code. The redesign of the
dataflow improves cache locality and data loading, and can be used to process
batches of data with vectorised SIMD computations. This reduces the time for
computing unbinned likelihoods by a factor four to 16. This will allow to fit
larger datasets of the future in the same time or faster than today's fits.
"
1330,Local congruence of chain complexes,"  The object of this paper is to transform a set of local chain complexes to a
single global complex using an equivalence relation of congruence of cells,
solving topologically the numerical inaccuracies of floating-point arithmetics.
While computing the space arrangement generated by a collection of cellular
complexes, one may start from independently and efficiently computing the
intersection of each single input 2-cell with the others. The topology of these
intersections is codified within a set of (0-2)-dimensional chain complexes.
The target of this paper is to merge the local chains by using the equivalence
relations of {\epsilon}-congruence between 0-, 1-, and 2-cells (elementary
chains). In particular, we reduce the block-diagonal coboundary matrices
[\Delta_0] and [\Delta_1], used as matrix accumulators of the local coboundary
chains, to the global matrices [\delta_0] and [\delta_1], representative of
congruence topology, i.e., of congruence quotients between all 0-,1-,2-cells,
via elementary algebraic operations on their columns. This algorithm is
codified using the Julia porting of the SuiteSparse:GraphBLAS implementation of
the GraphBLAS standard, conceived to efficiently compute algorithms on large
graphs using linear algebra and sparse matrices [1, 2].
"
1331,"Interpolation of Dense and Sparse Rational Functions and other
  Improvements in $\texttt{FireFly}$","  We present the main improvements and new features in version $\texttt{2.0}$
of the open-source $\texttt{C++}$ library $\texttt{FireFly}$ for the
interpolation of rational functions. This includes algorithmic improvements,
e.g. a hybrid algorithm for dense and sparse rational functions and an
algorithm to identify and remove univariate factors. The new version is applied
to a Feynman-integral reduction to showcase the runtime improvements achieved.
Moreover, $\texttt{FireFly}$ now supports parallelization with $\texttt{MPI}$
and offers new tools like a parser for expressions or an executable for the
insertion of replacement tables.
"
1332,Maintaining a Library of Formal Mathematics,"  The Lean mathematical library mathlib is developed by a community of users
with very different backgrounds and levels of experience. To lower the barrier
of entry for contributors and to lessen the burden of reviewing contributions,
we have developed a number of tools for the library which check proof
developments for subtle mistakes in the code and generate documentation suited
for our varied audience.
"
1333,Automatic Differentiation in ROOT,"  In mathematics and computer algebra, automatic differentiation (AD) is a set
of techniques to evaluate the derivative of a function specified by a computer
program. AD exploits the fact that every computer program, no matter how
complicated, executes a sequence of elementary arithmetic operations (addition,
subtraction, multiplication, division, etc.), elementary functions (exp, log,
sin, cos, etc.) and control flow statements. AD takes source code of a function
as input and produces source code of the derived function. By applying the
chain rule repeatedly to these operations, derivatives of arbitrary order can
be computed automatically, accurately to working precision, and using at most a
small constant factor more arithmetic operations than the original program.
  This paper presents AD techniques available in ROOT, supported by Cling, to
produce derivatives of arbitrary C/C++ functions through implementing source
code transformation and employing the chain rule of differential calculus in
both forward mode and reverse mode. We explain its current integration for
gradient computation in TFormula. We demonstrate the correctness and
performance improvements in ROOT's fitting algorithms.
"
1334,Geomstats: A Python Package for Riemannian Geometry in Machine Learning,"  We introduce Geomstats, an open-source Python toolbox for computations and
statistics on nonlinear manifolds, such as hyperbolic spaces, spaces of
symmetric positive definite matrices, Lie groups of transformations, and many
more. We provide object-oriented and extensively unit-tested implementations.
Among others, manifolds come equipped with families of Riemannian metrics, with
associated exponential and logarithmic maps, geodesics and parallel transport.
Statistics and learning algorithms provide methods for estimation, clustering
and dimension reduction on manifolds. All associated operations are vectorized
for batch computation and provide support for different execution backends,
namely NumPy, PyTorch and TensorFlow, enabling GPU acceleration. This paper
presents the package, compares it with related libraries and provides relevant
code examples. We show that Geomstats provides reliable building blocks to
foster research in differential geometry and statistics, and to democratize the
use of Riemannian geometry in machine learning applications. The source code is
freely available under the MIT license at \url{geomstats.ai}.
"
1335,"Fully Parallel Mesh I/O using PETSc DMPlex with an Application to
  Waveform Modeling","  Large-scale PDE simulations using high-order finite-element methods on
unstructured meshes are an indispensable tool in science and engineering. The
widely used open-source PETSc library offers an efficient representation of
generic unstructured meshes within its DMPlex module. This paper details our
recent implementation of parallel mesh reading and topological interpolation
(computation of edges and faces from a cell-vertex mesh) into DMPlex. We apply
these developments to seismic wave propagation scenarios on Mars as an example
application. The principal motivation is to overcome single-node memory limits
and reach mesh sizes which were impossible before. Moreover, we demonstrate
that scalability of I/O and topological interpolation goes beyond 12'000 cores,
and memory-imposed limits on mesh size vanish.
"
1336,"A practical approach to testing random number generators in computer
  algebra systems","  This paper has a practical aim. For a long time, implementations of
pseudorandom number generators in standard libraries of programming languages
had poor quality. The situation started to improve only recently. Up to now, a
large number of libraries and weakly supported mathematical packages use
outdated algorithms for random number generation. Four modern sets of
statistical tests that can be used for verifying random number generators are
described. It is proposed to use command line utilities, which makes it
possible to avoid low-level programming in such languages as C or C++. Only
free open source systems are considered.
"
1337,GAPS: Generator for Automatic Polynomial Solvers,"  Minimal problems in computer vision raise the demand of generating efficient
automatic solvers for polynomial equation systems. Given a polynomial system
repeated with different coefficient instances, the traditional Gr\""obner basis
or normal form based solution is very inefficient. Fortunately the Gr\""obner
basis of a same polynomial system with different coefficients is found to share
consistent inner structure. By precomputing such structures offline, Gr\""obner
basis as well as the polynomial system solutions can be solved automatically
and efficiently online. In the past decade, several tools have been released to
generate automatic solvers for a general minimal problems. The most recent tool
autogen from Larsson et al. is a representative of these tools with
state-of-the-art performance in solver efficiency. GAPS wraps and improves
autogen with more user-friendly interface, more functionality and better
stability. We demonstrate in this report the main approach and enhancement
features of GAPS. A short tutorial of the software is also included.
"
1338,Enhancements to the DIDO Optimal Control Toolbox,"  In 2020, DIDO$^\copyright$ turned 20! The software package emerged in 2001 as
a basic, user-friendly MATLAB$^\circledR$ teaching-tool to illustrate the
various nuances of Pontryagin's Principle but quickly rose to prominence in
2007 after NASA announced it had executed a globally optimal maneuver using
DIDO. Since then, the toolbox has grown in applications well beyond its
aerospace roots: from solving problems in quantum control to ushering rapid,
nonlinear sensitivity-analysis in designing high-performance automobiles. Most
recently, it has been used to solve continuous-time traveling-salesman
problems. Over the last two decades, DIDO's algorithms have evolved from their
simple use of generic nonlinear programming solvers to a multifaceted
engagement of fast spectral Hamiltonian programming techniques. A description
of the internal enhancements to DIDO that define its mathematics and algorithms
are described in this paper. A challenge example problem from robotics is
included to showcase how the latest version of DIDO is capable of escaping the
trappings of a ``local minimum'' that ensnare many other trajectory
optimization methods.
"
1339,Various Ways to Quantify BDMPs,"  A Boolean logic driven Markov process (BDMP) is a dependability analysis
model that defines a continuous-time Markov chain (CTMC). This formalism has
high expressive power, yet it remains readable because its graphical
representation stays close to standard fault trees. The size of a BDMP is
roughly speaking proportional to the size of the system it models, whereas the
size of the CTMC specified by this BDMP suffers from exponential growth. Thus
quantifying large BDMPs can be a challenging task. The most general method to
quantify them is Monte Carlo simulation, but this may be intractable for highly
reliable systems. On the other hand, some subcategories of BDMPs can be
processed with much more efficient methods. For example, BDMPs without repairs
can be translated into dynamic fault trees, a formalism accepted as an input of
the STORM model checker, that performs numerical calculations on sparse
matrices, or they can be processed with the tool FIGSEQ that explores paths
going to a failure state and calculates their probabilities. BDMPs with repairs
can be quantified by FIGSEQ (BDMPs capturing quickly and completely repairable
behaviors are solved by a different algorithm), and by the I&AB (Initiator and
All Barriers) method, recently published and implemented in a prototype version
of RISKSPECTRUM PSA. This tool, based exclusively on Boolean representations
looks for and quantifies minimal cut sets of the system, i.e., minimal
combinations of component failures that induce the loss of the system. This
allows a quick quantification of large models with repairable components,
standby redundancies and some other types of dependencies between omponents.
All these quantification methods have been tried on a benchmark whose
definition was published at the MARS 2017 workshop: the model of emergency
power supplies of a nuclear power plant. In this paper, after a recall of the
theoretical principles of the various quantification methods, we compare their
performances on that benchmark.
"
1340,Synergistic CPU-FPGA Acceleration of Sparse Linear Algebra,"  This paper describes REAP, a software-hardware approach that enables high
performance sparse linear algebra computations on a cooperative CPU-FPGA
platform. REAP carefully separates the task of organizing the matrix elements
from the computation phase. It uses the CPU to provide a first-pass
re-organization of the matrix elements, allowing the FPGA to focus on the
computation. We introduce a new intermediate representation that allows the CPU
to communicate the sparse data and the scheduling decisions to the FPGA. The
computation is optimized on the FPGA for effective resource utilization with
pipelining. REAP improves the performance of Sparse General Matrix
Multiplication (SpGEMM) and Sparse Cholesky Factorization by 3.2X and 1.85X
compared to widely used sparse libraries for them on the CPU, respectively.
"
1341,"Custom-Precision Mathematical Library Explorations for Code Profiling
  and Optimization","  The typical processors used for scientific computing have fixed-width
data-paths. This implies that mathematical libraries were specifically
developed to target each of these fixed precisions (binary16, binary32,
binary64). However, to address the increasing energy consumption and throughput
requirements of scientific applications, library and hardware designers are
moving beyond this one-size-fits-all approach. In this article we propose to
study the effects and benefits of using user-defined floating-point formats and
target accuracies in calculations involving mathematical functions. Our tool
collects input-data profiles and iteratively explores lower precisions for each
call-site of a mathematical function in user applications. This profiling data
will be a valuable asset for specializing and fine-tuning mathematical function
implementations for a given application. We demonstrate the tool's capabilities
on SGP4, a satellite tracking application. The profile data shows the potential
for specialization and provides insight into answering where it is useful to
provide variable-precision designs for elementary function evaluation.
"
1342,"CS-TSSOS: Correlative and term sparsity for large-scale polynomial
  optimization","  This work proposes a new moment-SOS hierarchy, called CS-TSSOS, for solving
large-scale sparse polynomial optimization problems. Its novelty is to exploit
simultaneously correlative sparsity and term sparsity by combining advantages
of two existing frameworks for sparse polynomial optimization. The former is
due to Waki et al. while the latter was initially proposed by Wang et al. and
later exploited in the TSSOS hierarchy. In doing so we obtain CS-TSSOS -- a
two-level hierarchy of semidefinite programming relaxations with (i), the
crucial property to involve quasi block-diagonal matrices and (ii), the
guarantee of convergence to the global optimum. We demonstrate its efficiency
on several large-scale instances of the celebrated Max-Cut problem and the
important industrial optimal power flow problem, involving up to several
thousands of variables and ten thousands of constraints.
"
1343,Delayed approximate matrix assembly in multigrid with dynamic precisions,"  The accurate assembly of the system matrix is an important step in any code
that solves partial differential equations on a mesh. We either explicitly set
up a matrix, or we work in a matrix-free environment where we have to be able
to quickly return matrix entries upon demand. Either way, the construction can
become costly due to non-trivial material parameters entering the equations,
multigrid codes requiring cascades of matrices that depend upon each other, or
dynamic adaptive mesh refinement that necessitates the recomputation of matrix
entries or the whole equation system throughout the solve. We propose that
these constructions can be performed concurrently with the multigrid cycles.
Initial geometric matrices and low accuracy integrations kickstart the
multigrid, while improved assembly data is fed to the solver as and when it
becomes available. The time to solution is improved as we eliminate an
expensive preparation phase traditionally delaying the actual computation. We
eliminate algorithmic latency. Furthermore, we desynchronise the assembly from
the solution process. This anarchic increase of the concurrency level improves
the scalability. Assembly routines are notoriously memory- and
bandwidth-demanding. As we work with iteratively improving operator accuracies,
we finally propose the use of a hierarchical, lossy compression scheme such
that the memory footprint is brought down aggressively where the system matrix
entries carry little information or are not yet available with high accuracy.
"
1344,AutoHOOT: Automatic High-Order Optimization for Tensors,"  High-order optimization methods, including Newton's method and its variants
as well as alternating minimization methods, dominate the optimization
algorithms for tensor decompositions and tensor networks. These tensor methods
are used for data analysis and simulation of quantum systems. In this work, we
introduce AutoHOOT, the first automatic differentiation (AD) framework
targeting at high-order optimization for tensor computations. AutoHOOT takes
input tensor computation expressions and generates optimized derivative
expressions. In particular, AutoHOOT contains a new explicit Jacobian / Hessian
expression generation kernel whose outputs maintain the input tensors'
granularity and are easy to optimize. The expressions are then optimized by
both the traditional compiler optimization techniques and specific tensor
algebra transformations. Experimental results show that AutoHOOT achieves
competitive performance for both tensor decomposition and tensor network
applications compared to existing AD software and other tensor computation
libraries with manually written kernels, both on CPU and GPU architectures. The
scalability of the generated kernels is as good as other well-known high-order
numerical algorithms so that it can be executed efficiently on distributed
parallel systems.
"
1345,A modular extension for a computer algebra system,"  Computer algebra systems are complex software systems that cover a wide range
of scientific and practical problems. However, the absolute coverage cannot be
achieved. Often, it is required to create a user extension for an existing
computer algebra system. In this case, the extensibility of the system should
be taken into account. In this paper, we consider a technology for extending
the SymPy computer algebra system with a low-level module that implements a
random number generator.
"
1346,"The JuliaConnectoR: a functionally oriented interface for integrating
  Julia in R","  Like many groups considering the new programming language Julia, we faced the
challenge of accessing the algorithms that we develop in Julia from R.
Therefore, we developed the R package JuliaConnectoR, available from the CRAN
repository and GitHub (https://github.com/stefan-m-lenz/JuliaConnectoR), in
particular for making advanced deep learning tools available. For
maintainability and stability, we decided to base communication between R and
Julia on TCP, using an optimized binary format for exchanging data. Our package
also specifically contains features that allow for a convenient interactive use
in R. This makes it easy to develop R extensions with Julia or to simply call
functionality from Julia packages in R. With its functionally oriented design,
the JuliaConnectoR enables a clean programming style by avoiding state in Julia
that is not visible in the R workspace. We illustrate the further features of
our package with code examples, and also discuss advantages over the two
alternative packages JuliaCall and XRJulia. Finally, we demonstrate the usage
of the package with a more extensive example for employing neural ordinary
differential equations, a recent deep learning technique that has received much
attention. This example also provides more general guidance for integrating
deep learning techniques from Julia into R.
"
1347,"Reproducibility of Parallel Preconditioned Conjugate Gradient in Hybrid
  Programming Environments","  The Preconditioned Conjugate Gradient method is often employed for the
solution of linear systems of equations arising in numerical simulations of
physical phenomena. While being widely used, the solver is also known for its
lack of accuracy while computing the residual. In this article, we propose two
algorithmic solutions that originate from the ExBLAS project to enhance the
accuracy of the solver as well as to ensure its reproducibility in a hybrid MPI
+ OpenMP tasks programming environment. One is based on ExBLAS and preserves
every bit of information until the final rounding, while the other relies upon
floating-point expansions and, hence, expands the intermediate precision.
Instead of converting the entire solver into its ExBLAS-related implementation,
we identify those parts that violate reproducibility/non-associativity, secure
them, and combine this with the sequential executions. These algorithmic
strategies are reinforced with programmability suggestions to assure
deterministic executions. Finally, we verify these approaches on two modern HPC
systems: both versions deliver reproducible number of iterations, residuals,
direct errors, and vector-solutions for the overhead of less than 37.7 % on 768
cores.
"
1348,"Batched computation of the singular value decompositions of order two by
  the AVX-512 vectorization","  In this paper a vectorized algorithm for simultaneously computing up to eight
singular value decompositions (SVDs, each of the form $A=U\Sigma V^{\ast}$) of
real or complex matrices of order two is proposed. The algorithm extends to a
batch of matrices of an arbitrary length $n$, that arises, for example, in the
annihilation part of the parallel Kogbetliantz algorithm for the SVD of a
square matrix of order $2n$. The SVD algorithm for a single matrix of order two
is derived first. It scales, in most instances error-free, the input matrix $A$
such that its singular values $\Sigma_{ii}$ cannot overflow whenever its
elements are finite, and then computes the URV factorization of the scaled
matrix, followed by the SVD of a non-negative upper-triangular middle factor. A
vector-friendly data layout for the batch is then introduced, where the
same-indexed elements of each of the input and the output matrices form
vectors, and the algorithm's steps over such vectors are described. The
vectorized approach is then shown to be about three times faster than
processing each matrix in isolation, while slightly improving accuracy over the
straightforward method for the $2\times 2$ SVD.
"
1349,"SciANN: A Keras/Tensorflow wrapper for scientific computations and
  physics-informed deep learning using artificial neural networks","  In this paper, we introduce SciANN, a Python package for scientific computing
and physics-informed deep learning using artificial neural networks. SciANN
uses the widely used deep-learning packages Tensorflow and Keras to build deep
neural networks and optimization models, thus inheriting many of Keras's
functionalities, such as batch optimization and model reuse for transfer
learning. SciANN is designed to abstract neural network construction for
scientific computations and solution and discovery of partial differential
equations (PDE) using the physics-informed neural networks (PINN) architecture,
therefore providing the flexibility to set up complex functional forms. We
illustrate, in a series of examples, how the framework can be used for curve
fitting on discrete data, and for solution and discovery of PDEs in strong and
weak forms. We summarize the features currently available in SciANN, and also
outline ongoing and future developments.
"
1350,"High-Performance GPU and CPU Signal Processing for a Reverse-GPS
  Wildlife Tracking System","  We present robust high-performance implementations of signal-processing tasks
performed by a high-throughput wildlife tracking system called ATLAS. The
system tracks radio transmitters attached to wild animals by estimating the
time of arrival of packets encoding known pseudo-random codes to receivers
(base stations). Time-of-arrival estimation of wideband radio signals is
computatoinally expensive, especially when it is not known when a transmitter
transmits. These computation are a key bottleneck that limits the throughput of
the system. The paper reports on two implementations of ATLAS's
signal-processing algorithms, one for CPUs and the other for GPUs, and
carefully evaluates their performance. The evaluations, performed on two CPU
platforms and on three GPU platforms, show dramatic improvements relative to
our baseline, a high-end desktop CPU that is typical of the computers in
current base stations. The improvements are both in terms of absolute
performance (more than 50X with a high-end GPU and more than 4X with a GPU
platform consumes almost 5 times less power than the CPU platform), in terms of
performance-per-Watt ratios (more than 16X), and in terms of price-performance
ratios.
"
1351,SymJAX: symbolic CPU/GPU/TPU programming,"  SymJAX is a symbolic programming version of JAX simplifying graph
input/output/updates and providing additional functionalities for general
machine learning and deep learning applications. From an user perspective
SymJAX provides a la Theano experience with fast graph optimization/compilation
and broad hardware support, along with Lasagne-like deep learning
functionalities.
"
1352,Model Evidence with Fast Tree Based Quadrature,"  High dimensional integration is essential to many areas of science, ranging
from particle physics to Bayesian inference. Approximating these integrals is
hard, due in part to the difficulty of locating and sampling from regions of
the integration domain that make significant contributions to the overall
integral. Here, we present a new algorithm called Tree Quadrature (TQ) that
separates this sampling problem from the problem of using those samples to
produce an approximation of the integral. TQ places no qualifications on how
the samples provided to it are obtained, allowing it to use state-of-the-art
sampling algorithms that are largely ignored by existing integration
algorithms. Given a set of samples, TQ constructs a surrogate model of the
integrand in the form of a regression tree, with a structure optimised to
maximise integral precision. The tree divides the integration domain into
smaller containers, which are individually integrated and aggregated to
estimate the overall integral. Any method can be used to integrate each
individual container, so existing integration methods, like Bayesian Monte
Carlo, can be combined with TQ to boost their performance. On a set of
benchmark problems, we show that TQ provides accurate approximations to
integrals in up to 15 dimensions; and in dimensions 4 and above, it outperforms
simple Monte Carlo and the popular Vegas method.
"
1353,copent: Estimating Copula Entropy in R,"  Statistical independence and conditional independence are the fundemental
concepts in statistics and machine learning. Copula Entropy is a mathematical
concept for multivariate statistical independence measuring and testing, and
also closely related to conditional independence or transfer entropy. It has
been applied to solve several statistical or machine learning problems,
including association discovery, structure learning, variable selection, and
causal discovery. Copula entropy was proposed to be estimated nonparametrically
with rank statistic and the kNN method for estimating entropy. copent, is a R
package which implements this proposed method for estimating copula entropy.
The implementation detail of the package is presented in this paper. Two
illustration examples with simulated data and real-world data on causal
discovery are also presented. The copent package is available on the
Comprehensive R Archive Network (CRAN) and also on GitHub at
https://github.com/majianthu/copent.
"
1354,"AutoMat -- Automatic Differentiation for Generalized Standard Materials
  on GPUs","  We propose a universal method for the evaluation of generalized standard
materials that greatly simplifies the material law implementation process. By
means of automatic differentiation and a numerical integration scheme, AutoMat
reduces the implementation effort to two potential functions. By moving AutoMat
to the GPU, we close the performance gap to conventional evaluation routines
and demonstrate in detail that the expression level reverse mode of automatic
differentiation as well as its extension to second order derivatives can be
applied inside CUDA kernels. We underline the effectiveness and the
applicability of AutoMat by integrating it into the FFT-based homogenization
scheme of Moulinec and Suquet and discuss the benefits of using AutoMat with
respect to runtime and solution accuracy for an elasto-viscoplastic example.
"
1355,"The aggregated unfitted finite element method on parallel tree-based
  adaptive meshes","  In this work, we present an adaptive unfitted finite element scheme that
combines the aggregated finite element method with parallel adaptive mesh
refinement. We introduce a novel scalable distributed-memory implementation of
the resulting scheme on locally-adapted Cartesian forest-of-trees meshes. We
propose a two-step algorithm to construct the finite element space at hand that
carefully mixes aggregation constraints of problematic degrees of freedom,
which get rid of the small cut cell problem, and standard hanging degree of
freedom constraints, which ensure trace continuity on non-conforming meshes.
Following this approach, we derive a finite element space that can be expressed
as the original one plus well-defined linear constraints. Moreover, it requires
minimum parallelization effort, using standard functionality available in
existing large-scale finite element codes. Numerical experiments demonstrate
its optimal mesh adaptation capability, robustness to cut location and parallel
efficiency, on classical Poisson $hp$-adaptivity benchmarks. Our work opens the
path to functional and geometrical error-driven dynamic mesh adaptation with
the aggregated finite element method in large-scale realistic scenarios.
Likewise, it can offer guidance for bridging other scalable unfitted methods
and parallel adaptive mesh refinement.
"
1356,Accelerating linear solvers for Stokes problems with C++ metaprogramming,"  The efficient solution of large sparse saddle point systems is very important
in computational fluid mechanics. The discontinuous Galerkin finite element
methods have become increasingly popular for incompressible flow problems but
their application is limited due to high computational cost. We describe the
C++ programming techniques that may help to accelerate linear solvers for such
problems. The approach is based on the policy-based design pattern and partial
template specialization, and is implemented in the open source AMGCL library.
The efficiency is demonstrated with the example of accelerating an iterative
solver of a discontinuous Galerkin finite element method for the Stokes
problem. The implementation allows selecting algorithmic components of the
solver by adjusting template parameters without any changes to the codebase. It
is possible to switch to block values, or use a mixed precision solution, which
results in up to 4 times speedup, and reduces the memory footprint of the
algorithm by about 40\%. We evaluate both monolithic and composite
preconditioning strategies for the 3 benchmark problems. The performance of the
proposed solution is compared with a multithreaded direct Pardiso solver and a
parallel iterative PETSc solver.
"
1357,"On Computing the Kronecker Structure of Polynomial and Rational Matrices
  using Julia","  In this paper we discuss the mathematical background and the computational
aspects which underly the implementation of a collection of Julia functions in
the MatrixPencils package for the determination of structural properties of
polynomial and rational matrices. We primarily focus on the computation of the
finite and infinite spectral structures (e.g., eigenvalues, zeros, poles) as
well as the left and right singular structures (e.g., Kronecker indices), which
play a fundamental role in the structure of the solution of many problems
involving polynomial and rational matrices. The basic analysis tool is the
determination of the Kronecker structure of linear matrix pencils using
numerically reliable algorithms, which is used in conjunction with several
linearization techniques of polynomial and rational matrices. Examples of
polynomial and rational matrices, which exhibit all relevant structural
features, are considered to illustrate the main mathematical concepts and the
capabilities of implemented tools.
"
1358,Array Programming with NumPy,"  Array programming provides a powerful, compact, expressive syntax for
accessing, manipulating, and operating on data in vectors, matrices, and
higher-dimensional arrays. NumPy is the primary array programming library for
the Python language. It plays an essential role in research analysis pipelines
in fields as diverse as physics, chemistry, astronomy, geoscience, biology,
psychology, material science, engineering, finance, and economics. For example,
in astronomy, NumPy was an important part of the software stack used in the
discovery of gravitational waves and the first imaging of a black hole. Here we
show how a few fundamental array concepts lead to a simple and powerful
programming paradigm for organizing, exploring, and analyzing scientific data.
NumPy is the foundation upon which the entire scientific Python universe is
constructed. It is so pervasive that several projects, targeting audiences with
specialized needs, have developed their own NumPy-like interfaces and array
objects. Because of its central position in the ecosystem, NumPy increasingly
plays the role of an interoperability layer between these new array computation
libraries.
"
1359,"Robust and scalable h-adaptive aggregated unfitted finite elements for
  interface elliptic problems","  This work introduces a novel, fully robust and highly-scalable, $h$-adaptive
aggregated unfitted finite element method for large-scale interface elliptic
problems. The new method is based on a recent distributed-memory implementation
of the aggregated finite element method atop a highly-scalable Cartesian
forest-of-trees mesh engine. It follows the classical approach of weakly
coupling nonmatching discretisations at the interface to model internal
discontinuities at the interface. We propose a natural extension of a
single-domain parallel cell aggregation scheme to problems with a finite number
of interfaces; it straightforwardly leads to aggregated finite element spaces
that have the structure of a Cartesian product. We demonstrate, through
standard numerical analysis and exhaustive numerical experimentation on several
complex Poisson and linear elasticity benchmarks, that the new technique enjoys
the following properties: well-posedness, robustness to cut location and
material contrast, optimal (h-adaptive) approximation properties, high
scalability and easy implementation in large-scale finite element codes. As a
result, the method offers great potential as a useful finite element solver for
large-scale multiphase and multiphysics problems modelled by partial
differential equations.
"
1360,"Index handling and assign optimization for Algorithmic Differentiation
  reuse index managers","  For operator overloading Algorithmic Differentiation tools, the
identification of primal variables and adjoint variables is usually done via
indices. Two common schemes exist for their management and distribution. The
linear approach is easy to implement and supports memory optimization with
respect to copy statements. On the other hand, the reuse approach requires more
implementation effort but results in much smaller adjoint vectors, which are
more suitable for the vector mode of Algorithmic Differentiation. In this
paper, we present both approaches, how to implement them, and discuss their
advantages, disadvantages and properties of the resulting Algorithmic
Differentiation type. In addition, a new management scheme is presented which
supports copy optimizations and the reuse of indices, thus combining the
advantages of the other two. The implementations of all three schemes are
compared on a simple synthetic example and on a real world example using the
computational fluid dynamics solver in SU2.
"
1361,"Preparing Ginkgo for AMD GPUs -- A Testimonial on Porting CUDA Code to
  HIP","  With AMD reinforcing their ambition in the scientific high performance
computing ecosystem, we extend the hardware scope of the Ginkgo linear algebra
package to feature a HIP backend for AMD GPUs. In this paper, we report and
discuss the porting effort from CUDA, the extension of the HIP framework to add
missing features such as cooperative groups, the performance price of compiling
HIP code for AMD architectures, and the design of a library providing native
backends for NVIDIA and AMD GPUs while minimizing code duplication by using a
shared code base.
"
1362,"The flare Package for High Dimensional Linear Regression and Precision
  Matrix Estimation in R","  This paper describes an R package named flare, which implements a family of
new high dimensional regression methods (LAD Lasso, SQRT Lasso, $\ell_q$ Lasso,
and Dantzig selector) and their extensions to sparse precision matrix
estimation (TIGER and CLIME). These methods exploit different nonsmooth loss
functions to gain modeling flexibility, estimation robustness, and tuning
insensitiveness. The developed solver is based on the alternating direction
method of multipliers (ADMM). The package flare is coded in double precision C,
and called from R by a user-friendly interface. The memory usage is optimized
by using the sparse matrix output. The experiments show that flare is efficient
and can scale up to large problems.
"
1363,"Hierarchical Jacobi Iteration for Structured Matrices on GPUs using
  Shared Memory","  High fidelity scientific simulations modeling physical phenomena typically
require solving large linear systems of equations which result from
discretization of a partial differential equation (PDE) by some numerical
method. This step often takes a vast amount of computational time to complete,
and therefore presents a bottleneck in simulation work. Solving these linear
systems efficiently requires the use of massively parallel hardware with high
computational throughput, as well as the development of algorithms which
respect the memory hierarchy of these hardware architectures to achieve high
memory bandwidth.
  In this paper, we present an algorithm to accelerate Jacobi iteration for
solving structured problems on graphics processing units (GPUs) using a
hierarchical approach in which multiple iterations are performed within on-chip
shared memory every cycle. A domain decomposition style procedure is adopted in
which the problem domain is partitioned into subdomains whose data is copied to
the shared memory of each GPU block. Jacobi iterations are performed internally
within each block's shared memory, avoiding the need to perform expensive
global memory accesses every step. We test our algorithm on the linear systems
arising from discretization of Poisson's equation in 1D and 2D, and observe
speedup in convergence using our shared memory approach compared to a
traditional Jacobi implementation which only uses global memory on the GPU. We
observe a x8 speedup in convergence in the 1D problem and a nearly x6 speedup
in the 2D case from the use of shared memory compared to a conventional GPU
approach.
"
1364,Adaptive SpMV/SpMSpV on GPUs for Input Vectors of Varied Sparsity,"  Despite numerous efforts for optimizing the performance of Sparse Matrix and
Vector Multiplication (SpMV) on modern hardware architectures, few works are
done to its sparse counterpart, Sparse Matrix and Sparse Vector Multiplication
(SpMSpV), not to mention dealing with input vectors of varied sparsity. The key
challenge is that depending on the sparsity levels, distribution of data, and
compute platform, the optimal choice of SpMV/SpMSpV kernel can vary, and a
static choice does not suffice. In this paper, we propose an adaptive
SpMV/SpMSpV framework, which can automatically select the appropriate
SpMV/SpMSpV kernel on GPUs for any sparse matrix and vector at the runtime.
Based on systematic analysis on key factors such as computing pattern, workload
distribution and write-back strategy, eight candidate SpMV/SpMSpV kernels are
encapsulated into the framework to achieve high performance in a seamless
manner. A comprehensive study on machine learning based kernel selector is
performed to choose the kernel and adapt with the varieties of both the input
and hardware from both accuracy and overhead perspectives. Experiments
demonstrate that the adaptive framework can substantially outperform the
previous state-of-the-art in real-world applications on NVIDIA Tesla K40m, P100
and V100 GPUs.
"
1365,"Ginkgo: A Modern Linear Operator Algebra Framework for High Performance
  Computing","  In this paper, we present Ginkgo, a modern C++ math library for scientific
high performance computing. While classical linear algebra libraries act on
matrix and vector objects, Ginkgo's design principle abstracts all
functionality as ""linear operators"", motivating the notation of a ""linear
operator algebra library"". Ginkgo's current focus is oriented towards providing
sparse linear algebra functionality for high performance GPU architectures, but
given the library design, this focus can be easily extended to accommodate
other algorithms and hardware architectures. We introduce this sophisticated
software architecture that separates core algorithms from architecture-specific
back ends and provide details on extensibility and sustainability measures. We
also demonstrate Ginkgo's usability by providing examples on how to use its
functionality inside the MFEM and deal.ii finite element ecosystems. Finally,
we offer a practical demonstration of Ginkgo's high performance on
state-of-the-art GPU architectures.
"
1366,"SParSH-AMG: A library for hybrid CPU-GPU algebraic multigrid and
  preconditioned iterative methods","  Hybrid CPU-GPU algorithms for Algebraic Multigrid methods (AMG) to
efficiently utilize both CPU and GPU resources are presented. In particular,
hybrid AMG framework focusing on minimal utilization of GPU memory with
performance on par with GPU-only implementations is developed. The hybrid AMG
framework can be tuned to operate at a significantly lower GPU-memory,
consequently, enables to solve large algebraic systems. Combining the hybrid
AMG framework as a preconditioner with Krylov Subspace solvers like Conjugate
Gradient, BiCG methods provides a solver stack to solve a large class of
problems. The performance of the proposed hybrid AMG framework is analysed for
an array of matrices with different properties and size. Further, the
performance of CPU-GPU algorithms are compared with the GPU-only
implementations to illustrate the significantly lower memory requirements.
"
1367,"Massively parallel 3D computation of the compressible Euler equations
  with an invariant-domain preserving second-order finite-element scheme","  We discuss the efficient implementation of a high-performance second-order
colocation-type finite-element scheme for solving the compressible Euler
equations of gas dynamics on unstructured meshes. The solver is based on the
convex limiting technique introduced by Guermond et al. (SIAM J. Sci. Comput.
40, A3211--A3239, 2018). As such it is invariant-domain preserving, i.e., the
solver maintains important physical invariants and is guaranteed to be stable
without the use of ad-hoc tuning parameters. This stability comes at the
expense of a significantly more involved algorithmic structure that renders
conventional high-performance discretizations challenging. We demonstrate that
it is nevertheless possible to achieve an appreciably high throughput of the
computing kernels of such a scheme. We discuss the algorithmic design that
allows a SIMD vectorization of the compute kernel, analyze the node-level
performance and report excellent weak and strong scaling of a hybrid thread/MPI
parallelization.
"
1368,"Sparse Approximate Multifrontal Factorization with Butterfly Compression
  for High Frequency Wave Equations","  We present a fast and approximate multifrontal solver for large-scale sparse
linear systems arising from finite-difference, finite-volume or finite-element
discretization of high-frequency wave equations. The proposed solver leverages
the butterfly algorithm and its hierarchical matrix extension for compressing
and factorizing large frontal matrices via graph-distance guided entry
evaluation or randomized matrix-vector multiplication-based schemes. Complexity
analysis and numerical experiments demonstrate $\mathcal{O}(N\log^2 N)$
computation and $\mathcal{O}(N)$ memory complexity when applied to an $N\times
N$ sparse system arising from 3D high-frequency Helmholtz and Maxwell problems.
"
1369,On Designing GPU Algorithms with Applications to Mesh Refinement,"  We present a set of rules to guide the design of GPU algorithms. These rules
are grounded on the principle of reducing waste in GPU utility to achieve good
speed up. In accordance to these rules, we propose GPU algorithms for 2D
constrained, 3D constrained and 3D Restricted Delaunay refinement problems
respectively. Our algorithms take a 2D planar straight line graph (PSLG) or 3D
piecewise linear complex (PLC) $\mathcal{G}$ as input, and generate quality
meshes conforming or approximating to $\mathcal{G}$. The implementation of our
algorithms shows that they are the first to run an order of magnitude faster
than current state-of-the-art counterparts in sequential and parallel manners
while using similar numbers of Steiner points to produce triangulations of
comparable qualities. It thus reduces the computing time of mesh refinement
from possibly hours to a few seconds or minutes for possible use in interactive
graphics applications.
"
1370,volesti: Volume Approximation and Sampling for Convex Polytopes in R,"  Sampling from high dimensional distributions and volume approximation of
convex bodies are fundamental operations that appear in optimization, finance,
engineering and machine learning. In this paper we present volesti, a C++
package with an R interface that provides efficient, scalable algorithms for
volume estimation, uniform and Gaussian sampling from convex polytopes. volesti
scales to hundreds of dimensions, handles efficiently three different types of
polyhedra and provides non existing sampling routines to R. We demonstrate the
power of volesti by solving several challenging problems using the R language.
"
1371,A Task-based Multi-shift QR/QZ Algorithm with Aggressive Early Deflation,"  The QR algorithm is one of the three phases in the process of computing the
eigenvalues and the eigenvectors of a dense nonsymmetric matrix. This paper
describes a task-based QR algorithm for reducing an upper Hessenberg matrix to
real Schur form. The task-based algorithm also supports generalized eigenvalue
problems (QZ algorithm) but this paper focuses more on the standard case. The
task-based algorithm inherits previous algorithmic improvements, such as
tightly-coupled multi-shifts and Aggressive Early Deflation (AED), and also
incorporates several new ideas that significantly improve the performance. This
includes the elimination of several synchronization points, the dynamic merging
of previously separate computational steps, the shorting and the prioritization
of the critical path, and the introduction of an experimental GPU support. The
task-based implementation is demonstrated to be significantly faster than
multi-threaded LAPACK and ScaLAPACK in both single-node and multi-node
configurations on two different machines based on Intel and AMD CPUs. The
implementation is built on top of the StarPU runtime system and is part of an
open-source StarNEig library.
"
1372,Blends in Maple,"  A blend of two Taylor series for the same smooth real- or complex-valued
function of a single variable can be useful for approximation. We use an
explicit formula for a two-point Hermite interpolational polynomial to
construct such blends. We show a robust Maple implementation that can stably
and efficiently evaluate blends using linear-cost Horner form, evaluate their
derivatives to arbitrary order at the same time, or integrate a blend exactly.
The implementation is suited for use with evalhf. We provide a top-level user
interface and efficient module exports for programmatic use.
  This work intended for presentation at the Maple Conference 2020. See
www.maplesoft.com/mapleconference
"
1373,ACORNS: An Easy-To-Use Code Generator for Gradients and Hessians,"  The computation of first and second-order derivatives is a staple in many
computing applications, ranging from machine learning to scientific computing.
We propose an algorithm to automatically differentiate algorithms written in a
subset of C99 code and its efficient implementation as a Python script. We
demonstrate that our algorithm enables automatic, reliable, and efficient
differentiation of common algorithms used in physical simulation and geometry
processing.
"
1374,Algorithmic differentiation of hyperbolic flow problems,"  We are interested in the development of an algorithmic differentiation
framework for computing approximations to tangent vectors to scalar and systems
of hyperbolic partial differential equations. The main difficulty of such a
numerical method is the presence of shock waves that are resolved by proposing
a numerical discretization of the calculus introduced in Bressan and Marson
[Rend. Sem. Mat. Univ. Padova, 94:79-94, 1995]. Numerical results are presented
for the one-dimensional Burgers equation and the Euler equations. Using the
essential routines of a state-of-the-art code for computational fluid dynamics
(CFD) as a starting point, three modifications are required to apply the
introduced calculus. First, the CFD code is modified to solve an additional
equation for the shock location. Second, we customize the computation of the
corresponding tangent to the shock location. Finally, the modified method is
enhanced by algorithmic differentiation. Applying the introduced calculus to
problems of the Burgers equation and the Euler equations, it is found that
correct sensitivities can be computed, whereas the application of black-box
algorithmic differentiation fails.
"
1375,"A Novel Approach to Generate Correctly Rounded Math Libraries for New
  Floating Point Representations","  Given the importance of floating-point~(FP) performance in numerous domains,
several new variants of FP and its alternatives have been proposed (e.g.,
Bfloat16, TensorFloat32, and Posits). These representations do not have
correctly rounded math libraries. Further, the use of existing FP libraries for
these new representations can produce incorrect results. This paper proposes a
novel methodology for generating polynomial approximations that can be used to
implement correctly rounded math libraries. Existing methods produce
polynomials that approximate the real value of an elementary function $f(x)$
and experience wrong results due to errors in the approximation and due to
rounding errors in the implementation. In contrast, our approach generates
polynomials that approximate the correctly rounded value of $f(x)$ (i.e., the
value of $f(x)$ rounded to the target representation). This methodology
provides more margin to identify efficient polynomials that produce correctly
rounded results for all inputs. We frame the problem of generating efficient
polynomials that produce correctly rounded results as a linear programming
problem. Our approach guarantees that we produce the correct result even with
range reduction techniques. Using our approach, we have developed correctly
rounded, yet faster, implementations of elementary functions for multiple
target representations. Our Bfloat16 library is 2.3$\times$ faster than the
corresponding state-of-the-art while producing correct results for all inputs.
"
1376,"fenicsR13: A Tensorial Mixed Finite Element Solver for the Linear R13
  Equations Using the FEniCS Computing Platform","  We present a mixed finite element solver for the linearized R13 equations of
non-equilibrium gas dynamics. The Python implementation builds upon the
software tools provided by the FEniCS computing platform. We describe a new
tensorial approach utilizing the extension capabilities of FEniCS's Unified
Form Language (UFL) to define required differential operators for tensors above
second degree. The presented solver serves as an example for implementing
tensorial variational formulations in FEniCS, for which the documentation and
literature seem to be very sparse. Using the software abstraction levels
provided by the UFL allows an almost one-to-one correspondence between the
underlying mathematics and the resulting source code. Test cases support the
correctness of the proposed method using validation with exact solutions. To
justify the usage of extended gas flow models, we discuss typical application
cases involving rarefaction effects. We provide the documented and validated
solver publicly.
"
1377,A Survey of Numerical Methods Utilizing Mixed Precision Arithmetic,"  Within the past years, hardware vendors have started designing low precision
special function units in response to the demand of the Machine Learning
community and their demand for high compute power in low precision formats.
Also the server-line products are increasingly featuring low-precision special
function units, such as the NVIDIA tensor cores in ORNL's Summit supercomputer
providing more than an order of magnitude higher performance than what is
available in IEEE double precision. At the same time, the gap between the
compute power on the one hand and the memory bandwidth on the other hand keeps
increasing, making data access and communication prohibitively expensive
compared to arithmetic operations. To start the multiprecision focus effort, we
survey the numerical linear algebra community and summarize all existing
multiprecision knowledge, expertise, and software capabilities in this
landscape analysis report. We also include current efforts and preliminary
results that may not yet be considered ""mature technology,"" but have the
potential to grow into production quality within the multiprecision focus
effort. As we expect the reader to be familiar with the basics of numerical
linear algebra, we refrain from providing a detailed background on the
algorithms themselves but focus on how mixed- and multiprecision technology can
help improving the performance of these methods and present highlights of
application significantly outperforming the traditional fixed precision
methods.
"
1378,"Accelerating Geometric Multigrid Preconditioning with Half-Precision
  Arithmetic on GPUs","  With the hardware support for half-precision arithmetic on NVIDIA V100 GPUs,
high-performance computing applications can benefit from lower precision at
appropriate spots to speed up the overall execution time. In this paper, we
investigate a mixed-precision geometric multigrid method to solve large sparse
systems of equations stemming from discretization of elliptic PDEs. While the
final solution is always computed with high-precision accuracy, an iterative
refinement approach with multigrid preconditioning in lower precision and
residuum scaling is employed. We compare the FP64 baseline for Poisson's
equation to purely FP16 multigrid preconditioning and to the employment of
FP16-FP32-FP64 combinations within a mesh hierarchy. While the iteration count
is almost not affected by using lower accuracy, the solver runtime is
considerably decreased due to the reduced memory transfer and a speedup of up
to 2.5x is gained for the overall solver. We investigate the performance of
selected kernels with the hierarchical Roofline model.
"
1379,"Meta-analysis parameters computation: a Python approach to facilitate
  the crossing of experimental conditions","  Meta-analysis is a data aggregation method that establishes an overall and
objective level of evidence based on the results of several studies. It is
necessary to maintain a high level of homogeneity in the aggregation of data
collected from a systematic literature review. However, the current tools do
not allow a cross-referencing of the experimental conditions that could explain
the heterogeneity observed between studies. This article aims at proposing a
Python programming code containing several functions allowing the analysis and
rapid visualization of data from many studies, while allowing the possibility
of cross-checking the results by experimental condition.
"
1380,"Languages for modeling the RED active queue management algorithms:
  Modelica vs. Julia","  This work is devoted to the study of the capabilities of the Modelica and
Julia programming languages for the implementation of a continuously discrete
paradigm in modeling hybrid systems that contain both continuous and discrete
aspects of behavior. A system consisting of an incoming stream that is
processed according to the Transmission Control Protocol (TCP) and a router
that processes traffic using the Random Early Detection (RED) algorithm acts as
a simulated threshold system.
"
1381,"Approaches to the implementation of generalized complex numbers in the
  Julia language","  In problems of mathematical physics, to study the structures of spaces using
the Cayley-Klein models in theoretical calculations, the use of generalized
complex numbers is required. In the case of computational experiments, such
tasks require their high-quality implementation in a programming language. The
proposed small implementation of generalized complex numbers in modern
programming languages have several disadvantages. In this article, we propose
using the Julia language as the language for implementing generalized complex
numbers, not least because it supports the multiple dispatch mechanism. The
paper demonstrates the approach to the implementation of one of the types of
generalized complex numbers, namely dual numbers. We place particular emphasis
on the description of the use of the multiple dispatch mechanism to implement a
new numerical type. The resulting implementation of dual numbers can be
considered as a prototype for a complete software module for supporting
generalized complex numbers.
"
1382,Tegula -- exploring a galaxy of two-dimensional periodic tilings,"  Periodic tilings play a role in the decorative arts, in construction and in
crystal structures. Combinatorial tiling theory allows the systematic
generation, visualization and exploration of such tilings of the plane, sphere
and hyperbolic plane, using advanced algorithms and software.Here we present a
""galaxy"" of tilings that consists of the set of all 2.4 billion different types
of periodic tilings that have Dress complexity up to 24. We make these
available in a database and provide a new program called Tegula that can be
used to search and visualize such tilings.
  Availability: All tilings and software and are open source and available
here: https://ab.inf.uni-tuebingen.de/software/tegula.
"
1383,An Adaptive Solver for Systems of Linear Equations,"  Computational implementations for solving systems of linear equations often
rely on a one-size-fits-all approach based on LU decomposition of dense
matrices stored in column-major format. Such solvers are typically implemented
with the aid of the xGESV set of functions available in the low-level LAPACK
software, with the aim of reducing development time by taking advantage of
well-tested routines. However, this straightforward approach does not take into
account various matrix properties which can be exploited to reduce the
computational effort and/or to increase numerical stability. Furthermore,
direct use of LAPACK functions can be error-prone for non-expert users and
results in source code that has little resemblance to originating mathematical
expressions. We describe an adaptive solver that we have implemented inside
recent versions of the high-level Armadillo C++ library for linear algebra. The
solver automatically detects several common properties of a given system
(banded, triangular, symmetric positive definite), followed by solving the
system via mapping to a set of suitable LAPACK functions best matched to each
property. The solver also detects poorly conditioned systems and automatically
seeks a solution via singular value decomposition as a fallback. We show that
the adaptive solver leads to notable speedups, while also freeing the user from
using direct calls to cumbersome LAPACK functions.
"
1384,Optimizing Block-Sparse Matrix Multiplications on CUDA with TVM,"  We implemented and optimized matrix multiplications between dense and
block-sparse matrices on CUDA. We leveraged TVM, a deep learning compiler, to
explore the schedule space of the operation and generate efficient CUDA code.
With the automatic parameter tuning in TVM, our cross-thread reduction based
implementation achieved competitive or better performance compared with other
state-of-the-art frameworks.
"
1385,"multivar_horner: a python package for computing Horner factorisations of
  multivariate polynomials","  Many applications in the sciences require numerically stable and
computationally efficient evaluation of multivariate polynomials. Finding
beneficial representations of polynomials, such as Horner factorisations, is
therefore crucial. multivar_horner, the python package presented here, is the
first open source software for computing multivariate Horner factorisations.
This work briefly outlines the functionality of the package and puts it into
reference to previous work in the field. Benchmarks additionally prove the
advantages of the implementation and Horner factorisations in general.
"
1386,"HeAT -- a Distributed and GPU-accelerated Tensor Framework for Data
  Analytics","  To cope with the rapid growth in available data, the efficiency of data
analysis and machine learning libraries has recently received increased
attention. Although great advancements have been made in traditional
array-based computations, most are limited by the resources available on a
single computation node. Consequently, novel approaches must be made to exploit
distributed resources, e.g. distributed memory architectures. To this end, we
introduce HeAT, an array-based numerical programming framework for large-scale
parallel processing with an easy-to-use NumPy-like API. HeAT utilizes PyTorch
as a node-local eager execution engine and distributes the workload on
arbitrarily large high-performance computing systems via MPI. It provides both
low-level array computations, as well as assorted higher-level algorithms. With
HeAT, it is possible for a NumPy user to take full advantage of their available
resources, significantly lowering the barrier to distributed data analysis.
When compared to similar frameworks, HeAT achieves speedups of up to two orders
of magnitude.
"
1387,The ITensor Software Library for Tensor Network Calculations,"  ITensor is a system for programming tensor network calculations with an
interface modeled on tensor diagram notation, which allows users to focus on
the connectivity of a tensor network without manually bookkeeping tensor
indices. The ITensor interface rules out common programming errors and enables
rapid prototyping of tensor network algorithms. After discussing the philosophy
behind the ITensor approach, we show examples of each part of the interface
including Index objects, the ITensor product operator, tensor factorizations,
tensor storage types, algorithms for matrix product state (MPS) and matrix
product operator (MPO) tensor networks, quantum number conserving block-sparse
tensors, and the NDTensors library. We also review publications that have used
ITensor for quantum many-body physics and for other areas where tensor networks
are increasingly applied. To conclude we discuss promising features and
optimizations to be added in the future.
"
1388,A new framework for the computation of Hessians,"  We investigate the computation of Hessian matrices via Automatic
Differentiation, using a graph model and an algebraic model. The graph model
reveals the inherent symmetries involved in calculating the Hessian. The
algebraic model, based on Griewank and Walther's state transformations,
synthesizes the calculation of the Hessian as a formula. These dual points of
view, graphical and algebraic, lead to a new framework for Hessian computation.
This is illustrated by developing edge_pushing, a new truly reverse Hessian
computation algorithm that fully exploits the Hessian's symmetry. Computational
experiments compare the performance of edge_pushing on sixteen functions from
the CUTE collection against two algorithms available as drivers of the software
ADOL-C, and the results are very promising.
"
1389,"Improved Time Warp Edit Distance -- A Parallel Dynamic Program in Linear
  Memory","  Edit Distance is a classic family of dynamic programming problems, among
which Time Warp Edit Distance refines the problem with the notion of a metric
and temporal elasticity. A novel Improved Time Warp Edit Distance algorithm
that is both massively parallelizable and requiring only linear storage is
presented. This method uses the procession of a three diagonal band to cover
the original dynamic program space. Every element of the diagonal update can be
computed in parallel. The core method is a feature of the TWED Longest Common
Subsequence data dependence and is applicable to dynamic programs that share
similar band subproblem structure. The algorithm has been implemented as a CUDA
C library with Python bindings. Speedups for challenging problems are
phenomenal.
"
1390,"A parallel structured divide-and-conquer algorithm for symmetric
  tridiagonal eigenvalue problems","  In this paper, a parallel structured divide-and-conquer (PSDC) eigensolver is
proposed for symmetric tridiagonal matrices based on ScaLAPACK and a parallel
structured matrix multiplication algorithm, called PSMMA. Computing the
eigenvectors via matrix-matrix multiplications is the most computationally
expensive part of the divide-and-conquer algorithm, and one of the matrices
involved in such multiplications is a rank-structured Cauchy-like matrix. By
exploiting this particular property, PSMMA constructs the local matrices by
using generators of Cauchy-like matrices without any communication, and further
reduces the computation costs by using a structured low-rank approximation
algorithm. Thus, both the communication and computation costs are reduced.
Experimental results show that both PSMMA and PSDC are highly scalable and
scale to 4096 processes at least. PSDC has better scalability than PHDC that
was proposed in [J. Comput. Appl. Math. 344 (2018) 512--520] and only scaled to
300 processes for the same matrices. Comparing with \texttt{PDSTEDC} in
ScaLAPACK, PSDC is always faster and achieves $1.4$x--$1.6$x speedup for some
matrices with few deflations. PSDC is also comparable with ELPA, with PSDC
being faster than ELPA when using few processes and a little slower when using
many processes.
"
1391,"EagerPy: Writing Code That Works Natively with PyTorch, TensorFlow, JAX,
  and NumPy","  EagerPy is a Python framework that lets you write code that automatically
works natively with PyTorch, TensorFlow, JAX, and NumPy. Library developers no
longer need to choose between supporting just one of these frameworks or
reimplementing the library for each framework and dealing with code
duplication. Users of such libraries can more easily switch frameworks without
being locked in by a specific 3rd party library. Beyond multi-framework
support, EagerPy also brings comprehensive type annotations and consistent
support for method chaining to any framework. The latest documentation is
available online at https://eagerpy.jonasrauber.de and the code can be found on
GitHub at https://github.com/jonasrauber/eagerpy.
"
1392,"Randomized Projection for Rank-Revealing Matrix Factorizations and
  Low-Rank Approximations","  Rank-revealing matrix decompositions provide an essential tool in spectral
analysis of matrices, including the Singular Value Decomposition (SVD) and
related low-rank approximation techniques. QR with Column Pivoting (QRCP) is
usually suitable for these purposes, but it can be much slower than the
unpivoted QR algorithm. For large matrices, the difference in performance is
due to increased communication between the processor and slow memory, which
QRCP needs in order to choose pivots during decomposition. Our main algorithm,
Randomized QR with Column Pivoting (RQRCP), uses randomized projection to make
pivot decisions from a much smaller sample matrix, which we can construct to
reside in a faster level of memory than the original matrix. This technique may
be understood as trading vastly reduced communication for a controlled increase
in uncertainty during the decision process. For rank-revealing purposes, the
selection mechanism in RQRCP produces results that are the same quality as the
standard algorithm, but with performance near that of unpivoted QR (often an
order of magnitude faster for large matrices). We also propose two formulas
that facilitate further performance improvements. The first efficiently updates
sample matrices to avoid computing new randomized projections. The second
avoids large trailing updates during the decomposition in truncated low-rank
approximations. Our truncated version of RQRCP also provides a key initial step
in our truncated SVD approximation, TUXV. These advances open up a new
performance domain for large matrix factorizations that will support efficient
problem-solving techniques for challenging applications in science,
engineering, and data analysis.
"
1393,PyMGRIT: A Python Package for the parallel-in-time method MGRIT,"  In this paper, we introduce the Python framework PyMGRIT, which implements
the multigrid-reduction-in-time (MGRIT) algorithm for solving the (non-)linear
systems arising from the discretization of time-dependent problems. The MGRIT
algorithm is a reduction-based iterative method that allows parallel-in-time
simulations, i. e., calculating multiple time steps simultaneously in a
simulation, by using a time-grid hierarchy. The PyMGRIT framework features many
different variants of the MGRIT algorithm, ranging from different multigrid
cycle types and relaxation schemes, as well as various coarsening strategies,
including time-only and space-time coarsening, to using different time
integrators on different levels in the multigrid hierachy. PyMGRIT allows
serial runs for prototyping and testing of new approaches, as well as parallel
runs using the Message Passing Interface (MPI). Here, we describe the
implementation of the MGRIT algorithm in PyMGRIT and present the usage from
both user and developer point of views. Three examples illustrate different
aspects of the package, including pure time parallelism as well as space-time
parallelism by coupling PyMGRIT with PETSc or Firedrake, which enable spatial
parallelism through MPI.
"
1394,"Elmer FEM-Dakota: A unified open-source computational framework for
  electromagnetics and data analytics","  Open-source electromagnetic design software, Elmer FEM, was interfaced with
data analytics toolkit, Dakota. Furthermore, the coupled software was validated
against a benchmark test. The interface developed provides a unified
open-source computational framework for electromagnetics and data analytics.
Its key features include uncertainty quantification, surrogate modelling and
parameter studies. This framework enables a richer understanding of model
predictions to better design electric machines in a time sensitive manner.
"
1395,Just another quantum assembly language (Jaqal),"  The Quantum Scientific Computing Open User Testbed (QSCOUT) is a trapped-ion
quantum computer testbed realized at Sandia National Laboratories on behalf of
the Department of Energy's Office of Science and its Advanced Scientific
Computing (ASCR) program. Here we describe Jaqal, for Just another quantum
assembly language, the programming language we invented to specify programs
executed on QSCOUT. Jaqal is useful beyond QSCOUT---it can support mutliple
hardware targets because it offloads gate names and their pulse-sequence
definitions to external files. We describe the capabilities of the Jaqal
language, our approach in designing it, and the reasons for its creation. To
learn more about QSCOUT, Jaqal, or JaqalPaq, the metaprogramming Python package
we developed for Jaqal, please visit https://qscout.sandia.gov,
https://gitlab.com/jaqal, or send an e-mail to qscout@sandia.gov.
"
1396,"Evaluating the Performance of NVIDIA's A100 Ampere GPU for Sparse Linear
  Algebra Computations","  GPU accelerators have become an important backbone for scientific high
performance computing, and the performance advances obtained from adopting new
GPU hardware are significant. In this paper we take a first look at NVIDIA's
newest server line GPU, the A100 architecture part of the Ampere generation.
Specifically, we assess its performance for sparse linear algebra operations
that form the backbone of many scientific applications and assess the
performance improvements over its predecessor.
"
1397,GPU-accelerating ImageJ Macro image processing workflows using CLIJ,"  This chapter introduces GPU-accelerated image processing in ImageJ/FIJI. The
reader is expected to have some pre-existing knowledge of ImageJ Macro
programming. Core concepts such as variables, for-loops, and functions are
essential. The chapter provides basic guidelines for improved performance in
typical image processing workflows. We present in a step-by-step tutorial how
to translate a pre-existing ImageJ macro into a GPU-accelerated macro.
"
1398,BSF-skeleton: user manual,"  The BSF-skeleton is designed for creating parallel programs in C++ using the
MPI library. The scope of the BSF-skeleton is cluster computing systems and
iterative numerical algorithms of high computational complexity. The
BSF-skeleton completely encapsulates all aspects that are associated with
parallelizing a program on a cluster computing system. The source code of the
BSF-skeleton is freely available on Github at
https://github.com/leonid-sokolinsky/BSF-skeleton.
"
1399,"TriCG and TriMR: Two Iterative Methods for Symmetric Quasi-Definite
  Systems","  We introduce iterative methods named TriCG and TriMR for solving symmetric
quasi-definite systems based on the orthogonal tridiagonalization process
proposed by Saunders, Simon and Yip in 1988. TriCG and TriMR are tantamount to
preconditioned block-CG and block-MINRES with two right-hand sides in which the
two approximate solutions are summed at each iteration, but require less
storage and work per iteration. We evaluate the performance of TriCG and TriMR
on linear systems generated from the SuiteSparse Matrix Collection and from
discretized and stablized Stokes equations. We compare TriCG and TriMR with
SYMMLQ and MINRES, the recommended Krylov methods for symmetric and indefinite
systems. In all our experiments, TriCG and TriMR terminate earlier than SYMMLQ
and MINRES on a residual-based stopping condition with an improvement of up to
50% in terms of number of iterations.
"
1400,"A Survey of Singular Value Decomposition Methods for Distributed
  Tall/Skinny Data","  The Singular Value Decomposition (SVD) is one of the most important matrix
factorizations, enjoying a wide variety of applications across numerous
application domains. In statistics and data analysis, the common applications
of SVD such as Principal Components Analysis (PCA) and linear regression.
Usually these applications arise on data that has far more rows than columns,
so-called ""tall/skinny"" matrices. In the big data analytics context, this may
take the form of hundreds of millions to billions of rows with only a few
hundred columns. There is a need, therefore, for fast, accurate, and scalable
tall/skinny SVD implementations which can fully utilize modern computing
resources. To that end, we present a survey of three different algorithms for
computing the SVD for these kinds of tall/skinny data layouts using MPI for
communication. We contextualize these with common big data analytics
techniques, principally PCA. Finally, we present both CPU and GPU timing
results from the Summit supercomputer, and discuss possible alternative
approaches.
"
1401,"Introduction to Medical Image Registration with DeepReg, Between Old and
  New","  This document outlines a tutorial to get started with medical image
registration using the open-source package DeepReg. The basic concepts of
medical image registration are discussed, linking classical methods to newer
methods using deep learning. Two iterative, classical algorithms using
optimisation and one learning-based algorithm using deep learning are coded
step-by-step using DeepReg utilities, all with real, open-accessible, medical
data.
"
1402,distr6: R6 Object-Oriented Probability Distributions Interface in R,"  distr6 is an object-oriented (OO) probability distributions interface
leveraging the extensibility and scalability of R6, and the speed and
efficiency of Rcpp. Over 50 probability distributions are currently implemented
in the package with `core' methods including density, distribution, and
generating functions, and more `exotic' ones including hazards and distribution
function anti-derivatives. In addition to simple distributions, distr6 supports
compositions such as truncation, mixtures, and product distributions. This
paper presents the core functionality of the package and demonstrates examples
for key use-cases. In addition this paper provides a critical review of the
object-oriented programming paradigms in R and describes some novel
implementations for design patterns and core object-oriented features
introduced by the package for supporting distr6 components.
"
1403,"Performance Analysis of FEM Solvers on Practical Electromagnetic
  Problems","  The paper presents a comparative analysis of different commercial and
academic software. The comparison aims to examine how the integrated adaptive
grid refinement methodologies can deal with challenging, electromagnetic-field
related problems. For this comparison, two benchmark problems were examined in
the paper. The first example is a solution of an L-shape domain like test
problem, which has a singularity at a certain point in the geometry. The second
problem is an induction heated aluminum rod, which accurate solution needs to
solve a non-linear, coupled physical fields. The accurate solution of this
problem requires applying adaptive mesh generation strategies or applying a
very fine mesh in the electromagnetic domain, which can significantly increase
the computational complexity. The results show that the fully-hp adaptive
meshing strategies, which are integrated into Agros-suite, can significantly
reduce the task's computational complexity compared to the automatic
h-adaptivity, which is part of the examined, popular commercial solvers.
"
1404,Dune-CurvedGrid -- A Dune module for surface parametrization,"  In this paper we introduce and describe an implementation of curved (surface)
geometries within the Dune framework for grid-based discretizations. Therefore,
we employ the abstraction of geometries as local-functions bound to a grid
element, and the abstraction of a grid as connectivity of elements together
with a grid-function that can be localized to the elements to provide element
local parametrizations of the curved surface.
"
1405,"SeqROCTM: A Matlab toolbox for the analysis of Sequence of Random
  Objects driven by Context Tree Models","  In several research problems we face probabilistic sequences of inputs (e.g.,
sequence of stimuli) from which an agent generates a corresponding sequence of
responses and it is of interest to model/discover some kind of relation between
them. To model such relation in the context of statistical learning in
neuroscience, a new class of stochastic process have been introduced [5],
namely sequences of random objects driven by context tree models. In this paper
we introduce a freely available Matlab toolbox (SeqROCTM) that implements three
model selection methods to make inference about the parameters of this kind of
stochastic process.
"
1406,"An Integer Arithmetic-Based Sparse Linear Solver Using a GMRES Method
  and Iterative Refinement","  In this paper, we develop a (preconditioned) GMRES solver based on integer
arithmetic, and introduce an iterative refinement framework for the solver. We
describe the data format for the coefficient matrix and vectors for the solver
that is based on integer or fixed-point numbers. To avoid overflow in
calculations, we introduce initial scaling and logical shifts (adjustments) of
operands in arithmetic operations. We present the approach for operand shifts,
considering the characteristics of the GMRES algorithm. Numerical tests
demonstrate that the integer arithmetic-based solver with iterative refinement
has comparable solver performance in terms of convergence to the standard
solver based on floating-point arithmetic. Moreover, we show that
preconditioning is important, not only for improving convergence but also
reducing the risk of overflow.
"
1407,"m-arcsinh: An Efficient and Reliable Function for SVM and MLP in
  scikit-learn","  This paper describes the 'm-arcsinh', a modified ('m-') version of the
inverse hyperbolic sine function ('arcsinh'). Kernel and activation functions
enable Machine Learning (ML)-based algorithms, such as Support Vector Machine
(SVM) and Multi-Layer Perceptron (MLP), to learn from data in a supervised
manner. m-arcsinh, implemented in the open source Python library
'scikit-learn', is hereby presented as an efficient and reliable kernel and
activation function for SVM and MLP respectively. Improvements in reliability
and speed to convergence in classification tasks on fifteen (N = 15) datasets
available from scikit-learn and the University California Irvine (UCI) Machine
Learning repository are discussed. Experimental results demonstrate the overall
competitive classification performance of both SVM and MLP, achieved via the
proposed function. This function is compared to gold standard kernel and
activation functions, demonstrating its overall competitive reliability
regardless of the complexity of the classification tasks involved.
"
1408,"Accelerating Domain Propagation: an Efficient GPU-Parallel Algorithm
  over Sparse Matrices","  Fast domain propagation of linear constraints has become a crucial component
of today's best algorithms and solvers for mixed integer programming and
pseudo-boolean optimization to achieve peak solving performance. Irregularities
in the form of dynamic algorithmic behaviour, dependency structures, and
sparsity patterns in the input data make efficient implementations of domain
propagation on GPUs and, more generally, on parallel architectures challenging.
This is one of the main reasons why domain propagation in state-of-the-art
solvers is single thread only. In this paper, we present a new algorithm for
domain propagation which (a) avoids these problems and allows for an efficient
implementation on GPUs, and is (b) capable of running propagation rounds
entirely on the GPU, without any need for synchronization or communication with
the CPU. We present extensive computational results which demonstrate the
effectiveness of our approach and show that ample speedups are possible on
practically relevant problems: on state-of-the-art GPUs, our geometric mean
speed-up for reasonably-large instances is around 10x to 20x and can be as high
as 195x on favorably-large instances.
"
1409,"HDGlab: An open-source implementation of the hybridisable discontinuous
  Galerkin method in MATLAB","  This paper presents HDGlab, an open source MATLAB implementation of the
hybridisable discontinuous Galerkin (HDG) method. The main goal is to provide a
detailed description of both the HDG method for elliptic problems and its
implementation available in HDGlab. Ultimately, this is expected to make this
relatively new advanced discretisation method more accessible to the
computational engineering community. HDGlab presents some features not
available in other implementations of the HDG method that can be found in the
free domain. First, it implements high-order polynomial shape functions up to
degree nine, with both equally-spaced and Fekete nodal distributions. Second,
it supports curved isoparametric simplicial elements in two and three
dimensions. Third, it supports non-uniform degree polynomial approximations and
it provides a flexible structure to devise degree adaptivity strategies.
Finally, an interface with the open-source high-order mesh generator Gmsh is
provided to facilitate its application to practical engineering problems.
"
1410,"QR and LQ Decomposition Matrix Backpropagation Algorithms for Square,
  Wide, and Deep Matrices and Their Software Implementation","  This article presents matrix backpropagation algorithms for the QR
decomposition of matrices $A_{m, n}$, that are either square (m = n), wide (m <
n), or deep (m > n), with rank $k = min(m, n)$. Furthermore, we derive novel
matrix backpropagation results for the pivoted (full-rank) QR decomposition and
for the LQ decomposition of deep input matrices. Differentiable QR
decomposition offers a numerically stable, computationally efficient method to
solve least squares problems frequently encountered in machine learning and
computer vision. Software implementation across popular deep learning
frameworks (PyTorch, TensorFlow, MXNet) incorporate the methods for general use
within the deep learning community. Furthermore, this article aids the
practitioner in understanding the matrix backpropagation methodology as part of
larger computational graphs, and hopefully, leads to new lines of research.
"
1411,Portable high-order finite element kernels I: Streaming Operations,"  This paper is devoted to the development of highly efficient kernels
performing vector operations relevant in linear system solvers. In particular,
we focus on the low arithmetic intensity operations (i.e., streaming
operations) performed within the conjugate gradient iterative method, using the
parameters specified in the CEED benchmark problems for high-order hexahedral
finite elements. We propose a suite of new Benchmark Streaming tests to focus
on the distinct streaming operations which must be performed. We implemented
these new tests using the OCCA abstraction framework to demonstrate portability
of these streaming operations on different GPU architectures, and propose a
simple performance model for such kernels which can accurately capture data
movement rates as well as kernel launch costs.
"
1412,"A compute-bound formulation of Galerkin model reduction for linear
  time-invariant dynamical systems","  This work aims to advance computational methods for projection-based reduced
order models (ROMs) of linear time-invariant (LTI) dynamical systems. For such
systems, current practice relies on ROM formulations expressing the state as a
rank-1 tensor (i.e., a vector), leading to computational kernels that are
memory bandwidth bound and, therefore, ill-suited for scalable performance on
modern many-core and hybrid computing nodes. This weakness can be particularly
limiting when tackling many-query studies, where one needs to run a large
number of simulations. This work introduces a reformulation, called rank-2
Galerkin, of the Galerkin ROM for LTI dynamical systems which converts the
nature of the ROM problem from memory bandwidth to compute bound. We present
the details of the formulation and its implementation, and demonstrate its
utility through numerical experiments using, as a test case, the simulation of
elastic seismic shear waves in an axisymmetric domain. We quantify and analyze
performance and scaling results for varying numbers of threads and problem
sizes. Finally, we present an end-to-end demonstration of using the rank-2
Galerkin ROM for a Monte Carlo sampling study. We show that the rank-2 Galerkin
ROM is one order of magnitude more efficient than the rank-1 Galerkin ROM (the
current practice) and about 970X more efficient than the full order model,
while maintaining excellent accuracy in both the mean and statistics of the
field.
"
1413,"AMReX: Block-Structured Adaptive Mesh Refinement for Multiphysics
  Applications","  Block-structured adaptive mesh refinement (AMR) provides the basis for the
temporal and spatial discretization strategy for a number of ECP applications
in the areas of accelerator design, additive manufacturing, astrophysics,
combustion, cosmology, multiphase flow, and wind plant modelling. AMReX is a
software framework that provides a unified infrastructure with the
functionality needed for these and other AMR applications to be able to
effectively and efficiently utilize machines from laptops to exascale
architectures. AMR reduces the computational cost and memory footprint compared
to a uniform mesh while preserving accurate descriptions of different physical
processes in complex multi-physics algorithms. AMReX supports algorithms that
solve systems of partial differential equations (PDEs) in simple or complex
geometries, and those that use particles and/or particle-mesh operations to
represent component physical processes. In this paper, we will discuss the core
elements of the AMReX framework such as data containers and iterators as well
as several specialized operations to meet the needs of the application
projects. In addition we will highlight the strategy that the AMReX team is
pursuing to achieve highly performant code across a range of accelerator-based
architectures for a variety of different applications.
"
1414,Compressed Basis GMRES on High Performance GPUs,"  Krylov methods provide a fast and highly parallel numerical tool for the
iterative solution of many large-scale sparse linear systems. To a large
extent, the performance of practical realizations of these methods is
constrained by the communication bandwidth in all current computer
architectures, motivating the recent investigation of sophisticated techniques
to avoid, reduce, and/or hide the message-passing costs (in distributed
platforms) and the memory accesses (in all architectures).
  This paper introduces a new communication-reduction strategy for the (Krylov)
GMRES solver that advocates for decoupling the storage format (i.e., the data
representation in memory) of the orthogonal basis from the arithmetic precision
that is employed during the operations with that basis. Given that the
execution time of the GMRES solver is largely determined by the memory access,
the datatype transforms can be mostly hidden, resulting in the acceleration of
the iterative step via a lower volume of bits being retrieved from memory.
Together with the special properties of the orthonormal basis (whose elements
are all bounded by 1), this paves the road toward the aggressive customization
of the storage format, which includes some floating point as well as fixed
point formats with little impact on the convergence of the iterative process.
  We develop a high performance implementation of the ""compressed basis GMRES""
solver in the Ginkgo sparse linear algebra library and using a large set of
test problems from the SuiteSparse matrix collection we demonstrate robustness
and performance advantages on a modern NVIDIA V100 GPU of up to 50% over the
standard GMRES solver that stores all data in IEEE double precision.
"
1415,Flexible Performant GEMM Kernels on GPUs,"  General Matrix Multiplication or GEMM kernels take center place in high
performance computing and machine learning. Recent NVIDIA GPUs include GEMM
accelerators, such as NVIDIA's Tensor Cores. Their exploitation is hampered by
the two-language problem: it requires either low-level programming which
implies low programmer productivity or using libraries that only offer a
limited set of components. Because rephrasing algorithms in terms of
established components often introduces overhead, the libraries' lack of
flexibility limits the freedom to explore new algorithms. Researchers using
GEMMs can hence not enjoy programming productivity, high performance, and
research flexibility at once.
  In this paper we solve this problem. We present three sets of abstractions
and interfaces to program GEMMs within the scientific Julia programming
language. The interfaces and abstractions are co-designed for researchers'
needs and Julia's features to achieve sufficient separation of concerns and
flexibility to easily extend basic GEMMs in many different ways without paying
a performance price. Comparing our GEMMs to state-of-the-art libraries cuBLAS
and CUTLASS, we demonstrate that our performance is mostly on par with, and in
some cases even exceeds, the libraries, without having to write a single line
of code in CUDA C++ or assembly, and without facing flexibility limitations.
"
1416,Regressor: A C program for Combinatorial Regressions,"  In statistics, researchers use Regression models for data analysis and
prediction in many productive sectors (industry, business, academy, etc.).
Regression models are mathematical functions representing an approximation of
dependent variable $Y$ from n independent variables $X_i \in X$. The literature
presents many regression methods divided into single and multiple regressions.
There are several procedures to generate regression models and sets of
commercial and academic tools that implement these procedures. This work
presents one open-source program called Regressor that makes models from a
specific variation of polynomial regression. These models relate the
independent variables to generate an approximation of the original output
dependent data. In many tests, Regressor was able to build models five times
more accurate than commercial tools.
"
1417,"A highly scalable approach to solving linear systems using two-stage
  multisplitting","  Iterative methods for solving large sparse systems of linear equations are
widely used in many HPC applications. Extreme scaling of these methods can be
difficult, however, since global communication to form dot products is
typically required at every iteration.
  To try to overcome this limitation we propose a hybrid approach, where the
matrix is partitioned into blocks. Within each block, we use a highly optimised
(parallel) conventional solver, but we then couple the blocks together using
block Jacobi or some other multisplitting technique that can be implemented in
either a synchronous or an asynchronous fashion. This allows us to limit the
block size to the point where the conventional iterative methods no longer
scale, and to avoid global communication (and possibly synchronisation) across
all processes.
  Our block framework has been built to use PETSc, a popular scientific suite
for solving sparse linear systems, as the synchronous intra-block solver, and
we demonstrate results on up to 32768 cores of a Cray XE6 system. At this
scale, the conventional solvers are still more efficient, though trends suggest
that the hybrid approach may be beneficial at higher core counts.
"
1418,"BOML: A Modularized Bilevel Optimization Library in Python for Meta
  Learning","  Meta-learning (a.k.a. learning to learn) has recently emerged as a promising
paradigm for a variety of applications. There are now many meta-learning
methods, each focusing on different modeling aspects of base and meta learners,
but all can be (re)formulated as specific bilevel optimization problems. This
work presents BOML, a modularized optimization library that unifies several
meta-learning algorithms into a common bilevel optimization framework. It
provides a hierarchical optimization pipeline together with a variety of
iteration modules, which can be used to solve the mainstream categories of
meta-learning methods, such as meta-feature-based and meta-initialization-based
formulations. The library is written in Python and is available at
https://github.com/dut-media-lab/BOML.
"
1419,"Extendible and Efficient Python Framework for Solving Evolution
  Equations with Stabilized Discontinuous Galerkin Method","  This paper discusses a Python interface for the recently published
DUNE-FEM-DG module which provides highly efficient implementations of the
Discontinuous Galerkin (DG) method for solving a wide range of non linear
partial differential equations (PDE). Although the C++ interfaces of
DUNE-FEM-DG are highly flexible and customizable, a solid knowledge of C++ is
necessary to make use of this powerful tool. With this work easier user
interfaces based on Python and the Unified Form Language are provided to open
DUNE-FEM-DG for a broader audience. The Python interfaces are demonstrated for
both parabolic and first order hyperbolic PDEs.
"
1420,"ParaMonte: A high-performance serial/parallel Monte Carlo simulation
  library for C, C++, Fortran","  ParaMonte (standing for Parallel Monte Carlo) is a serial and
MPI/Coarray-parallelized library of Monte Carlo routines for sampling
mathematical objective functions of arbitrary-dimensions, in particular, the
posterior distributions of Bayesian models in data science, Machine Learning,
and scientific inference. The ParaMonte library has been developed with the
design goal of unifying the **automation**, **accessibility**,
**high-performance**, **scalability**, and **reproducibility** of Monte Carlo
simulations. The current implementation of the library includes **ParaDRAM**, a
**Para**llel **D**elyaed-**R**ejection **A**daptive **M**etropolis Markov Chain
Monte Carlo sampler, accessible from a wide range of programming languages
including C, C++, Fortran, with a unified Application Programming Interface and
simulation environment across all supported programming languages. The
ParaMonte library is MIT-licensed and is permanently located and maintained at
[https://github.com/cdslaborg/paramonte](https://github.com/cdslaborg/paramonte).
"
1421,"A 200 Line MATLAB Code for Inverse Design in Photonics by Topology
  Optimization","  We provide a compact 200 line MATLAB code demonstrating how Topology
Optimization (TopOpt) as an inverse design tool may be used in photonics,
targeting the design of two-dimensional dielectric metalenses and a metallic
reflector as examples. The physics model is solved using the finite element
method and the code utilizes MATLABs fmincon algorithm to solve the
optimization problem. In addition to presenting the code itself, we briefly
discuss a number of extensions and provide the code required to implement some
of these. Finally, we demonstrate the superiority of using a gradient-based
method compared to a genetic-algorithm-based method (using MATLABs ga
algorithm) for solving inverse design problems in photonics. The MATLAB
software is freely available in the paper and may be downloaded from
https://www.topopt.dtu.dk.
"
1422,Accelerating Sparse Matrix-Matrix Multiplication with GPU Tensor Cores,"  Sparse general matrix-matrix multiplication (spGEMM) is an essential
component in many scientific and data analytics applications. However, the
sparsity pattern of the input matrices and the interaction of their patterns
make spGEMM challenging. Modern GPUs include Tensor Core Units (TCUs), which
specialize in dense matrix multiplication. Our aim is to re-purpose TCUs for
sparse matrices. The key idea of our spGEMM algorithm, tSparse, is to multiply
sparse rectangular blocks using the mixed precision mode of TCUs. tSparse
partitions the input matrices into tiles and operates only on tiles which
contain one or more elements. It creates a task list of the tiles, and performs
matrix multiplication of these tiles using TCUs. To the best of our knowledge,
this is the first time that TCUs are used in the context of spGEMM. We show
that spGEMM, with our tiling approach, benefits from TCUs. Our approach
significantly improves the performance of spGEMM in comparison to cuSPARSE,
CUSP, RMerge2, Nsparse, AC-SpGEMM and spECK.
"
1423,"Scipp: Scientific data handling with labeled multi-dimensional arrays
  for C++ and Python","  Scipp is heavily inspired by the Python library xarray. It enriches raw
NumPy-like multi-dimensional arrays of data by adding named dimensions and
associated coordinates. Multiple arrays are combined into datasets. On top of
this, scipp introduces (i) implicit handling of physical units, (ii) implicit
propagation of uncertainties, (iii) support for histograms, i.e., bin-edge
coordinate axes, which exceed the data's dimension extent by one, and (iv)
support for event data. In conjunction these features enable a more natural and
more concise user experience. The combination of named dimensions, coordinates,
and units helps to drastically reduce the risk for programming errors. The core
of scipp is written in C++ to open opportunities for performance improvements
that a Python-based solution would not allow for. On top of the C++ core,
scipp's Python components provide functionality for plotting and content
representations, e.g., for use in Jupyter Notebooks. While none of scipp's
concepts in isolation is novel per-se, we are not aware of any project
combining all of these aspects in a single coherent software package.
"
1424,"Fast fully-reproducible serial/parallel Monte Carlo and MCMC simulations
  and visualizations via ParaMonte::Python library","  ParaMonte::Python (standing for Parallel Monte Carlo in Python) is a serial
and MPI-parallelized library of (Markov Chain) Monte Carlo (MCMC) routines for
sampling mathematical objective functions, in particular, the posterior
distributions of parameters in Bayesian modeling and analysis in data science,
Machine Learning, and scientific inference in general. In addition to providing
access to fast high-performance serial/parallel Monte Carlo and MCMC sampling
routines, the ParaMonte::Python library provides extensive post-processing and
visualization tools that aim to automate and streamline the process of model
calibration and uncertainty quantification in Bayesian data analysis.
Furthermore, the automatically-enabled restart functionality of
ParaMonte::Python samplers ensure seamless fully-deterministic into-the-future
restart of Monte Carlo simulations, should any interruptions happen. The
ParaMonte::Python library is MIT-licensed and is permanently maintained on
GitHub at
https://github.com/cdslaborg/paramonte/tree/master/src/interface/Python.
"
1425,"Simflowny 3: An upgraded platform for scientific modelling and
  simulation","  Simflowny is an open platform which automatically generates efficient
parallel code of scientific dynamical models for different simulation
frameworks. Here we present major upgrades on this software to support
simultaneously a quite generic family of partial differential equations. These
equations can be discretized using: (i) standard finite-difference for systems
with derivatives up to any order, (ii) High-Resolution-Shock-Capturing methods
to deal with shocks and discontinuities of balance law equations, and (iii)
particle-based methods. We have improved the adaptive-mesh-refinement
algorithms to preserve the convergence order of the numerical methods, which is
a requirement for improving scalability. Finally, we have also extended our
graphical user interface (GUI) to accommodate these and future families of
equations. This paper summarizes the formal representation and implementation
of these new families, providing several validation results.
"
1426,"Instead of Rewriting Foreign Code for Machine Learning, Automatically
  Synthesize Fast Gradients","  Applying differentiable programming techniques and machine learning
algorithms to foreign programs requires developers to either rewrite their code
in a machine learning framework, or otherwise provide derivatives of the
foreign code. This paper presents Enzyme, a high-performance automatic
differentiation (AD) compiler plugin for the LLVM compiler framework capable of
synthesizing gradients of statically analyzable programs expressed in the LLVM
intermediate representation (IR). Enzyme synthesizes gradients for programs
written in any language whose compiler targets LLVM IR including C, C++,
Fortran, Julia, Rust, Swift, MLIR, etc., thereby providing native AD
capabilities in these languages. Unlike traditional source-to-source and
operator-overloading tools, Enzyme performs AD on optimized IR. On a
machine-learning focused benchmark suite including Microsoft's ADBench, AD on
optimized IR achieves a geometric mean speedup of 4.5x over AD on IR before
optimization allowing Enzyme to achieve state-of-the-art performance. Packaging
Enzyme for PyTorch and TensorFlow provides convenient access to gradients of
foreign code with state-of-the art performance, enabling foreign code to be
directly incorporated into existing machine learning workflows.
"
1427,"VECMAtk: A Scalable Verification, Validation and Uncertainty
  Quantification Toolkit for Scientific Simulations","  We present the VECMA toolkit (VECMAtk), a flexible software environment for
single and multiscale simulations that introduces directly applicable and
reusable procedures for verification, validation (V&V), sensitivity analysis
(SA) and uncertainty quantification (UQ). It enables users to verify key
aspects of their applications, systematically compare and validate the
simulation outputs against observational or benchmark data, and run simulations
conveniently on any platform from the desktop to current multi-petascale
computers. In this sequel to our paper on VECMAtk which we presented last year,
we focus on a range of functional and performance improvements that we have
introduced, cover newly introduced components, and applications examples from
seven different domains such as conflict modelling and environmental sciences.
We also present several implemented patterns for UQ/SA and V&V, and guide the
reader through one example concerning COVID-19 modelling in detail.
"
1428,Extending C++ for Heterogeneous Quantum-Classical Computing,"  We present qcor - a language extension to C++ and compiler implementation
that enables heterogeneous quantum-classical programming, compilation, and
execution in a single-source context. Our work provides a first-of-its-kind C++
compiler enabling high-level quantum kernel (function) expression in a
quantum-language agnostic manner, as well as a hardware-agnostic, retargetable
compiler workflow targeting a number of physical and virtual quantum computing
backends. qcor leverages novel Clang plugin interfaces and builds upon the XACC
system-level quantum programming framework to provide a state-of-the-art
integration mechanism for quantum-classical compilation that leverages the best
from the community at-large. qcor translates quantum kernels ultimately to the
XACC intermediate representation, and provides user-extensible hooks for
quantum compilation routines like circuit optimization, analysis, and
placement. This work details the overall architecture and compiler workflow for
qcor, and provides a number of illuminating programming examples demonstrating
its utility for near-term variational tasks, quantum algorithm expression, and
feed-forward error correction schemes.
"
1429,"Concurrent Alternating Least Squares for multiple simultaneous Canonical
  Polyadic Decompositions","  Tensor decompositions, such as CANDECOMP/PARAFAC (CP), are widely used in a
variety of applications, such as chemometrics, signal processing, and machine
learning. A broadly used method for computing such decompositions relies on the
Alternating Least Squares (ALS) algorithm. When the number of components is
small, regardless of its implementation, ALS exhibits low arithmetic intensity,
which severely hinders its performance and makes GPU offloading ineffective. We
observe that, in practice, experts often have to compute multiple
decompositions of the same tensor, each with a small number of components
(typically fewer than 20), to ultimately find the best ones to use for the
application at hand. In this paper, we illustrate how multiple decompositions
of the same tensor can be fused together at the algorithmic level to increase
the arithmetic intensity. Therefore, it becomes possible to make efficient use
of GPUs for further speedups; at the same time the technique is compatible with
many enhancements typically used in ALS, such as line search, extrapolation,
and non-negativity constraints. We introduce the Concurrent ALS algorithm and
library, which offers an interface to Matlab, and a mechanism to effectively
deal with the issue that decompositions complete at different times.
Experimental results on artificial and real datasets demonstrate a shorter time
to completion due to increased arithmetic intensity.
"
1430,Temporal Vectorization for Stencils,"  Stencil computations represent a very common class of nested loops in
scientific and engineering applications. Exploiting vector units in modern CPUs
is crucial to achieving peak performance. Previous vectorization approaches
often consider the data space, in particular the innermost unit-strided loop.
It leads to the well-known data alignment conflict problem that vector loads
are overlapped due to the data sharing between continuous stencil computations.
This paper proposes a novel temporal vectorization scheme for stencils. It
vectorizes the stencil computation in the iteration space and assembles points
with different time coordinates in one vector. The temporal vectorization leads
to a small fixed number of vector reorganizations that is irrelevant to the
vector length, stencil order, and dimension. Furthermore, it is also applicable
to Gauss-Seidel stencils, whose vectorization is not well-studied. The
effectiveness of the temporal vectorization is demonstrated by various Jacobi
and Gauss-Seidel stencils.
"
1431,"CAPD::DynSys: a flexible C++ toolbox for rigorous numerical analysis of
  dynamical systems","  We present the CAPD::DynSys library for rigorous numerical analysis of
dynamical systems. The basic interface is described together with several
interesting case studies illustrating how it can be used for computer-assisted
proofs in dynamics of ODEs.
"
1432,DSLib: An open source library for the dominant set clustering method,"  DSLib is an open-source implementation of the Dominant Set (DS) clustering
algorithm written entirely in Matlab. The DS method is a graph-based clustering
technique rooted in the evolutionary game theory that starts gaining lots of
interest in the computer science community. Thanks to its duality with game
theory and its strict relation to the notion of maximal clique, has been
explored in several directions not only related to clustering problems.
Applications in graph matching, segmentation, classification and medical
imaging are common in literature. This package provides an implementation of
the original DS clustering algorithm since no code has been officially released
yet, together with a still growing collection of methods and variants related
to it. Our library is integrable into a Matlab pipeline without dependencies,
it is simple to use and easily extendable for upcoming works. The latest source
code, the documentation and some examples can be downloaded from
https://xwasco.github.io/DominantSetLibrary.
"
1433,The Polylogarithm Function in Julia,"  The polylogarithm function is one of the constellation of important
mathematical functions. It has a long history, and many connections to other
special functions and series, and many applications, for instance in
statistical physics. However, the practical aspects of its numerical evaluation
have not received the type of comprehensive treatments lavished on its
siblings. Only a handful of formal publications consider the evaluation of the
function, and most focus on a specific domain and/or presume arbitrary
precision arithmetic will be used. And very little of the literature contains
any formal validation of numerical performance. In this paper we present an
algorithm for calculating polylogarithms for both complex parameter and
argument and evaluate it thoroughly in comparison to the arbitrary precision
implementation in Mathematica. The implementation was created in a new
scientific computing language Julia, which is ideal for the purpose, but also
allows us to write the code in a simple, natural manner so as to make it easy
to port the implementation to other such languages.
"
1434,"Temporal blocking of finite-difference stencil operators with sparse
  ""off-the-grid"" sources","  Stencil kernels dominate a range of scientific applications including seismic
and medical imaging, image processing, and neural networks. Temporal blocking
is a performance optimisation that aims to reduce the required memory bandwidth
of stencil computations by re-using data from the cache for multiple time
steps. It has already been shown to be beneficial for this class of algorithms.
However, optimising stencils for practical applications remains challenging.
These computations often include sparsely located operators, not aligned with
the computational grid (""off-the-grid""). For example, our work is motivated by
sources that inject a wavefield and measurements interpolating grid values. The
resulting data dependencies make the adoption of temporal blocking much more
challenging. We propose a methodology to inspect these data dependencies and
reorder the computation, leading to performance gains in stencil codes where
temporal blocking has not been applicable. We implement this novel scheme in
the Devito domain-specific compiler toolchain. Devito implements a
domain-specific language embedded in Python to generate optimised partial
differential equation solvers using the finite-difference method from
high-level symbolic problem definitions. We evaluate our scheme using isotropic
acoustic, anisotropic acoustic and isotropic elastic wave propagators of
industrial significance. Performance evaluation, after auto-tuning, shows that
this enables substantial performance improvement through temporal blocking,
over highly-optimised vectorized spatially-blocked code of up to 1.6x.
"
1435,"Textbook efficiency: massively parallel matrix-free multigrid for the
  Stokes system","  We employ textbook multigrid efficiency (TME), as introduced by Achi Brandt,
to construct an asymptotically optimal monolithic multigrid solver for the
Stokes system. The geometric multigrid solver builds upon the concept of
hierarchical hybrid grids (HHG), which is extended to higher-order
finite-element discretizations, and a corresponding matrix-free implementation.
The computational cost of the full multigrid (FMG) iteration is quantified, and
the solver is applied to multiple benchmark problems. Through a parameter
study, we suggest configurations that achieve TME for both, stabilized
equal-order, and Taylor-Hood discretizations. The excellent node-level
performance of the relevant compute kernels is presented via a roofline
analysis. Finally, we demonstrate the weak and strong scalability to up to
$147,456$ parallel processes and solve Stokes systems with more than $3.6
\times 10^{12}$ (trillion) unknowns.
"
1436,"LightSeq: A High Performance Inference Library for Sequence Processing
  and Generation","  LightSeq is a high performance inference library for sequence processing and
generation implemented in CUDA. To our best knowledge, this is the first
open-source inference library which fully supports highly efficient computation
of modern NLP models such as BERT, GPT, Transformer, etc. This library is
efficient, functional and convenient. A demo usage can be found here:
https://github.com/bytedance/lightseq/blob/master/example.
"
1437,A comparison of techniques for solving the Poisson equation in CFD,"  CFD is a ubiquitous technique central to much of computational simulation
such as that required by aircraft design. Solving of the Poisson equation
occurs frequently in CFD and there are a number of possible approaches one may
leverage. The dynamical core of the MONC atmospheric model is one example of
CFD which requires the solving of the Poisson equation to determine pressure
terms. Traditionally this aspect of the model has been very time consuming
and-so it is important to consider how we might reduce the runtime cost.
  In this paper we survey the different approaches implemented in MONC to
perform the pressure solve. Designed to take advantage of large scale, modern,
HPC machines, we are concerned with the computation and communication behaviour
of the available techniques and in this text we focus on direct FFT and
indirect iterative methods. In addition to describing the implementation of
these techniques we illustrate on up to 32768 processor cores of a Cray XC30
both the performance and scalability of our approaches. Raw runtime is not the
only measure so we also make some comments around the stability and accuracy of
solution. The result of this work are a number of techniques, optimised for
large scale HPC systems, and an understanding of which is most appropriate in
different situations.
"
1438,"Generalized eigen, singular value, and partial least squares
  decompositions: The GSVD package","  The generalized singular value decomposition (GSVD, a.k.a. ""SVD triplet"",
""duality diagram"" approach) provides a unified strategy and basis to perform
nearly all of the most common multivariate analyses (e.g., principal
components, correspondence analysis, multidimensional scaling, canonical
correlation, partial least squares). Though the GSVD is ubiquitous, powerful,
and flexible, it has very few implementations. Here I introduce the GSVD
package for R. The general goal of GSVD is to provide a small set of accessible
functions to perform the GSVD and two other related decompositions (generalized
eigenvalue decomposition, generalized partial least squares-singular value
decomposition). Furthermore, GSVD helps provide a more unified conceptual
approach and nomenclature to many techniques. I first introduce the concept of
the GSVD, followed by a formal definition of the generalized decompositions.
Next I provide some key decisions made during development, and then a number of
examples of how to use GSVD to implement various statistical techniques. These
examples also illustrate one of the goals of GSVD: how others can (or should)
build analysis packages that depend on GSVD. Finally, I discuss the possible
future of GSVD.
"
1439,"Parallelizing multiple precision Taylor series method for integrating
  the Lorenz system","  A hybrid MPI+OpenMP strategy for parallelizing multiple precision Taylor
series method is proposed, realized and tested. To parallelize the algorithm we
combine MPI and OpenMP parallel technologies together with GMP library (GNU
miltiple precision libary) and the tiny MPIGMP library. The details of the
parallelization are explained on the paradigmatic model of the Lorenz system.
We succeed to obtain a correct reference solution in the rather long time
interval - [0,7000]. The solution is verified by comparing the results for
2700-th order Taylor series method and precision of ~ 3374 decimal digits, and
those with 2800-th order and precision of ~ 3510 decimal digits. With 192 CPU
cores in Nestum cluster, Sofia, Bulgaria, the 2800-th order computation was ~
145 hours with speedup ~ 105.
"
1440,"DistStat.jl: Towards Unified Programming for High-Performance
  Statistical Computing Environments in Julia","  The demand for high-performance computing (HPC) is ever-increasing for
everyday statistical computing purposes. The downside is that we need to write
specialized code for each HPC environment. CPU-level parallelization needs to
be explicitly coded for effective use of multiple nodes in cluster
supercomputing environments. Acceleration via graphics processing units (GPUs)
requires to write kernel code. The Julia software package DistStat.jl
implements a data structure for distributed arrays that work on both multi-node
CPU clusters and multi-GPU environments transparently. This package paves a way
to developing high-performance statistical software in various HPC environments
simultaneously. As a demonstration of the transparency and scalability of the
package, we provide applications to large-scale nonnegative matrix
factorization, multidimensional scaling, and $\ell_1$-regularized Cox
proportional hazards model on an 8-GPU workstation and a 720-CPU-core virtual
cluster in Amazon Web Services (AWS) cloud. As a case in point, we analyze the
on-set of type-2 diabetes from the UK Biobank with 400,000 subjects and 500,000
single nucleotide polymorphisms using the $\ell_1$-regularized Cox proportional
hazards model. Fitting a half-million-variate regression model took less than
50 minutes on AWS.
"
1441,Toward Performance-Portable PETSc for GPU-based Exascale Systems,"  The Portable Extensible Toolkit for Scientific computation (PETSc) library
delivers scalable solvers for nonlinear time-dependent differential and
algebraic equations and for numerical optimization.The PETSc design for
performance portability addresses fundamental GPU accelerator challenges and
stresses flexibility and extensibility by separating the programming model used
by the application from that used by the library, and it enables application
developers to use their preferred programming model, such as Kokkos, RAJA,
SYCL, HIP, CUDA, or OpenCL, on upcoming exascale systems. A blueprint for using
GPUs from PETSc-based codes is provided, and case studies emphasize the
flexibility and high performance achieved on current GPU-based systems.
"
1442,"c-lasso -- a Python package for constrained sparse and robust regression
  and classification","  We introduce c-lasso, a Python package that enables sparse and robust linear
regression and classification with linear equality constraints. The underlying
statistical forward model is assumed to be of the following form: \[ y = X
\beta + \sigma \epsilon \qquad \textrm{subject to} \qquad C\beta=0 \] Here, $X
\in \mathbb{R}^{n\times d}$is a given design matrix and the vector $y \in
\mathbb{R}^{n}$ is a continuous or binary response vector. The matrix $C$ is a
general constraint matrix. The vector $\beta \in \mathbb{R}^{d}$ contains the
unknown coefficients and $\sigma$ an unknown scale. Prominent use cases are
(sparse) log-contrast regression with compositional data $X$, requiring the
constraint $1_d^T \beta = 0$ (Aitchion and Bacon-Shone 1984) and the
Generalized Lasso which is a special case of the described problem (see, e.g,
(James, Paulson, and Rusmevichientong 2020), Example 3). The c-lasso package
provides estimators for inferring unknown coefficients and scale (i.e.,
perspective M-estimators (Combettes and M\""uller 2020a)) of the form \[
\min_{\beta \in \mathbb{R}^d, \sigma \in \mathbb{R}_{0}} f\left(X\beta -
y,{\sigma} \right) + \lambda \left\lVert \beta\right\rVert_1 \qquad
\textrm{subject to} \qquad C\beta = 0 \] for several convex loss functions
$f(\cdot,\cdot)$. This includes the constrained Lasso, the constrained scaled
Lasso, and sparse Huber M-estimators with linear equality constraints.
"
1443,"Tinker-HP : Accelerating Molecular Dynamics Simulations of Large Complex
  Systems with Advanced Point Dipole Polarizable Force Fields using GPUs and
  Multi-GPUs systems","  We present the extension of the Tinker-HP package (Lagard\`ere et al., Chem.
Sci., 2018,9, 956-972) to the use of Graphics Processing Unit (GPU) cards to
accelerate molecular dynamics simulations using polarizable many-body force
fields. The new high-performance module allows for an efficient use of single-
and multi-GPU architectures ranging from research laboratories to modern
pre-exascale supercomputer centers. After detailing an analysis of our general
scalable strategy that relies on OpenACC and CUDA, we discuss the various
capabilities of the package. Among them, the multi-precision possibilities of
the code are discussed. If an efficient double precision implementation is
provided to preserve the possibility of fast reference computations, we show
that a lower precision arithmetic is preferred providing a similar accuracy for
molecular dynamics while exhibiting superior performances. As Tinker-HP is
mainly dedicated to accelerate simulations using new generation point dipole
polarizable force field, we focus our study on the implementation of the AMOEBA
model and provide illustrative benchmarks of the code for single- and
multi-cards simulations on large biosystems encompassing up to millions of
atoms.The new code strongly reduces time to solution and offers the best
performances ever obtained using the AMOEBA polarizable force field.
Perspectives toward the strong-scaling performance of our multi-node massive
parallelization strategy, unsupervised adaptive sampling and large scale
applicability of the Tinker-HP code in biophysics are discussed. The present
software has been released in phase advance on GitHub in link with the High
Performance Computing community COVID-19 research efforts and is free for
Academics (see https://github.com/TinkerTools/tinker-hp).
"
1444,Calcium: computing in exact real and complex fields,"  Calcium is a C library for real and complex numbers in a form suitable for
exact algebraic and symbolic computation. Numbers are represented as elements
of fields $\mathbb{Q}(a_1,\ldots,a_n)$ where the extensions numbers $a_k$ may
be algebraic or transcendental. The system combines efficient field operations
with automatic discovery and certification of algebraic relations, resulting in
a practical computational model of $\mathbb{R}$ and $\mathbb{C}$ in which
equality is rigorously decidable for a large class of numbers.
"
1445,"Solving large number of non-stiff, low-dimensional ordinary differential
  equation systems on GPUs and CPUs: performance comparisons of MPGOS, ODEINT
  and DifferentialEquations.jl","  In this paper, the performance characteristics of different solution
techniques and program packages to solve a large number of independent ordinary
differential equation systems is examined. The employed hardware are an Intel
Core i7-4820K CPU with 30.4 GFLOPS peak double-precision performance per cores
and an Nvidia GeForce Titan Black GPU that has a total of 1707 GFLOPS peak
double-precision performance. The tested systems (Lorenz equation,
Keller--Miksis equation and a pressure relief valve model) are non-stiff and
have low dimension. Thus, the performance of the codes are not limited by
memory bandwidth, and Runge--Kutta type solvers are efficient and suitable
choices. The tested program packages are MPGOS written in C++ and specialised
only for GPUs; ODEINT implemented in C++, which supports execution on both CPUs
and GPUs; finally, DifferentialEquations.jl written in Julia that also supports
execution on both CPUs and GPUs. Using GPUs, the program package MPGOS is
superior. For CPU computations, the ODEINT program package has the best
performance.
"
1446,"Improving the Performance of the GMRES Method using Mixed-Precision
  Techniques","  The GMRES method is used to solve sparse, non-symmetric systems of linear
equations arising from many scientific applications. The solver performance
within a single node is memory bound, due to the low arithmetic intensity of
its computational kernels. To reduce the amount of data movement, and thus, to
improve performance, we investigated the effect of using a mix of single and
double precision while retaining double-precision accuracy. Previous efforts
have explored reduced precision in the preconditioner, but the use of reduced
precision in the solver itself has received limited attention. We found that
GMRES only needs double precision in computing the residual and updating the
approximate solution to achieve double-precision accuracy, although it must
restart after each improvement of single-precision accuracy. This finding holds
for the tested orthogonalization schemes: Modified Gram-Schmidt (MGS) and
Classical Gram-Schmidt with Re-orthogonalization (CGSR). Furthermore, our
mixed-precision GMRES, when restarted at least once, performed 19% and 24%
faster on average than double-precision GMRES for MGS and CGSR, respectively.
Our implementation uses generic programming techniques to ease the burden of
coding implementations for different data types. Our use of the Kokkos library
allowed us to exploit parallelism and optimize data management. Additionally,
KokkosKernels was used when producing performance results. In conclusion, using
a mix of single and double precision in GMRES can improve performance while
retaining double-precision accuracy.
"
1447,"Extending the statistical software package Engine for Likelihood-Free
  Inference","  Bayesian inference is a principled framework for dealing with uncertainty.
The practitioner can perform an initial assumption for the physical phenomenon
they want to model (prior belief), collect some data and then adjust the
initial assumption in the light of the new evidence (posterior belief).
Approximate Bayesian Computation (ABC) methods, also known as likelihood-free
inference techniques, are a class of models used for performing inference when
the likelihood is intractable. The unique requirement of these models is a
black-box sampling machine. Due to the modelling-freedom they provide these
approaches are particularly captivating. Robust Optimisation Monte Carlo (ROMC)
is one of the most recent techniques of the specific domain. It approximates
the posterior distribution by solving independent optimisation problems. This
dissertation focuses on the implementation of the ROMC method in the software
package Engine for Likelihood-Free Inference (ELFI). In the first chapters, we
provide the mathematical formulation and the algorithmic description of the
ROMC approach. In the following chapters, we describe our implementation; (a)
we present all the functionalities provided to the user and (b) we demonstrate
how to perform inference on some real examples. Our implementation provides a
robust and efficient solution to a practitioner who wants to perform inference
on a simulator-based model. Furthermore, it exploits parallel processing for
accelerating the inference wherever it is possible. Finally, it has been
designed to serve extensibility; the user can easily replace specific subparts
of the method without significant overhead on the development side. Therefore,
it can be used by a researcher for further experimentation.
"
1448,DoWhy: An End-to-End Library for Causal Inference,"  In addition to efficient statistical estimators of a treatment's effect,
successful application of causal inference requires specifying assumptions
about the mechanisms underlying observed data and testing whether they are
valid, and to what extent. However, most libraries for causal inference focus
only on the task of providing powerful statistical estimators. We describe
DoWhy, an open-source Python library that is built with causal assumptions as
its first-class citizens, based on the formal framework of causal graphs to
specify and test causal assumptions. DoWhy presents an API for the four steps
common to any causal analysis---1) modeling the data using a causal graph and
structural assumptions, 2) identifying whether the desired effect is estimable
under the causal model, 3) estimating the effect using statistical estimators,
and finally 4) refuting the obtained estimate through robustness checks and
sensitivity analyses. In particular, DoWhy implements a number of robustness
checks including placebo tests, bootstrap tests, and tests for unoberved
confounding. DoWhy is an extensible library that supports interoperability with
other implementations, such as EconML and CausalML for the the estimation step.
The library is available at https://github.com/microsoft/dowhy
"
1449,tvopt: A Python Framework for Time-Varying Optimization,"  This paper introduces tvopt, a Python framework for prototyping and
benchmarking time-varying (or online) optimization algorithms. The paper first
describes the theoretical approach that informed the development of tvopt. Then
it discusses the different components of the framework and their use for
modeling and solving time-varying optimization problems. In particular, tvopt
provides functionalities for defining both centralized and distributed online
problems, and a collection of built-in algorithms to solve them, for example
gradient-based methods, ADMM and other splitting methods. Moreover, the
framework implements prediction strategies to improve the accuracy of the
online solvers. The paper then proposes some numerical results on a benchmark
problem and discusses their implementation using tvopt. The code for tvopt is
available at https://github.com/nicola-bastianello/tvopt.
"
1450,RCHOL: Randomized Cholesky Factorization for Solving SDD Linear Systems,"  We introduce a randomized algorithm, namely {\tt rchol}, to construct an
approximate Cholesky factorization for a given sparse Laplacian matrix (a.k.a.,
graph Laplacian). The (exact) Cholesky factorization for the matrix introduces
a clique in the associated graph after eliminating every row/column. By
randomization, {\tt rchol} samples a subset of the edges in the clique. We
prove {\tt rchol} is breakdown free and apply it to solving linear systems with
symmetric diagonally-dominant matrices. In addition, we parallelize {\tt rchol}
based on the nested dissection ordering for shared-memory machines. Numerical
experiments demonstrated the robustness and the scalability of {\tt rchol}. For
example, our parallel code scaled up to 64 threads on a single node for solving
the 3D Poisson equation, discretized with the 7-point stencil on a $1024\times
1024 \times 1024$ grid, or \textbf{one billion} unknowns.
"
1451,"A simple technique for unstructured mesh generation via adaptive finite
  elements","  This work describes a concise algorithm for the generation of triangular
meshes with the help of standard adaptive finite element methods. We
demonstrate that a generic adaptive finite element solver can be repurposed
into a triangular mesh generator if a robust mesh smoothing algorithm is
applied between the mesh refinement steps. We present an implementation of the
mesh generator and demonstrate the resulting meshes via several examples.
"
1452,Combining the Mersenne Twister and the Xorgens Designs,"  We combine the design of two \emph{random number generators}, \emph{Mersenne
Twister} and \emph{Xorgens}, to obtain a new class of generators with
heavy-weight characteristic polynomials (exceeded only by the {\sc well}
generators) and high speed (comparable with the originals). Tables with
parameter combinations are included for state sizes ranging from 521 to 44497
bits and each of the word lengths 32, 64, 128. These generators passed all
tests of the \emph{TestU01}-package for each 32-bit integer part and each
64-bit derived real part of the output. We determine \emph{dimension gaps} for
32-bit words, neglecting the non-linear tempering, and compare with an
alternative experimental linear tempering.
"
1453,"Threaded Gr\""{o}bner Bases: a Macaulay2 package","  The complexity of Gr\""{o}bner computations has inspired many improvements to
Buchberger's
  algorithm over the years. Looking for further insights into the algorithm's
performance, we offer a threaded implementation of classical Buchberger's
algorithm in {\it Macaulay2}. The output of the main function of the package
includes information about {\it lineages} of non-zero remainders that are added
to the basis during the computation. This information can be used for further
algorithm improvements and optimization.
"
1454,Deep Learning Framework From Scratch Using Numpy,"  This work is a rigorous development of a complete and general-purpose deep
learning framework from the ground up. The fundamental components of deep
learning - automatic differentiation and gradient methods of optimizing
multivariable scalar functions - are developed from elementary calculus and
implemented in a sensible object-oriented approach using only Python and the
Numpy library. Demonstrations of solved problems using the framework, named
ArrayFlow, include a computer vision classification task, solving for the shape
of a catenary, and a 2nd order differential equation.
"
1455,Ginkgo -- A Math Library designed for Platform Portability,"  The first associations to software sustainability might be the existence of a
continuous integration (CI) framework; the existence of a testing framework
composed of unit tests, integration tests, and end-to-end tests; and also the
existence of software documentation. However, when asking what is a common
deathblow for a scientific software product, it is often the lack of platform
and performance portability. Against this background, we designed the Ginkgo
library with the primary focus on platform portability and the ability to not
only port to new hardware architectures, but also achieve good performance. In
this paper we present the Ginkgo library design, radically separating
algorithms from hardware-specific kernels forming the distinct hardware
executors, and report our experience when adding execution backends for NVIDIA,
AMD, and Intel GPUs. We also comment on the different levels of performance
portability, and the performance we achieved on the distinct hardware backends.
"
1456,Generalized Box-Muller method for generating q-Gaussian random deviates,"  Addendum: The generalized Box-M\""uller algorithm provides a methodology for
generating q-Gaussian random variates. The parameter $-\infty<q\leq3$ is
related to the shape of the tail decay; $q<1$ for compact-support including
parabola $(q=0)$; $1<q\leq3$ for heavy-tail including Cauchy $(q=2)$. This
addendum clarifies the transformation $q'=((3q-1)/(q+1))$ within the algorithm
is due to a difference in the dimensions d of the generalized logarithm and the
generalized distribution. The transformation is clarified by the decomposition
of $q=1+2\kappa/(1+d\kappa)$, where the shape parameter $-1<\kappa\leq\infty$
quantifies the magnitude of the deformation from exponential. A simpler
specification for the generalized Box- M\""uller algorithm is provided using the
shape of the tail decay.
  Original: The q-Gaussian distribution is known to be an attractor of certain
correlated systems, and is the distribution which, under appropriate
constraints, maximizes the entropy Sq, basis of nonextensive statistical
mechanics. This theory is postulated as a natural extension of the standard
(Boltzmann-Gibbs) statistical mechanics, and may explain the ubiquitous
appearance of heavy-tailed distributions in both natural and man-made systems.
The q-Gaussian distribution is also used as a numerical tool, for example as a
visiting distribution in Generalized Simulated Annealing. We develop and
present a simple, easy to implement numerical method for generating random
deviates from a q-Gaussian distribution based upon a generalization of the well
known Box-Muller method. Our method is suitable for a larger range of q values,
q<3, than has previously appeared in the literature, and can generate deviates
from q-Gaussian distributions of arbitrary width and center. MATLAB code
showing a straightforward implementation is also included.
"
1457,Adaptive simulated annealing (ASA): Lessons learned,"  Adaptive simulated annealing (ASA) is a global optimization algorithm based
on an associated proof that the parameter space can be sampled much more
efficiently than by using other previous simulated annealing algorithms. The
author's ASA code has been publicly available for over two years. During this
time the author has volunteered to help people via e-mail, and the feedback
obtained has been used to further develop the code. Some lessons learned, in
particular some which are relevant to other simulated annealing algorithms, are
described.
"
1458,"Mathematical Software: Past, Present, and Future","  This paper provides some reflections on the field of mathematical software on
the occasion of John Rice's 65th birthday. I describe some of the common themes
of research in this field and recall some significant events in its evolution.
Finally, I raise a number of issues that are of concern to future developments.
"
1459,Automatic Differentiation Tools in Optimization Software,"  We discuss the role of automatic differentiation tools in optimization
software. We emphasize issues that are important to large-scale optimization
and that have proved useful in the installation of nonlinear solvers in the
NEOS Server. Our discussion centers on the computation of the gradient and
Hessian matrix for partially separable functions and shows that the gradient
and Hessian matrix can be computed with guaranteed bounds in time and memory
requirements
"
1460,"GPCG: A Case Study in the Performance and Scalability of Optimization
  Algorithms","  GPCG is an algorithm within the Toolkit for Advanced Optimization (TAO) for
solving bound constrained, convex quadratic problems. Originally developed by
More' and Toraldo, this algorithm was designed for large-scale problems but had
been implemented only for a single processor. The TAO implementation is
available for a wide range of high-performance architecture, and has been
tested on up to 64 processors to solve problems with over 2.5 million
variables.
"
1461,Benchmarking Optimization Software with Performance Profiles,"  We propose performance profiles-distribution functions for a performance
metric-as a tool for benchmarking and comparing optimization software. We show
that performance profiles combine the best features of other tools for
performance evaluation.
"
1462,Lectures on Reduce and Maple at UAM I - Mexico,"  These lectures give a brief introduction to the Computer Algebra systems
Reduce and Maple. The aim is to provide a systematic survey of most important
commands and concepts. In particular, this includes a discussion of
simplification schemes and the handling of simplification and substitution
rules (e.g., a Lie Algebra is implemented in Reduce by means of simplification
rules).
  Another emphasis is on the different implementations of tensor calculi and
the exterior calculus by Reduce and Maple and their application in Gravitation
theory and Differential Geometry.
  I held the lectures at the Universidad Autonoma Metropolitana-Iztapalapa,
Departamento de Fisica, Mexico, in November 1999.
"
1463,"Users Guide for SnadiOpt: A Package Adding Automatic Differentiation to
  Snopt","  SnadiOpt is a package that supports the use of the automatic differentiation
package ADIFOR with the optimization package Snopt. Snopt is a general-purpose
system for solving optimization problems with many variables and constraints.
It minimizes a linear or nonlinear function subject to bounds on the variables
and sparse linear or nonlinear constraints. It is suitable for large-scale
linear and quadratic programming and for linearly constrained optimization, as
well as for general nonlinear programs. The method used by Snopt requires the
first derivatives of the objective and constraint functions to be available.
The SnadiOpt package allows users to avoid the time-consuming and error-prone
process of evaluating and coding these derivatives. Given Fortran code for
evaluating only the values of the objective and constraints, SnadiOpt
automatically generates the code for evaluating the derivatives and builds the
relevant Snopt input files and sparse data structures.
"
1464,Computer validated proofs of a toolset for adaptable arithmetic,"  Most existing implementations of multiple precision arithmetic demand that
the user sets the precision {\em a priori}. Some libraries are said adaptable
in the sense that they dynamically change the precision of each intermediate
operation individually to deliver the target accuracy according to the actual
inputs. We present in this text a new adaptable numeric core inspired both from
floating point expansions and from on-line arithmetic.
  The numeric core is cut down to four tools. The tool that contains arithmetic
operations is proved to be correct. The proofs have been formally checked by
the Coq assistant. Developing the proofs, we have formally proved many results
published in the literature and we have extended a few of them. This work may
let users (i) develop application specific adaptable libraries based on the
toolset and / or (ii) write new formal proofs based on the set of validated
facts.
"
1465,"TeXmacs interfaces to Maxima, MuPAD and REDUCE","  GNU TeXmacs is a free wysiwyg word processor providing an excellent
typesetting quality of texts and formulae. It can also be used as an interface
to Computer Algebra Systems (CASs). In the present work, interfaces to three
general-purpose CASs have been implemented.
"
1466,Algorithm for generating orthogonal matrices with rational elements,"  Special orthogonal matrices with rational elements form the group SO(n,Q),
where Q is the field of rational numbers. A theorem describing the structure of
an arbitrary matrix from this group is proved. This theorem yields an algorithm
for generating such matrices by means of random number routines.
"
1467,"Recursive function templates as a solution of linear algebra expressions
  in C++","  The article deals with a kind of recursive function templates in C++, where
the recursion is realized corresponding template parameters to achieve better
computational performance. Some specialization of these template functions ends
the recursion and can be implemented using optimized hardware dependent or
independent routines. The method is applied in addition to the known expression
templates technique to solve linear algebra expressions with the help of the
BLAS library. The whole implementation produces a new library, which keeps
object-oriented benefits and has a higher computational speed represented in
the tests.
"
1468,Reliability Conditions in Quadrature Algorithms,"  The detection of insufficiently resolved or ill-conditioned integrand
structures is critical for the reliability assessment of the quadrature rule
outputs. We discuss a method of analysis of the profile of the integrand at the
quadrature knots which allows inferences approaching the theoretical 100% rate
of success, under error estimate sharpening. The proposed procedure is of the
highest interest for the solution of parametric integrals arising in complex
physical models.
"
1469,A Bird's eye view of Matrix Distributed Processing,"  We present Matrix Distributed Processing, a C++ library for fast development
of efficient parallel algorithms. MDP is based on MPI and consists of a
collection of C++ classes and functions such as lattice, site and field. Once
an algorithm is written using these components the algorithm is automatically
parallel and no explicit call to communication functions is required. MDP is
particularly suitable for implementing parallel solvers for multi-dimensional
differential equations and mesh-like problems.
"
1470,"A Representation of Changes of Images and its Application for
  Developmental Biolology","  In this paper, we consider a series of events observed at spaced time
intervals and present a method of representation of the series. To explain an
idea, by dealing with a set of gene expression data, which could be obtained
from developmental biology, the procedures are sketched with comments in some
details. We mean representation by choosing a proper function, which fits well
with observed data of a series, and turning its characteristics into numbers,
which extract the intrinsic properties of fluctuating data. With help of a
machine learning techniques, this method will give a classification of
developmental biological data as well as any varying data during a certain
period and the classification can be applied for diagnosis of a disease.
"
1471,Development of a Java Package for Matrix Programming,"  We had assembled a Java package, known as MatrixPak, of four classes for the
purpose of numerical matrix computation. The classes are matrix,
matrix_operations, StrToMatrix, and MatrixToStr; all of which are inherited
from java.lang.Object class. Class matrix defines a matrix as a two-dimensional
array of float types, and contains the following mathematical methods:
transpose, adjoint, determinant, inverse, minor and cofactor. Class
matrix_operations contains the following mathematical methods: matrix addition,
matrix subtraction, matrix multiplication, and matrix exponential. Class
StrToMatrix contains methods necessary to parse a string representation (for
example, [[2 3 4]-[5 6 7]]) of a matrix into a matrix definition, whereas class
MatrixToStr does the reverse.
"
1472,"Finding the ""truncated"" polynomial that is closest to a function","  When implementing regular enough functions (e.g., elementary or special
functions) on a computing system, we frequently use polynomial approximations.
In most cases, the polynomial that best approximates (for a given distance and
in a given interval) a function has coefficients that are not exactly
representable with a finite number of bits. And yet, the polynomial
approximations that are actually implemented do have coefficients that are
represented with a finite - and sometimes small - number of bits: this is due
to the finiteness of the floating-point representations (for software
implementations), and to the need to have small, hence fast and/or inexpensive,
multipliers (for hardware implementations). We then have to consider polynomial
approximations for which the degree-$i$ coefficient has at most $m_i$
fractional bits (in other words, it is a rational number with denominator
$2^{m_i}$). We provide a general method for finding the best polynomial
approximation under this constraint. Then, we suggest refinements than can be
used to accelerate our method.
"
1473,Boundary knot method for Laplace and biharmonic problems,"  The boundary knot method (BKM) [1] is a meshless boundary-type radial basis
function (RBF) collocation scheme, where the nonsingular general solution is
used instead of fundamental solution to evaluate the homogeneous solution,
while the dual reciprocity method (DRM) is employed to approximation of
particular solution. Despite the fact that there are not nonsingular RBF
general solutions available for Laplace and biharmonic problems, this study
shows that the method can be successfully applied to these problems. The
high-order general and fundamental solutions of Burger and Winkler equations
are also first presented here.
"
1474,Mace4 Reference Manual and Guide,"  Mace4 is a program that searches for finite models of first-order formulas.
For a given domain size, all instances of the formulas over the domain are
constructed. The result is a set of ground clauses with equality. Then, a
decision procedure based on ground equational rewriting is applied. If
satisfiability is detected, one or more models are printed. Mace4 is a useful
complement to first-order theorem provers, with the prover searching for proofs
and Mace4 looking for countermodels, and it is useful for work on finite
algebras. Mace4 performs better on equational problems than did our previous
model-searching program Mace2.
"
1475,OTTER 3.3 Reference Manual,"  OTTER is a resolution-style theorem-proving program for first-order logic
with equality. OTTER includes the inference rules binary resolution,
hyperresolution, UR-resolution, and binary paramodulation. Some of its other
abilities and features are conversion from first-order formulas to clauses,
forward and back subsumption, factoring, weighting, answer literals, term
ordering, forward and back demodulation, evaluable functions and predicates,
Knuth-Bendix completion, and the hints strategy. OTTER is coded in ANSI C, is
free, and is portable to many different kinds of computer.
"
1476,An Introduction to Using Software Tools for Automatic Differentiation,"  We give a gentle introduction to using various software tools for automatic
differentiation (AD). Ready-to-use examples are discussed, and links to further
information are presented. Our target audience includes all those who are
looking for a straightforward way to get started using the available AD
technology. The document is dynamic in the sense that its content will be
updated as the AD software evolves.
"
1477,"Cluster computing performances using virtual processors and mathematical
  software","  In this paper I describe some results on the use of virtual processors
technology for parallelize some SPMD computational programs in a cluster
environment. The tested technology is the INTEL Hyper Threading on real
processors, and the programs are MATLAB 6.5 Release 13 scripts for floating
points computation. By the use of this technology, I tested that a cluster can
run with benefit a number of concurrent processes double the amount of physical
processors. The conclusions of the work concern on the utility and limits of
the used approach. The main result is that using virtual processors is a good
technique for improving parallel programs not only for memory-based
computations, but in the case of massive disk-storage operations too.
"
1478,"Algorithm xxx: Modified Bessel functions of imaginary order and positive
  argument","  Fortran 77 programs for the computation of modified Bessel functions of
purely imaginary order are presented. The codes compute the functions
$K_{ia}(x)$, $L_{ia}(x)$ and their derivatives for real $a$ and positive $x$;
these functions are independent solutions of the differential equation $x^2 w''
+x w' +(a^2 -x^2)w=0$. The code also computes exponentially scaled functions.
The range of computation is $(x,a)\in (0,1500]\times [-1500,1500]$ when scaled
functions are considered and it is larger than $(0,500]\times [-400,400]$ for
standard IEEE double precision arithmetic. The relative accuracy is better than
$10^{-13}$ in the range $(0,200]\times [-200,200]$ and close to $10^{-12}$ in
$(0,1500]\times [-1500,1500]$.
"
1479,Directional Consistency for Continuous Numerical Constraints,"  Bounds consistency is usually enforced on continuous constraints by first
decomposing them into binary and ternary primitives. This decomposition has
long been shown to drastically slow down the computation of solutions. To
tackle this, Benhamou et al. have introduced an algorithm that avoids formally
decomposing constraints. Its better efficiency compared to the former method
has already been experimentally demonstrated. It is shown here that their
algorithm implements a strategy to enforce on a continuous constraint a
consistency akin to Directional Bounds Consistency as introduced by Dechter and
Pearl for discrete problems. The algorithm is analyzed in this framework, and
compared with algorithms that enforce bounds consistency. These theoretical
results are eventually contrasted with new experimental results on standard
benchmarks from the interval constraint community.
"
1480,"A Fast, Vectorizable Algorithm for Producing Single-Precision
  Sine-Cosine Pairs","  This paper presents an algorithm for computing Sine-Cosine pairs to modest
accuracy, but in a manner which contains no conditional tests or branching,
making it highly amenable to vectorization. An exemplary implementation for
PowerPC AltiVec processors is included, but the algorithm should be easily
portable to other achitectures, such as Intel SSE.
"
1481,"M@th Desktop and MD Tools - Mathematics and Mathematica Made Easy for
  Students","  We present two add-ons for Mathematica for teaching mathematics to
undergraduate and high school students. These two applications, M@th Desktop
(MD) and M@th Desktop Tools (MDTools), include several palettes and notebooks
covering almost every field. The underlying didactic concept is so-called
""blended learning"", in which these tools are meant to be used as a complement
to the professor or teacher rather than as a replacement, which other
e-learning applications do. They enable students to avoid the usual problem of
computer-based learning, namely that too large an amount of time is wasted
struggling with computer and program errors instead of actually learning the
mathematical concepts.
  M@th Desktop Tools is palette-based and provides easily accessible and
user-friendly templates for the most important functions in the fields of
Analysis, Algebra, Linear Algebra and Statistics. M@th Desktop, in contrast, is
a modern, interactive teaching and learning software package for mathematics
classes. It is comprised of modules for Differentiation, Integration, and
Statistics, and each module presents its topic with a combination of
interactive notebooks and palettes.
  Both packages can be obtained from Deltasoft's homepage at
http://www.deltasoft.at/ .
"
1482,"Tsnnls: A solver for large sparse least squares problems with
  non-negative variables","  The solution of large, sparse constrained least-squares problems is a staple
in scientific and engineering applications. However, currently available codes
for such problems are proprietary or based on MATLAB. We announce a freely
available C implementation of the fast block pivoting algorithm of Portugal,
Judice, and Vicente. Our version is several times faster than Matstoms' MATLAB
implementation of the same algorithm. Further, our code matches the accuracy of
MATLAB's built-in lsqnonneg function.
"
1483,Mean and Variance Estimation by Kriging,"  The aim of the paper is to derive the numerical least-squares estimator for
mean and variance of random variable. In order to do so the following questions
have to be answered: (i) what is the statistical model for the estimation
procedure? (ii) what are the properties of the estimator, like optimality (in
which class) or asymptotic properties? (iii) how does the estimator work in
practice, how compared to competing estimators?
"
1484,An Example of Clifford Algebras Calculations with GiNaC,"  This example of Clifford algebras calculations uses GiNaC
(http://www.ginac.de/) library, which includes a support for generic Clifford
algebra starting from version~1.3.0. Both symbolic and numeric calculation are
possible and can be blended with other functions of GiNaC. This calculations
was made for the paper math.CV/0410399.
  Described features of GiNaC are already available at PyGiNaC
(http://sourceforge.net/projects/pyginac/) and due to course should propagate
into other software like GNU Octave (http://www.octave.org/), gTybalt
(http://www.fis.unipr.it/~stefanw/gtybalt.html), which use GiNaC library as
their back-end.
"
1485,"ADF95: Tool for automatic differentiation of a FORTRAN code designed for
  large numbers of independent variables","  ADF95 is a tool to automatically calculate numerical first derivatives for
any mathematical expression as a function of user defined independent
variables. Accuracy of derivatives is achieved within machine precision. ADF95
may be applied to any FORTRAN 77/90/95 conforming code and requires minimal
changes by the user. It provides a new derived data type that holds the value
and derivatives and applies forward differencing by overloading all FORTRAN
operators and intrinsic functions. An efficient indexing technique leads to a
reduced memory usage and a substantially increased performance gain over other
available tools with operator overloading. This gain is especially pronounced
for sparse systems with large number of independent variables. A wide class of
numerical simulations, e.g., those employing implicit solvers, can profit from
ADF95.
"
1486,TeXmacs-maxima interface,"  This tutorial presents features of the new and improved TeXmacs-maxima
interface. It is designed for running maxima-5.9.2 from TeXmacs-1.0.5 (or
later).
"
1487,"Estudo e Implementacao de Algoritmos de Roteamento sobre Grafos em um
  Sistema de Informacoes Geograficas","  This article presents an implementation of a graphical software with various
algorithms in Operations research, like minimum path, minimum tree, chinese
postman problem and travelling salesman.
"
1488,"A Maple Package for Computing Groebner Bases for Linear Recurrence
  Relations","  A Maple package for computing Groebner bases of linear difference ideals is
described. The underlying algorithm is based on Janet and Janet-like monomial
divisions associated with finite difference operators. The package can be used,
for example, for automatic generation of difference schemes for linear partial
differential equations and for reduction of multiloop Feynman integrals. These
two possible applications are illustrated by simple examples of the Laplace
equation and a one-loop scalar integral of propagator type
"
1489,COMODI: On the Graphical User Interface,"  We propose a series of features for the graphical user interface (GUI) of the
COmputational MOdule Integrator (COMODI) \cite{Synasc05a}\cite{COMODI}. In view
of the special requirements that a COMODI type of framework for scientific
computing imposes and inspiring from existing solutions that provide advanced
graphical visual programming environments, we identify those elements and
associated behaviors that will have to find their way into the first release of
COMODI.
"
1490,Numerical resolution of some BVP using Bernstein polynomials,"  In this work we present a method, based on the use of Bernstein polynomials,
for the numerical resolution of some boundary values problems. The computations
have not need of particular approximations of derivatives, such as finite
differences, or particular techniques, such as finite elements. Also, the
method doesn't require the use of matrices, as in resolution of linear
algebraic systems, nor the use of like-Newton algorithms, as in resolution of
non linear sets of equations. An initial equation is resolved only once, then
the method is based on iterated evaluations of appropriate polynomials.
"
1491,"PURRS: Towards Computer Algebra Support for Fully Automatic Worst-Case
  Complexity Analysis","  Fully automatic worst-case complexity analysis has a number of applications
in computer-assisted program manipulation. A classical and powerful approach to
complexity analysis consists in formally deriving, from the program syntax, a
set of constraints expressing bounds on the resources required by the program,
which are then solved, possibly applying safe approximations. In several
interesting cases, these constraints take the form of recurrence relations.
While techniques for solving recurrences are known and implemented in several
computer algebra systems, these do not completely fulfill the needs of fully
automatic complexity analysis: they only deal with a somewhat restricted class
of recurrence relations, or sometimes require user intervention, or they are
restricted to the computation of exact solutions that are often so complex to
be unmanageable, and thus useless in practice. In this paper we briefly
describe PURRS, a system and software library aimed at providing all the
computer algebra services needed by applications performing or exploiting the
results of worst-case complexity analyses. The capabilities of the system are
illustrated by means of examples derived from the analysis of programs written
in a domain-specific functional programming language for real-time embedded
systems.
"
1492,Computations with one and two real algebraic numbers,"  We present algorithmic and complexity results concerning computations with
one and two real algebraic numbers, as well as real solving of univariate
polynomials and bivariate polynomial systems with integer coefficients using
Sturm-Habicht sequences.
  Our main results, in the univariate case, concern the problems of real root
isolation (Th. 19) and simultaneous inequalities (Cor.26) and in the bivariate,
the problems of system real solving (Th.42), sign evaluation (Th. 37) and
simultaneous inequalities (Cor. 43).
"
1493,Schwerdtfeger-Fillmore-Springer-Cnops Construction Implemented in GiNaC,"  This paper presents an implementation of the
Schwerdtfeger-Fillmore-Springer-Cnops construction (SFSCc) along with
illustrations of its usage. SFSCc linearises the linear-fraction action of the
Moebius group in R^n. This has clear advantages in several theoretical and
applied fields including engineering. Our implementation is based on the
Clifford algebra capacities of the GiNaC computer algebra system
(http://www.ginac.de/), which were described in cs.MS/0410044.
  The core of this realisation of SFSCc is done for an arbitrary dimension of
R^n with a metric given by an arbitrary bilinear form. We also present a
subclass for two dimensional cycles (i.e. circles, parabolas and hyperbolas),
which add some 2D specific routines including a visualisation to PostScript
files through the MetaPost (http://www.tug.org/metapost.html) or Asymptote
(http://asymptote.sourceforge.net/) packages.
  This software is the backbone of many results published in math.CV/0512416
and we use its applications their for demonstration. The library can be ported
(with various level of required changes) to other CAS with Clifford algebras
capabilities similar to GiNaC.
  There is an ISO image of a Live Debian DVD attached to this paper as an
auxiliary file, a copy is stored on Google Drive as well.
"
1494,A library of Taylor models for PVS automatic proof checker,"  We present in this paper a library to compute with Taylor models, a technique
extending interval arithmetic to reduce decorrelation and to solve differential
equations. Numerical software usually produces only numerical results. Our
library can be used to produce both results and proofs. As seen during the
development of Fermat's last theorem reported by Aczel 1996, providing a proof
is not sufficient. Our library provides a proof that has been thoroughly
scrutinized by a trustworthy and tireless assistant. PVS is an automatic proof
assistant that has been fairly developed and used and that has no internal
connection with interval arithmetic or Taylor models. We built our library so
that PVS validates each result as it is produced. As producing and validating a
proof, is and will certainly remain a bigger task than just producing a
numerical result our library will never be a replacement to imperative
implementations of Taylor models such as Cosy Infinity. Our library should
mainly be used to validate small to medium size results that are involved in
safety or life critical applications.
"
1495,BioSig - An application of Octave,"  BioSig is an open source software library for biomedical signal processing.
Most users in the field are using Matlab; however, significant effort was
undertaken to provide compatibility to Octave, too. This effort has been widely
successful, only some non-critical components relying on a graphical user
interface are missing. Now, installing BioSig on Octave is as easy as on
Matlab. Moreover, a benchmark test based on BioSig has been developed and the
benchmark results of several platforms are presented.
"
1496,A Basic Introduction on Math-Link in Mathematica,"  Starting from the basic ideas of mathematica, we give a detailed description
about the way of linking of external programs with mathematica through proper
mathlink commands. This article may be quite helpful for the beginners to start
with and write programs in mathematica.
  In the first part, we illustrate how to use a mathemtica notebook and write a
complete program in the notebook. Following with this, we also mention
elaborately about the utility of the local and global variables those are very
essential for writing a program in mathematica. All the commands needed for
doing different mathematical operations can be found with some proper examples
in the mathematica book written by Stephen Wolfram \cite{wolfram}.
  In the rest of this article, we concentrate our study on the most significant
issue which is the process of linking of {\em external programs} with
mathematica, so-called the mathlink operation. By using proper mathlink
commands one can run very tedious jobs efficiently and the operations become
extremely fast.
"
1497,"Evaluation of interval extension of the power function by graph
  decomposition","  The subject of our talk is the correct evaluation of interval extension of
the function specified by the expression x^y without any constraints on the
values of x and y. The core of our approach is a decomposition of the graph of
x^y into a small number of parts which can be transformed into subsets of the
graph of x^y for non-negative bases x. Because of this fact, evaluation of
interval extension of x^y, without any constraints on x and y, is not much
harder than evaluation of interval extension of x^y for non-negative bases x.
"
1498,Sparse Matrix Implementation in Octave,"  There are many classes of mathematical problems which give rise to matrices,
where a large number of the elements are zero. In this case it makes sense to
have a special matrix type to handle this class of problems where only the
non-zero elements of the matrix are stored. Not only does this reduce the
amount of memory to store the matrix, but it also means that operations on this
type of matrix can take advantage of the a-priori knowledge of the positions of
the non-zero elements to accelerate their calculations. A matrix type that
stores only the non-zero elements is generally called sparse.
  Until recently Octave has lacked a full implementation of sparse matrices.
This article address the implementation of sparse matrices within Octave,
including their storage, creation, fundamental algorithms used, their
implementations and the basic operations and functions implemented for sparse
matrices. Mathematical issues such as the return types of sparse operations,
matrix fill-in and reordering for sparse matrix factorization is discussed in
the context of a real example.
  Benchmarking of Octave's implementation of sparse operations compared to
their equivalent in Matlab are given and their implications discussed. Results
are presented for multiplication and linear algebra operations for various
matrix orders and densities. Furthermore, the use of Octave's sparse matrix
implementation is demonstrated using a real example of a finite element model
(FEM) problem. Finally, the method of using sparse matrices with Octave's
oct-files is discussed. The means of creating, using and returning sparse
matrices within oct-files is discussed as well as the differences between
Octave's Sparse and Array classes.
"
1499,UniCalc.LIN: a linear constraint solver for the UniCalc system,"  In this short paper we present a linear constraint solver for the UniCalc
system, an environment for reliable solution of mathematical modeling problems.
"
1500,A Fixed-Point Type for Octave,"  This paper announces the availability of a fixed point toolbox for the Matlab
compatible software package Octave. This toolbox is released under the GNU
Public License, and can be used to model the losses in algorithms implemented
in hardware. Furthermore, this paper presents as an example of the use of this
toolbox, the effects of a fixed point implementation on the precision of an
OFDM modulator.
"
1501,Univariate polynomial real root isolation: Continued Fractions revisited,"  We present algorithmic, complexity and implementation results concerning real
root isolation of integer univariate polynomials using the continued fraction
expansion of real algebraic numbers. One motivation is to explain the method's
good performance in practice. We improve the previously known bound by a factor
of $d \tau$, where $d$ is the polynomial degree and $\tau$ bounds the
coefficient bitsize, thus matching the current record complexity for real root
isolation by exact methods. Namely, the complexity bound is $\sOB(d^4 \tau^2)$
using the standard bound on the expected bitsize of the integers in the
continued fraction expansion. We show how to compute the multiplicities within
the same complexity and extend the algorithm to non square-free polynomials.
Finally, we present an efficient open-source \texttt{C++} implementation in the
algebraic library \synaps, and illustrate its efficiency as compared to other
available software. We use polynomials with coefficient bitsize up to 8000 and
degree up to 1000.
"
1502,How to Run Mathematica Batch-files in Background ?,"  Mathematica is a versatile equipment for doing numeric and symbolic
computations and it has wide spread applications in all branches of science.
Mathematica has a complete consistency to design it at every stage that gives
it multilevel capability and helps advanced usage evolve naturally. Mathematica
functions work for any precision of number and it can be easily computed with
symbols, represented graphically to get the best answer. Mathematica is a
robust software development that can be used in any popular operating systems
and it can be communicated with external programs by using proper mathlink
commands.
  Sometimes it is quite desirable to run jobs in background of a computer which
can take considerable amount of time to finish, and this allows us to do work
on other tasks, while keeping the jobs running. Most of us are very familiar to
run jobs in background for the programs written in the languages like C, C++,
F77, F90, F95, etc. But the way of running jobs, written in a mathematica
notebook, in background is quite different from the conventional method. In
this article, we explore how to create a mathematica batch-file from a
mathematica notebook and run it in background. Here we concentrate our study
only for the Unix version, but one can run mathematica programs in background
for the Windows version as well by using proper mathematica batch-file.
"
1503,"A Monadic, Functional Implementation of Real Numbers","  Large scale real number computation is an essential ingredient in several
modern mathematical proofs. Because such lengthy computations cannot be
verified by hand, some mathematicians want to use software proof assistants to
verify the correctness of these proofs. This paper develops a new
implementation of the constructive real numbers and elementary functions for
such proofs by using the monad properties of the completion operation on metric
spaces. Bishop and Bridges's notion of regular sequences is generalized to,
what I call, regular functions which form the completion of any metric space.
Using the monad operations, continuous functions on length spaces (a common
subclass of metric spaces) are created by lifting continuous functions on the
original space. A prototype Haskell implementation has been created. I believe
that this approach yields a real number library that is reasonably efficient
for computation, and still simple enough to easily verify its correctness.
"
1504,Caract\'{e}ristiques arithm\'{e}tiques des processeurs graphiques,"  Les unit\'{e}s graphiques (Graphic Processing Units- GPU) sont d\'{e}sormais
des processeurs puissants et flexibles. Les derni\`{e}res g\'{e}n\'{e}rations
de GPU contiennent des unit\'{e}s programmables de traitement des sommets
(vertex shader) et des pixels (pixel shader) supportant des op\'{e}rations en
virgule flottante sur 8, 16 ou 32 bits. La repr\'{e}sentation flottante sur 32
bits correspond \`{a} la simple pr\'{e}cision de la norme IEEE sur
l'arithm\'{e}tique en virgule flottante (IEEE-754). Les GPU sont bien
adapt\'{e}s aux applications avec un fort parall\'{e}lisme de donn\'{e}es.
Cependant ils ne sont que peu utilis\'{e}s en dehors des calculs graphiques
(General Purpose computation on GPU -- GPGPU). Une des raisons de cet \'{e}tat
de faits est la pauvret\'{e} des documentations techniques fournies par les
fabricants (ATI et Nvidia), particuli\`{e}rement en ce qui concerne
l'implantation des diff\'{e}rents op\'{e}rateurs arithm\'{e}tiques
embarqu\'{e}s dans les diff\'{e}rentes unit\'{e}s de traitement. Or ces
informations sont essentielles pour estimer et contr\^{o}ler les erreurs
d'arrondi ou pour mettre en oeuvre des techniques de r\'{e}duction ou de
compensation afin de travailler en pr\'{e}cision double, quadruple ou
arbitrairement \'{e}tendue. Nous proposons dans cet article un ensemble de
programmes qui permettent de d\'{e}couvrir les caract\'{e}ristiques principales
des GPU en ce qui concerne l'arithm\'{e}tique \`{a} virgule flottante. Nous
donnons les r\'{e}sultats obtenus sur deux cartes graphiques r\'{e}centes: la
Nvidia 7800GTX et l'ATI RX1800XL.
"
1505,Mathematica: A System of Computer Programs,"  Starting from the basic level of mathematica here we illustrate how to use a
mathematica notebook and write a program in the notebook. Next, we investigate
elaborately the way of linking of external programs with mathematica, so-called
the mathlink operation. Using this technique we can run very tedious jobs quite
efficiently, and the operations become extremely fast. Sometimes it is quite
desirable to run jobs in background of a computer which can take considerable
amount of time to finish, and this allows us to do work on other tasks, while
keeping the jobs running. The way of running jobs, written in a mathematica
notebook, in background is quite different from the conventional methods i.e.,
the techniques for the programs written in other languages like C, C++, F77,
F90, F95, etc. To illustrate it, in the present article we study how to create
a mathematica batch-file from a mathematica notebook and run it in the
background. Finally, we explore the most significant issue of this article.
Here we describe the basic ideas for parallelizing a mathematica program by
sharing its independent parts into all other remote computers available in the
network. Doing the parallelization, we can perform large computational
operations within a very short period of time, and therefore, the efficiency of
the numerical works can be achieved. Parallel computation supports any version
of mathematica and it also works significantly well even if different versions
of mathematica are installed in different computers. All the operations studied
in this article run under any supported operating system like Unix, Windows,
Macintosh, etc. For the sake of our illustrations, here we concentrate all the
discussions only for the Unix based operating system.
"
1506,"Parallel Evaluation of Mathematica Programs in Remote Computers
  Available in Network","  Mathematica is a powerful application package for doing mathematics and is
used almost in all branches of science. It has widespread applications ranging
from quantum computation, statistical analysis, number theory, zoology,
astronomy, and many more. Mathematica gives a rich set of programming
extensions to its end-user language, and it permits us to write programs in
procedural, functional, or logic (rule-based) style, or a mixture of all three.
For tasks requiring interfaces to the external environment, mathematica
provides mathlink, which allows us to communicate mathematica programs with
external programs written in C, C++, F77, F90, F95, Java, or other languages.
It has also extensive capabilities for editing graphics, equations, text, etc.
  In this article, we explore the basic mechanisms of parallelization of a
mathematica program by sharing different parts of the program into all other
computers available in the network. Doing the parallelization, we can perform
large computational operations within a very short period of time, and
therefore, the efficiency of the numerical works can be achieved. Parallel
computation supports any version of mathematica and it also works as well even
if different versions of mathematica are installed in different computers. The
whole operation can run under any supported operating system like Unix,
Windows, Macintosh, etc. Here we focus our study only for the Unix based
operating system, but this method works as well for all other cases.
"
1507,"Stochastic Formal Methods: An application to accuracy of numeric
  software","  This paper provides a bound on the number of numeric operations (fixed or
floating point) that can safely be performed before accuracy is lost. This work
has important implications for control systems with safety-critical software,
as these systems are now running fast enough and long enough for their errors
to impact on their functionality. Furthermore, worst-case analysis would
blindly advise the replacement of existing systems that have been successfully
running for years. We present here a set of formal theorems validated by the
PVS proof assistant. These theorems will allow code analyzing tools to produce
formal certificates of accurate behavior. For example, FAA regulations for
aircraft require that the probability of an error be below $10^{-9}$ for a 10
hour flight.
"
1508,Ideas by Statistical Mechanics (ISM),"  Ideas by Statistical Mechanics (ISM) is a generic program to model evolution
and propagation of ideas/patterns throughout populations subjected to
endogenous and exogenous interactions. The program is based on the author's
work in Statistical Mechanics of Neocortical Interactions (SMNI), and uses the
author's Adaptive Simulated Annealing (ASA) code for optimizations of training
sets, as well as for importance-sampling to apply the author's copula financial
risk-management codes, Trading in Risk Dimensions (TRD), for assessments of
risk and uncertainty. This product can be used for decision support for
projects ranging from diplomatic, information, military, and economic (DIME)
factors of propagation/evolution of ideas, to commercial sales, trading
indicators across sectors of financial markets, advertising and political
campaigns, etc. A statistical mechanical model of neocortical interactions,
developed by the author and tested successfully in describing short-term memory
and EEG indicators, is the proposed model. Parameters with a given subset of
macrocolumns will be fit using ASA to patterns representing ideas. Parameters
of external and inter-regional interactions will be determined that promote or
inhibit the spread of these ideas. Tools of financial risk management,
developed by the author to process correlated multivariate systems with
differing non-Gaussian distributions using modern copula analysis,
importance-sampled using ASA, will enable bona fide correlations and
uncertainties of success and failure to be calculated. Marginal distributions
will be evolved to determine their expected duration and stability using
algorithms developed by the author, i.e., PATHTREE and PATHINT codes.
"
1509,On a solution to display non-filled-in quaternionic Julia sets,"  During early 1980s, the so-called `escape time' method, developed to display
the Julia sets for complex dynamical systems, was exported to quaternions in
order to draw analogous pictures in this wider numerical field. Despite of the
fine results in the complex plane, where all topological configurations of
Julia sets have been successfully displayed, the `escape time' method fails to
render properly the non-filled-in variety of quaternionic Julia sets. So their
digital visualisation remained an open problem for several years. Both the
solution for extending this old method to non-filled-in quaternionic Julia sets
and its implementation into a program are explained here.
"
1510,Classifying extrema using intervals,"  We present a straightforward and verified method of deciding whether the
n-dimensional point x (n>=1), such that \nabla f(x)=0, is the local minimizer,
maximizer or just a saddle point of a real-valued function f.
  The method scales linearly with dimensionality of the problem and never
produces false results.
"
1511,"One approach to the digital visualization of hedgehogs in holomorphic
  dynamics","  In the field of holomorphic dynamics in one complex variable, hedgehog is the
local invariant set arising about a Cremer point and endowed with a very
complicate shape as well as relating to very weak numerical conditions. We give
a solution to the open problem of its digital visualization, featuring either a
time saving approach and a far-reaching insight.
"
1512,Stochastic Formal Methods for Hybrid Systems,"  We provide a framework to bound the probability that accumulated errors were
never above a given threshold on hybrid systems. Such systems are used for
example to model an aircraft or a nuclear power plant on one side and its
software on the other side. This report contains simple formulas based on
L\'evy's and Markov's inequalities and it presents a formal theory of random
variables with a special focus on producing concrete results. We selected four
very common applications that fit in our framework and cover the common
practices of hybrid systems that evolve for a long time. We compute the number
of bits that remain continuously significant in the first two applications with
a probability of failure around one against a billion, where worst case
analysis considers that no significant bit remains. We are using PVS as such
formal tools force explicit statement of all hypotheses and prevent incorrect
uses of theorems.
"
1513,Classdesc and Graphcode: support for scientific programming in C++,"  Object-oriented programming languages such as Java and Objective C have
become popular for implementing agent-based and other object-based simulations
since objects in those languages can {\em reflect} (i.e. make runtime queries
of an object's structure). This allows, for example, a fairly trivial {\em
serialisation} routine (conversion of an object into a binary representation
that can be stored or passed over a network) to be written. However C++ does
not offer this ability, as type information is thrown away at compile time. Yet
C++ is often a preferred development environment, whether for performance
reasons or for its expressive features such as operator overloading.
  In scientific coding, changes to a model's codes takes place constantly, as
the model is refined, and different phenomena are studied. Yet traditionally,
facilities such as checkpointing, routines for initialising model parameters
and analysis of model output depend on the underlying model remaining static,
otherwise each time a model is modified, a whole slew of supporting routines
needs to be changed to reflect the new data structures. Reflection offers the
advantage of the simulation framework adapting to the underlying model without
programmer intervention, reducing the effort of modifying the model.
  In this paper, we present the {\em Classdesc} system which brings many of the
benefits of object reflection to C++, {\em ClassdescMP} which dramatically
simplifies coding of MPI based parallel programs and {\em
  Graphcode} a general purpose data parallel programming environment.
"
1514,Faithful Polynomial Evaluation with Compensated Horner Algorithm,"  This paper presents two sufficient conditions to ensure a faithful evaluation
of polynomial in IEEE-754 floating point arithmetic. Faithfulness means that
the computed value is one of the two floating point neighbours of the exact
result; it can be satisfied using a more accurate algorithm than the classic
Horner scheme. One condition here provided is an apriori bound of the
polynomial condition number derived from the error analysis of the compensated
Horner algorithm. The second condition is both dynamic and validated to check
at the running time the faithfulness of a given evaluation. Numerical
experiments illustrate the behavior of these two conditions and that associated
running time over-cost is really interesting.
"
1515,Coupling Methodology within the Software Platform Alliances,"  CEA, ANDRA and EDF are jointly developing the software platform ALLIANCES
which aim is to produce a tool for the simulation of nuclear waste storage and
disposal repository. This type of simulations deals with highly coupled
thermo-hydro-mechanical and chemical (T-H-M-C) processes. A key objective of
Alliances is to give the capability for coupling algorithms development between
existing codes. The aim of this paper is to present coupling methodology use in
the context of this software platform.
"
1516,Revisiting Matrix Product on Master-Worker Platforms,"  This paper is aimed at designing efficient parallel matrix-product algorithms
for heterogeneous master-worker platforms. While matrix-product is
well-understood for homogeneous 2D-arrays of processors (e.g., Cannon algorithm
and ScaLAPACK outer product algorithm), there are three key hypotheses that
render our work original and innovative:
  - Centralized data. We assume that all matrix files originate from, and must
be returned to, the master.
  - Heterogeneous star-shaped platforms. We target fully heterogeneous
platforms, where computational resources have different computing powers.
  - Limited memory. Because we investigate the parallelization of large
problems, we cannot assume that full matrix panels can be stored in the worker
memories and re-used for subsequent updates (as in ScaLAPACK).
  We have devised efficient algorithms for resource selection (deciding which
workers to enroll) and communication ordering (both for input and result
messages), and we report a set of numerical experiments on various platforms at
Ecole Normale Superieure de Lyon and the University of Tennessee. However, we
point out that in this first version of the report, experiments are limited to
homogeneous platforms.
"
1517,"The Parma Polyhedra Library: Toward a Complete Set of Numerical
  Abstractions for the Analysis and Verification of Hardware and Software
  Systems","  Since its inception as a student project in 2001, initially just for the
handling (as the name implies) of convex polyhedra, the Parma Polyhedra Library
has been continuously improved and extended by joining scrupulous research on
the theoretical foundations of (possibly non-convex) numerical abstractions to
a total adherence to the best available practices in software development. Even
though it is still not fully mature and functionally complete, the Parma
Polyhedra Library already offers a combination of functionality, reliability,
usability and performance that is not matched by similar, freely available
libraries. In this paper, we present the main features of the current version
of the library, emphasizing those that distinguish it from other similar
libraries and those that are important for applications in the field of
analysis and verification of hardware and software systems.
"
1518,The virtual reality framework for engineering objects,"  A framework for virtual reality of engineering objects has been developed.
This framework may simulate different equipment related to virtual reality.
Framework supports 6D dynamics, ordinary differential equations, finite
formulas, vector and matrix operations. The framework also supports embedding
of external software.
"
1519,"Applications of Polyhedral Computations to the Analysis and Verification
  of Hardware and Software Systems","  Convex polyhedra are the basis for several abstractions used in static
analysis and computer-aided verification of complex and sometimes mission
critical systems. For such applications, the identification of an appropriate
complexity-precision trade-off is a particularly acute problem, so that the
availability of a wide spectrum of alternative solutions is mandatory. We
survey the range of applications of polyhedral computations in this area; give
an overview of the different classes of polyhedra that may be adopted; outline
the main polyhedral operations required by automatic analyzers and verifiers;
and look at some possible combinations of polyhedra with other numerical
abstractions that have the potential to improve the precision of the analysis.
Areas where further theoretical investigations can result in important
contributions are highlighted.
"
1520,Certification of bounds on expressions involving rounded operators,"  Gappa uses interval arithmetic to certify bounds on mathematical expressions
that involve rounded as well as exact operators. Gappa generates a theorem with
its proof for each bound treated. The proof can be checked with a higher order
logic automatic proof checker, either Coq or HOL Light, and we have developed a
large companion library of verified facts for Coq dealing with the addition,
multiplication, division, and square root, in fixed- and floating-point
arithmetics. Gappa uses multiple-precision dyadic fractions for the endpoints
of intervals and performs forward error analysis on rounded operators when
necessary. When asked, Gappa reports the best bounds it is able to reach for a
given expression in a given context. This feature is used to quickly obtain
coarse bounds. It can also be used to identify where the set of facts and
automatic techniques implemented in Gappa becomes insufficient. Gappa handles
seamlessly additional properties expressed as interval properties or rewriting
rules in order to establish more intricate bounds. Recent work showed that
Gappa is perfectly suited to the proof of correctness of small pieces of
software. Proof obligations can be written by designers, produced by
third-party tools or obtained by overloading arithmetic operators.
"
1521,A canonical form for some piecewise defined functions,"  We define a canonical form for piecewise defined functions. We show that this
has a wider range of application as well as better complexity properties than
previous work.
"
1522,"LIBOPT - An environment for testing solvers on heterogeneous collections
  of problems - Version 1.0","  The Libopt environment is both a methodology and a set of tools that can be
used for testing, comparing, and profiling solvers on problems belonging to
various collections. These collections can be heterogeneous in the sense that
their problems can have common features that differ from one collection to the
other. Libopt brings a unified view on this composite world by offering, for
example, the possibility to run any solver on any problem compatible with it,
using the same Unix/Linux command. The environment also provides tools for
comparing the results obtained by solvers on a specified set of problems. Most
of the scripts going with the Libopt environment have been written in Perl.
"
1523,Why the Standard Data Processing should be changed,"  The basic statistical methods of data representation did not change since
their emergence. Their simplicity was dictated by the intricacies of
computations in the before computers epoch. It turns out that such approach is
not uniquely possible in the presence of quick computers. The suggested here
method improves significantly the reliability of data processing and their
graphical representation. In this paper we show problems of the standard data
processing which can bring to incorrect results. A method solving these
problems is proposed. It is based on modification of data representation. The
method was implemented in a computer program Consensus5. The program
performances are illustrated through varied examples.
"
1524,"Type-II/III DCT/DST algorithms with reduced number of arithmetic
  operations","  We present algorithms for the discrete cosine transform (DCT) and discrete
sine transform (DST), of types II and III, that achieve a lower count of real
multiplications and additions than previously published algorithms, without
sacrificing numerical accuracy. Asymptotically, the operation count is reduced
from ~ 2N log_2 N to ~ (17/9) N log_2 N for a power-of-two transform size N.
Furthermore, we show that a further N multiplications may be saved by a certain
rescaling of the inputs or outputs, generalizing a well-known technique for N=8
by Arai et al. These results are derived by considering the DCT to be a special
case of a DFT of length 4N, with certain symmetries, and then pruning redundant
operations from a recent improved fast Fourier transform algorithm (based on a
recursive rescaling of the conjugate-pair split radix algorithm). The improved
algorithms for DCT-III, DST-II, and DST-III follow immediately from the
improved count for the DCT-II.
"
1525,Developing numerical libraries in Java,"  The rapid and widespread adoption of Java has created a demand for reliable
and reusable mathematical software components to support the growing number of
compute-intensive applications now under development, particularly in science
and engineering. In this paper we address practical issues of the Java language
and environment which have an effect on numerical library design and
development. Benchmarks which illustrate the current levels of performance of
key numerical kernels on a variety of Java platforms are presented. Finally, a
strategy for the development of a fundamental numerical toolkit for Java is
proposed and its current status is described.
"
1526,Hyper-Systolic Matrix Multiplication,"  A novel parallel algorithm for matrix multiplication is presented. The
hyper-systolic algorithm makes use of a one-dimensional processor abstraction.
The procedure can be implemented on all types of parallel systems. It can
handle matrix-vector multiplications as well as transposed matrix products.
"
1527,"Fast Computational Algorithms for the Discrete Wavelet Transform and
  Applications of Localized Orthonormal Bases in Signal Classification","  We construct an algorithm for implementing the discrete wavelet transform by
means of matrices in SO_2(R) for orthonormal compactly supported wavelets and
matrices in SL_m(R), m > = 2, for compactly supported biorthogonal wavelets. We
show that in 1 dimension the total operation count using this algorithm can be
reduced to about 50% of the conventional convolution and downsampling by
2-operation for both orthonormal and biorthogonal filters. In the special case
of biorthogonal symmetric odd-odd filters, we show an implementation yielding a
total operation count of about 38% of the conventional method. In 2 dimensions
we show an implementation of this algorithm yielding a reduction in the total
operation count of about 70% when the filters are orthonormal, a reduction of
about 62% for general biorthogonal filters, and a reduction of about 70% if the
filters are symmetric odd-odd length filters. We further extend these results
to 3 dimensions. We also show how the SO_2(R)-method for implementing the
discrete wavelet transform may be exploited to compute short FIR filters, and
we construct edge mappings where we try to improve upon the degree of
preservation of regularity in the conventional methods. We also consider a
two-class waveform discrimination problem. A statistical space-frequency
analysis is performed on a training data set using the LDB-algorithm of N.Saito
and R.Coifman. The success of the algorithm on this particular problem is
evaluated on a disjoint test data set.
"
1528,"An Algebraic Programming Style for Numerical Software and its
  Optimization","  The abstract mathematical theory of partial differential equations (PDEs) is
formulated in terms of manifolds, scalar fields, tensors, and the like, but
these algebraic structures are hardly recognizable in actual PDE solvers. The
general aim of the Sophus programming style is to bridge the gap between theory
and practice in the domain of PDE solvers. Its main ingredients are a library
of abstract datatypes corresponding to the algebraic structures used in the
mathematical theory and an algebraic expression style similar to the expression
style used in the mathematical theory. Because of its emphasis on abstract
datatypes, Sophus is most naturally combined with object-oriented languages or
other languages supporting abstract datatypes. The resulting source code
patterns are beyond the scope of current compiler optimizations, but are
sufficiently specific for a dedicated source-to-source optimizer. The limited,
domain-specific, character of Sophus is the key to success here. This kind of
optimization has been tested on computationally intensive Sophus style code
with promising results. The general approach may be useful for other styles and
in other application domains as well.
"
1529,"Seeing the Forest in the Tree: Applying VRML to Mathematical Problems in
  Number Theory","  We show how VRML (Virtual Reality Modeling Language) can provide potentially
powerful insight into the 3x + 1 problem via the introduction of a unique
geometrical object, called the 'G-cell', akin to a fractal generator. We
present an example of a VRML world developed programmatically with the G-cell.
The role of VRML as a tool for furthering the understanding the 3x+1 problem is
potentially significant for several reasons: a) VRML permits the observer to
zoom into the geometric structure at all scales (up to limitations of the
computing platform). b) VRML enables rotation to alter comparative visual
perspective (similar to Tukey's data-spinning concept). c) VRML facilitates the
demonstration of interesting tree features between collaborators on the
internet who might otherwise have difficulty conveying their ideas
unambiguously. d) VRML promises to reveal any dimensional dependencies among
3x+1 sequences.
"
1530,"Matrix Distributed Processing: A set of C++ Tools for implementing
  generic lattice computations on parallel systems","  We present a set of programming tools (classes and functions written in C++
and based on Message Passing Interface) for fast development of generic
parallel (and non-parallel) lattice simulations. They are collectively called
MDP 1.2.
  These programming tools include classes and algorithms for matrices, random
number generators, distributed lattices (with arbitrary topology), fields and
parallel iterations. No previous knowledge of MPI is required in order to use
them.
  Some applications in electromagnetism, electronics, condensed matter and
lattice QCD are presented.
"
1531,"LSJK - a C++ library for arbitrary-precision numeric evaluation of the
  generalized log-sine functions","  Generalized log-sine functions appear in higher order epsilon-expansion of
different Feynman diagrams. We present an algorithm for numerical evaluation of
these functions of real argument. This algorithm is implemented as C++ library
with arbitrary-precision arithmetics for integer 0 < k < 9 and j > 1. Some new
relations and representations for the generalized log-sine functions are given.
"
1532,"Introducing LambdaTensor1.0 - A package for explicit symbolic and
  numeric Lie algebra and Lie group calculations","  Due to the occurrence of large exceptional Lie groups in supergravity,
calculations involving explicit Lie algebra and Lie group element manipulations
easily become very complicated and hence also error-prone if done by hand.
Research on the extremal structure of maximal gauged supergravity theories in
various dimensions sparked the development of a library for efficient abstract
multilinear algebra calculations involving sparse and non-sparse higher-rank
tensors, which is presented here.
"
1533,"Lanczos $\tau$-method optimal algorithm in APS for approximating the
  mathematical functions","  A new procedure is constructed by means of APS in APLAN language. The
procedure solves the initial-value problem for linear differential equations of
order $k$ with polynomial coefficients and regular singularity in the
initialization point in the interval $[a, b]$ and computes the algebraic
polynomial $y_n$ of given order $n$. A new algorithm of Lanczos $\tau$-method
is built for this procedure, the solution existence $y_n$ of the initial-value
problem proved on this algorithm and also is proved the optimality by precision
of order $k$ derivative of the initial-value problem solution.
"
1534,One method for proving inequalities by computer,"  In this article we consider a method for proving a class of analytical
inequalities via minimax rational approximations. All numerical calculations in
this paper are given by Maple computer program.
"
1535,Some notes on a method for proving inequalities by computer,"  In this article we consider mathematical fundamentals of one method for
proving inequalities by computer, based on the Remez algorithm. Using the
well-known results of undecidability of the existence of zeros of real
elementary functions, we demonstrate that the considered method generally in
practice becomes one heuristic for the verification of inequalities. We give
some improvements of the inequalities considered in the theorems for which the
existing proofs have been based on the numerical verifications of Remez
algorithm.
"
1536,"An Implementation of the Bestvina-Handel Algorithm for Surface
  Homeomorphisms","  Bestvina and Handel have found an effective algorithm that determines whether
a given homeomorphism of an orientable, possibly punctured surface is
pseudo-Anosov. We present a software package in Java that realizes this
algorithm for surfaces with one puncture. Moreover, the package allows the user
to define homeomorphisms in terms of Dehn twists, and in the pseudo-Anosov case
it generates images of train tracks in the sense of Bestvina-Handel.
"
1537,"Construction of Single-valued Solutions for Nonintegrable Systems with
  the Help of the Painleve Test","  The Painleve test is very useful to construct not only the Laurent-series
solutions but also the elliptic and trigonometric ones. Such single-valued
functions are solutions of some polynomial first order differential equations.
To find the elliptic solutions we transform an initial nonlinear differential
equation in a nonlinear algebraic system in parameters of the Laurent-series
solutions of the initial equation. The number of unknowns in the obtained
nonlinear system does not depend on number of arbitrary coefficients of the
used first order equation. In this paper we describe the corresponding
algorithm, which has been realized in REDUCE and Maple.
"
